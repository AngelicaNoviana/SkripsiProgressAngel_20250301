Title,Summary,Published,Link,Authors
Concentration of ergotropy in many-body systems,"Ergotropy -- the maximal amount of unitarily extractable work -- measures the
``charge level'' of quantum batteries. We prove that in large many-body
batteries ergotropy exhibits a concentration of measure phenomenon. Namely, the
ergotropy of such systems is almost constant for almost all states sampled from
the Hilbert--Schmidt measure. We establish this by first proving that
ergotropy, as a function of the state, is Lipschitz-continuous with respect to
the Bures distance, and then applying Levy's measure concentration lemma. In
parallel, we showcase the analogous properties of von Neumann entropy,
compiling and adapting known results about its continuity and concentration
properties. Furthermore, we consider the situation with the least amount of
prior information about the state. This corresponds to the quantum version of
the Jeffreys prior distribution -- the Bures measure. In this case, there exist
no analytical bounds guaranteeing exponential concentration of measure.
Nonetheless, we provide numerical evidence that ergotropy, as well as von
Neumann entropy, concentrate also in this case.",2024-12-27T18:58:43Z,http://arxiv.org/abs/2412.19801v1,"Karen V. Hovhannisyan, Rick P. A. Simon, Janet Anders"
InfAlign: Inference-aware language model alignment,"Language model alignment has become a critical step in training modern
generative language models. The goal of alignment is to finetune a reference
model such that the win rate of a sample from the aligned model over a sample
from the reference model is high, subject to a KL divergence constraint. Today,
we are increasingly using inference-time algorithms (e.g., Best-of-N,
controlled decoding, tree search) to decode from language models rather than
standard sampling. However, the alignment objective does not capture such
inference-time decoding procedures. We show that the existing alignment
framework is sub-optimal in view of such inference-time methods. We then modify
the alignment objective and propose a framework for inference-aware alignment
(IAPO). We prove that for any inference-time decoding algorithm, the optimal
solution that optimizes the inference-time win rate of the aligned policy
against the reference policy is the solution to the typical RLHF problem with a
transformation of the reward. This motivates us to provide the KL-regularized
calibrate-and-transform RL (CTRL) algorithm to solve this problem, which
involves a reward calibration step and a KL-regularized reward maximization
step with a transformation of the calibrated reward. We particularize our study
to two important inference-time strategies: best-of-N sampling and best-of-N
jailbreaking, where N responses are sampled from the model and the one with the
highest or lowest reward is selected. We propose specific transformations for
these strategies and demonstrate that our framework offers significant
improvements over existing state-of-the-art methods for language model
alignment. Empirically, we outperform baselines that are designed without
taking inference-time decoding into consideration by 8-12% and 4-9% on
inference-time win rates over the Anthropic helpfulness and harmlessness dialog
benchmark datasets.",2024-12-27T18:45:36Z,http://arxiv.org/abs/2412.19792v1,"Ananth Balashankar, Ziteng Sun, Jonathan Berant, Jacob Eisenstein, Michael Collins, Adrian Hutter, Jong Lee, Chirag Nagpal, Flavien Prost, Aradhana Sinha, and Ananda Theertha Suresh, Ahmad Beirami"
Composite operators in $\mathcal{N}=4$ Super Yang-Mills,"We consider four-point functions of protected, double- and single-trace
operators in the large central charge limit. We use superconformal symmetry to
disentangle the contribution of protected operators in the partial wave
decomposition. With this information, we fix the non protected part of such
correlators up to subleading order in the large central charge expansion. We
particularly focus on the triple-trace sector of the correlator and comment on
the connection to the holographic description of these correlators.",2024-12-27T18:40:23Z,http://arxiv.org/abs/2412.19788v1,"Agnese Bissi, Giulia Fardelli, Andrea Manenti"
"Enhancing Whisper's Accuracy and Speed for Indian Languages through
  Prompt-Tuning and Tokenization","Automatic speech recognition has recently seen a significant advancement with
large foundational models such as Whisper. However, these models often struggle
to perform well in low-resource languages, such as Indian languages. This paper
explores two novel approaches to enhance Whisper's multilingual speech
recognition performance in Indian languages. First, we propose prompt-tuning
with language family information, which enhances Whisper's accuracy in
linguistically similar languages. Second, we introduce a novel tokenizer that
reduces the number of generated tokens, thereby accelerating Whisper's
inference speed. Our extensive experiments demonstrate that the tokenizer
significantly reduces inference time, while prompt-tuning enhances accuracy
across various Whisper model sizes, including Small, Medium, and Large.
Together, these techniques achieve a balance between optimal WER and inference
speed.",2024-12-27T18:32:24Z,http://arxiv.org/abs/2412.19785v1,"Kumud Tripathi, Raj Gothi, Pankaj Wasnik"
"Analysis of Premature Death Rates in Texas Counties: The Impact of Air
  Quality, Socioeconomic Factors, and COPD Prevalence","Understanding factors contributing to premature mortality is critical for
public health planning. This study examines the relationships between premature
death rates and multiple risk factors across several Texas counties, utilizing
EPA air quality data, Census information, and county health records from recent
years. We analyze the impact of air quality (PM2.5 levels), socioeconomic
factors (median household income), and health conditions (COPD prevalence)
through statistical analysis and modeling techniques. Results reveal COPD
prevalence as a strong predictor of premature death rates, with higher
prevalence associated with a substantial increase in years of potential life
lost. While socioeconomic factors show a significant negative correlation, air
quality demonstrates more complex indirect relationships. These findings
emphasize the need for integrated public health interventions that prioritize
key health conditions while addressing underlying socioeconomic disparities.",2024-12-27T18:12:04Z,http://arxiv.org/abs/2412.19774v1,"Richard Rich, Ernesto Diaz"
"On Universally Free First-Order Extensions of Belnap-Dunn's Four-Valued
  Logic and Nelson's Paraconsistent Logic N4","The aim of this paper is to introduce the logics FFDE and FN4, which are
universally free versions of Belnap-Dunn's four-valued logic, also known as the
logic of first-degree entailment (FDE), and Nelson's paraconsistent logic QN4
(N-). Both FDE and QN4 are suitable to be interpreted as information-based
logics, that is, logics that are capable of representing the deductive behavior
of possibly inconsistent and incomplete information in a database. Like QN4 and
some non-free first-order extensions of FDE, FFDE and FN4 are endowed with
Kripke-style variable domain semantics, which allows representing the dynamic
aspect of information processing, that is, how a database receives new
information over time, including information about new individuals. We argue,
however, that FFDE and FN4 can better represent the development of inconsistent
and incomplete information states (i.e., configurations of a database) over
time than their non-free versions. First, because they allow for empty domains,
which corresponds to the idea that a database may acknowledge no individual at
all at an early stage of its development. Second, because they allow for empty
names, which get interpreted as information about new individuals is inserted
into the database. Also, both systems include an identity predicate that is
interpreted along the same lines of the other logical operators, viz., in terms
of independent positive and negative rules.",2024-12-27T17:57:18Z,http://arxiv.org/abs/2412.19767v1,"Henrique Antunes, Abilio Rodrigues"
"UAV-Enabled Secure ISAC Against Dual Eavesdropping Threats: Joint
  Beamforming and Trajectory Design","In this work, we study an unmanned aerial vehicle (UAV)-enabled secure
integrated sensing and communication (ISAC) system, where a UAV serves as an
aerial base station (BS) to simultaneously perform communication with a user
and detect a target on the ground, while a dual-functional eavesdropper
attempts to intercept the signals for both sensing and communication. Facing
the dual eavesdropping threats, we aim to enhance the average achievable
secrecy rate for the communication user by jointly designing the UAV trajectory
together with the transmit information and sensing beamforming, while
satisfying the requirements on sensing performance and sensing security, as
well as the UAV power and flight constraints. To address the non-convex nature
of the optimization problem, we employ the alternating optimization (AO)
strategy, jointly with the successive convex approximation (SCA) and
semidefinite relaxation (SDR) methods. Numerical results validate the proposed
approach, demonstrating its ability to achieve a high secrecy rate while
meeting the required sensing and security constraints.",2024-12-27T17:15:20Z,http://arxiv.org/abs/2412.19748v1,"Jianping Yao, Zeyu Yang, Zai Yang, Jie Xu, Tony Q. S. Quek"
"A General Framework of Brain Region Detection And Genetic Variants
  Selection in Imaging Genetics","Imaging genetics is a growing field that employs structural or functional
neuroimaging techniques to study individuals with genetic risk variants
potentially linked to specific illnesses. This area presents considerable
challenges to statisticians due to the heterogeneous information and different
data forms it involves. In addition, both imaging and genetic data are
typically high-dimensional, creating a ""big data squared"" problem. Moreover,
brain imaging data contains extensive spatial information. Simply vectorizing
tensor images and treating voxels as independent features can lead to
computational issues and disregard spatial structure. This paper presents a
novel statistical method for imaging genetics modeling while addressing all
these challenges. We explore a Canonical Correlation Analysis based linear
model for the joint modeling of brain imaging, genetic information, and
clinical phenotype, enabling the simultaneous detection of significant brain
regions and selection of important genetic variants associated with the
phenotype outcome. Scalable algorithms are developed to tackle the ""big data
squared"" issue. We apply the proposed method to explore the reaction speed, an
indicator of cognitive functions, and its associations with brain MRI and
genetic factors using the UK Biobank database. Our study reveals a notable
connection between the caudate nucleus region of brain and specific significant
SNPs, along with their respective regulated genes, and the reaction speed.",2024-12-27T16:54:11Z,http://arxiv.org/abs/2412.19735v1,"Siqiang Su, Zhenghao Li, Long Feng, Ting Li"
"Fully-relativistic evolution of vacuum tensor inhomogeneities during
  inflation","We present a complete method for the initialisation and extraction of
first-order inflationary tensor perturbations for fully relativistic
simulations which incorporate gravitational back-reaction. We outline a
correspondence between the Cosmological Perturbation Theory (CPT) framework and
the numerical relativity BSSN variables in the appropriate limit. We describe a
generation method for stochastic tensoral initial conditions, inspired by the
standard scalar initial condition used from inflation and implemented in
lattice cosmology. We discuss the implementation of this procedure in the
GRChombo/GRTeclyn code, and demonstrate the detailed quantitative
correspondence between the linearised and fully-nonlinear solutions in the
perturbative limit, through the evolution of the background and the tensor
power spectrum. We also validate the methodology by showing that energy and
momentum constraints are introduced and preserved to second-order or better. We
provide some preliminary indicative results probing tensoral non-Gaussianity
using the skewness and kurtosis. The computational pipeline presented here will
be used to study the emergence of a primordial tensor bispectra and
cross-spectra that incorporate the effect of nonlinear gravitational couplings
with the metric, which has potential applications for the analysis of
next-generation CMB surveys.",2024-12-27T16:42:59Z,http://arxiv.org/abs/2412.19731v1,"Ericka Florio, E. Paul S. Shellard"
"Learning to Forget: Bayesian Time Series Forecasting using Recurrent
  Sparse Spectrum Signature Gaussian Processes","The signature kernel is a kernel between time series of arbitrary length and
comes with strong theoretical guarantees from stochastic analysis. It has found
applications in machine learning such as covariance functions for Gaussian
processes. A strength of the underlying signature features is that they provide
a structured global description of a time series. However, this property can
quickly become a curse when local information is essential and forgetting is
required; so far this has only been addressed with ad-hoc methods such as
slicing the time series into subsegments. To overcome this, we propose a
principled, data-driven approach by introducing a novel forgetting mechanism
for signatures. This allows the model to dynamically adapt its context length
to focus on more recent information. To achieve this, we revisit the recently
introduced Random Fourier Signature Features, and develop Random Fourier
Decayed Signature Features (RFDSF) with Gaussian processes (GPs). This results
in a Bayesian time series forecasting algorithm with variational inference,
that offers a scalable probabilistic algorithm that processes and transforms a
time series into a joint predictive distribution over time steps in one pass
using recurrence. For example, processing a sequence of length $10^4$ steps in
$\approx 10^{-2}$ seconds and in $&lt; 1\text{GB}$ of GPU memory. We demonstrate
that it outperforms other GP-based alternatives and competes with
state-of-the-art probabilistic time series forecasting algorithms.",2024-12-27T16:31:09Z,http://arxiv.org/abs/2412.19727v1,"Csaba Tóth, Masaki Adachi, Michael A. Osborne, Harald Oberhauser"
"Text2Insight: Transform natural language text into insights seamlessly
  using multi-model architecture","The growing demand for dynamic, user-centric data analysis and visualization
is evident across domains like healthcare, finance, and research. Traditional
visualization tools often fail to meet individual user needs due to their
static and predefined nature. To address this gap, Text2Insight is introduced
as an innovative solution that delivers customized data analysis and
visualizations based on user-defined natural language requirements. Leveraging
a multi-model architecture, Text2Insight transforms user inputs into actionable
insights and dynamic visualizations.
  The methodology begins with analyzing the input dataset to extract structural
details such as columns and values. A pre-trained Llama3 model converts the
user's natural language query into an SQL query, which is further refined using
a Named Entity Recognition (NER) model for accuracy. A chart predictor
determines the most suitable visualization type, while the Llama3 model
generates insights based on the SQL query's results. The output is a
user-friendly and visually informative chart. To enhance analysis capabilities,
the system integrates a question-answering model and a predictive model using
the BERT framework. These models provide insights into historical data and
predict future trends.
  Performance evaluation of Text2Insight demonstrates its effectiveness,
achieving high accuracy (99%), precision (100%), recall (99%), and F1-score
(99%), with a BLEU score of 0.5. The question-answering model attained an
accuracy of 89% and the predictive model achieved 70% accuracy. These results
validate Text2Insight as a robust and viable solution for transforming natural
language text into dynamic, user-specific data analysis and visualizations.",2024-12-27T16:17:22Z,http://arxiv.org/abs/2412.19718v1,Pradeep Sain
"From Elements to Design: A Layered Approach for Automatic Graphic Design
  Composition","In this work, we investigate automatic design composition from multimodal
graphic elements. Although recent studies have developed various generative
models for graphic design, they usually face the following limitations: they
only focus on certain subtasks and are far from achieving the design
composition task; they do not consider the hierarchical information of graphic
designs during the generation process. To tackle these issues, we introduce the
layered design principle into Large Multimodal Models (LMMs) and propose a
novel approach, called LaDeCo, to accomplish this challenging task.
Specifically, LaDeCo first performs layer planning for a given element set,
dividing the input elements into different semantic layers according to their
contents. Based on the planning results, it subsequently predicts element
attributes that control the design composition in a layer-wise manner, and
includes the rendered image of previously generated layers into the context.
With this insightful design, LaDeCo decomposes the difficult task into smaller
manageable steps, making the generation process smoother and clearer. The
experimental results demonstrate the effectiveness of LaDeCo in design
composition. Furthermore, we show that LaDeCo enables some interesting
applications in graphic design, such as resolution adjustment, element filling,
design variation, etc. In addition, it even outperforms the specialized models
in some design subtasks without any task-specific training.",2024-12-27T16:13:08Z,http://arxiv.org/abs/2412.19712v1,"Jiawei Lin, Shizhao Sun, Danqing Huang, Ting Liu, Ji Li, Jiang Bian"
High precision spectroscopy of trilobite Rydberg molecules,"We perform three-photon photoassociation to obtain high resolution spectra of
$^{87}$Rb trilobite dimers for the principal quantum numbers $n = 22,24,25,26$,
and 27. The large binding energy of the molecules in combination with a
relative spectroscopic resolution of $10^{-4}$ provides a rigorous benchmark
for existing theoretical models. A recently developed Green's function
framework, which circumvents the convergence issues that afflicted previous
studies,, is employed to theoretically reproduce the vibrational spectrum of
the molecule with high accuracy. The relatively large molecular binding energy
are primarily determined by the low energy $S$-wave electron-atom scattering
length, thereby allowing us to extract the $^3S_1$ scattering phase shift with
unprecedented accuracy, at low energy regimes inaccessible to free electrons.",2024-12-27T16:04:17Z,http://arxiv.org/abs/2412.19710v1,"Markus Exner, Rohan Srikumar, Richard Blättner, Matthew T. Eiles, Peter Schmelcher, Herwig Ott"
"A Review on the Integration of Artificial Intelligence and Medical
  Imaging in IVF Ovarian Stimulation","Artificial intelligence (AI) has emerged as a powerful tool to enhance
decision-making and optimize treatment protocols in in vitro fertilization
(IVF). In particular, AI shows significant promise in supporting
decision-making during the ovarian stimulation phase of the IVF process. This
review evaluates studies focused on the applications of AI combined with
medical imaging in ovarian stimulation, examining methodologies, outcomes, and
current limitations. Our analysis of 13 studies on this topic reveals that,
reveal that while AI algorithms demonstrated notable potential in predicting
optimal hormonal dosages, trigger timing, and oocyte retrieval outcomes, the
medical imaging data utilized predominantly came from two-dimensional (2D)
ultrasound which mainly involved basic quantifications, such as follicle size
and number, with limited use of direct feature extraction or advanced image
analysis techniques. This points to an underexplored opportunity where advanced
image analysis approaches, such as deep learning, and more diverse imaging
modalities, like three-dimensional (3D) ultrasound, could unlock deeper
insights. Additionally, the lack of explainable AI (XAI) in most studies raises
concerns about the transparency and traceability of AI-driven decisions - key
factors for clinical adoption and trust. Furthermore, many studies relied on
single-center designs and small datasets, which limit the generalizability of
their findings. This review highlights the need for integrating advanced
imaging analysis techniques with explainable AI methodologies, as well as the
importance of leveraging multicenter collaborations and larger datasets.
Addressing these gaps has the potential to enhance ovarian stimulation
management, paving the way for efficient, personalized, and data-driven
treatment pathways that improve IVF outcomes.",2024-12-27T15:29:08Z,http://arxiv.org/abs/2412.19688v1,"Jana Zakall, Birgit Pohn, Antonia Graf, Daniel Kovatchki, Arezoo Borji, Ragib Shahriar Islam, Hossam Haick, Heinz Strohmer, Sepideh Hatamikia"
Deep ReLU networks -- injectivity capacity upper bounds,"We study deep ReLU feed forward neural networks (NN) and their injectivity
abilities. The main focus is on \emph{precisely} determining the so-called
injectivity capacity. For any given hidden layers architecture, it is defined
as the minimal ratio between number of network's outputs and inputs which
ensures unique recoverability of the input from a realizable output. A strong
recent progress in precisely studying single ReLU layer injectivity properties
is here moved to a deep network level. In particular, we develop a program that
connects deep $l$-layer net injectivity to an $l$-extension of the $\ell_0$
spherical perceptrons, thereby massively generalizing an isomorphism between
studying single layer injectivity and the capacity of the so-called
(1-extension) $\ell_0$ spherical perceptrons discussed in [82]. \emph{Random
duality theory} (RDT) based machinery is then created and utilized to
statistically handle properties of the extended $\ell_0$ spherical perceptrons
and implicitly of the deep ReLU NNs. A sizeable set of numerical evaluations is
conducted as well to put the entire RDT machinery in practical use. From these
we observe a rapidly decreasing tendency in needed layers' expansions, i.e., we
observe a rapid \emph{expansion saturation effect}. Only $4$ layers of depth
are sufficient to closely approach level of no needed expansion -- a result
that fairly closely resembles observations made in practical experiments and
that has so far remained completely untouchable by any of the existing
mathematical methodologies.",2024-12-27T14:57:40Z,http://arxiv.org/abs/2412.19677v1,Mihailo Stojnic
"Optimizing Local-Global Dependencies for Accurate 3D Human Pose
  Estimation","Transformer-based methods have recently achieved significant success in 3D
human pose estimation, owing to their strong ability to model long-range
dependencies. However, relying solely on the global attention mechanism is
insufficient for capturing the fine-grained local details, which are crucial
for accurate pose estimation. To address this, we propose SSR-STF, a
dual-stream model that effectively integrates local features with global
dependencies to enhance 3D human pose estimation. Specifically, we introduce
SSRFormer, a simple yet effective module that employs the skeleton selective
refine attention (SSRA) mechanism to capture fine-grained local dependencies in
human pose sequences, complementing the global dependencies modeled by the
Transformer. By adaptively fusing these two feature streams, SSR-STF can better
learn the underlying structure of human poses, overcoming the limitations of
traditional methods in local feature extraction. Extensive experiments on the
Human3.6M and MPI-INF-3DHP datasets demonstrate that SSR-STF achieves
state-of-the-art performance, with P1 errors of 37.4 mm and 13.2 mm
respectively, outperforming existing methods in both accuracy and
generalization. Furthermore, the motion representations learned by our model
prove effective in downstream tasks such as human mesh recovery. Codes are
available at https://github.com/poker-xu/SSR-STF.",2024-12-27T14:54:12Z,http://arxiv.org/abs/2412.19676v1,"Guangsheng Xu, Guoyi Zhang, Lejia Ye, Shuwei Gan, Xiaohu Zhang, Xia Yang"
"Innovation beyond intention: harnessing exaptation for technological
  breakthroughs","The frameworks that explore scientific and technological evolution suggest
that discoveries and inventions are intrinsic processes, while the wealth of
knowledge accumulated over time enables researchers to make further
advancements, echoing Newton's sentiment of ""standing on the shoulders of
giants."" Despite the exponential growth in new scientific and technical
knowledge, the consolidation-disruption (D) index suggests a concerning decline
in the disruptiveness of papers and patents. ""Exaptation"" a concept borrowed
from biological evolution, is now recognized as a pivotal yet often neglected
mechanism in technological evolution. Significant technologies often do not
emerge out of thin air but rather result from the application of existing
technologies in other domains. For instance, bird feathers initially served as
waterproofing and insulation before enabling flight, and microwave ovens
originated from radar magnetrons. Exaptation, acknowledged as the catalyst for
""innovation beyond intention"" signifies a cross-field evolutionary process that
is driven by functional shifts in pre-existing knowledge, technology, or
artifacts. In this study, we introduce the concept of exaptation value,
deliberately excluding serendipity. Our analysis reveals that, despite a
declining trend in the disruptiveness of innovation, there is an increasing
trend in the application of cross-domain knowledge within the innovation
process over time. We also explore the impact of technology exaptation on
innovation disruptiveness and discuss how leveraging technology adaptability
enhances innovation's disruptive potential.",2024-12-27T14:19:17Z,http://arxiv.org/abs/2412.19662v1,"Youwei He, Jeong-Dong Lee, Seungmin Lee"
The Value of Recall in Extensive-Form Games,"Imperfect-recall games, in which players may forget previously acquired
information, have found many practical applications, ranging from game
abstractions to team games and testing AI agents. In this paper, we quantify
the utility gain by endowing a player with perfect recall, which we call the
value of recall (VoR). While VoR can be unbounded in general, we parameterize
it in terms of various game properties, namely the structure of chance nodes
and the degree of absentmindedness (the number of successive times a player
enters the same information set). Further, we identify several pathologies that
arise with VoR, and show how to circumvent them. We also study the complexity
of computing VoR, and how to optimally apportion partial recall. Finally, we
connect VoR to other previously studied concepts in game theory, including the
price of anarchy. We use that connection in conjunction with the celebrated
smoothness framework to characterize VoR in a broad class of games.",2024-12-27T14:12:45Z,http://arxiv.org/abs/2412.19659v1,"Ratip Emin Berker, Emanuel Tewolde, Ioannis Anagnostides, Tuomas Sandholm, Vincent Conitzer"
Movable Antenna Aided Physical Layer Security with No Eavesdropper CSI,"A novel movable antenna (MA)-aided secure transmission framework is proposed
to enhance the secrecy transmission rate without relying on the eavesdropper's
channel state information. Within this framework, a joint beamforming and
jamming scheme is proposed, where the power of the confidential signal is
minimized by optimizing the positions of the MAs, and the residual power is
used to jam the eavesdropper. An efficient gradient-based method is employed to
solve this non-convex problem. Numerical results are provided to demonstrate
the superiority of the MA-based framework over systems using traditional
fixed-position antennas in secure transmission.",2024-12-27T14:05:08Z,http://arxiv.org/abs/2412.19656v1,"Zhenqiao Cheng, Chongjun Ouyang, Xingqi Zhang"
"FreStega: A Plug-and-Play Method for Boosting Imperceptibility and
  Capacity in Generative Linguistic Steganography for Real-World Scenarios","Linguistic steganography embeds secret information in seemingly innocent
texts, safeguarding privacy in surveillance environments. Generative linguistic
steganography leverages the probability distribution of language models (LMs)
and applies steganographic algorithms to generate stego tokens, gaining
attention with recent Large Language Model (LLM) advancements. To enhance
security, researchers develop distribution-preserving stego algorithms to
minimize the gap between stego sampling and LM sampling. However, the reliance
on language model distributions, coupled with deviations from real-world cover
texts, results in insufficient imperceptibility when facing steganalysis
detectors in real-world scenarios. Moreover, LLM distributions tend to be more
deterministic, resulting in reduced entropy and, consequently, lower embedding
capacity. In this paper, we propose FreStega, a plug-and-play method to
reconstruct the distribution of language models used for generative linguistic
steganography. FreStega dynamically adjusts token probabilities from the
language model at each step of stegotext auto-regressive generation, leveraging
both sequential and spatial dimensions. In sequential adjustment, the
temperature is dynamically adjusted based on instantaneous entropy, enhancing
the diversity of stego texts and boosting embedding capacity. In the spatial
dimension, the distribution is aligned with guidance from the target domain
corpus, closely mimicking real cover text in the target domain. By reforming
the distribution, FreStega enhances the imperceptibility of stego text in
practical scenarios and improves steganographic capacity by 15.41\%, all
without compromising the quality of the generated text. FreStega serves as a
plug-and-play remedy to enhance the imperceptibility and embedding capacity of
existing distribution-preserving steganography methods in real-world scenarios.",2024-12-27T13:56:51Z,http://arxiv.org/abs/2412.19652v1,Kaiyi Pang
"Branes and Representations of DAHA $C^\vee C_1$: affine braid group
  action on category","We study the representation theory of the spherical double affine Hecke
algebra (DAHA) of $C^\vee C_1$, using brane quantization. By showing a
one-to-one correspondence between Lagrangian $A$-branes with compact support
and finite-dimensional representations of the spherical DAHA, we provide
evidence of derived equivalence between the $A$-brane category of
$\mathrm{SL}(2,\mathbb{C})$-character variety of a four-punctured sphere and
the representation category of DAHA of $C^\vee C_1$. The $D_4$ root system
plays an essential role in understanding both the geometry and representation
theory. In particular, this $A$-model approach reveals the action of an affine
braid group of type $D_4$ on the category. As a by-product, our geometric
investigation offers detailed information about the low-energy dynamics of the
SU(2) $N_f=4$ Seiberg-Witten theory.",2024-12-27T13:54:31Z,http://arxiv.org/abs/2412.19647v1,"Junkang Huang, Satoshi Nawata, Yutai Zhang, Shutong Zhuang"
"VideoMaker: Zero-shot Customized Video Generation with the Inherent
  Force of Video Diffusion Models","Zero-shot customized video generation has gained significant attention due to
its substantial application potential. Existing methods rely on additional
models to extract and inject reference subject features, assuming that the
Video Diffusion Model (VDM) alone is insufficient for zero-shot customized
video generation. However, these methods often struggle to maintain consistent
subject appearance due to suboptimal feature extraction and injection
techniques. In this paper, we reveal that VDM inherently possesses the force to
extract and inject subject features. Departing from previous heuristic
approaches, we introduce a novel framework that leverages VDM's inherent force
to enable high-quality zero-shot customized video generation. Specifically, for
feature extraction, we directly input reference images into VDM and use its
intrinsic feature extraction process, which not only provides fine-grained
features but also significantly aligns with VDM's pre-trained knowledge. For
feature injection, we devise an innovative bidirectional interaction between
subject features and generated content through spatial self-attention within
VDM, ensuring that VDM has better subject fidelity while maintaining the
diversity of the generated video.Experiments on both customized human and
object video generation validate the effectiveness of our framework.",2024-12-27T13:49:25Z,http://arxiv.org/abs/2412.19645v1,"Tao Wu, Yong Zhang, Xiaodong Cun, Zhongang Qi, Junfu Pu, Huanzhang Dou, Guangcong Zheng, Ying Shan, Xi Li"
Signatures of prediction during natural listening in MEG data?,"The brain uses contextual information and prior knowledge to anticipate
upcoming content during language comprehension. Recent research has shown
predictive signals can be revealed in pre-onset ECoG activity during
naturalistic narrative listening, by building encoding models based on word
embeddings from Large Language Models (LLMs). Similarly, evidence for
long-range predictive encoding has been observed in fMRI data, where
incorporating embeddings for multiple upcoming words in a narrative improves
alignment with brain activity. This study examines whether similar predictive
information can be detected in MEG, a technique with higher temporal resolution
than fMRI but a lower signal-to-noise ratio than ECoG. Our findings indicate
that MEG captures pre-onset representations up to 1 second before word onset,
consistent with ECoG results. However, unlike fMRI findings, incorporating
future word embeddings did not enhance MEG encoding, even for one word into the
future, which suggests that the pre-onset encoding may not reflect predictive
processing. This work demonstrates that MEG combined with LLMs is a valuable
approach for studying language processing in naturalistic narratives and
highlights the need to study further what constitutes evidence for prediction
during natural listening.",2024-12-27T12:49:03Z,http://arxiv.org/abs/2412.19622v1,"Sahel Azizpour, Britta U. Westner, Jakub Szewczyk, Umut Güçlü, Linda Geerligs"
"Machine Generated Product Advertisements: Benchmarking LLMs Against
  Human Performance","This study compares the performance of AI-generated and human-written product
descriptions using a multifaceted evaluation model. We analyze descriptions for
100 products generated by four AI models (Gemma 2B, LLAMA, GPT2, and ChatGPT 4)
with and without sample descriptions, against human-written descriptions. Our
evaluation metrics include sentiment, readability, persuasiveness, Search
Engine Optimization(SEO), clarity, emotional appeal, and call-to-action
effectiveness. The results indicate that ChatGPT 4 performs the best. In
contrast, other models demonstrate significant shortcomings, producing
incoherent and illogical output that lacks logical structure and contextual
relevance. These models struggle to maintain focus on the product being
described, resulting in disjointed sentences that do not convey meaningful
information. This research provides insights into the current capabilities and
limitations of AI in the creation of content for e-Commerce.",2024-12-27T12:11:50Z,http://arxiv.org/abs/2412.19610v1,Sanjukta Ghosh
"Enhancing Fine-grained Image Classification through Attentive Batch
  Training","Fine-grained image classification, which is a challenging task in computer
vision, requires precise differentiation among visually similar object
categories. In this paper, we propose 1) a novel module called Residual
Relationship Attention (RRA) that leverages the relationships between images
within each training batch to effectively integrate visual feature vectors of
batch images and 2) a novel technique called Relationship Position Encoding
(RPE), which encodes the positions of relationships between original images in
a batch and effectively preserves the relationship information between images
within the batch. Additionally, we design a novel framework, namely
Relationship Batch Integration (RBI), which utilizes RRA in conjunction with
RPE, allowing the discernment of vital visual features that may remain elusive
when examining a singular image representative of a particular class. Through
extensive experiments, our proposed method demonstrates significant
improvements in the accuracy of different fine-grained classifiers, with an
average increase of $(+2.78\%)$ and $(+3.83\%)$ on the CUB200-2011 and Stanford
Dog datasets, respectively, while achieving a state-of-the-art results
$(95.79\%)$ on the Stanford Dog dataset. Despite not achieving the same level
of improvement as in fine-grained image classification, our method still
demonstrates its prowess in leveraging general image classification by
attaining a state-of-the-art result of $(93.71\%)$ on the Tiny-Imagenet
dataset. Furthermore, our method serves as a plug-in refinement module and can
be easily integrated into different networks.",2024-12-27T12:07:58Z,http://arxiv.org/abs/2412.19606v1,"Duy M. Le, Bao Q. Bui, Anh Tran, Cong Tran, Cuong Pham"
"Nonequilibrium Response Theory: From Precision Limits to Strong
  Perturbation","Fluctuation-response relations lie at the heart of statistical physics, yet
their formulation in nonequilibrium steady states remains challenging. This
Letter makes two key contributions to this field: First, we establish
fundamental limits on nonequilibrium steady-state responses by deriving upper
bounds on response precisions using steady-state Fisher information. Our
analysis reveals that the sensitivity of observables to perturbations is
governed by mean first passage times, steady-state currents, and activities,
though it cannot be enhanced indefinitely by increasing these quantities.
Notably, we demonstrate that the role of activity in response precision
parallels that of repeated measurements in metrology. Second, we develop novel
identities connecting the responses to arbitrarily strong perturbations with
those to small perturbations. These identities significantly extend previous
nonequilibrium response theories, which primarily focused on small
perturbations, to encompass arbitrarily strong perturbations.",2024-12-27T11:57:42Z,http://arxiv.org/abs/2412.19602v1,"Ruicheng Bao, Shiling Liang"
"ViDTA: Enhanced Drug-Target Affinity Prediction via Virtual Graph Nodes
  and Attention-based Feature Fusion","Drug-target interaction is fundamental in understanding how drugs affect
biological systems, and accurately predicting drug-target affinity (DTA) is
vital for drug discovery. Recently, deep learning methods have emerged as a
significant approach for estimating the binding strength between drugs and
target proteins. However, existing methods simply utilize the drug's local
information from molecular topology rather than global information.
Additionally, the features of drugs and proteins are usually fused with a
simple concatenation operation, limiting their effectiveness. To address these
challenges, we proposed ViDTA, an enhanced DTA prediction framework. We
introduce virtual nodes into the Graph Neural Network (GNN)-based drug feature
extraction network, which acts as a global memory to exchange messages more
efficiently. By incorporating virtual graph nodes, we seamlessly integrate
local and global features of drug molecular structures, expanding the GNN's
receptive field. Additionally, we propose an attention-based linear feature
fusion network for better capturing the interaction information between drugs
and proteins. Experimental results evaluated on various benchmarks including
Davis, Metz, and KIBA demonstrate that our proposed ViDTA outperforms the
state-of-the-art baselines.",2024-12-27T11:19:10Z,http://arxiv.org/abs/2412.19589v1,"Minghui Li, Zikang Guo, Yang Wu, Peijin Guo, Yao Shi, Shengshan Hu, Wei Wan, Shengqing Hu"
"An Actionable Hierarchical Scene Representation Enhancing Autonomous
  Inspection Missions in Unknown Environments","In this article, we present the Layered Semantic Graphs (LSG), a novel
actionable hierarchical scene graph, fully integrated with a multi-modal
mission planner, the FLIE: A First-Look based Inspection and Exploration
planner. The novelty of this work stems from aiming to address the task of
maintaining an intuitive and multi-resolution scene representation, while
simultaneously offering a tractable foundation for planning and scene
understanding during an ongoing inspection mission of apriori unknown
targets-of-interest in an unknown environment. The proposed LSG scheme is
composed of locally nested hierarchical graphs, at multiple layers of
abstraction, with the abstract concepts grounded on the functionality of the
integrated FLIE planner. Furthermore, LSG encapsulates real-time semantic
segmentation models that offer extraction and localization of desired semantic
elements within the hierarchical representation. This extends the capability of
the inspection planner, which can then leverage LSG to make an informed
decision to inspect a particular semantic of interest. We also emphasize the
hierarchical and semantic path-planning capabilities of LSG, which can extend
inspection missions by improving situational awareness for human operators in
an unknown environment. The validity of the proposed scheme is proven through
extensive evaluations of the proposed architecture in simulations, as well as
experimental field deployments on a Boston Dynamics Spot quadruped robot in
urban outdoor environment settings.",2024-12-27T10:57:17Z,http://arxiv.org/abs/2412.19582v1,"Vignesh Kottayam Viswanathan, Mario Alberto Valdes Saucedo, Sumeet Gajanan Satpute, Christoforos Kanellakis, George Nikolakopoulos"
"Graph-attention-based Casual Discovery with Trust Region-navigated
  Clipping Policy Optimization","In many domains of empirical sciences, discovering the causal structure
within variables remains an indispensable task. Recently, to tackle with
unoriented edges or latent assumptions violation suffered by conventional
methods, researchers formulated a reinforcement learning (RL) procedure for
causal discovery, and equipped REINFORCE algorithm to search for the
best-rewarded directed acyclic graph. The two keys to the overall performance
of the procedure are the robustness of RL methods and the efficient encoding of
variables. However, on the one hand, REINFORCE is prone to local convergence
and unstable performance during training. Neither trust region policy
optimization, being computationally-expensive, nor proximal policy optimization
(PPO), suffering from aggregate constraint deviation, is decent alternative for
combinatory optimization problems with considerable individual subactions. We
propose a trust region-navigated clipping policy optimization method for causal
discovery that guarantees both better search efficiency and steadiness in
policy optimization, in comparison with REINFORCE, PPO and our prioritized
sampling-guided REINFORCE implementation. On the other hand, to boost the
efficient encoding of variables, we propose a refined graph attention encoder
called SDGAT that can grasp more feature information without priori
neighbourhood information. With these improvements, the proposed method
outperforms former RL method in both synthetic and benchmark datasets in terms
of output results and optimization robustness.",2024-12-27T10:50:43Z,http://arxiv.org/abs/2412.19578v1,"Shixuan Liu, Yanghe Feng, Keyu Wu, Guangquan Cheng, Jincai Huang, Zhong Liu"
"Gauging or extending bulk and boundary conformal field theories:
  Application to bulk and domain wall problem in topological matter and their
  descriptions by (mock) modular covariant","We study gauging operations (or group extensions) in (smeared) boundary
conformal field theories (BCFTs) and bulk conformal field theories and their
applications to various phenomena in topologically ordered systems. We apply
the resultant theories to the correspondence between the renormalization group
(RG) flow of CFTs and the classification of topological quantum field theories
in the testable information of general classes of partition functions. One can
obtain the bulk topological properties of $2+1$ dimensional topological ordered
phase corresponding to the massive RG flow of $1+1$ dimensional systems, or
smeared BCFT. We present an obstruction of mass condensation for smeared BCFT
analogous to the Lieb-Shultz-Mattis theorem for noninvertible symmetry. Related
to the bulk topological degeneracies in $2+1$ dimensions and quantum phases in
$1+1$ dimensions we construct a new series of BCFT. We also investigate the
implications of the massless RG flow of $1+1$ dimensional CFT to $2+1$
dimensional topological order which corresponds to the earlier proposal by L.
Kong and H. Zheng in [Nucl. Phys. B 966 (2021), 115384], arXiv:1912.01760
closely related to the integer-spin simple current by Schellekens and
Gato-Rivera. We study the properties of the product of two CFTs connected by
the two kinds of massless flows. The (mock) modular covariants appearing in the
analysis seem to contain new ones. By applying the folding trick to the coupled
model, we provide a general method to solve the gapped and charged domain wall.
One can obtain the general phenomenology of the transportation of anyons
through the domain wall. Our work gives a unified direction for the future
theoretical and numerical studies of the topological phase based on the
established data of classifications of conformal field theories or modular
invariants.",2024-12-27T10:46:30Z,http://arxiv.org/abs/2412.19577v1,Yoshiki Fukusumi
"xFLIE: Leveraging Actionable Hierarchical Scene Representations for
  Autonomous Semantic-Aware Inspection Missions","This article presents xFLIE, a fully integrated 3D hierarchical scene graph
based autonomous inspection architecture. Specifically, we present a
tightly-coupled solution of incremental 3D Layered Semantic Graphs (LSG)
construction and real-time exploitation by a multi-modal autonomy, First-Look
based Inspection and Exploration (FLIE) planner, to address the task of
inspection of apriori unknown semantic targets of interest in unknown
environments. This work aims to address the challenge of maintaining, in
addition to or as an alternative to volumetric models, an intuitive scene
representation during large-scale inspection missions. Through its
contributions, the proposed architecture aims to provide a high-level
multi-tiered abstract environment representation whilst simultaneously
maintaining a tractable foundation for rapid and informed decision-making
capable of enhancing inspection planning through scene understanding, what
should it inspect ?, and reasoning, why should it inspect ?. The proposed LSG
framework is designed to leverage the concept of nesting lower local graphs, at
multiple layers of abstraction, with the abstract concepts grounded on the
functionality of the integrated FLIE planner. Through intuitive scene
representation, the proposed architecture offers an easily digestible
environment model for human operators which helps to improve situational
awareness and their understanding of the operating environment. We highlight
the use-case benefits of hierarchical and semantic path-planning capability
over LSG to address queries, by the integrated planner as well as the human
operator. The validity of the proposed architecture is evaluated in large-scale
simulated outdoor urban scenarios as well as being deployed onboard a Boston
Dynamics Spot quadruped robot for extensive outdoor field experiments.",2024-12-27T10:26:59Z,http://arxiv.org/abs/2412.19571v1,"Vignesh Kottayam Viswanathan, Mario A. V. Saucedo, Sumeet Gajanan Satpute, Christoforos Kanellakis, George Nikolakopoulos"
"Hindsight Planner: A Closed-Loop Few-Shot Planner for Embodied
  Instruction Following","This work focuses on building a task planner for Embodied Instruction
Following (EIF) using Large Language Models (LLMs). Previous works typically
train a planner to imitate expert trajectories, treating this as a supervised
task. While these methods achieve competitive performance, they often lack
sufficient robustness. When a suboptimal action is taken, the planner may
encounter an out-of-distribution state, which can lead to task failure. In
contrast, we frame the task as a Partially Observable Markov Decision Process
(POMDP) and aim to develop a robust planner under a few-shot assumption. Thus,
we propose a closed-loop planner with an adaptation module and a novel
hindsight method, aiming to use as much information as possible to assist the
planner. Our experiments on the ALFRED dataset indicate that our planner
achieves competitive performance under a few-shot assumption. For the first
time, our few-shot agent's performance approaches and even surpasses that of
the full-shot supervised agent.",2024-12-27T10:05:45Z,http://arxiv.org/abs/2412.19562v1,"Yuxiao Yang, Shenao Zhang, Zhihan Liu, Huaxiu Yao, Zhaoran Wang"
Single-qubit quantum gate at an arbitrary speed,"Quantum information processing comprises physical processes, which obey the
quantum speed limit (QSL): high speed requires strong driving. Single-qubit
gates using Rabi oscillation, which is based on the rotating wave approximation
(RWA), satisfy this bound in the form that the gate time $T$ is inversely
proportional to the Rabi frequency $\Omega$, characterizing the driving
strength. However, if the gate time is comparable or shorter than the qubit
period $T_{0} \equiv 2\pi / \omega_{0}$, the RWA actually breaks down since the
Rabi frequency has to be large compared to the qubit frequency $\omega_{0}$ due
to the QSL, which is given as $T \gtrsim \pi/\Omega$. We show that it is
possible to construct a universal set of single-qubit gates at this
strong-coupling and ultrafast regime, by adjusting the central frequency
$\omega$ and the Rabi frequency $\Omega$ of the driving pulse. We observe a
transition in the scaling behavior of the central frequency from the long-gate
time regime ($T \gg T_{0}$) to the short-gate time ($T \ll T_{0}$) regime. In
the former, the central frequency is nearly resonant to the qubit, i.e.,
$\omega \simeq \omega_{0}$, whereas in the latter, the central frequency is
inversely proportional to the gate time, i.e., $\omega \sim \pi/T$. We identify
the transition gate time at which the scaling exponent $n$ of the optimal
central frequency $\omega \sim T^{n}$ changes from $n=0$ to $n=-1$.",2024-12-27T10:05:27Z,http://arxiv.org/abs/2412.19561v1,"Seongjin Ahn, Kichan Park, Daehee Cho, Mikyoung Lim, Taeyoung Choi, Andrey S. Moskalenko"
Bolstering up the existence of $P_s(2080)$,"We present a detailed study of the partial decay widths of a spin-parity
resonance $J^P=3/2^-$ $N^*$ with a mass of $\simeq$ 2070 MeV obtained from the
coupled channel s wave vector-baryon $\rho N$, $\omega N$, $\phi N$,
$K^*\Lambda$ and $K^*\Sigma$ dynamics. This state, which couples strongly to
the $K^*\Sigma$ channel, corresponds to a nucleon with a hidden strange quark
content, in analogy to the $P_c$ states discovered by the LHCb collaboration,
and we denote it as $P_s(2080)$. A state with such a nature can decay to
vector-baryon, pseudoscalar-baryon, and pseudoscalar-baryon resonance channels,
involving triangular loops in the latter two cases. As we will show, the
partial decay widths to pseudoscalar-baryon resonance channels, like $\pi
N^*(1535)$, $\pi N^*(1650)$, $K\Lambda(1405)$, are comparable to those related
to ground state baryons in the final state, like $\pi N$, $\eta N$, $K\Lambda$.
In this way, reactions involving such lighter baryon resonances in the final
state can be used as an alternative source of information on the properties of
a $N^*$ with hidden strangeness.",2024-12-27T10:00:42Z,http://arxiv.org/abs/2412.19559v1,"Breno Agatão, A. Vertel Nieto, K. P. Khemchandani, A. Martinez Torres, Seung-il Nam"
"Learning states enhanced knowledge tracing: Simulating the diversity in
  real-world learning process","The Knowledge Tracing (KT) task focuses on predicting a learner's future
performance based on the historical interactions. The knowledge state plays a
key role in learning process. However, considering that the knowledge state is
influenced by various learning factors in the interaction process, such as the
exercises similarities, responses reliability and the learner's learning state.
Previous models still face two major limitations. First, due to the exercises
differences caused by various complex reasons and the unreliability of
responses caused by guessing behavior, it is hard to locate the historical
interaction which is most relevant to the current answered exercise. Second,
the learning state is also a key factor to influence the knowledge state, which
is always ignored by previous methods. To address these issues, we propose a
new method named Learning State Enhanced Knowledge Tracing (LSKT). Firstly, to
simulate the potential differences in interactions, inspired by Item Response
Theory~(IRT) paradigm, we designed three different embedding methods ranging
from coarse-grained to fine-grained views and conduct comparative analysis on
them. Secondly, we design a learning state extraction module to capture the
changing learning state during the learning process of the learner. In turn,
with the help of the extracted learning state, a more detailed knowledge state
could be captured. Experimental results on four real-world datasets show that
our LSKT method outperforms the current state-of-the-art methods.",2024-12-27T09:41:25Z,http://arxiv.org/abs/2412.19550v1,"Shanshan Wang, Xueying Zhang, Keyang Wang, Xun Yang, Xingyi Zhang"
"Unprejudiced Training Auxiliary Tasks Makes Primary Better: A Multi-Task
  Learning Perspective","Human beings can leverage knowledge from relative tasks to improve learning
on a primary task. Similarly, multi-task learning methods suggest using
auxiliary tasks to enhance a neural network's performance on a specific primary
task. However, previous methods often select auxiliary tasks carefully but
treat them as secondary during training. The weights assigned to auxiliary
losses are typically smaller than the primary loss weight, leading to
insufficient training on auxiliary tasks and ultimately failing to support the
main task effectively. To address this issue, we propose an uncertainty-based
impartial learning method that ensures balanced training across all tasks.
Additionally, we consider both gradients and uncertainty information during
backpropagation to further improve performance on the primary task. Extensive
experiments show that our method achieves performance comparable to or better
than state-of-the-art approaches. Moreover, our weighting strategy is effective
and robust in enhancing the performance of the primary task regardless the
noise auxiliary tasks' pseudo labels.",2024-12-27T09:27:18Z,http://arxiv.org/abs/2412.19547v1,"Yuanze Li, Chun-Mei Feng, Qilong Wang, Guanglei Yang, Wangmeng Zuo"
"GHZ-W Genuinely Entangled Subspace Verification with Adaptive Local
  Measurements","Genuinely entangled subspaces (GESs) are valuable resources in quantum
information science. Among these, the three-qubit GHZ-W GES, spanned by the
three-qubit Greenberger-Horne-Zeilinger (GHZ) and W states, is a universal and
crucial entangled subspace resource for three-qubit systems. In this work, we
develop two adaptive verification strategies, the XZ strategy and the rotation
strategy, for the three-qubit GHZ-W GES using local measurements and one-way
classical communication. These strategies are experimentally feasible,
efficient and possess a concise analytical expression for the sample complexity
of the rotation strategy, which scales approximately as
$2.248/\epsilon\ln(1/\delta)$, where $\epsilon$ is the infidelity and
$1-\delta$ is the confidence level. Furthermore, we comprehensively analyze the
two-dimensional two-qubit subspaces and classify them into three distinct
types, including unverifiable entangled subspaces, revealing intrinsic
limitations in local verification of entangled subspaces.",2024-12-27T09:07:44Z,http://arxiv.org/abs/2412.19540v1,"Congcong Zheng, Ping Xu, Kun Wang, Zaichen Zhang"
"Finger in Camera Speaks Everything: Unconstrained Air-Writing for
  Real-World","Air-writing is a challenging task that combines the fields of computer vision
and natural language processing, offering an intuitive and natural approach for
human-computer interaction. However, current air-writing solutions face two
primary challenges: (1) their dependency on complex sensors (e.g., Radar, EEGs
and others) for capturing precise handwritten trajectories, and (2) the absence
of a video-based air-writing dataset that covers a comprehensive vocabulary
range. These limitations impede their practicality in various real-world
scenarios, including the use on devices like iPhones and laptops. To tackle
these challenges, we present the groundbreaking air-writing Chinese character
video dataset (AWCV-100K-UCAS2024), serving as a pioneering benchmark for
video-based air-writing. This dataset captures handwritten trajectories in
various real-world scenarios using commonly accessible RGB cameras, eliminating
the need for complex sensors. AWCV-100K-UCAS2024 includes 8.8 million video
frames, encompassing the complete set of 3,755 characters from the GB2312-80
level-1 set (GB1). Furthermore, we introduce our baseline approach, the
video-based character recognizer (VCRec). VCRec adeptly extracts fingertip
features from sparse visual cues and employs a spatio-temporal sequence module
for analysis. Experimental results showcase the superior performance of VCRec
compared to existing models in recognizing air-written characters, both
quantitatively and qualitatively. This breakthrough paves the way for enhanced
human-computer interaction in real-world contexts. Moreover, our approach
leverages affordable RGB cameras, enabling its applicability in a diverse range
of scenarios. The code and data examples will be made public at
https://github.com/wmeiqi/AWCV.",2024-12-27T09:04:04Z,http://arxiv.org/abs/2412.19537v1,"Meiqi Wu, Kaiqi Huang, Yuanqiang Cai, Shiyu Hu, Yuzhong Zhao, Weiqiang Wang"
"Estimation of System Parameters Including Repeated Cross-Sectional Data
  through Emulator-Informed Deep Generative Model","Differential equations (DEs) are crucial for modeling the evolution of
natural or engineered systems. Traditionally, the parameters in DEs are
adjusted to fit data from system observations. However, in fields such as
politics, economics, and biology, available data are often independently
collected at distinct time points from different subjects (i.e., repeated
cross-sectional (RCS) data). Conventional optimization techniques struggle to
accurately estimate DE parameters when RCS data exhibit various
heterogeneities, leading to a significant loss of information. To address this
issue, we propose a new estimation method called the emulator-informed
deep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM
integrates a physics-informed neural network-based emulator that immediately
generates DE solutions and a Wasserstein generative adversarial network-based
parameter generator that can effectively mimic the RCS data. We evaluated EIDGM
on exponential growth, logistic population models, and the Lorenz system,
demonstrating its superior ability to accurately capture parameter
distributions. Additionally, we applied EIDGM to an experimental dataset of
Amyloid beta 40 and beta 42, successfully capturing diverse parameter
distribution shapes. This shows that EIDGM can be applied to model a wide range
of systems and extended to uncover the operating principles of systems based on
limited data.",2024-12-27T08:19:23Z,http://arxiv.org/abs/2412.19517v1,"Hyunwoo Cho, Sung Woong Cho, Hyeontae Jo, Hyung Ju Hwang"
"Real-time classification of EEG signals using Machine Learning
  deployment","The prevailing educational methods predominantly rely on traditional
classroom instruction or online delivery, often limiting the teachers' ability
to engage effectively with all the students simultaneously. A more intrinsic
method of evaluating student attentiveness during lectures can enable the
educators to tailor the course materials and their teaching styles in order to
better meet the students' needs. The aim of this paper is to enhance teaching
quality in real time, thereby fostering a higher student engagement in the
classroom activities. By monitoring the students' electroencephalography (EEG)
signals and employing machine learning algorithms, this study proposes a
comprehensive solution for addressing this challenge. Machine learning has
emerged as a powerful tool for simplifying the analysis of complex variables,
enabling the effective assessment of the students' concentration levels based
on specific parameters. However, the real-time impact of machine learning
models necessitates a careful consideration as their deployment is concerned.
This study proposes a machine learning-based approach for predicting the level
of students' comprehension with regard to a certain topic. A browser interface
was introduced that accesses the values of the system's parameters to determine
a student's level of concentration on a chosen topic. The deployment of the
proposed system made it necessary to address the real-time challenges faced by
the students, consider the system's cost, and establish trust in its efficacy.
This paper presents the efforts made for approaching this pertinent issue
through the implementation of innovative technologies and provides a framework
for addressing key considerations for future research directions.",2024-12-27T08:14:28Z,http://arxiv.org/abs/2412.19515v1,"Swati Chowdhuri, Satadip Saha, Samadrita Karmakar, Ankur Chanda"
"Uncertainty quantification for improving radiomic-based models in
  radiation pneumonitis prediction","Background and Objective: Radiation pneumonitis (RP) is a side effect of
thoracic radiation therapy. Recently, Machine learning (ML) models enhanced
with radiomic and dosiomic features provide better predictions by incorporating
spatial information beyond DVHs. However, to improve the clinical decision
process, we propose to use uncertainty quantification (UQ) to improve the
confidence in model prediction. This study evaluates the impact of post hoc UQ
methods on the discriminative performance and calibration of ML models for RP
prediction. Methods: This study evaluated four ML models: logistic regression
(LR), support vector machines (SVM), extreme gradient boosting (XGB), and
random forest (RF), using radiomic, dosiomic, and dosimetric features to
predict RP. We applied UQ methods, including Patt scaling, isotonic regression,
Venn-ABERS predictor, and Conformal Prediction, to quantify uncertainty. Model
performance was assessed through Area Under the Receiver Operating
Characteristic curve (AUROC), Area Under the Precision-Recall Curve (AUPRC),
and Adaptive Calibration Error (ACE) using Leave-One-Out Cross-Validation
(LOO-CV). Results: UQ methods enhanced predictive performance, particularly for
high-certainty predictions, while also improving calibration. Radiomic and
dosiomic features increased model accuracy but introduced calibration
challenges, especially for non-linear models like XGB and RF. Performance gains
from UQ methods were most noticeable at higher certainty thresholds.
Conclusion: Integrating UQ into ML models with radiomic and dosiomic features
improves both predictive accuracy and calibration, supporting more reliable
clinical decision-making. The findings emphasize the value of UQ methods in
enhancing applicability of predictive models for RP in healthcare settings.",2024-12-27T08:01:42Z,http://arxiv.org/abs/2412.19511v1,"Chanon Puttanawarut, Romen Samuel Wabina, Nat Sirirutbunkajorn"
"DrivingWorld: ConstructingWorld Model for Autonomous Driving via Video
  GPT","Recent successes in autoregressive (AR) generation models, such as the GPT
series in natural language processing, have motivated efforts to replicate this
success in visual tasks. Some works attempt to extend this approach to
autonomous driving by building video-based world models capable of generating
realistic future video sequences and predicting ego states. However, prior
works tend to produce unsatisfactory results, as the classic GPT framework is
designed to handle 1D contextual information, such as text, and lacks the
inherent ability to model the spatial and temporal dynamics essential for video
generation. In this paper, we present DrivingWorld, a GPT-style world model for
autonomous driving, featuring several spatial-temporal fusion mechanisms. This
design enables effective modeling of both spatial and temporal dynamics,
facilitating high-fidelity, long-duration video generation. Specifically, we
propose a next-state prediction strategy to model temporal coherence between
consecutive frames and apply a next-token prediction strategy to capture
spatial information within each frame. To further enhance generalization
ability, we propose a novel masking strategy and reweighting strategy for token
prediction to mitigate long-term drifting issues and enable precise control.
Our work demonstrates the ability to produce high-fidelity and consistent video
clips of over 40 seconds in duration, which is over 2 times longer than
state-of-the-art driving world models. Experiments show that, in contrast to
prior works, our method achieves superior visual quality and significantly more
accurate controllable future video generation. Our code is available at
https://github.com/YvanYin/DrivingWorld.",2024-12-27T07:44:07Z,http://arxiv.org/abs/2412.19505v1,"Xiaotao Hu, Wei Yin, Mingkai Jia, Junyuan Deng, Xiaoyang Guo, Qian Zhang, Xiaoxiao Long, Ping Tan"
Casevo: A Cognitive Agents and Social Evolution Simulator,"In this paper, we introduce a multi-agent simulation framework Casevo
(Cognitive Agents and Social Evolution Simulator), that integrates large
language models (LLMs) to simulate complex social phenomena and decision-making
processes. Casevo is designed as a discrete-event simulator driven by agents
with features such as Chain of Thoughts (CoT), Retrieval-Augmented Generation
(RAG), and Customizable Memory Mechanism. Casevo enables dynamic social
modeling, which can support various scenarios such as social network analysis,
public opinion dynamics, and behavior prediction in complex social systems. To
demonstrate the effectiveness of Casevo, we utilize one of the U.S. 2020
midterm election TV debates as a simulation example. Our results show that
Casevo facilitates more realistic and flexible agent interactions, improving
the quality of dynamic social phenomena simulation. This work contributes to
the field by providing a robust system for studying large-scale, high-fidelity
social behaviors with advanced LLM-driven agents, expanding the capabilities of
traditional agent-based modeling (ABM). The open-source code repository address
of casevo is https://github.com/rgCASS/casevo.",2024-12-27T07:33:49Z,http://arxiv.org/abs/2412.19498v1,"Zexun Jiang, Yafang Shi, Maoxu Li, Hongjiang Xiao, Yunxiao Qin, Qinglan Wei, Ye Wang, Yuan Zhang"
"Multi-P$^2$A: A Multi-perspective Benchmark on Privacy Assessment for
  Large Vision-Language Models","Large Vision-Language Models (LVLMs) exhibit impressive potential across
various tasks but also face significant privacy risks, limiting their practical
applications. Current researches on privacy assessment for LVLMs is limited in
scope, with gaps in both assessment dimensions and privacy categories. To
bridge this gap, we propose Multi-P$^2$A, a comprehensive benchmark for
evaluating the privacy preservation capabilities of LVLMs in terms of privacy
awareness and leakage. Privacy awareness measures the model's ability to
recognize the privacy sensitivity of input data, while privacy leakage assesses
the risk of the model unintentionally disclosing privacy information in its
output. We design a range of sub-tasks to thoroughly evaluate the model's
privacy protection offered by LVLMs. Multi-P$^2$A covers 26 categories of
personal privacy, 15 categories of trade secrets, and 18 categories of state
secrets, totaling 31,962 samples. Based on Multi-P$^2$A, we evaluate the
privacy preservation capabilities of 21 open-source and 2 closed-source LVLMs.
Our results reveal that current LVLMs generally pose a high risk of
facilitating privacy breaches, with vulnerabilities varying across personal
privacy, trade secret, and state secret.",2024-12-27T07:33:39Z,http://arxiv.org/abs/2412.19496v1,"Jie Zhang, Xiangkui Cao, Zhouyu Han, Shiguang Shan, Xilin Chen"
Retrieval-augmented Generation for GenAI-enabled Semantic Communications,"Semantic communication (SemCom) is an emerging paradigm aiming at
transmitting only task-relevant semantic information to the receiver, which can
significantly improve communication efficiency. Recent advancements in
generative artificial intelligence (GenAI) have empowered GenAI-enabled SemCom
(GenSemCom) to further expand its potential in various applications. However,
current GenSemCom systems still face challenges such as semantic inconsistency,
limited adaptability to diverse tasks and dynamic environments, and the
inability to leverage insights from past transmission. Motivated by the success
of retrieval-augmented generation (RAG) in the domain of GenAI, this paper
explores the integration of RAG in GenSemCom systems. Specifically, we first
provide a comprehensive review of existing GenSemCom systems and the
fundamentals of RAG techniques. We then discuss how RAG can be integrated into
GenSemCom. Following this, we conduct a case study on semantic image
transmission using an RAG-enabled diffusion-based SemCom system, demonstrating
the effectiveness of the proposed integration. Finally, we outline future
directions for advancing RAG-enabled GenSemCom systems.",2024-12-27T07:30:01Z,http://arxiv.org/abs/2412.19494v1,"Shunpu Tang, Ruichen Zhang, Yuxuan Yan, Qianqian Yang, Dusit Niyato, Xianbin Wang, Shiwen Mao"
"Two superconducting thin films systems with potential integration of
  different quantum functionalities","Quantum computation based on superconducting circuits utilizes
superconducting qubits with Josephson tunnel junctions. Engineering
high-coherence qubits requires materials optimization. In this work, we present
two superconducting thin film systems, grown on silicon (Si), and one obtained
from the other via annealing. Cobalt (Co) thin films grown on Si were found to
be superconducting [EPL 131 (2020) 47001]. These films also happen to be a
self-organised hybrid superconductor/ferromagnet/superconductor (S/F/S)
structure. The S/F/S hybrids are important for superconducting $\pi$-qubits
[PRL 95 (2005) 097001] and in quantum information processing. Here we present
our results on the superconductivity of a hybrid Co film followed by the
superconductivity of a CoSi$_2$ film, which was prepared by annealing the Co
film. CoSi$_2$, with its $1/f$ noise about three orders of magnitude smaller
compared to the most commonly used superconductor aluminium (Al), is a
promising material for high-coherence qubits. The hybrid Co film revealed
superconducting transition temperature $T_c$ = 5 K and anisotropy in the upper
critical field between the in-plane and out-of-plane directions. The anisotropy
was of the order of ratio of lateral dimensions to thickness of the
superconducting Co grains, suggesting a quasi-2D nature of superconductivity.
On the other hand, CoSi$_2$ film showed a $T_c$ of 900 mK. In the resistivity
vs. temperature curve, we observe a peak near $T_c$. Magnetic field scan as a
function of $T$ shows a monotonic increase in intensity of this peak with
temperature. The origin of the peak has been explained in terms of parallel
resistive model for the particular measurement configuration. Although our
CoSi$_2$ film contains grain boundaries, we observed a perpendicular critical
field of 15 mT and a critical current density of 3.8x10$^7$ A/m$^2$, comparable
with epitaxial CoSi$_2$ films.",2024-12-27T07:23:20Z,http://arxiv.org/abs/2412.19493v1,"Snehal Mandal, Biplab Biswas, Suvankar Purakait, Anupam Roy, Biswarup Satpati, Indranil Das, B. N. Dev"
Towards Open-Vocabulary Remote Sensing Image Semantic Segmentation,"Recently, deep learning based methods have revolutionized remote sensing
image segmentation. However, these methods usually rely on a pre-defined
semantic class set, thus needing additional image annotation and model training
when adapting to new classes. More importantly, they are unable to segment
arbitrary semantic classes. In this work, we introduce Open-Vocabulary Remote
Sensing Image Semantic Segmentation (OVRSISS), which aims to segment arbitrary
semantic classes in remote sensing images. To address the lack of OVRSISS
datasets, we develop LandDiscover50K, a comprehensive dataset of 51,846 images
covering 40 diverse semantic classes. In addition, we propose a novel framework
named GSNet that integrates domain priors from special remote sensing models
and versatile capabilities of general vision-language models. Technically,
GSNet consists of a Dual-Stream Image Encoder (DSIE), a Query-Guided Feature
Fusion (QGFF), and a Residual Information Preservation Decoder (RIPD). DSIE
first captures comprehensive features from both special models and general
models in dual streams. Then, with the guidance of variable vocabularies, QGFF
integrates specialist and generalist features, enabling them to complement each
other. Finally, RIPD is proposed to aggregate multi-source features for more
accurate mask predictions. Experiments show that our method outperforms other
methods by a large margin, and our proposed LandDiscover50K improves the
performance of OVRSISS methods. The proposed dataset and method will be made
publicly available at https://github.com/yecy749/GSNet.",2024-12-27T07:20:30Z,http://arxiv.org/abs/2412.19492v1,"Chengyang Ye, Yunzhi Zhuge, Pingping Zhang"
"Multi-label Classification using Deep Multi-order Context-aware Kernel
  Networks","Multi-label classification is a challenging task in pattern recognition. Many
deep learning methods have been proposed and largely enhanced classification
performance. However, most of the existing sophisticated methods ignore context
in the models' learning process. Since context may provide additional cues to
the learned models, it may significantly boost classification performances. In
this work, we make full use of context information (namely geometrical
structure of images) in order to learn better context-aware similarities
(a.k.a. kernels) between images. We reformulate context-aware kernel design as
a feed-forward network that outputs explicit kernel mapping features. Our
obtained context-aware kernel network further leverages multiple orders of
patch neighbors within different distances, resulting into a more
discriminating Deep Multi-order Context-aware Kernel Network (DMCKN) for
multi-label classification. We evaluate the proposed method on the challenging
Corel5K and NUS-WIDE benchmarks, and empirical results show that our method
obtains competitive performances against the related state-of-the-art, and both
quantitative and qualitative performances corroborate its effectiveness and
superiority for multi-label image classification.",2024-12-27T07:16:11Z,http://arxiv.org/abs/2412.19491v1,"Mingyuan Jiu, Hailong Zhu, Hichem Sahbi"
UniBrain: A Unified Model for Cross-Subject Brain Decoding,"Brain decoding aims to reconstruct original stimuli from fMRI signals,
providing insights into interpreting mental content. Current approaches rely
heavily on subject-specific models due to the complex brain processing
mechanisms and the variations in fMRI signals across individuals. Therefore,
these methods greatly limit the generalization of models and fail to capture
cross-subject commonalities. To address this, we present UniBrain, a unified
brain decoding model that requires no subject-specific parameters. Our approach
includes a group-based extractor to handle variable fMRI signal lengths, a
mutual assistance embedder to capture cross-subject commonalities, and a
bilevel feature alignment scheme for extracting subject-invariant features. We
validate our UniBrain on the brain decoding benchmark, achieving comparable
performance to current state-of-the-art subject-specific models with extremely
fewer parameters. We also propose a generalization benchmark to encourage the
community to emphasize cross-subject commonalities for more general brain
decoding. Our code is available at https://github.com/xiaoyao3302/UniBrain.",2024-12-27T07:03:47Z,http://arxiv.org/abs/2412.19487v1,"Zicheng Wang, Zhen Zhao, Luping Zhou, Parashkev Nachev"
Learning Radiance Fields from a Single Snapshot Compressive Image,"In this paper, we explore the potential of Snapshot Compressive Imaging (SCI)
technique for recovering the underlying 3D scene structure from a single
temporal compressed image. SCI is a cost-effective method that enables the
recording of high-dimensional data, such as hyperspectral or temporal
information, into a single image using low-cost 2D imaging sensors. To achieve
this, a series of specially designed 2D masks are usually employed, reducing
storage and transmission requirements and offering potential privacy
protection. Inspired by this, we take one step further to recover the encoded
3D scene information leveraging powerful 3D scene representation capabilities
of neural radiance fields (NeRF). Specifically, we propose SCINeRF, in which we
formulate the physical imaging process of SCI as part of the training of NeRF,
allowing us to exploit its impressive performance in capturing complex scene
structures. In addition, we further integrate the popular 3D Gaussian Splatting
(3DGS) framework and propose SCISplat to improve 3D scene reconstruction
quality and training/rendering speed by explicitly optimizing point clouds into
3D Gaussian representations. To assess the effectiveness of our method, we
conduct extensive evaluations using both synthetic data and real data captured
by our SCI system. Experimental results demonstrate that our proposed approach
surpasses the state-of-the-art methods in terms of image reconstruction and
novel view synthesis. Moreover, our method also exhibits the ability to render
high frame-rate multi-view consistent images in real time by leveraging SCI and
the rendering capabilities of 3DGS. Codes will be available at:
https://github.com/WU- CVGL/SCISplat.",2024-12-27T06:40:44Z,http://arxiv.org/abs/2412.19483v1,"Yunhao Li, Xiang Liu, Xiaodong Wang, Xin Yuan, Peidong Liu"
"Exploiting Dynamic Sparsity for Near-Field Spatial Non-Stationary
  XL-MIMO Channel Tracking","This work considers a spatial non-stationary channel tracking problem in
broadband extremely large-scale multiple-input-multiple-output (XL-MIMO)
systems. In the case of spatial non-stationary, each scatterer has a certain
visibility region (VR) over antennas and power change may occur among visible
antennas. Concentrating on the temporal correlation of XL-MIMO channels, we
design a three-layer Markov prior model and hierarchical two-dimensional (2D)
Markov model to exploit the dynamic sparsity of sparse channel vectors and VRs,
respectively. Then, we formulate the channel tracking problem as a bilinear
measurement process, and a novel dynamic alternating maximum a posteriori
(DA-MAP) framework is developed to solve the problem. The DA-MAP contains four
basic modules: channel estimation module, VR detection module, grid update
module, and temporal correlated module. Specifically, the first module is an
inverse-free variational Bayesian inference (IF-VBI) estimator that avoids
computational intensive matrix inverse each iteration; the second module is a
turbo compressive sensing (Turbo-CS) algorithm that only needs small-scale
matrix operations in a parallel fashion; the third module refines the
polar-delay domain grid; and the fourth module can process the temporal prior
information to ensure high-efficiency channel tracking. Simulations show that
the proposed method can achieve a significant channel tracking performance
while achieving low computational overhead.",2024-12-27T06:00:30Z,http://arxiv.org/abs/2412.19475v1,"Wenkang Xu amd An Liu, Min-jian Zhao, Giuseppe Caire, Yik-Chung Wu"
Movable Antenna-Aided Near-Field Integrated Sensing and Communication,"Integrated sensing and communication (ISAC) is emerging as a pivotal
technology for next-generation wireless networks. However, existing ISAC
systems are based on fixed-position antennas (FPAs), which inevitably incur a
loss in performance when balancing the trade-off between sensing and
communication. Movable antenna (MA) technology offers promising potential to
enhance ISAC performance by enabling flexible antenna movement. Nevertheless,
exploiting more spatial channel variations requires larger antenna moving
regions, which may invalidate the conventional far-field assumption for
channels between transceivers. Therefore, this paper utilizes the MA to enhance
sensing and communication capabilities in near-field ISAC systems, where a
full-duplex base station (BS) is equipped with multiple transmit and receive
MAs movable in large-size regions to simultaneously sense multiple targets and
serve multiple uplink (UL) and downlink (DL) users for communication. We aim to
maximize the weighted sum of sensing and communication rates (WSR) by jointly
designing the transmit beamformers, sensing signal covariance matrices, receive
beamformers, and MA positions at the BS, as well as the UL power allocation.
The resulting optimization problem is challenging to solve, while we propose an
efficient two-layer random position (RP) algorithm to tackle it. In addition,
to reduce movement delay and cost, we design an antenna position matching (APM)
algorithm based on the greedy strategy to minimize the total MA movement
distance. Extensive simulation results demonstrate the substantial performance
improvement achieved by deploying MAs in near-field ISAC systems. Moreover, the
results show the effectiveness of the proposed APM algorithm in reducing the
antenna movement distance, which is helpful for energy saving and time overhead
reduction for MA-aided near-field ISAC systems with large moving regions.",2024-12-27T05:45:35Z,http://arxiv.org/abs/2412.19470v1,"Jingze Ding, Zijian Zhou, Xiaodan Shao, Bingli Jiao, Rui Zhang"
"MNet-SAt: A Multiscale Network with Spatial-enhanced Attention for
  Segmentation of Polyps in Colonoscopy","Objective: To develop a novel deep learning framework for the automated
segmentation of colonic polyps in colonoscopy images, overcoming the
limitations of current approaches in preserving precise polyp boundaries,
incorporating multi-scale features, and modeling spatial dependencies that
accurately reflect the intricate and diverse morphology of polyps. Methods: To
address these limitations, we propose a novel Multiscale Network with
Spatial-enhanced Attention (MNet-SAt) for polyp segmentation in colonoscopy
images. This framework incorporates four key modules: Edge-Guided Feature
Enrichment (EGFE) preserves edge information for improved boundary quality;
Multi-Scale Feature Aggregator (MSFA) extracts and aggregates multi-scale
features across channel spatial dimensions, focusing on salient regions;
Spatial-Enhanced Attention (SEAt) captures spatial-aware global dependencies
within the multi-scale aggregated features, emphasizing the region of interest;
and Channel-Enhanced Atrous Spatial Pyramid Pooling (CE-ASPP) resamples and
recalibrates attentive features across scales. Results: We evaluated MNet-SAt
on the Kvasir-SEG and CVC-ClinicDB datasets, achieving Dice Similarity
Coefficients of 96.61% and 98.60%, respectively. Conclusion: Both quantitative
(DSC) and qualitative assessments highlight MNet-SAt's superior performance and
generalization capabilities compared to existing methods. Significance:
MNet-SAt's high accuracy in polyp segmentation holds promise for improving
clinical workflows in early polyp detection and more effective treatment,
contributing to reduced colorectal cancer mortality rates.",2024-12-27T05:17:29Z,http://arxiv.org/abs/2412.19464v1,"Chandravardhan Singh Raghaw, Aryan Yadav, Jasmer Singh Sanjotra, Shalini Dangi, Nagendra Kumar"
A Prototype Unit for Image De-raining using Time-Lapse Data,"We address the challenge of single-image de-raining, a task that involves
recovering rain-free background information from a single rain image. While
recent advancements have utilized real-world time-lapse data for training,
enabling the estimation of consistent backgrounds and realistic rain streaks,
these methods often suffer from computational and memory consumption, limiting
their applicability in real-world scenarios. In this paper, we introduce a
novel solution: the Rain Streak Prototype Unit (RsPU). The RsPU efficiently
encodes rain streak-relevant features as real-time prototypes derived from
time-lapse data, eliminating the need for excessive memory resources. Our
de-raining network combines encoder-decoder networks with the RsPU, allowing us
to learn and encapsulate diverse rain streak-relevant features as concise
prototypes, employing an attention-based approach. To ensure the effectiveness
of our approach, we propose a feature prototype loss encompassing cohesion and
divergence components. This loss function captures both the compactness and
diversity aspects of the prototypical rain streak features within the RsPU. Our
method evaluates various de-raining benchmarks, accompanied by comprehensive
ablation studies. We show that it can achieve competitive results in various
rain images compared to state-of-the-art methods.",2024-12-27T05:04:56Z,http://arxiv.org/abs/2412.19459v1,"Jaehoon Cho, Minjung Yoo, Jini Yang, Sunok Kim"
"DriveEditor: A Unified 3D Information-Guided Framework for Controllable
  Object Editing in Driving Scenes","Vision-centric autonomous driving systems require diverse data for robust
training and evaluation, which can be augmented by manipulating object
positions and appearances within existing scene captures. While recent
advancements in diffusion models have shown promise in video editing, their
application to object manipulation in driving scenarios remains challenging due
to imprecise positional control and difficulties in preserving high-fidelity
object appearances. To address these challenges in position and appearance
control, we introduce DriveEditor, a diffusion-based framework for object
editing in driving videos. DriveEditor offers a unified framework for
comprehensive object editing operations, including repositioning, replacement,
deletion, and insertion. These diverse manipulations are all achieved through a
shared set of varying inputs, processed by identical position control and
appearance maintenance modules. The position control module projects the given
3D bounding box while preserving depth information and hierarchically injects
it into the diffusion process, enabling precise control over object position
and orientation. The appearance maintenance module preserves consistent
attributes with a single reference image by employing a three-tiered approach:
low-level detail preservation, high-level semantic maintenance, and the
integration of 3D priors from a novel view synthesis model. Extensive
qualitative and quantitative evaluations on the nuScenes dataset demonstrate
DriveEditor's exceptional fidelity and controllability in generating diverse
driving scene edits, as well as its remarkable ability to facilitate downstream
tasks.",2024-12-27T04:49:36Z,http://arxiv.org/abs/2412.19458v1,"Yiyuan Liang, Zhiying Yan, Liqun Chen, Jiahuan Zhou, Luxin Yan, Sheng Zhong, Xu Zou"
"Feature Alignment-Based Knowledge Distillation for Efficient Compression
  of Large Language Models","This study proposes a knowledge distillation algorithm based on large
language models and feature alignment, aiming to effectively transfer the
knowledge of large pre-trained models into lightweight student models, thereby
reducing computational costs while maintaining high model performance.
Different from the traditional soft label distillation method, this method
introduces a multi-layer feature alignment strategy to deeply align the
intermediate features and attention mechanisms of the teacher model and the
student model, maximally retaining the semantic expression ability and context
modeling ability of the teacher model. In terms of method design, a multi-task
loss function is constructed, including feature matching loss, attention
alignment loss, and output distribution matching loss, to ensure multi-level
information transfer through joint optimization. The experiments were
comprehensively evaluated on the GLUE data set and various natural language
processing tasks. The results show that the proposed model performs very close
to the state-of-the-art GPT-4 model in terms of evaluation indicators such as
perplexity, BLEU, ROUGE, and CER. At the same time, it far exceeds baseline
models such as DeBERTa, XLNet, and GPT-3, showing significant performance
improvements and computing efficiency advantages. Research results show that
the feature alignment distillation strategy is an effective model compression
method that can significantly reduce computational overhead and storage
requirements while maintaining model capabilities. Future research can be
further expanded in the directions of self-supervised learning, cross-modal
feature alignment, and multi-task transfer learning to provide more flexible
and efficient solutions for the deployment and optimization of deep learning
models.",2024-12-27T04:37:06Z,http://arxiv.org/abs/2412.19449v1,"Shuo Wang, Chihang Wang, Jia Gao, Zhen Qi, Hongye Zheng, Xiaoxuan Liao"
The Rendezvous Between Extreme Value Theory and Next-generation Networks,"Promising technologies such as massive multiple-input and multiple-output,
reconfigurable intelligent reflecting surfaces, non-terrestrial networks,
millimetre wave communication, ultra-reliable lowlatency communication are
envisioned as the enablers for next-generation (NG) networks. In contrast to
conventional communication systems meeting specific average performance
requirements, NG systems are expected to meet quality-of-service requirements
in extreme scenarios as well. In this regard, extreme value theory (EVT)
provides a powerful framework for the design of communication systems. In this
paper, we provide a comprehensive survey of advances in communication that
utilize EVT to characterize the extreme order statistics of interest. We first
give an overview of the history of EVT and then elaborate on the fundamental
theorems. Subsequently, we discuss different problems of interest in NG
communication systems and how EVT can be utilized for their analysis. We
finally point out the open challenges and future directions of EVT in NG
communication systems.",2024-12-27T04:06:32Z,http://arxiv.org/abs/2412.19438v1,"Srinivas Sagar, Athira Subhash, Chen-Feng Liu, Ahmed Elzanaty, Yazan H. Al-Badarneh, Sheetal Kalyani, Mohamed-Slim Alouini, Mehdi Bennis, Lajos Hanzo"
"Low-Rank Contextual Reinforcement Learning from Heterogeneous Human
  Feedback","Reinforcement learning from human feedback (RLHF) has become a cornerstone
for aligning large language models with human preferences. However, the
heterogeneity of human feedback, driven by diverse individual contexts and
preferences, poses significant challenges for reward learning. To address this,
we propose a Low-rank Contextual RLHF (LoCo-RLHF) framework that integrates
contextual information to better model heterogeneous feedback while maintaining
computational efficiency. Our approach builds on a contextual preference model,
leveraging the intrinsic low-rank structure of the interaction between user
contexts and query-answer pairs to mitigate the high dimensionality of feature
representations. Furthermore, we address the challenge of distributional shifts
in feedback through our Pessimism in Reduced Subspace (PRS) policy, inspired by
pessimistic offline reinforcement learning techniques. We theoretically
demonstrate that our policy achieves a tighter sub-optimality gap compared to
existing methods. Extensive experiments validate the effectiveness of
LoCo-RLHF, showcasing its superior performance in personalized RLHF settings
and its robustness to distribution shifts.",2024-12-27T04:02:46Z,http://arxiv.org/abs/2412.19436v1,"Seong Jin Lee, Will Wei Sun, Yufeng Liu"
"Residual Feature-Reutilization Inception Network for Image
  Classification","Capturing feature information effectively is of great importance in the field
of computer vision. With the development of convolutional neural networks
(CNNs), concepts like residual connection and multiple scales promote continual
performance gains in diverse deep learning vision tasks. In this paper, we
propose a novel CNN architecture that it consists of residual
feature-reutilization inceptions (ResFRI) or split-residual
feature-reutilization inceptions (Split-ResFRI). And it is composed of four
convolutional combinations of different structures connected by specially
designed information interaction passages, which are utilized to extract
multi-scale feature information and effectively increase the receptive field of
the model. Moreover, according to the network structure designed above,
Split-ResFRI can adjust the segmentation ratio of the input information,
thereby reducing the number of parameters and guaranteeing the model
performance. Specifically, in experiments based on popular vision datasets,
such as CIFAR10 ($97.94$\%), CIFAR100 ($85.91$\%) and Tiny Imagenet
($70.54$\%), we obtain state-of-the-art results compared with other modern
models under the premise that the model size is approximate and no additional
data is used.",2024-12-27T03:55:25Z,http://arxiv.org/abs/2412.19433v1,"Yuanpeng He, Wenjie Song, Lijian Li, Tianxiang Zhan, Wenpin Jiao"
Revisiting PCA for time series reduction in temporal dimension,"Revisiting PCA for Time Series Reduction in Temporal Dimension; Jiaxin Gao,
Wenbo Hu, Yuntian Chen; Deep learning has significantly advanced time series
analysis (TSA), enabling the extraction of complex patterns for tasks like
classification, forecasting, and regression. Although dimensionality reduction
has traditionally focused on the variable space-achieving notable success in
minimizing data redundancy and computational complexity-less attention has been
paid to reducing the temporal dimension. In this study, we revisit Principal
Component Analysis (PCA), a classical dimensionality reduction technique, to
explore its utility in temporal dimension reduction for time series data. It is
generally thought that applying PCA to the temporal dimension would disrupt
temporal dependencies, leading to limited exploration in this area. However,
our theoretical analysis and extensive experiments demonstrate that applying
PCA to sliding series windows not only maintains model performance, but also
enhances computational efficiency. In auto-regressive forecasting, the temporal
structure is partially preserved through windowing, and PCA is applied within
these windows to denoise the time series while retaining their statistical
information. By preprocessing time-series data with PCA, we reduce the temporal
dimensionality before feeding it into TSA models such as Linear, Transformer,
CNN, and RNN architectures. This approach accelerates training and inference
and reduces resource consumption. Notably, PCA improves Informer training and
inference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%,
without sacrificing model accuracy. Comparative analysis against other
reduction methods further highlights the effectiveness of PCA in improving the
efficiency of TSA models.",2024-12-27T03:17:26Z,http://arxiv.org/abs/2412.19423v1,"Jiaxin Gao, Wenbo Hu, Yuntian Chen"
"Gx2Mol: De Novo Generation of Hit-like Molecules from Gene Expression
  Profiles via Deep Learning","De novo generation of hit-like molecules is a challenging task in the drug
discovery process. Most methods in previous studies learn the semantics and
syntax of molecular structures by analyzing molecular graphs or simplified
molecular input line entry system (SMILES) strings; however, they do not take
into account the drug responses of the biological systems consisting of genes
and proteins. In this study we propose a deep generative model, Gx2Mol, which
utilizes gene expression profiles to generate molecular structures with
desirable phenotypes for arbitrary target proteins. In the algorithm, a
variational autoencoder is employed as a feature extractor to learn the latent
feature distribution of the gene expression profiles. Then, a long short-term
memory is leveraged as the chemical generator to produce syntactically valid
SMILES strings that satisfy the feature conditions of the gene expression
profile extracted by the feature extractor. Experimental results and case
studies demonstrate that the proposed Gx2Mol model can produce new molecules
with potential bioactivities and drug-like properties.",2024-12-27T03:16:56Z,http://arxiv.org/abs/2412.19422v1,"Chen Li, Yuki Matsukiyo, Yoshihiro Yamanishi"
"Adiabatic topological passage based on coupling of giant atom with two
  Su-Schrieffer-Heeger chains","We study an adiabatic topological passage of two Su-Schrieffer-Heeger (SSH)
chains mediated by a giant atom. When two finite SSH chains are in the
topological phase and the frequency of the giant atom is equal to the center
frequency of the SSH chains, the system is reduced to a subsystem that
describes the coupling of a giant atom to the edge states of two SSH chains. In
this case, we can find dark states that act as adiabatic topological passages.
This allows us to adiabatically transfer excitations of the giant atom to
either one end of two SSH chains in a fully controllable way. In addition, we
show good robustness of the adiabatic topological passages to both giant atom
frequency mismatch and the coupling disorders in two SSH chains. Our study
provides a method to realize quantum information processing and fabricate
quantum optical devices based on the coupling of the giant atom to topological
matter.",2024-12-27T03:15:49Z,http://arxiv.org/abs/2412.19421v1,"Da-Wei Wang, Ling Zhou, Yu-xi Liu"
"Generalized Uncertainty-Based Evidential Fusion with Hybrid Multi-Head
  Attention for Weak-Supervised Temporal Action Localization","Weakly supervised temporal action localization (WS-TAL) is a task of
targeting at localizing complete action instances and categorizing them with
video-level labels. Action-background ambiguity, primarily caused by background
noise resulting from aggregation and intra-action variation, is a significant
challenge for existing WS-TAL methods. In this paper, we introduce a hybrid
multi-head attention (HMHA) module and generalized uncertainty-based evidential
fusion (GUEF) module to address the problem. The proposed HMHA effectively
enhances RGB and optical flow features by filtering redundant information and
adjusting their feature distribution to better align with the WS-TAL task.
Additionally, the proposed GUEF adaptively eliminates the interference of
background noise by fusing snippet-level evidences to refine uncertainty
measurement and select superior foreground feature information, which enables
the model to concentrate on integral action instances to achieve better action
localization and classification performance. Experimental results conducted on
the THUMOS14 dataset demonstrate that our method outperforms state-of-the-art
methods. Our code is available in
\url{https://github.com/heyuanpengpku/GUEF/tree/main}.",2024-12-27T03:04:57Z,http://arxiv.org/abs/2412.19418v1,"Yuanpeng He, Lijian Li, Tianxiang Zhan, Wenpin Jiao, Chi-Man Pun"
KALAHash: Knowledge-Anchored Low-Resource Adaptation for Deep Hashing,"Deep hashing has been widely used for large-scale approximate nearest
neighbor search due to its storage and search efficiency. However, existing
deep hashing methods predominantly rely on abundant training data, leaving the
more challenging scenario of low-resource adaptation for deep hashing
relatively underexplored. This setting involves adapting pre-trained models to
downstream tasks with only an extremely small number of training samples
available. Our preliminary benchmarks reveal that current methods suffer
significant performance degradation due to the distribution shift caused by
limited training samples. To address these challenges, we introduce
Class-Calibration LoRA (CLoRA), a novel plug-and-play approach that dynamically
constructs low-rank adaptation matrices by leveraging class-level textual
knowledge embeddings. CLoRA effectively incorporates prior class knowledge as
anchors, enabling parameter-efficient fine-tuning while maintaining the
original data distribution. Furthermore, we propose Knowledge-Guided Discrete
Optimization (KIDDO), a framework to utilize class knowledge to compensate for
the scarcity of visual information and enhance the discriminability of hash
codes. Extensive experiments demonstrate that our proposed method, Knowledge-
Anchored Low-Resource Adaptation Hashing (KALAHash), significantly boosts
retrieval performance and achieves a 4x data efficiency in low-resource
scenarios.",2024-12-27T03:04:54Z,http://arxiv.org/abs/2412.19417v1,"Shu Zhao, Tan Yu, Xiaoshuai Hao, Wenchao Ma, Vijaykrishnan Narayanan"
MINIMA: Modality Invariant Image Matching,"Image matching for both cross-view and cross-modality plays a critical role
in multimodal perception. In practice, the modality gap caused by different
imaging systems/styles poses great challenges to the matching task. Existing
works try to extract invariant features for specific modalities and train on
limited datasets, showing poor generalization. In this paper, we present
MINIMA, a unified image matching framework for multiple cross-modal cases.
Without pursuing fancy modules, our MINIMA aims to enhance universal
performance from the perspective of data scaling up. For such purpose, we
propose a simple yet effective data engine that can freely produce a large
dataset containing multiple modalities, rich scenarios, and accurate matching
labels. Specifically, we scale up the modalities from cheap but rich RGB-only
matching data, by means of generative models. Under this setting, the matching
labels and rich diversity of the RGB dataset are well inherited by the
generated multimodal data. Benefiting from this, we construct MD-syn, a new
comprehensive dataset that fills the data gap for general multimodal image
matching. With MD-syn, we can directly train any advanced matching pipeline on
randomly selected modality pairs to obtain cross-modal ability. Extensive
experiments on in-domain and zero-shot matching tasks, including $19$
cross-modal cases, demonstrate that our MINIMA can significantly outperform the
baselines and even surpass modality-specific methods. The dataset and code are
available at https://github.com/LSXI7/MINIMA .",2024-12-27T02:39:50Z,http://arxiv.org/abs/2412.19412v1,"Xingyu Jiang, Jiangwei Ren, Zizhuo Li, Xin Zhou, Dingkang Liang, Xiang Bai"
"MLLM-SUL: Multimodal Large Language Model for Semantic Scene
  Understanding and Localization in Traffic Scenarios","Multimodal large language models (MLLMs) have shown satisfactory effects in
many autonomous driving tasks. In this paper, MLLMs are utilized to solve joint
semantic scene understanding and risk localization tasks, while only relying on
front-view images. In the proposed MLLM-SUL framework, a dual-branch visual
encoder is first designed to extract features from two resolutions, and rich
visual information is conducive to the language model describing risk objects
of different sizes accurately. Then for the language generation, LLaMA model is
fine-tuned to predict scene descriptions, containing the type of driving
scenario, actions of risk objects, and driving intentions and suggestions of
ego-vehicle. Ultimately, a transformer-based network incorporating a regression
token is trained to locate the risk objects. Extensive experiments on the
existing DRAMA-ROLISP dataset and the extended DRAMA-SRIS dataset demonstrate
that our method is efficient, surpassing many state-of-the-art image-based and
video-based methods. Specifically, our method achieves 80.1% BLEU-1 score and
298.5% CIDEr score in the scene understanding task, and 59.6% accuracy in the
localization task. Codes and datasets are available at
https://github.com/fjq-tongji/MLLM-SUL.",2024-12-27T02:05:38Z,http://arxiv.org/abs/2412.19406v1,"Jiaqi Fan, Jianhua Wu, Jincheng Gao, Jianhao Yu, Yafei Wang, Hongqing Chu, Bingzhao Gao"
"Online distributed algorithms for mixed equilibrium problems in dynamic
  environments","In this paper, the mixed equilibrium problem with coupled inequality
constraints in dynamic environments is solved by employing a multi-agent
system, where each agent only has access to its own bifunction, its own
constraint function, and can only communicate with its immediate neighbors via
a time-varying digraph. At each time, the goal of agents is to cooperatively
find a point in the constraint set such that the sum of local bifunctions with
a free variable is non-negative. Different from existing works, here the
bifunctions and the constraint functions are time-varying and only available to
agents after decisions are made. To tackle this problem, first, an online
distributed algorithm involving accurate gradient information is proposed based
on mirror descent algorithms and primal-dual strategies. Of particular interest
is that dynamic regrets, whose offline benchmarks are to find the solution at
each time, are employed to measure the performance of the algorithm. Under mild
assumptions on the graph and the bifunctions, we prove that if the deviation in
the solution sequence grows within a certain rate, then both the dynamic regret
and the violation of coupled inequality constraints increase sublinearly.
Second, considering the case where each agent only has access to a noisy
estimate on the accurate gradient, we propose an online distributed algorithm
involving the stochastic gradients. The result shows that under the same
conditions as in the first case, if the noise distribution satisfies the
sub-Gaussian condition, then dynamic regrets, as well as constraint violations,
increase sublinearly with high probability. Finally, several simulation
examples are presented to corroborate the validity of our results.",2024-12-27T01:26:26Z,http://arxiv.org/abs/2412.19399v1,"Hang Xu, Kaihong Lu, Yu-Long Wang, Qixin Zhu"
"A Generalized Einstein Relation for Markovian Friction Coefficients from
  Molecular Trajectories","We present a generalized Einstein relation for the friction coefficients
associated with an underlying memory kernel in terms of observable time
correlation functions. There is considerable freedom in the correlations
involved, and this allows the expression to be tailored to the particular
system to achieve numerical stability. We demonstrate this by recovering the
site-specific friction coefficients from trajectories of a freely diffusing
model trimer, and we show that the accuracy is greatly improved over
established Volterra inversion methods for kernel extraction.",2024-12-27T01:20:37Z,http://arxiv.org/abs/2412.19398v1,"J. M. Hall, M. G. Guenza"
"Comparing Few to Rank Many: Active Human Preference Learning using
  Randomized Frank-Wolfe","We study learning of human preferences from a limited comparison feedback.
This task is ubiquitous in machine learning. Its applications such as
reinforcement learning from human feedback, have been transformational. We
formulate this problem as learning a Plackett-Luce model over a universe of $N$
choices from $K$-way comparison feedback, where typically $K \ll N$. Our
solution is the D-optimal design for the Plackett-Luce objective. The design
defines a data logging policy that elicits comparison feedback for a small
collection of optimally chosen points from all ${N \choose K}$ feasible
subsets. The main algorithmic challenge in this work is that even fast methods
for solving D-optimal designs would have $O({N \choose K})$ time complexity. To
address this issue, we propose a randomized Frank-Wolfe (FW) algorithm that
solves the linear maximization sub-problems in the FW method on randomly chosen
variables. We analyze the algorithm, and evaluate it empirically on synthetic
and open-source NLP datasets.",2024-12-27T01:10:17Z,http://arxiv.org/abs/2412.19396v1,"Kiran Koshy Thekumparampil, Gaurush Hiranandani, Kousha Kalantari, Shoham Sabach, Branislav Kveton"
"BeSplat -- Gaussian Splatting from a Single Blurry Image and Event
  Stream","Novel view synthesis has been greatly enhanced by the development of radiance
field methods. The introduction of 3D Gaussian Splatting (3DGS) has effectively
addressed key challenges, such as long training times and slow rendering
speeds, typically associated with Neural Radiance Fields (NeRF), while
maintaining high-quality reconstructions. In this work (BeSplat), we
demonstrate the recovery of sharp radiance field (Gaussian splats) from a
single motion-blurred image and its corresponding event stream. Our method
jointly learns the scene representation via Gaussian Splatting and recovers the
camera motion through Bezier SE(3) formulation effectively, minimizing
discrepancies between synthesized and real-world measurements of both blurry
image and corresponding event stream. We evaluate our approach on both
synthetic and real datasets, showcasing its ability to render view-consistent,
sharp images from the learned radiance field and the estimated camera
trajectory. To the best of our knowledge, ours is the first work to address
this highly challenging ill-posed problem in a Gaussian Splatting framework
with the effective incorporation of temporal information captured using the
event stream.",2024-12-26T22:35:29Z,http://arxiv.org/abs/2412.19370v1,"Gopi Raju Matta, Reddypalli Trisha, Kaushik Mitra"
Neuromorphic Dual-channel Encoding of Luminance and Contrast,"There is perceptual and physiological evidence that the retina registers and
signals luminance and luminance contrast using dual-channel mechanisms. This
process begins in the retina, wherein the luminance of a uniform zone and
differentials of luminance in neighboring zones determine the degree of
brightness or darkness of the zones. The neurons that process the information
can be classified as ""bright"" or ""dark"" channels. The present paper provides an
overview of these retinal mechanisms along with evidence that they provide
brightness judgments that are log-linear across roughly seven orders of
magnitude.",2024-12-26T22:09:30Z,http://arxiv.org/abs/2412.19365v1,Ernest Greene
"Evaluating Convolutional Neural Networks for COVID-19 classification in
  chest X-ray images","Coronavirus Disease 2019 (COVID-19) pandemic rapidly spread globally,
impacting the lives of billions of people. The effective screening of infected
patients is a critical step to struggle with COVID-19, and treating the
patients avoiding this quickly disease spread. The need for automated and
scalable methods has increased due to the unavailability of accurate automated
toolkits. Recent researches using chest X-ray images suggest they include
relevant information about the COVID-19 virus. Hence, applying machine learning
techniques combined with radiological imaging promises to identify this disease
accurately. It is straightforward to collect these images once it is spreadly
shared and analyzed in the world. This paper presents a method for automatic
COVID-19 detection using chest Xray images through four convolutional neural
networks, namely: AlexNet, VGG-11, SqueezeNet, and DenseNet-121. This method
had been providing accurate diagnostics for positive or negative COVID-19
classification. We validate our experiments using a ten-fold cross-validation
procedure over the training and test sets. Our findings include the shallow
fine-tuning and data augmentation strategies that can assist in dealing with
the low number of positive COVID-19 images publicly available. The accuracy for
all CNNs is higher than 97.00%, and the SqueezeNet model achieved the best
result with 99.20%.",2024-12-26T22:05:30Z,http://arxiv.org/abs/2412.19362v1,"Leonardo Gabriel Ferreira Rodrigues, Danilo Ferreira da Silva, Larissa Ferreira Rodrigues, João Fernando Mari"
Microscopic imprints of learned solutions in adaptive resistor networks,"In physical networks trained using supervised learning, physical parameters
are adjusted to produce desired responses to inputs. An example is electrical
contrastive local learning networks of nodes connected by edges that are
resistors that adjust their conductances during training. When an edge
conductance changes, it upsets the current balance of every node. In response,
physics adjusts the node voltages to minimize the dissipated power. Learning in
these systems is therefore a coupled double-optimization process, in which the
network descends both a cost landscape in the high-dimensional space of edge
conductances, and a physical landscape -- the power -- in the high-dimensional
space of node voltages. Because of this coupling, the physical landscape of a
trained network contains information about the learned task. Here we
demonstrate that all the physical information relevant to the trained
input-output relation can be captured by a susceptibility, an experimentally
measurable quantity. We supplement our theoretical results with simulations to
show that the susceptibility is positively correlated with functional
importance and that we can extract physical insight into how the system
performs the task from the conductances of highly susceptible edges.",2024-12-26T21:36:23Z,http://arxiv.org/abs/2412.19356v1,"Marcel Guzman, Felipe Martins, Menachem Stern, Andrea J. Liu"
"Experimental demonstration and modeling of near-infrared nonlinear
  third-order triple-photon generation stimulated over one mode","Triple Photon Generation (TPG) is a third-order nonlinear optical interaction
in which a photon, i.e. the pump, splits into three lower energy photons, i.e.
modes 1, 2 and 3. The triplets possess different quantum signatures from those
of photon pairs, with a strong interest in quantum information. In the present
study, we performed the first experimental demonstration of TPG stimulated over
one mode of the triplet, mode 1, the previous work on TPG concerning
stimulation over two modes,2 and 3. The nonlinear medium is a KTiOPO4 crystal
pumped in the picosecond regime (15 ps, 10 Hz) at a pump wavelength of 532 nm.
The stimulation beam is emitted by a tunable optical parametric generator: the
phase-matching was found at a stimulation wavelength of 1491 nm, the other two
modes of the triplet being both at 1654 nm in orthogonal polarizations. Using
superconducting nanowires single photon detectors, the measurement of the
polarizations and wavelength signatures of the two generated modes are in full
agreement with calculations. It has been possible to generate a total number of
photons per pulse on modes 2 and 3 up to 2x10-4, which corresponds to the
generation of 10-4 triplets per pulse, or 10-5 triplets per second since the
repetition rate is equal to 10 Hz. We interpreted these results in the
framework of a model we developed on the basis of the nonlinear momentum
operator in the Heisenberg representation under the undepleted pump and
stimulation approximation.",2024-12-26T20:42:17Z,http://arxiv.org/abs/2412.19348v1,"Julien Bertrand, Veronique Boutou, Corinne Felix, David Jegouso, Benoit Boulanger"
"Semi-Supervised Learning from Small Annotated Data and Large Unlabeled
  Data for Fine-grained PICO Entity Recognition","Objective: Extracting PICO elements -- Participants, Intervention,
Comparison, and Outcomes -- from clinical trial literature is essential for
clinical evidence retrieval, appraisal, and synthesis. Existing approaches do
not distinguish the attributes of PICO entities. This study aims to develop a
named entity recognition (NER) model to extract PICO entities with fine
granularities.
  Materials and Methods: Using a corpus of 2,511 abstracts with PICO mentions
from 4 public datasets, we developed a semi-supervised method to facilitate the
training of a NER model, FinePICO, by combining limited annotated data of PICO
entities and abundant unlabeled data. For evaluation, we divided the entire
dataset into two subsets: a smaller group with annotations and a larger group
without annotations. We then established the theoretical lower and upper
performance bounds based on the performance of supervised learning models
trained solely on the small, annotated subset and on the entire set with
complete annotations, respectively. Finally, we evaluated FinePICO on both the
smaller annotated subset and the larger, initially unannotated subset. We
measured the performance of FinePICO using precision, recall, and F1.
  Results: Our method achieved precision/recall/F1 of 0.567/0.636/0.60,
respectively, using a small set of annotated samples, outperforming the
baseline model (F1: 0.437) by more than 16\%. The model demonstrates
generalizability to a different PICO framework and to another corpus, which
consistently outperforms the benchmark in diverse experimental settings
(p-value \textless0.001).
  Conclusion: This study contributes a generalizable and effective
semi-supervised approach to named entity recognition leveraging large unlabeled
data together with small, annotated data. It also initially supports
fine-grained PICO extraction.",2024-12-26T20:24:35Z,http://arxiv.org/abs/2412.19346v1,"Fangyi Chen, Gongbo Zhang, Yilu Fang, Yifan Peng, Chunhua Weng"
"Sparse recovery from quadratic equations, part II: hardness and
  incoherence","We study the square root bottleneck in the recovery of sparse vectors from
quadratic equations. It is acknowledged that a sparse vector $ \mathbf x_0\in
\mathbb{R}^n$, $\| \mathbf x_0\|_0 = k$ can in theory be recovered from as few
as $O(k)$ generic quadratic equations but no polynomial time algorithm is known
for this task unless $m = \Omega(k^2)$. This bottleneck was in fact shown in
previous work to be essentially related to the initialization of descent
algorithms. Starting such algorithms sufficiently close to the planted signal
is known to imply convergence to this signal. In this paper, we show that as
soon as $m\gtrsim \mu_0^{-2}k \vee \mu_0^{-4}$ (up to log factors) where $\mu_0
= \| \mathbf x_0\|_\infty/\| \mathbf x_0\|_2$, it is possible to recover a
$k$-sparse vector $ \mathbf x_0\in \mathbb{R}^n$ from $m$ quadratic equations
of the form $\langle \mathbf A_i, \mathbf x \mathbf x^\intercal\rangle =
\langle \mathbf A_i, \mathbf x_0 \mathbf x_0^\intercal\rangle + \varepsilon_i $
by minimizing the classical empirical loss. The proof idea carries over to the
phase retrieval setting for which it provides an original initialization that
matches the current optimal sample complexity (see e.g. [Cai 2023]). In the
maximally incoherent regime $\mu_0^{-2}=k$, and for $m=o(k^2)$ we provide
evidence for topological hardness by showing that a property known as the
Overlap Gap Property (OGP), which originated in spin glass theory and is
conjectured to be indicative of algorithmic intractability when optimizing over
random structures, holds for a particular level of overparametrization. The key
ingredient of the proof is a lower bound on the tail of chi-squared random
variables which follows from the theory of moderate deviations.",2024-12-26T20:11:44Z,http://arxiv.org/abs/2412.19341v1,Augustin Cosse
"CALICO: Part-Focused Semantic Co-Segmentation with Large Vision-Language
  Models","Recent advances in Large Vision-Language Models (LVLMs) have sparked
significant progress in general-purpose vision tasks through visual instruction
tuning. While some works have demonstrated the capability of LVLMs to generate
segmentation masks that align phrases with natural language descriptions in a
single image, they struggle with segmentation-grounded comparisons across
multiple images, particularly at finer granularities such as object parts. In
this paper, we introduce the new task of part-focused semantic co-segmentation,
which seeks to identify and segment common and unique objects and parts across
images. To address this task, we present CALICO, the first LVLM that can
segment and reason over multiple masks across images, enabling object
comparison based on their constituent parts. CALICO features two proposed
components, a novel Correspondence Extraction Module, which captures
semantic-rich information to identify part-level correspondences between
objects, and a Correspondence Adaptation Module, which embeds this information
into the LVLM to facilitate multi-image understanding in a parameter-efficient
manner. To support training and evaluation, we curate MixedParts, a
comprehensive multi-image segmentation dataset containing $\sim$2.4M samples
across $\sim$44K images with diverse object and part categories. Experimental
results show CALICO, finetuned on only 0.3% of its architecture, achieves
robust performance in part-focused semantic co-segmentation.",2024-12-26T18:59:37Z,http://arxiv.org/abs/2412.19331v1,"Kiet A. Nguyen, Adheesh Juvekar, Tianjiao Yu, Muntasir Wahed, Ismini Lourentzou"
"Resolving the Ambiguity of Complete-to-Partial Point Cloud Registration
  for Image-Guided Liver Surgery with Patches-to-Partial Matching","In image-guided liver surgery, the initial rigid alignment between
preoperative and intraoperative data, often represented as point clouds, is
crucial for providing sub-surface information from preoperative CT/MRI images
to the surgeon during the procedure. Currently, this alignment is typically
performed using semi-automatic methods, which, while effective to some extent,
are prone to errors that demand manual correction. Point cloud
correspondence-based registration methods are promising to serve as a fully
automatic solution. However, they may struggle in scenarios with limited
intraoperative surface visibility, a common challenge in liver surgery,
particularly in laparoscopic procedures, which we refer to as
complete-to-partial ambiguity. We first illustrate this ambiguity by evaluating
the performance of state-of-the-art learning-based point cloud registration
methods on our carefully constructed in silico and in vitro datasets. Then, we
propose a patches-to-partial matching strategy as a plug-and-play module to
resolve the ambiguity, which can be seamlessly integrated into learning-based
registration methods without disrupting their end-to-end structure. It has
proven effective and efficient in improving registration performance for cases
with limited intraoperative visibility. The constructed benchmark and the
proposed module establish a solid foundation for advancing applications of
point cloud correspondence-based registration methods in image-guided liver
surgery.",2024-12-26T18:58:29Z,http://arxiv.org/abs/2412.19328v1,"Zixin Yang, Jon S. Heiselman, Cheng Han, Kelly Merrell, Richard Simon, Cristian. A. Linte"
"A novel framework for MCDM based on Z numbers and soft likelihood
  function","The optimization on the structure of process of information management under
uncertain environment has attracted lots of attention from researchers around
the world. Nevertheless, how to obtain accurate and rational evaluation from
assessments produced by experts is still an open problem. Specially,
intuitionistic fuzzy set provides an effective solution in handling
indeterminate information. And Yager proposes a novel method for fusion of
probabilistic evidence to handle uncertain and conflicting information lately
which is called soft likelihood function. This paper devises a novel framework
of soft likelihood function based on information volume of fuzzy membership and
credibility measure for extracting truly useful and valuable information from
uncertainty. An application is provided to verify the validity and correctness
of the proposed framework. Besides, the comparisons with other existing methods
further demonstrate the superiority of the novel framework of soft likelihood
function.",2024-12-26T18:47:19Z,http://arxiv.org/abs/2412.19321v1,Yuanpeng He
Thermodynamic reduction of contact dynamics,"A universal algorithm to derive a macroscopic dynamics from the microscopic
dynamical system via the averaging process and symplecto-contact reduction was
introduced by Jin-wook Lim and the second-named author in [LO23]. They apply
the algorithm to derive non-equilibrium thermodynamics from the statistical
mechanics utilizing the relative information entropy as a generating function
of the associated thermodynamic equilibrium. In the present paper, we apply
this algorithm to the contact Hamiltonian dynamical systems. We describe a
procedure of obtaining a discrete set of dynamical invariants of the given
contact Hamiltonian system, or more generally of a contact multi-Hamiltonian
system in a canonical way by deriving a (finite-dimensional non-equilibrium)
thermodynamic system. We call this reduction the thermodynamic reduction of
contact dynamics.",2024-12-26T18:42:11Z,http://arxiv.org/abs/2412.19319v1,"Hyun-Seok Do, Yong-Geun Oh"
"From Interets to Insights: An LLM Approach to Course Recommendations
  Using Natural Language Queries","Most universities in the United States encourage their students to explore
academic areas before declaring a major and to acquire academic breadth by
satisfying a variety of requirements. Each term, students must choose among
many thousands of offerings, spanning dozens of subject areas, a handful of
courses to take. The curricular environment is also dynamic, and poor
communication and search functions on campus can limit a student's ability to
discover new courses of interest. To support both students and their advisers
in such a setting, we explore a novel Large Language Model (LLM) course
recommendation system that applies a Retrieval Augmented Generation (RAG)
method to the corpus of course descriptions. The system first generates an
'ideal' course description based on the user's query. This description is
converted into a search vector using embeddings, which is then used to find
actual courses with similar content by comparing embedding similarities. We
describe the method and assess the quality and fairness of some example
prompts. Steps to deploy a pilot system on campus are discussed.",2024-12-26T18:19:53Z,http://arxiv.org/abs/2412.19312v1,"Hugh Van Deventer, Mark Mills, August Evrard"
"Perceive, Query &amp; Reason: Enhancing Video QA with Question-Guided
  Temporal Queries","Video Question Answering (Video QA) is a challenging video understanding task
that requires models to comprehend entire videos, identify the most relevant
information based on contextual cues from a given question, and reason
accurately to provide answers. Recent advancements in Multimodal Large Language
Models (MLLMs) have transformed video QA by leveraging their exceptional
commonsense reasoning capabilities. This progress is largely driven by the
effective alignment between visual data and the language space of MLLMs.
However, for video QA, an additional space-time alignment poses a considerable
challenge for extracting question-relevant information across frames. In this
work, we investigate diverse temporal modeling techniques to integrate with
MLLMs, aiming to achieve question-guided temporal modeling that leverages
pre-trained visual and textual alignment in MLLMs. We propose T-Former, a novel
temporal modeling method that creates a question-guided temporal bridge between
frame-wise visual perception and the reasoning capabilities of LLMs. Our
evaluation across multiple video QA benchmarks demonstrates that T-Former
competes favorably with existing temporal modeling approaches and aligns with
recent advancements in video QA.",2024-12-26T17:53:14Z,http://arxiv.org/abs/2412.19304v1,"Roberto Amoroso, Gengyuan Zhang, Rajat Koner, Lorenzo Baraldi, Rita Cucchiara, Volker Tresp"
Manga Generation via Layout-controllable Diffusion,"Generating comics through text is widely studied. However, there are few
studies on generating multi-panel Manga (Japanese comics) solely based on plain
text. Japanese manga contains multiple panels on a single page, with
characteristics such as coherence in storytelling, reasonable and diverse page
layouts, consistency in characters, and semantic correspondence between panel
drawings and panel scripts. Therefore, generating manga poses a significant
challenge. This paper presents the manga generation task and constructs the
Manga109Story dataset for studying manga generation solely from plain text.
Additionally, we propose MangaDiffusion to facilitate the intra-panel and
inter-panel information interaction during the manga generation process. The
results show that our method particularly ensures the number of panels,
reasonable and diverse page layouts. Based on our approach, there is potential
to converting a large amount of textual stories into more engaging manga
readings, leading to significant application prospects.",2024-12-26T17:52:19Z,http://arxiv.org/abs/2412.19303v1,"Siyu Chen, Dengjie Li, Zenghao Bao, Yao Zhou, Lingfeng Tan, Yujie Zhong, Zheng Zhao"
RecLM: Recommendation Instruction Tuning,"Modern recommender systems aim to deeply understand users' complex
preferences through their past interactions. While deep collaborative filtering
approaches using Graph Neural Networks (GNNs) excel at capturing user-item
relationships, their effectiveness is limited when handling sparse data or
zero-shot scenarios, primarily due to constraints in ID-based embedding
functions. To address these challenges, we propose a model-agnostic
recommendation instruction-tuning paradigm that seamlessly integrates large
language models with collaborative filtering. Our proposed Recommendation
Language Model (RecLM) enhances the capture of user preference diversity
through a carefully designed reinforcement learning reward function that
facilitates self-augmentation of language models. Comprehensive evaluations
demonstrate significant advantages of our approach across various settings, and
its plug-and-play compatibility with state-of-the-art recommender systems
results in notable performance enhancements.",2024-12-26T17:51:54Z,http://arxiv.org/abs/2412.19302v1,"Yangqin Jiang, Yuhao Yang, Lianghao Xia, Da Luo, Kangyi Lin, Chao Huang"
RAG with Differential Privacy,"Retrieval-Augmented Generation (RAG) has emerged as the dominant technique to
provide *Large Language Models* (LLM) with fresh and relevant context,
mitigating the risk of hallucinations and improving the overall quality of
responses in environments with large and fast moving knowledge bases. However,
the integration of external documents into the generation process raises
significant privacy concerns. Indeed, when added to a prompt, it is not
possible to guarantee a response will not inadvertently expose confidential
data, leading to potential breaches of privacy and ethical dilemmas. This paper
explores a practical solution to this problem suitable to general knowledge
extraction from personal data. It shows *differentially private token
generation* is a viable approach to private RAG.",2024-12-26T17:34:26Z,http://arxiv.org/abs/2412.19291v1,Nicolas Grislain
"ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image
  Captioning","Recent lightweight image captioning models using retrieved data mainly focus
on text prompts. However, previous works only utilize the retrieved text as
text prompts, and the visual information relies only on the CLIP visual
embedding. Because of this issue, there is a limitation that the image
descriptions inherent in the prompt are not sufficiently reflected in the
visual embedding space. To tackle this issue, we propose ViPCap, a novel
retrieval text-based visual prompt for lightweight image captioning. ViPCap
leverages the retrieved text with image information as visual prompts to
enhance the ability of the model to capture relevant visual information. By
mapping text prompts into the CLIP space and generating multiple randomized
Gaussian distributions, our method leverages sampling to explore randomly
augmented distributions and effectively retrieves the semantic features that
contain image information. These retrieved features are integrated into the
image and designated as the visual prompt, leading to performance improvements
on the datasets such as COCO, Flickr30k, and NoCaps. Experimental results
demonstrate that ViPCap significantly outperforms prior lightweight captioning
models in efficiency and effectiveness, demonstrating the potential for a
plug-and-play solution.",2024-12-26T17:29:38Z,http://arxiv.org/abs/2412.19289v1,"Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim"
"Thermal amplification and melting of phases in spin-orbit-coupled spin-1
  Bose-Einstein condensates","We implement Hartree-Fock-Bogoliubov theory with Popov approximation for a
homogeneous Raman-induced spin-orbit-coupled spin-1 Bose-Einstein condensate
and investigate the effects of finite temperature ($T$) on the ground-state
phase diagram. We calculate the roton gap as a function of Raman coupling
($\Omega$) or quadratic Zeeman field strength ($\epsilon$) to extract the
critical points separating the supersolid stripe phase from the plane wave or
zero-momentum phase at finite temperatures. We present a few representative
finite-temperature phase diagrams for the system in the $T-\Omega$ and
$T-\epsilon$ planes. Our observations indicate that the supersolid stripe phase
melts at finite temperatures. We also discuss the contrasting roles of quantum
and thermal fluctuations in shifting the phase boundary separating the
supersolid stripe from the plane-wave phase.",2024-12-26T17:03:05Z,http://arxiv.org/abs/2412.19285v1,"Ritu, Rajat, Arko Roy, Sandeep Gautam"
Improving Generalization for AI-Synthesized Voice Detection,"AI-synthesized voice technology has the potential to create realistic human
voices for beneficial applications, but it can also be misused for malicious
purposes. While existing AI-synthesized voice detection models excel in
intra-domain evaluation, they face challenges in generalizing across different
domains, potentially becoming obsolete as new voice generators emerge. Current
solutions use diverse data and advanced machine learning techniques (e.g.,
domain-invariant representation, self-supervised learning), but are limited by
predefined vocoders and sensitivity to factors like background noise and
speaker identity. In this work, we introduce an innovative disentanglement
framework aimed at extracting domain-agnostic artifact features related to
vocoders. Utilizing these features, we enhance model learning in a flat loss
landscape, enabling escape from suboptimal solutions and improving
generalization. Extensive experiments on benchmarks show our approach
outperforms state-of-the-art methods, achieving up to 5.12% improvement in the
equal error rate metric in intra-domain and 7.59% in cross-domain evaluations.",2024-12-26T16:45:20Z,http://arxiv.org/abs/2412.19279v1,"Hainan Ren, Lin Li, Chun-Hao Liu, Xin Wang, Shu Hu"
Optimizing Multi-Stage Language Models for Effective Text Retrieval,"Efficient text retrieval is critical for applications such as legal document
analysis, particularly in specialized contexts like Japanese legal systems.
Existing retrieval methods often underperform in such domain-specific
scenarios, necessitating tailored approaches. In this paper, we introduce a
novel two-phase text retrieval pipeline optimized for Japanese legal datasets.
Our method leverages advanced language models to achieve state-of-the-art
performance, significantly improving retrieval efficiency and accuracy. To
further enhance robustness and adaptability, we incorporate an ensemble model
that integrates multiple retrieval strategies, resulting in superior outcomes
across diverse tasks. Extensive experiments validate the effectiveness of our
approach, demonstrating strong performance on both Japanese legal datasets and
widely recognized benchmarks like MS-MARCO. Our work establishes new standards
for text retrieval in domain-specific and general contexts, providing a
comprehensive solution for addressing complex queries in legal and multilingual
environments.",2024-12-26T16:05:19Z,http://arxiv.org/abs/2412.19265v1,"Quang Hoang Trung, Le Trung Hoang, Nguyen Van Hoang Phuc"
"VoiceDiT: Dual-Condition Diffusion Transformer for Environment-Aware
  Speech Synthesis","We present VoiceDiT, a multi-modal generative model for producing
environment-aware speech and audio from text and visual prompts. While aligning
speech with text is crucial for intelligible speech, achieving this alignment
in noisy conditions remains a significant and underexplored challenge in the
field. To address this, we present a novel audio generation pipeline named
VoiceDiT. This pipeline includes three key components: (1) the creation of a
large-scale synthetic speech dataset for pre-training and a refined real-world
speech dataset for fine-tuning, (2) the Dual-DiT, a model designed to
efficiently preserve aligned speech information while accurately reflecting
environmental conditions, and (3) a diffusion-based Image-to-Audio Translator
that allows the model to bridge the gap between audio and image, facilitating
the generation of environmental sound that aligns with the multi-modal prompts.
Extensive experimental results demonstrate that VoiceDiT outperforms previous
models on real-world datasets, showcasing significant improvements in both
audio quality and modality integration.",2024-12-26T15:52:58Z,http://arxiv.org/abs/2412.19259v1,"Jaemin Jung, Junseok Ahn, Chaeyoung Jung, Tan Dat Nguyen, Youngjoon Jang, Joon Son Chung"
"Leveraging Self-Training and Variational Autoencoder for Agitation
  Detection in People with Dementia Using Wearable Sensors","Dementia is a neurodegenerative disorder that has been growing among elder
people over the past decades. This growth profoundly impacts the quality of
life for patients and caregivers due to the symptoms arising from it. Agitation
and aggression (AA) are some of the symptoms of people with severe dementia
(PwD) in long-term care or hospitals. AA not only causes discomfort but also
puts the patients or others at potential risk. Existing monitoring solutions
utilizing different wearable sensors integrated with Artificial Intelligence
(AI) offer a way to detect AA early enough for timely and adequate medical
intervention. However, most studies are limited by the availability of
accurately labeled datasets, which significantly affects the efficacy of such
solutions in real-world scenarios. This study presents a novel comprehensive
approach to detect AA in PwD using physiological data from the Empatica E4
wristbands. The research creates a diverse dataset, consisting of three
distinct datasets gathered from 14 participants across multiple hospitals in
Canada. These datasets have not been extensively explored due to their limited
labeling. We propose a novel approach employing self-training and a variational
autoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims
to learn the representation of the features extracted using the VAE and then
uses a semi-supervised block to generate labels, classify events, and detect
AA. We demonstrate that combining Self-Training and Variational Autoencoder
mechanism significantly improves model performance in classifying AA in PwD.
Among the tested techniques, the XGBoost classifier achieved the highest
accuracy of 90.16\%. By effectively addressing the challenge of limited labeled
data, the proposed system not only learns new labels but also proves its
superiority in detecting AA.",2024-12-26T15:34:25Z,http://arxiv.org/abs/2412.19254v1,"Abeer Badawi, Somayya Elmoghazy, Samira Choudhury, Khalid Elgazzar, Amer Burhan"
Network double autoregression,"Modeling high-dimensional time series with simple structures is a challenging
problem. This paper proposes a network double autoregression (NDAR) model,
which combines the advantages of network structure and the double
autoregression (DAR) model, to handle high-dimensional, conditionally
heteroscedastic, and network-structured data within a simple framework. The
parameters of the model are estimated using quasi-maximum likelihood
estimation, and the asymptotic properties of the estimators are derived. The
selection of the model's lag order will be based on the Bayesian information
criterion. Finite-sample simulations show that the proposed model performs well
even with moderate time dimensions and network sizes. Finally, the model is
applied to analyze three different categories of stock data.",2024-12-26T15:28:41Z,http://arxiv.org/abs/2412.19251v1,"Tingting Li, Hao Wang"
"Causal Speech Enhancement with Predicting Semantics based on Quantized
  Self-supervised Learning Features","Real-time speech enhancement (SE) is essential to online speech
communication. Causal SE models use only the previous context while predicting
future information, such as phoneme continuation, may help performing causal
SE. The phonetic information is often represented by quantizing latent features
of self-supervised learning (SSL) models. This work is the first to incorporate
SSL features with causality into an SE model. The causal SSL features are
encoded and combined with spectrogram features using feature-wise linear
modulation to estimate a mask for enhancing the noisy input speech.
Simultaneously, we quantize the causal SSL features using vector quantization
to represent phonetic characteristics as semantic tokens. The model not only
encodes SSL features but also predicts the future semantic tokens in multi-task
learning (MTL). The experimental results using VoiceBank + DEMAND dataset show
that our proposed method achieves 2.88 in PESQ, especially with semantic
prediction MTL, in which we confirm that the semantic prediction played an
important role in causal SE.",2024-12-26T15:08:36Z,http://arxiv.org/abs/2412.19248v1,"Emiru Tsunoo, Yuki Saito, Wataru Nakata, Hiroshi Saruwatari"
Sentiment trading with large language models,"We investigate the efficacy of large language models (LLMs) in sentiment
analysis of U.S. financial news and their potential in predicting stock market
returns. We analyze a dataset comprising 965,375 news articles that span from
January 1, 2010, to June 30, 2023; we focus on the performance of various LLMs,
including BERT, OPT, FINBERT, and the traditional Loughran-McDonald dictionary
model, which has been a dominant methodology in the finance literature. The
study documents a significant association between LLM scores and subsequent
daily stock returns. Specifically, OPT, which is a GPT-3 based LLM, shows the
highest accuracy in sentiment prediction with an accuracy of 74.4%, slightly
ahead of BERT (72.5%) and FINBERT (72.2%). In contrast, the Loughran-McDonald
dictionary model demonstrates considerably lower effectiveness with only 50.1%
accuracy. Regression analyses highlight a robust positive impact of OPT model
scores on next-day stock returns, with coefficients of 0.274 and 0.254 in
different model specifications. BERT and FINBERT also exhibit predictive
relevance, though to a lesser extent. Notably, we do not observe a significant
relationship between the Loughran-McDonald dictionary model scores and stock
returns, challenging the efficacy of this traditional method in the current
financial context. In portfolio performance, the long-short OPT strategy excels
with a Sharpe ratio of 3.05, compared to 2.11 for BERT and 2.07 for FINBERT
long-short strategies. Strategies based on the Loughran-McDonald dictionary
yield the lowest Sharpe ratio of 1.23. Our findings emphasize the superior
performance of advanced LLMs, especially OPT, in financial market prediction
and portfolio management, marking a significant shift in the landscape of
financial analysis tools with implications to financial regulation and policy
analysis.",2024-12-26T15:01:24Z,http://arxiv.org/abs/2412.19245v1,"Kemal Kirtac, Guido Germano"
Functional structural equation modeling with latent variables,"Handling latent variables in Structural Equation Models (SEMs) in a case
where both the latent variables and their corresponding indicators in the
measurement error part of the model are random curves presents significant
challenges, especially with sparse data. In this paper, we develop a novel
family of Functional Structural Equation Models (FSEMs) that incorporate latent
variables modeled as Gaussian Processes (GPs). The introduced FSEMs are built
upon functional regression models having response variables modeled as
underlying GPs. The model flexibly adapts to cases when the random curves'
realizations are observed only over a sparse subset of the domain, and the
inferential framework is based on a restricted maximum likelihood approach. The
advantage of this framework lies in its ability and flexibility in handling
various data scenarios, including regularly and irregularly spaced points and
thus missing data. To extract smooth estimates for the functional parameters,
we employ a penalized likelihood approach that selects the smoothing parameters
using a cross-validation method. We evaluate the performance of the proposed
model using simulation studies and a real data example, which suggests that our
model performs well in practice. The uncertainty associated with the estimates
of the functional coefficients is also assessed by constructing confidence
regions for each estimate. The goodness of fit indices that are commonly used
to evaluate the fit of SEMs are developed for the FSEMs introduced in this
paper. Overall, the proposed method is a promising approach for modeling
functional data in SEMs with functional latent variables.",2024-12-26T14:57:14Z,http://arxiv.org/abs/2412.19242v1,"Fatemeh Asgari, Valeria Vitelli, Uta Sailer"
SeaMo: A Multi-Seasonal and Multimodal Remote Sensing Foundation Model,"Remote Sensing (RS) data contains a wealth of multi-dimensional information
crucial for Earth observation. Owing to its vast volume, diverse sources, and
temporal properties, RS data is highly suitable for the development of large
Visual Foundation Models (VFMs). VFMs act as robust feature extractors,
learning from extensive RS data, and are subsequently fine-tuned for deployment
in various geoscientific tasks. However, current VFMs in the RS domain are
predominantly pretrained and tailored exclusively for specific characteristics
of RS imagery, neglecting the potential of utilizing the multi-dimensional
properties of RS data. Therefore, in this work, we propose SeaMo, a pioneering
visual foundation model that integrates multi-seasonal and multimodal
information in the RS field. SeaMo is designed to harness multiple properties
of RS data. Within the masked image modeling framework, we employ non-aligned
cropping techniques to extract spatial properties, use multi-source inputs for
multimodal integration, and incorporate temporal-multimodal fusion blocks for
effective assimilation of multi-seasonal data. SeaMo explicitly models the
multi-dimensional properties of RS data, making the model more comprehensive,
robust, and versatile. We applied SeaMo to several downstream geoscience tasks,
which demonstrated exceptional performance. Extensive ablation studies were
conducted to validate the model's superiority.",2024-12-26T14:40:38Z,http://arxiv.org/abs/2412.19237v1,"Xuyang Li, Danfeng Hong, Chenyu Li, Jocelyn Chanussot"
"Are Two Hidden Layers Still Enough for the Physics-Informed Neural
  Networks?","The article discusses the development of various methods and techniques for
initializing and training neural networks with a single hidden layer, as well
as training a separable physics-informed neural network consisting of neural
networks with a single hidden layer to solve physical problems described by
ordinary differential equations (ODEs) and partial differential equations
(PDEs). A method for strictly deterministic initialization of a neural network
with one hidden layer for solving physical problems described by an ODE is
proposed. Modifications to existing methods for weighting the loss function are
given, as well as new methods developed for training strictly
deterministic-initialized neural networks to solve ODEs (detaching, additional
weighting based on the second derivative, predicted solution-based weighting,
relative residuals). An algorithm for physics-informed data-driven
initialization of a neural network with one hidden layer is proposed. A neural
network with pronounced generalizing properties is presented, whose
generalizing abilities of which can be precisely controlled by adjusting
network parameters. A metric for measuring the generalization of such neural
network has been introduced. A gradient-free neuron-by-neuron fitting method
has been developed for adjusting the parameters of a single-hidden-layer neural
network, which does not require the use of an optimizer or solver for its
implementation. The proposed methods have been extended to 2D problems using
the separable physics-informed neural networks approach. Numerous experiments
have been carried out to develop the above methods and approaches. Experiments
on physical problems, such as solving various ODEs and PDEs, have demonstrated
that these methods for initializing and training neural networks with one or
two hidden layers (SPINN) achieve competitive accuracy and, in some cases,
state-of-the-art results.",2024-12-26T14:30:54Z,http://arxiv.org/abs/2412.19235v1,"Vasiliy A. Es'kin, Alexey O. Malkhanov, Mikhail E. Smorkalov"
Multi-view Fake News Detection Model Based on Dynamic Hypergraph,"With the rapid development of online social networks and the inadequacies in
content moderation mechanisms, the detection of fake news has emerged as a
pressing concern for the public. Various methods have been proposed for fake
news detection, including text-based approaches as well as a series of
graph-based approaches. However, the deceptive nature of fake news renders
text-based approaches less effective. Propagation tree-based methods focus on
the propagation process of individual news, capturing pairwise relationships
but lacking the capability to capture high-order complex relationships. Large
heterogeneous graph-based approaches necessitate the incorporation of
substantial additional information beyond news text and user data, while
hypergraph-based approaches rely on predefined hypergraph structures. To tackle
these issues, we propose a novel dynamic hypergraph-based multi-view fake news
detection model (DHy-MFND) that learns news embeddings across three distinct
views: text-level, propagation tree-level, and hypergraph-level. By employing
hypergraph structures to model complex high-order relationships among multiple
news pieces and introducing dynamic hypergraph structure learning, we optimize
predefined hypergraph structures while learning news embeddings. Additionally,
we introduce contrastive learning to capture authenticity-relevant embeddings
across different views. Extensive experiments on two benchmark datasets
demonstrate the effectiveness of our proposed DHy-MFND compared with a broad
range of competing baselines.",2024-12-26T14:05:51Z,http://arxiv.org/abs/2412.19227v1,"Rongping Ye, Xiaobing Pei"
"VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring
  of Heterogeneous Applications and Infrastructures","Monitoring heterogeneous infrastructures and applications is essential to
cope with user requirements properly, but it still lacks enhancements. The
well-known state-of-the-art methods and tools do not support seamless
monitoring of bare-metal, low-cost infrastructures, neither hosted nor
virtualized services with fine-grained details. This work proposes VIrtualized
NEtwork VIsion architecture (VINEVI), an intelligent method for seamless
monitoring heterogeneous infrastructures and applications. The VINEVI
architecture advances state of the art with a node-embedded traffic
classification agent placing physical and virtualized infrastructures enabling
real-time traffic classification. VINEVI combines this real-time traffic
classification with well-known tools such as Prometheus and Victoria Metrics to
monitor the entire stack from the hardware to the virtualized applications.
Experimental results showcased that VINEVI architecture allowed seamless
heterogeneous infrastructure monitoring with a higher level of detail beyond
literature. Also, our node-embedded real-time Internet traffic classifier
evolved with flexibility the methods with monitoring heterogeneous
infrastructures seamlessly.",2024-12-26T14:05:14Z,http://arxiv.org/abs/2412.19226v1,"Rodrigo Moreira, Hugo G. V. O. da Cunha, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva"
"Completion as Enhancement: A Degradation-Aware Selective Image Guided
  Network for Depth Completion","In this paper, we introduce the Selective Image Guided Network (SigNet), a
novel degradation-aware framework that transforms depth completion into depth
enhancement for the first time. Moving beyond direct completion using
convolutional neural networks (CNNs), SigNet initially densifies sparse depth
data through non-CNN densification tools to obtain coarse yet dense depth. This
approach eliminates the mismatch and ambiguity caused by direct convolution
over irregularly sampled sparse data. Subsequently, SigNet redefines completion
as enhancement, establishing a self-supervised degradation bridge between the
coarse depth and the targeted dense depth for effective RGB-D fusion. To
achieve this, SigNet leverages the implicit degradation to adaptively select
high-frequency components (e.g., edges) of RGB data to compensate for the
coarse depth. This degradation is further integrated into a multi-modal
conditional Mamba, dynamically generating the state parameters to enable
efficient global high-frequency information interaction. We conduct extensive
experiments on the NYUv2, DIML, SUN RGBD, and TOFDC datasets, demonstrating the
state-of-the-art (SOTA) performance of SigNet.",2024-12-26T14:05:01Z,http://arxiv.org/abs/2412.19225v1,"Zhiqiang Yan, Zhengxue Wang, Kun Wang, Jun Li, Jian Yang"
"Transformer-Based Wireless Capsule Endoscopy Bleeding Tissue Detection
  and Classification","Informed by the success of the transformer model in various computer vision
tasks, we design an end-to-end trainable model for the automatic detection and
classification of bleeding and non-bleeding frames extracted from Wireless
Capsule Endoscopy (WCE) videos. Based on the DETR model, our model uses the
Resnet50 for feature extraction, the transformer encoder-decoder for bleeding
and non-bleeding region detection, and a feedforward neural network for
classification. Trained in an end-to-end approach on the Auto-WCEBleedGen
Version 1 challenge training set, our model performs both detection and
classification tasks as a single unit. Our model achieves an accuracy, recall,
and F1-score classification percentage score of 98.28, 96.79, and 98.37
respectively, on the Auto-WCEBleedGen version 1 validation set. Further, we
record an average precision (AP @ 0.5), mean-average precision (mAP) of 0.7447
and 0.7328 detection results. This earned us a 3rd place position in the
challenge. Our code is publicly available via
https://github.com/BasitAlawode/WCEBleedGen.",2024-12-26T13:49:39Z,http://arxiv.org/abs/2412.19218v1,"Basit Alawode, Shibani Hamza, Adarsh Ghimire, Divya Velayudhan"
"Applying the maximum entropy principle to multi-species neural networks
  improves species distribution models","The rapid expansion of citizen science initiatives has led to a significant
growth of biodiversity databases, and particularly presence-only (PO)
observations. PO data are invaluable for understanding species distributions
and their dynamics, but their use in Species Distribution Models (SDM) is
curtailed by sampling biases and the lack of information on absences. Poisson
point processes are widely used for SDMs, with Maxent being one of the most
popular methods. Maxent maximises the entropy of a probability distribution
across sites as a function of predefined transformations of environmental
variables, called features. In contrast, neural networks and deep learning have
emerged as a promising technique for automatic feature extraction from complex
input variables. In this paper, we propose DeepMaxent, which harnesses neural
networks to automatically learn shared features among species, using the
maximum entropy principle. To do so, it employs a normalised Poisson loss where
for each species, presence probabilities across sites are modelled by a neural
network. We evaluate DeepMaxent on a benchmark dataset known for its spatial
sampling biases, using PO data for calibration and presence-absence (PA) data
for validation across six regions with different biological groups and
environmental covariates. Our results indicate that DeepMaxent improves model
performance over Maxent and other state-of-the-art SDMs across regions and
taxonomic groups. The method performs particularly well in regions of uneven
sampling, demonstrating substantial potential to improve species distribution
modelling. The method opens the possibility to learn more robust environmental
features predicting jointly many species and scales to arbitrary large numbers
of sites without an increased memory demand.",2024-12-26T13:47:04Z,http://arxiv.org/abs/2412.19217v1,"Maxime Ryckewaert, Diego Marcos, Christophe Botella, Maximilien Servajean, Pierre Bonnet, Alexis Joly"
"Large Language Models Meet Graph Neural Networks: A Perspective of Graph
  Mining","Graph mining is an important area in data mining and machine learning that
involves extracting valuable information from graph-structured data. In recent
years, significant progress has been made in this field through the development
of graph neural networks (GNNs). However, GNNs are still deficient in
generalizing to diverse graph data. Aiming to this issue, Large Language Models
(LLMs) could provide new solutions for graph mining tasks with their superior
semantic understanding. In this review, we systematically review the
combination and application techniques of LLMs and GNNs and present a novel
taxonomy for research in this interdisciplinary field, which involves three
main categories: GNN-driving-LLM, LLM-driving-GNN, and GNN-LLM-co-driving.
Within this framework, we reveal the capabilities of LLMs in enhancing graph
feature extraction as well as improving the effectiveness of downstream tasks
such as node classification, link prediction, and community detection. Although
LLMs have demonstrated their great potential in handling graph-structured data,
their high computational requirements and complexity remain challenges. Future
research needs to continue to explore how to efficiently fuse LLMs and GNNs to
achieve more powerful graph learning and reasoning capabilities and provide new
impetus for the development of graph mining techniques.",2024-12-26T13:21:09Z,http://arxiv.org/abs/2412.19211v1,"Yuxin You, Zhen Liu, Xiangchao Wen, Yongtao Zhang, Wei Ai"
"GAIS: A Novel Approach to Instance Selection with Graph Attention
  Networks","Instance selection (IS) is a crucial technique in machine learning that aims
to reduce dataset size while maintaining model performance. This paper
introduces a novel method called Graph Attention-based Instance Selection
(GAIS), which leverages Graph Attention Networks (GATs) to identify the most
informative instances in a dataset. GAIS represents the data as a graph and
uses GATs to learn node representations, enabling it to capture complex
relationships between instances. The method processes data in chunks, applies
random masking and similarity thresholding during graph construction, and
selects instances based on confidence scores from the trained GAT model.
Experiments on 13 diverse datasets demonstrate that GAIS consistently
outperforms traditional IS methods in terms of effectiveness, achieving high
reduction rates (average 96\%) while maintaining or improving model
performance. Although GAIS exhibits slightly higher computational costs, its
superior performance in maintaining accuracy with significantly reduced
training data makes it a promising approach for graph-based data selection.",2024-12-26T12:51:14Z,http://arxiv.org/abs/2412.19201v1,"Zahiriddin Rustamov, Ayham Zaitouny, Rafat Damseh, Nazar Zaki"
"Personalized Dynamic Music Emotion Recognition with Dual-Scale
  Attention-Based Meta-Learning","Dynamic Music Emotion Recognition (DMER) aims to predict the emotion of
different moments in music, playing a crucial role in music information
retrieval. The existing DMER methods struggle to capture long-term dependencies
when dealing with sequence data, which limits their performance. Furthermore,
these methods often overlook the influence of individual differences on emotion
perception, even though everyone has their own personalized emotional
perception in the real world. Motivated by these issues, we explore more
effective sequence processing methods and introduce the Personalized DMER
(PDMER) problem, which requires models to predict emotions that align with
personalized perception. Specifically, we propose a Dual-Scale Attention-Based
Meta-Learning (DSAML) method. This method fuses features from a dual-scale
feature extractor and captures both short and long-term dependencies using a
dual-scale attention transformer, improving the performance in traditional
DMER. To achieve PDMER, we design a novel task construction strategy that
divides tasks by annotators. Samples in a task are annotated by the same
annotator, ensuring consistent perception. Leveraging this strategy alongside
meta-learning, DSAML can predict personalized perception of emotions with just
one personalized annotation sample. Our objective and subjective experiments
demonstrate that our method can achieve state-of-the-art performance in both
traditional DMER and PDMER.",2024-12-26T12:47:35Z,http://arxiv.org/abs/2412.19200v1,"Dengming Zhang, Weitao You, Ziheng Liu, Lingyun Sun, Pei Chen"
An End-to-End Depth-Based Pipeline for Selfie Image Rectification,"Portraits or selfie images taken from a close distance typically suffer from
perspective distortion. In this paper, we propose an end-to-end deep
learning-based rectification pipeline to mitigate the effects of perspective
distortion. We learn to predict the facial depth by training a deep CNN. The
estimated depth is utilized to adjust the camera-to-subject distance by moving
the camera farther, increasing the camera focal length, and reprojecting the 3D
image features to the new perspective. The reprojected features are then fed to
an inpainting module to fill in the missing pixels. We leverage a
differentiable renderer to enable end-to-end training of our depth estimation
and feature extraction nets to improve the rectified outputs. To boost the
results of the inpainting module, we incorporate an auxiliary module to predict
the horizontal movement of the camera which decreases the area that requires
hallucination of challenging face parts such as ears. Unlike previous works, we
process the full-frame input image at once without cropping the subject's face
and processing it separately from the rest of the body, eliminating the need
for complex post-processing steps to attach the face back to the subject's
body. To train our network, we utilize the popular game engine Unreal Engine to
generate a large synthetic face dataset containing various subjects, head
poses, expressions, eyewear, clothes, and lighting. Quantitative and
qualitative results show that our rectification pipeline outperforms previous
methods, and produces comparable results with a time-consuming 3D GAN-based
method while being more than 260 times faster.",2024-12-26T11:57:54Z,http://arxiv.org/abs/2412.19189v1,"Ahmed Alhawwary, Phong Nguyen-Ha, Janne Mustaniemi, Janne Heikkilä"
"Multi-Head Attention Driven Dynamic Visual-Semantic Embedding for
  Enhanced Image-Text Matching","With the rapid development of multimodal learning, the image-text matching
task, as a bridge connecting vision and language, has become increasingly
important. Based on existing research, this study proposes an innovative visual
semantic embedding model, Multi-Headed Consensus-Aware Visual-Semantic
Embedding (MH-CVSE). This model introduces a multi-head self-attention
mechanism based on the consensus-aware visual semantic embedding model (CVSE)
to capture information in multiple subspaces in parallel, significantly
enhancing the model's ability to understand and represent the complex
relationship between images and texts. In addition, we adopt a parameterized
feature fusion strategy to flexibly integrate feature information at different
levels, further improving the model's expressive power. In terms of loss
function design, the MH-CVSE model adopts a dynamic weight adjustment strategy
to dynamically adjust the weight according to the loss value itself, so that
the model can better balance the contribution of different loss terms during
training. At the same time, we introduce a cosine annealing learning rate
strategy to help the model converge more stably in the later stages of
training. Extensive experimental verification on the Flickr30k dataset shows
that the MH-CVSE model achieves better performance than previous methods in
both bidirectional image and text retrieval tasks, fully demonstrating its
effectiveness and superiority.",2024-12-26T11:46:22Z,http://arxiv.org/abs/2412.19184v1,Wenjing Chen
"Unraveling the magnetic and electronic complexity of intermetallic
  ErPd$_2$Si$_2$: Anisotropic thermal expansion, phase transitions, and twofold
  magnetotransport behavior","We present a comprehensive investigation into the physical properties of
intermetallic ErPd$_2$Si$_2$, a compound renowned for its intriguing magnetic
and electronic characteristics. We confirm the tetragonal crystal structure of
ErPd$_2$Si$_2$ within the $I4/mmm$ space group. Notably, we observed
anisotropic thermal expansion, with the lattice constant $a$ expanding and $c$
contracting between 15 K and 300 K. This behavior is attributed to lattice
vibrations and electronic contributions. Heat capacity measurements revealed
three distinct temperature regimes: $T_1 \sim 3.0$ K, $T_\textrm{N} \sim 4.20$
K, and $T_2 \sim 15.31$ K. These correspond to the disappearance of
spin-density waves, the onset of an incommensurate antiferromagnetic (AFM)
structure, and the crystal-field splitting and/or the presence of short-range
spin fluctuations, respectively. Remarkably, the AFM phase transition anomaly
was observed exclusively in low-field magnetization data (120 Oe) at
$T_\textrm{N}$. A high magnetic field ($B =$ 3 T) effectively suppressed this
anomaly, likely due to spin-flop and spin-flip transitions. Furthermore, the
extracted effective PM moments closely matched the expected theoretical value,
suggesting a dominant magnetic contribution from localized 4$f$ spins of Er.
Additionally, significant differences in resistance ($R$) values at low
temperatures under applied $B$ indicated a magnetoresistance (MR) effect with a
minimum value of -4.36\%. Notably, the measured MR effect exhibited anisotropic
behavior, where changes in the strength or direction of the applied $B$ induced
variations in the MR effect. A twofold symmetry of $R$ was discerned at 3 T and
9 T, originating from the orientation of spin moments relative to the applied
$B$. Intriguingly, above $T_\textrm{N}$, short-range spin fluctuations also
displayed a preferred orientation along the $c$-axis due to single-ion
anisotropy.",2024-12-26T11:39:24Z,http://arxiv.org/abs/2412.19181v1,"Kaitong Sun, Si Wu, Guanping Xu, Lingwei Li, Hongyu Chen, Qian Zhao, Muqing Su, Wolfgang Schmidt, Chongde Cao, Hai-Feng Li"
"Mask Approximation Net: Merging Feature Extraction and Distribution
  Learning for Remote Sensing Change Captioning","Remote sensing image change description, as a novel multimodal task in the
field of remote sensing processing, not only enables the detection of changes
in surface conditions but also provides detailed descriptions of these changes,
thereby enhancing human interpretability and interactivity. However, previous
methods mainly employed Convolutional Neural Network (CNN) architectures to
extract bitemporal image features. This approach often leads to an overemphasis
on designing specific network architectures and limits the captured feature
distributions to the current dataset, resulting in poor generalizability and
robustness when applied to other datasets or real-world scenarios. To address
these limitations, this paper proposes a novel approach for remote sensing
image change detection and description that integrates diffusion models, aiming
to shift the focus from conventional feature learning paradigms to data
distribution learning. The proposed method primarily includes a simple
multi-scale change detection module, whose output features are subsequently
refined using a diffusion model. Additionally, we introduce a frequency-guided
complex filter module to handle high-frequency noise during the diffusion
process, which helps to maintain model performance. Finally, we validate the
effectiveness of our proposed method on several remote sensing change detection
description datasets, demonstrating its superior performance. The code
available at MaskApproxNet.",2024-12-26T11:35:57Z,http://arxiv.org/abs/2412.19179v1,"Dongwei Sun, Xiangyong Cao"
"Reversed in Time: A Novel Temporal-Emphasized Benchmark for Cross-Modal
  Video-Text Retrieval","Cross-modal (e.g. image-text, video-text) retrieval is an important task in
information retrieval and multimodal vision-language understanding field.
Temporal understanding makes video-text retrieval more challenging than
image-text retrieval. However, we find that the widely used video-text
benchmarks have shortcomings in comprehensively assessing abilities of models,
especially in temporal understanding, causing large-scale image-text
pre-trained models can already achieve comparable zero-shot performance with
video-text pre-trained models. In this paper, we introduce RTime, a novel
temporal-emphasized video-text retrieval dataset. We first obtain videos of
actions or events with significant temporality, and then reverse these videos
to create harder negative samples. We then recruit annotators to judge the
significance and reversibility of candidate videos, and write captions for
qualified videos. We further adopt GPT-4 to extend more captions based on
human-written captions. Our RTime dataset currently consists of 21k videos with
10 captions per video, totalling about 122 hours. Based on RTime, we propose
three retrieval benchmark tasks: RTime-Origin, RTime-Hard, and RTime-Binary. We
further enhance the use of harder-negatives in model training, and benchmark a
variety of video-text models on RTime. Extensive experiment analysis proves
that RTime indeed poses new and higher challenges to video-text retrieval. We
release our RTime
dataset\footnote{\url{https://github.com/qyr0403/Reversed-in-Time}} to further
advance video-text retrieval and multimodal understanding research.",2024-12-26T11:32:00Z,http://arxiv.org/abs/2412.19178v1,"Yang Du, Yuqi Liu, Qin Jin"
"Towards Popularity-Aware Recommendation: A Multi-Behavior Enhanced
  Framework with Orthogonality Constraint","Top-$K$ recommendation involves inferring latent user preferences and
generating personalized recommendations accordingly, which is now ubiquitous in
various decision systems. Nonetheless, recommender systems usually suffer from
severe \textit{popularity bias}, leading to the over-recommendation of popular
items. Such a bias deviates from the central aim of reflecting user preference
faithfully, compromising both customer satisfaction and retailer profits.
Despite the prevalence, existing methods tackling popularity bias still have
limitations due to the considerable accuracy-debias tradeoff and the
sensitivity to extensive parameter selection, further exacerbated by the
extreme sparsity in positive user-item interactions.
  In this paper, we present a \textbf{Pop}ularity-aware top-$K$ recommendation
algorithm integrating multi-behavior \textbf{S}ide \textbf{I}nformation
(PopSI), aiming to enhance recommendation accuracy and debias performance
simultaneously. Specifically, by leveraging multiple user feedback that mirrors
similar user preferences and formulating it as a three-dimensional tensor,
PopSI can utilize all slices to capture the desiring user preferences
effectively. Subsequently, we introduced a novel orthogonality constraint to
refine the estimated item feature space, enforcing it to be invariant to item
popularity features thereby addressing our model's sensitivity to popularity
bias. Comprehensive experiments on real-world e-commerce datasets demonstrate
the general improvements of PopSI over state-of-the-art debias methods with a
marginal accuracy-debias tradeoff and scalability to practical applications.
The source code for our algorithm and experiments is available at
\url{https://github.com/Eason-sys/PopSI}.",2024-12-26T11:06:49Z,http://arxiv.org/abs/2412.19172v1,"Yishan Han, Biao Xu, Yao Wang, Shanxing Gao"
"High-Precision Schottky Diagnostics for Low-SNR Betatron Tune
  Measurement in Ramping Synchrotrons","This paper presents a novel Schottky diagnostics-based method for real-time
betatron tune measurement in ramping synchrotrons, exemplified by the Shanghai
Advanced Proton Therapy (SAPT) facility. The proposed approach achieves high
precision under challenging conditions, including low frequency resolution and
signal-to-noise ratios (SNR) as low as -15 dB within the bandwidth of a
narrowband detector. By employing Short-Time Fourier Transform (STFT) analysis
with automatically optimized time windows, the method effectively addresses the
rapid increase in revolution frequency from 4 MHz to 7.5 MHz over 0.35 seconds,
assuming constant beam properties within each window. Monte Carlo
macro-particle simulations are employed to generate Schottky signals, which are
subsequently combined with real noise collected from an analog-to-digital
converter to emulate practical conditions. The betatron tune measurement
procedure integrates longitudinal signal exclusion, spectrum smoothing, and
spectral multiplication to reliably extract transverse Schottky spectra buried
in noise, to enable precise betatron tune determination. Experimental results
demonstrate that the proposed method surpasses existing approaches in
precision, accuracy, and robustness, while meeting stringent design
requirements. This innovative approach addresses key limitations of Schottky
diagnostics for betatron tune measurement in ramping synchrotrons, providing a
foundation for applications such as proton therapy.",2024-12-26T11:05:21Z,http://arxiv.org/abs/2412.19171v1,"Peihan Sun, Manzhou Zhang, Renxian Yuan, Deming Li, Jian Dong, Ying Shi"
GFG -- Gender-Fair Generation: A CALAMITA Challenge,"Gender-fair language aims at promoting gender equality by using terms and
expressions that include all identities and avoid reinforcing gender
stereotypes. Implementing gender-fair strategies is particularly challenging in
heavily gender-marked languages, such as Italian. To address this, the
Gender-Fair Generation challenge intends to help shift toward gender-fair
language in written communication. The challenge, designed to assess and
monitor the recognition and generation of gender-fair language in both mono-
and cross-lingual scenarios, includes three tasks: (1) the detection of
gendered expressions in Italian sentences, (2) the reformulation of gendered
expressions into gender-fair alternatives, and (3) the generation of
gender-fair language in automatic translation from English to Italian. The
challenge relies on three different annotated datasets: the GFL-it corpus,
which contains Italian texts extracted from administrative documents provided
by the University of Brescia; GeNTE, a bilingual test set for gender-neutral
rewriting and translation built upon a subset of the Europarl dataset; and
Neo-GATE, a bilingual test set designed to assess the use of non-binary
neomorphemes in Italian for both fair formulation and translation tasks.
Finally, each task is evaluated with specific metrics: average of F1-score
obtained by means of BERTScore computed on each entry of the datasets for task
1, an accuracy measured with a gender-neutral classifier, and a
coverage-weighted accuracy for tasks 2 and 3.",2024-12-26T10:58:40Z,http://arxiv.org/abs/2412.19168v1,"Simona Frenda, Andrea Piergentili, Beatrice Savoldi, Marco Madeddu, Martina Rosola, Silvia Casola, Chiara Ferrando, Viviana Patti, Matteo Negri, Luisa Bentivogli"
"Dual Channel Multi-Attention in ViT for Biometric Authentication using
  Forehead Subcutaneous Vein Pattern and Periocular Pattern","Traditional biometric systems, like face and fingerprint recognition, have
encountered significant setbacks due to wearing face masks and hygiene
concerns. To meet the challenges of the partially covered face due to face
masks and hygiene concerns of fingerprint recognition, this paper proposes a
novel dual-channel multi-attention Vision Transformer (ViT) framework for
biometric authentication using forehead subcutaneous vein patterns and
periocular patterns, offering a promising alternative to traditional methods,
capable of performing well even with face masks and without any physical touch.
The proposed framework leverages a dual-channel ViT architecture, designed to
handle two distinct biometric traits. It can capture long-range dependencies of
independent features from the vein and periocular patterns. A custom classifier
is then designed to integrate the independently extracted features, producing a
final class prediction. The performance of the proposed algorithm was
rigorously evaluated using the Forehead Subcutaneous Vein Pattern and
Periocular Biometric Pattern (FSVP-PBP) database. The results demonstrated the
superiority of the algorithm over state-of-the-art methods, achieving
remarkable classification accuracy of $99.3 \pm 0.02\%$ with the combined vein
and periocular patterns.",2024-12-26T10:40:15Z,http://arxiv.org/abs/2412.19160v1,"Arun K. Sharma, Shubhobrata Bhattacharya, Motahar Reza"
"Referencing Where to Focus: Improving VisualGrounding with Referential
  Query","Visual Grounding aims to localize the referring object in an image given a
natural language expression. Recent advancements in DETR-based visual grounding
methods have attracted considerable attention, as they directly predict the
coordinates of the target object without relying on additional efforts, such as
pre-generated proposal candidates or pre-defined anchor boxes. However,
existing research primarily focuses on designing stronger multi-modal decoder,
which typically generates learnable queries by random initialization or by
using linguistic embeddings. This vanilla query generation approach inevitably
increases the learning difficulty for the model, as it does not involve any
target-related information at the beginning of decoding. Furthermore, they only
use the deepest image feature during the query learning process, overlooking
the importance of features from other levels. To address these issues, we
propose a novel approach, called RefFormer. It consists of the query adaption
module that can be seamlessly integrated into CLIP and generate the referential
query to provide the prior context for decoder, along with a task-specific
decoder. By incorporating the referential query into the decoder, we can
effectively mitigate the learning difficulty of the decoder, and accurately
concentrate on the target object. Additionally, our proposed query adaption
module can also act as an adapter, preserving the rich knowledge within CLIP
without the need to tune the parameters of the backbone network. Extensive
experiments demonstrate the effectiveness and efficiency of our proposed
method, outperforming state-of-the-art approaches on five visual grounding
benchmarks.",2024-12-26T10:19:20Z,http://arxiv.org/abs/2412.19155v1,"Yabing Wang, Zhuotao Tian, Qingpei Guo, Zheng Qin, Sanping Zhou, Ming Yang, Le Wang"
AskChart: Universal Chart Understanding through Textual Enhancement,"Chart understanding tasks such as ChartQA and Chart-to-Text involve
automatically extracting and interpreting key information from charts, enabling
users to query or convert visual data into structured formats. State-of-the-art
approaches primarily focus on visual cues from chart images, failing to
explicitly incorporate rich textual information (e.g., data labels and axis
labels) embedded within the charts. This textual information is vital for
intuitive human comprehension and interpretation of charts. Moreover, existing
models are often large and computationally intensive, limiting their practical
applicability. In this paper, we introduce AskChart, a universal model that
explicitly integrates both textual and visual cues from charts using a Mixture
of Experts (MoE) architecture. AskChart facilitates the learning of enhanced
visual-textual representations of charts for effectively handling multiple
chart understanding tasks, while maintaining a smaller model size. To capture
the synergy between visual and textual modalities, we curate a large-scale
dataset named ChartBank with about 7.5M data samples, which helps align textual
and visual information and facilitates the extraction of visual entities and
text. To effectively train AskChart, we design a three-stage training strategy
to align visual and textual modalities for learning robust visual-textual
representations and optimizing the learning of the MoE layer. Extensive
experiments across five datasets demonstrate the significant performance gains
of AskChart in four chart understanding tasks. Remarkably, AskChart with 4.6B
parameters outperforms state-of-the-art models with 13B parameters by 68.3% in
Open-ended ChartQA and 49.2% in Chart-to-Text tasks, while achieving comparable
performance in ChartQA and Chart-to-Table tasks.",2024-12-26T09:59:43Z,http://arxiv.org/abs/2412.19146v1,"Xudong Yang, Yifan Wu, Yizhang Zhu, Nan Tang, Yuyu Luo"
"CLIP-GS: Unifying Vision-Language Representation with 3D Gaussian
  Splatting","Recent works in 3D multimodal learning have made remarkable progress.
However, typically 3D multimodal models are only capable of handling point
clouds. Compared to the emerging 3D representation technique, 3D Gaussian
Splatting (3DGS), the spatially sparse point cloud cannot depict the texture
information of 3D objects, resulting in inferior reconstruction capabilities.
This limitation constrains the potential of point cloud-based 3D multimodal
representation learning. In this paper, we present CLIP-GS, a novel multimodal
representation learning framework grounded in 3DGS. We introduce the GS
Tokenizer to generate serialized gaussian tokens, which are then processed
through transformer layers pre-initialized with weights from point cloud
models, resulting in the 3DGS embeddings. CLIP-GS leverages contrastive loss
between 3DGS and the visual-text embeddings of CLIP, and we introduce an image
voting loss to guide the directionality and convergence of gradient
optimization. Furthermore, we develop an efficient way to generate triplets of
3DGS, images, and text, facilitating CLIP-GS in learning unified multimodal
representations. Leveraging the well-aligned multimodal representations,
CLIP-GS demonstrates versatility and outperforms point cloud-based models on
various 3D tasks, including multimodal retrieval, zero-shot, and few-shot
classification.",2024-12-26T09:54:25Z,http://arxiv.org/abs/2412.19142v1,"Siyu Jiao, Haoye Dong, Yuyang Yin, Zequn Jie, Yinlong Qian, Yao Zhao, Humphrey Shi, Yunchao Wei"
"How Panel Layouts Define Manga: Insights from Visual Ablation
  Experiments","Today, manga has gained worldwide popularity. However, the question of how
various elements of manga, such as characters, text, and panel layouts, reflect
the uniqueness of a particular work, or even define it, remains an unexplored
area. In this paper, we aim to quantitatively and qualitatively analyze the
visual characteristics of manga works, with a particular focus on panel layout
features. As a research method, we used facing page images of manga as input to
train a deep learning model for predicting manga titles, examining
classification accuracy to quantitatively analyze these features. Specifically,
we conducted ablation studies by limiting page image information to panel
frames to analyze the characteristics of panel layouts. Through a series of
quantitative experiments using all 104 works, 12 genres, and 10,122 facing page
images from the Manga109 dataset, as well as qualitative analysis using
Grad-CAM, our study demonstrates that the uniqueness of manga works is strongly
reflected in their panel layouts.",2024-12-26T09:53:37Z,http://arxiv.org/abs/2412.19141v1,"Siyuan Feng, Teruya Yoshinaga, Katsuhiko Hayashi, Koki Washio, Hidetaka Kamigaito"
"SILC-EFSA: Self-aware In-context Learning Correction for Entity-level
  Financial Sentiment Analysis","In recent years, fine-grained sentiment analysis in finance has gained
significant attention, but the scarcity of entity-level datasets remains a key
challenge. To address this, we have constructed the largest English and Chinese
financial entity-level sentiment analysis datasets to date. Building on this
foundation, we propose a novel two-stage sentiment analysis approach called
Self-aware In-context Learning Correction (SILC). The first stage involves
fine-tuning a base large language model to generate pseudo-labeled data
specific to our task. In the second stage, we train a correction model using a
GNN-based example retriever, which is informed by the pseudo-labeled data. This
two-stage strategy has allowed us to achieve state-of-the-art performance on
the newly constructed datasets, advancing the field of financial sentiment
analysis. In a case study, we demonstrate the enhanced practical utility of our
data and methods in monitoring the cryptocurrency market. Our datasets and code
are available at https://github.com/NLP-Bin/SILC-EFSA.",2024-12-26T09:53:01Z,http://arxiv.org/abs/2412.19140v1,"Senbin Zhu, Chenyuan He, Hongde Liu, Pengcheng Dong, Hanjie Zhao, Yuchen Yan, Yuxiang Jia, Hongying Zan, Min Peng"
PlanLLM: Video Procedure Planning with Refinable Large Language Models,"Video procedure planning, i.e., planning a sequence of action steps given the
video frames of start and goal states, is an essential ability for embodied AI.
Recent works utilize Large Language Models (LLMs) to generate enriched action
step description texts to guide action step decoding. Although LLMs are
introduced, these methods decode the action steps into a closed-set of one-hot
vectors, limiting the model's capability of generalizing to new steps or tasks.
Additionally, fixed action step descriptions based on world-level commonsense
may contain noise in specific instances of visual states. In this paper, we
propose PlanLLM, a cross-modal joint learning framework with LLMs for video
procedure planning. We propose an LLM-Enhanced Planning module which fully uses
the generalization ability of LLMs to produce free-form planning output and to
enhance action step decoding. We also propose Mutual Information Maximization
module to connect world-level commonsense of step descriptions and
sample-specific information of visual states, enabling LLMs to employ the
reasoning ability to generate step sequences. With the assistance of LLMs, our
method can both closed-set and open vocabulary procedure planning tasks. Our
PlanLLM achieves superior performance on three benchmarks, demonstrating the
effectiveness of our designs.",2024-12-26T09:51:05Z,http://arxiv.org/abs/2412.19139v1,"Dejie Yang, Zijing Zhao, YangLiu"
"A Rhetorical Relations-Based Framework for Tailored Multimedia Document
  Summarization","In the rapidly evolving landscape of digital content, the task of summarizing
multimedia documents, which encompass textual, visual, and auditory elements,
presents intricate challenges. These challenges include extracting pertinent
information from diverse formats, maintaining the structural integrity and
semantic coherence of the original content, and generating concise yet
informative summaries. This paper introduces a novel framework for multimedia
document summarization that capitalizes on the inherent structure of the
document to craft coherent and succinct summaries. Central to this framework is
the incorporation of a rhetorical structure for structural analysis, augmented
by a graph-based representation to facilitate the extraction of pivotal
information. Weighting algorithms are employed to assign significance values to
document units, thereby enabling effective ranking and selection of relevant
content. Furthermore, the framework is designed to accommodate user preferences
and time constraints, ensuring the production of personalized and contextually
relevant summaries. The summarization process is elaborately delineated,
encompassing document specification, graph construction, unit weighting, and
summary extraction, supported by illustrative examples and algorithmic
elucidation. This proposed framework represents a significant advancement in
automatic summarization, with broad potential applications across multimedia
document processing, promising transformative impacts in the field.",2024-12-26T09:29:59Z,http://arxiv.org/abs/2412.19133v1,"Azze-Eddine Maredj, Madjid Sadallah"
Semantic Residual for Multimodal Unified Discrete Representation,"Recent research in the domain of multimodal unified representations
predominantly employs codebook as representation forms, utilizing Vector
Quantization(VQ) for quantization, yet there has been insufficient exploration
of other quantization representation forms. Our work explores more precise
quantization methods and introduces a new framework, Semantic Residual
Cross-modal Information Disentanglement (SRCID), inspired by the numerical
residual concept inherent to Residual Vector Quantization (RVQ). SRCID employs
semantic residual-based information disentanglement for multimodal data to
better handle the inherent discrepancies between different modalities. Our
method enhances the capabilities of unified multimodal representations and
demonstrates exceptional performance in cross-modal generalization and
cross-modal zero-shot retrieval. Its average results significantly surpass
existing state-of-the-art models, as well as previous attempts with RVQ and
Finite Scalar Quantization (FSQ) based on these modals.",2024-12-26T09:08:52Z,http://arxiv.org/abs/2412.19128v1,"Hai Huang, Shulei Wang, Yan Xia"
SDRS: Shape-Differentiable Robot Simulator,"Robot simulators are indispensable tools across many fields, and recent
research has significantly improved their functionality by incorporating
additional gradient information. However, existing differentiable robot
simulators suffer from non-differentiable singularities, when robots undergo
substantial shape changes. To address this, we present the Shape-Differentiable
Robot Simulator (SDRS), designed to be differentiable under significant robot
shape changes. The core innovation of SDRS lies in its representation of robot
shapes using a set of convex polyhedrons. This approach allows us to generalize
smooth, penalty-based contact mechanics for interactions between any pair of
convex polyhedrons. Using the separating hyperplane theorem, SDRS introduces a
separating plane for each pair of contacting convex polyhedrons. This
separating plane functions as a zero-mass auxiliary entity, with its state
determined by the principle of least action. This setup ensures global
differentiability, even as robot shapes undergo significant geometric and
topological changes. To demonstrate the practical value of SDRS, we provide
examples of robot co-design scenarios, where both robot shapes and control
movements are optimized simultaneously.",2024-12-26T09:05:22Z,http://arxiv.org/abs/2412.19127v1,"Xiaohan Ye, Xifeng Gao, Kui Wu, Zherong Pan, Taku Komura"
Generalizations of Cyclic Codes over Product Rings,"In this article, for the finite field $\mathbb{F}_q$, we show that the
$\mathbb{F}_q$-algebra $\mathbb{F}_q[x]/\langle f(x) \rangle$ is isomorphic to
the product ring $\mathbb{F}_q^{\deg f(x)}$ if and only if $f(x)$ splits over
$\mathbb{F}_q$ into distinct factors. We generalize this result to the quotient
of the polynomial algebra $\mathbb{F}_q[x_1, x_2,\dots, x_k]$ by the ideal
$\langle f_1(x_1), f_2(x_2),\dots, f_k(x_k)\rangle.$ On the other hand, every
finite dimensional $\mathbb{F}_q$-algebra $\mathcal{A}$ has an orthogonal basis
of idempotents with their sum equal to $1_{\mathcal{A}}$ if and only if
$\mathcal{A}\cong\mathbb{F}_q^l$ as $\mathbb{F}_q$-algebras, where
$l=\dim_{\mathbb{F}_q} \mathcal{A}$. We utilize this characterization to study
polycyclic codes over $\mathcal{A}$ and get a unique decomposition of
polycyclic codes over $\mathcal{A}$ into polycyclic codes over $\mathbb{F}_q$
for every such orthogonal basis of $\mathcal{A}$, which is referred to as an
$\mathbb{F}_q$-decomposition. An $\mathbb{F}_q$-decomposition enables us to use
results of polycyclic codes over $\mathbb{F}_q$ to study polycyclic codes over
$\mathcal{A}$; for instance, we show that the annihilator dual of a polycyclic
code over $\mathcal{A}$ is a polycyclic code over $\mathcal{A}$. Furthermore,
we consider the obvious Gray map (which is obtained by restricting scalars from
$\mathcal{A}$ to $\mathbb{F}_q$) to find and study codes over $\mathbb{F}_q$
from codes over $\mathcal{A}$. Finally, with the help of different Gray maps,
we produce a good number of examples of MDS or almost-MDS or/and optimal codes;
some of them are LCD over $\mathbb{F}_q$.",2024-12-26T08:58:48Z,http://arxiv.org/abs/2412.19126v1,"Akanksha, Ritumoni Sarma"
"Advanced Knowledge Transfer: Refined Feature Distillation for Zero-Shot
  Quantization in Edge Computing","We introduce AKT (Advanced Knowledge Transfer), a novel method to enhance the
training ability of low-bit quantized (Q) models in the field of zero-shot
quantization (ZSQ). Existing research in ZSQ has focused on generating
high-quality data from full-precision (FP) models. However, these approaches
struggle with reduced learning ability in low-bit quantization due to its
limited information capacity. To overcome this limitation, we propose effective
training strategy compared to data generation. Particularly, we analyzed that
refining feature maps in the feature distillation process is an effective way
to transfer knowledge to the Q model. Based on this analysis, AKT efficiently
transfer core information from the FP model to the Q model. AKT is the first
approach to utilize both spatial and channel attention information in feature
distillation in ZSQ. Our method addresses the fundamental gradient exploding
problem in low-bit Q models. Experiments on CIFAR-10 and CIFAR-100 datasets
demonstrated the effectiveness of the AKT. Our method led to significant
performance enhancement in existing generative models. Notably, AKT achieved
significant accuracy improvements in low-bit Q models, achieving
state-of-the-art in the 3,5bit scenarios on CIFAR-10. The code is available at
https://github.com/Inpyo-Hong/AKT-Advanced-knowledge-Transfer.",2024-12-26T08:52:27Z,http://arxiv.org/abs/2412.19125v1,"Inpyo Hong, Youngwan Jo, Hyojeong Lee, Sunghyun Ahn, Sanghyun Park"
"Evaluating Self-Supervised Learning in Medical Imaging: A Benchmark for
  Robustness, Generalizability, and Multi-Domain Impact","Self-supervised learning (SSL) has emerged as a promising paradigm in medical
imaging, addressing the chronic challenge of limited labeled data in healthcare
settings. While SSL has shown impressive results, existing studies in the
medical domain are often limited in scope, focusing on specific datasets or
modalities, or evaluating only isolated aspects of model performance. This
fragmented evaluation approach poses a significant challenge, as models
deployed in critical medical settings must not only achieve high accuracy but
also demonstrate robust performance and generalizability across diverse
datasets and varying conditions. To address this gap, we present a
comprehensive evaluation of SSL methods within the medical domain, with a
particular focus on robustness and generalizability. Using the MedMNIST dataset
collection as a standardized benchmark, we evaluate 8 major SSL methods across
11 different medical datasets. Our study provides an in-depth analysis of model
performance in both in-domain scenarios and the detection of
out-of-distribution (OOD) samples, while exploring the effect of various
initialization strategies, model architectures, and multi-domain pre-training.
We further assess the generalizability of SSL methods through cross-dataset
evaluations and the in-domain performance with varying label proportions (1%,
10%, and 100%) to simulate real-world scenarios with limited supervision. We
hope this comprehensive benchmark helps practitioners and researchers make more
informed decisions when applying SSL methods to medical applications.",2024-12-26T08:51:56Z,http://arxiv.org/abs/2412.19124v1,"Valay Bundele, Oğuz Ata Çal, Bora Kargi, Karahan Sarıtaş, Kıvanç Tezören, Zohreh Ghaderi, Hendrik Lensch"
"Characterizing resources for multiparameter estimation of SU(2) and
  SU(1,1) unitaries","We investigate the estimation of multiple parameters generated by a unitary
evolution with non-commuting Hamiltonians that form a closed algebra. In
particular, we consider the three-parameter estimation of SU(2) and SU(1,1)
unitaries and analyze the ideal scaling of precision in terms of typical
resources such as the total particle number, identifying novel probe states
that can achieve Heisenberg scaling for all the three parameters. On top of
that, we also consider a more pragmatic framework where the estimation is
performed via the so-called method of moments, i.e., via measurements of
signal-to-noise ratios of time-evolved observables, which we restrict to be the
first two moments of the Hamiltonian generators. We consider the ideal classes
of states that we have identified by maximizing the quantum Fisher information
matrix, and analyze the maximal precision achievable from measuring only the
first two moments of the generators. As a result, we find that in this context
with limited resources accessible, the twin-Fock state emerges as the only
probe state that allows the estimation of two out of the three parameters with
Heisenberg precision scaling. We also analyze further states, including
Gaussian states, as well as Schr{\""o}dinger-cat-like states, this time
restricting to measurements linear in the su(2) and su(1,1) operators. In this
case, we find that while the former can indeed achieve Heisenberg scaling for
one or two parameters, the latter cannot, which confirms the fact that more
complicated measurements would be needed in that case.",2024-12-26T08:36:38Z,http://arxiv.org/abs/2412.19119v1,"Shaowei Du, Shuheng Liu, Frank E. S. Steinhoff, Giuseppe Vitagliano"
Discrete vs. Continuous Trade-offs for Generative Models,"This work explores the theoretical and practical foundations of denoising
diffusion probabilistic models (DDPMs) and score-based generative models, which
leverage stochastic processes and Brownian motion to model complex data
distributions. These models employ forward and reverse diffusion processes
defined through stochastic differential equations (SDEs) to iteratively add and
remove noise, enabling high-quality data generation. By analyzing the
performance bounds of these models, we demonstrate how score estimation errors
propagate through the reverse process and bound the total variation distance
using discrete Girsanov transformations, Pinsker's inequality, and the data
processing inequality (DPI) for an information theoretic lens.",2024-12-26T08:14:27Z,http://arxiv.org/abs/2412.19114v1,"Jathin Korrapati, Tanish Baranwal, Rahul Shah"
"Spectral Enhancement and Pseudo-Anchor Guidance for Infrared-Visible
  Person Re-Identification","The development of deep learning has facilitated the application of person
re-identification (ReID) technology in intelligent security. Visible-infrared
person re-identification (VI-ReID) aims to match pedestrians across infrared
and visible modality images enabling 24-hour surveillance. Current studies
relying on unsupervised modality transformations as well as inefficient
embedding constraints to bridge the spectral differences between infrared and
visible images, however, limit their potential performance. To tackle the
limitations of the above approaches, this paper introduces a simple yet
effective Spectral Enhancement and Pseudo-anchor Guidance Network, named
SEPG-Net. Specifically, we propose a more homogeneous spectral enhancement
scheme based on frequency domain information and greyscale space, which avoids
the information loss typically caused by inefficient modality transformations.
Further, a Pseudo Anchor-guided Bidirectional Aggregation (PABA) loss is
introduced to bridge local modality discrepancies while better preserving
discriminative identity embeddings. Experimental results on two public
benchmark datasets demonstrate the superior performance of SEPG-Net against
other state-of-the-art methods. The code is available at
https://github.com/1024AILab/ReID-SEPG.",2024-12-26T08:03:53Z,http://arxiv.org/abs/2412.19111v1,"Yiyuan Ge, Zhihao Chen, Ziyang Wang, Jiaju Kang, Mingya Zhang"
"A Selective Secure Precoding Framework for MU-MIMO Rate-Splitting
  Multiple Access Networks Under Limited CSIT","In this paper, we propose a robust and adaptable secure precoding framework
designed to encapsulate a intricate scenario where legitimate users have
different information security: secure private or normal public information.
Leveraging rate-splitting multiple access (RSMA), we formulate the sum secrecy
spectral efficiency (SE) maximization problem in downlink multi-user
multiple-input multiple-output (MIMO) systems with multi-eavesdropper. To
resolve the challenges including the heterogeneity of security, non-convexity,
and non-smoothness of the problem, we initially approximate the problem using a
LogSumExp technique. Subsequently, we derive the first-order optimality
condition in the form of a generalized eigenvalue problem. We utilize a power
iteration-based method to solve the condition, thereby achieving a superior
local optimal solution. The proposed algorithm is further extended to a more
realistic scenario involving limited channel state information at the
transmitter (CSIT). To effectively utilize the limited channel information, we
employ a conditional average rate approach. Handling the conditional average by
deriving useful bounds, we establish a lower bound for the objective function
under the conditional average. Then we apply the similar optimization method as
for the perfect CSIT case. In simulations, we validate the proposed algorithm
in terms of the sum secrecy SE.",2024-12-26T08:00:02Z,http://arxiv.org/abs/2412.19110v1,"Sangmin Lee, Seokjun Park, Jeonghun Park, Jinseok Choi"
"Graph Mixture of Experts and Memory-augmented Routers for Multivariate
  Time Series Anomaly Detection","Multivariate time series (MTS) anomaly detection is a critical task that
involves identifying abnormal patterns or events in data that consist of
multiple interrelated time series. In order to better model the complex
interdependence between entities and the various inherent characteristics of
each entity, the GNN based methods are widely adopted by existing methods. In
each layer of GNN, node features aggregate information from their neighboring
nodes to update their information. In doing so, from shallow layer to deep
layer in GNN, original individual node features continue to be weakened and
more structural information,i.e., from short-distance neighborhood to
long-distance neighborhood, continues to be enhanced. However, research to date
has largely ignored the understanding of how hierarchical graph information is
represented and their characteristics that can benefit anomaly detection.
Existing methods simply leverage the output from the last layer of GNN for
anomaly estimation while neglecting the essential information contained in the
intermediate GNN layers. To address such limitations, in this paper, we propose
a Graph Mixture of Experts (Graph-MoE) network for multivariate time series
anomaly detection, which incorporates the mixture of experts (MoE) module to
adaptively represent and integrate hierarchical multi-layer graph information
into entity representations. It is worth noting that our Graph-MoE can be
integrated into any GNN-based MTS anomaly detection method in a plug-and-play
manner. In addition, the memory-augmented routers are proposed in this paper to
capture the correlation temporal information in terms of the global historical
features of MTS to adaptively weigh the obtained entity representations to
achieve successful anomaly estimation. Extensive experiments on five
challenging datasets prove the superiority of our approach and each proposed
module.",2024-12-26T07:49:51Z,http://arxiv.org/abs/2412.19108v1,"Xiaoyu Huang, Weidong Chen, Bo Hu, Zhendong Mao"
"How Can Haptic Feedback Assist People with Blind and Low Vision (BLV): A
  Systematic Literature Review","People who are blind or have low vision (BLV) encounter numerous challenges
in their daily lives and work. To support them, various haptic assistive tools
have been developed. Despite these advancements, the effective utilization of
these tools -- including the optimal haptic feedback and on-body stimulation
positions for different tasks along with their limitations -- remains poorly
understood. Recognizing these gaps, we conducted a systematic literature review
spanning two decades (2004-2024) to evaluate the development of haptic
assistive tools within the HCI community. Our findings reveal that these tools
are primarily used for understanding graphical information, providing guidance
and navigation, and facilitating education and training, among other life and
work tasks. We identified three main limitations: hardware limitations,
functionality limitations, and UX and evaluation methods limitations. Based on
these insights, we discuss potential research avenues and offer suggestions for
enhancing the effectiveness of future haptic assistive technologies.",2024-12-26T07:47:26Z,http://arxiv.org/abs/2412.19105v1,"Chutian Jiang, Emily Kuang, Mingming Fan"
"Improving Generative Pre-Training: An In-depth Study of Masked Image
  Modeling and Denoising Models","In this work, we dive deep into the impact of additive noise in pre-training
deep networks. While various methods have attempted to use additive noise
inspired by the success of latent denoising diffusion models, when used in
combination with masked image modeling, their gains have been marginal when it
comes to recognition tasks. We thus investigate why this would be the case, in
an attempt to find effective ways to combine the two ideas. Specifically, we
find three critical conditions: corruption and restoration must be applied
within the encoder, noise must be introduced in the feature space, and an
explicit disentanglement between noised and masked tokens is necessary. By
implementing these findings, we demonstrate improved pre-training performance
for a wide range of recognition tasks, including those that require
fine-grained, high-frequency information to solve.",2024-12-26T07:47:20Z,http://arxiv.org/abs/2412.19104v1,"Hyesong Choi, Daeun Kim, Sungmin Cha, Kwang Moo Yi, Dongbo Min"
"The role of potential energy landscape research in the development of
  new electrolyte solutions","The development of new electrolyte solutions with improved characteristics is
a key challenge for creating high-performance batteries, fuel cells,
supercapacitors, and other electrochemical devices. The study of the potential
energy landscape (PEL) plays an important role in this process, providing
information about the interactions between solution components at the molecular
level. In this work, we review the practice of applying PEL research methods
based on classical and quantum-chemical algorithms to analyze the structure,
dynamics, and thermodynamic properties of electrolyte solutions. Intermolecular
and ion-molecular interactions at the microscopic level, which determine the
macroscopic properties of the electrolyte solution, are considered in detail.
The importance of identifying stable configurations of ions and their solvates
is emphasized. PEL analysis allows for the systematic determination of the most
probable structures and complexes formed in solution, which is important for
understanding ion transport mechanisms. The study of the PEL allows for the
determination of the energy barriers that must be overcome for ion migration,
which is related to the conductivity of the electrolyte. The application of PEL
research methods in combination with experimental data opens up new
possibilities for the rational design of electrolyte solutions with desired
physicochemical properties.",2024-12-26T07:45:29Z,http://arxiv.org/abs/2412.19103v1,Vitaly V. Chaban
"Reconstruction Target Matters in Masked Image Modeling for Cross-Domain
  Few-Shot Learning","Cross-Domain Few-Shot Learning (CDFSL) requires the model to transfer
knowledge from the data-abundant source domain to data-scarce target domains
for fast adaptation, where the large domain gap makes CDFSL a challenging
problem. Masked Autoencoder (MAE) excels in effectively using unlabeled data
and learning image's global structures, enhancing model generalization and
robustness. However, in the CDFSL task with significant domain shifts, we find
MAE even shows lower performance than the baseline supervised models. In this
paper, we first delve into this phenomenon for an interpretation. We find that
MAE tends to focus on low-level domain information during reconstructing pixels
while changing the reconstruction target to token features could mitigate this
problem. However, not all features are beneficial, as we then find
reconstructing high-level features can hardly improve the model's
transferability, indicating a trade-off between filtering domain information
and preserving the image's global structure. In all, the reconstruction target
matters for the CDFSL task. Based on the above findings and interpretations, we
further propose Domain-Agnostic Masked Image Modeling (DAMIM) for the CDFSL
task. DAMIM includes an Aggregated Feature Reconstruction module to
automatically aggregate features for reconstruction, with balanced learning of
domain-agnostic information and images' global structure, and a Lightweight
Decoder module to further benefit the encoder's generalizability. Experiments
on four CDFSL datasets demonstrate that our method achieves state-of-the-art
performance.",2024-12-26T07:43:01Z,http://arxiv.org/abs/2412.19101v1,"Ran Ma, Yixiong Zou, Yuhua Li, Ruixuan Li"
"BSDB-Net: Band-Split Dual-Branch Network with Selective State Spaces
  Mechanism for Monaural Speech Enhancement","Although the complex spectrum-based speech enhancement(SE) methods have
achieved significant performance, coupling amplitude and phase can lead to a
compensation effect, where amplitude information is sacrificed to compensate
for the phase that is harmful to SE. In addition, to further improve the
performance of SE, many modules are stacked onto SE, resulting in increased
model complexity that limits the application of SE. To address these problems,
we proposed a dual-path network based on compressed frequency using Mamba.
First, we extract amplitude and phase information through parallel dual
branches. This approach leverages structured complex spectra to implicitly
capture phase information and solves the compensation effect by decoupling
amplitude and phase, and the network incorporates an interaction module to
suppress unnecessary parts and recover missing components from the other
branch. Second, to reduce network complexity, the network introduces a
band-split strategy to compress the frequency dimension. To further reduce
complexity while maintaining good performance, we designed a Mamba-based module
that models the time and frequency dimensions under linear complexity. Finally,
compared to baselines, our model achieves an average 8.3 times reduction in
computational complexity while maintaining superior performance. Furthermore,
it achieves a 25 times reduction in complexity compared to transformer-based
models.",2024-12-26T07:42:07Z,http://arxiv.org/abs/2412.19099v1,"Cunhang Fan, Enrui Liu, Andong Li, Jianhua Tao, Jian Zhou, Jiahao Li, Chengshi Zheng, Zhao Lv"
"Towards structural softness and enhanced electromechanical responses in
  HfO2 ferroelectrics","Structural softness - often characterized by unstable phonon modes and large
electromechanical responses - is a hallmark of ferroelectric perovskites like
BaTiO3 or Pb(Ti,Zr)O3. Whether HfO2 ferroelectrics present any such structural
softness is still a matter of debate. Here, using first principles
calculations, we predict that it is possible to induce structural instabilities
in hafnia. More specifically, our calculations show that in-plane epitaxial
tensile strain causes a mechanical instability of the ferroelectric phase,
which transforms discontinuously into an antipolar polymorph. Then, upon
release of the tensile strain, the antipolar polymorph transforms back to the
ferroelectric state by a soft phonon instability. We show that the softening is
accompanied by enhancements in the dielectric and piezoelectric responses.
While these transitions occur at high epitaxial strains for pure ferroelectric
HfO2, we show that the required deformations are considerably lowered in
superlattices with other simple oxides, which may facilitate realizing these
effects experimentally.",2024-12-26T07:23:16Z,http://arxiv.org/abs/2412.19093v1,"Binayak Mukherjee, Natalya S. Fedorova, Jorge Íñiguez-González"
"Quantum Algorithm for Vector Set Orthogonal Normalization and Matrix QR
  Decomposition with Polynomial Speedup","Vector set orthogonal normalization and matrix QR decomposition are
fundamental problems in matrix analysis with important applications in many
fields. We know that Gram-Schmidt process is a widely used method to solve
these two problems. However, the existing methods, including Gram-Schmidt
process have problems of high complexity, scaling $O(N^3)$ in the system
dimension $N$, which leads to difficulties when calculating large-scale or
ill-conditioned problems. With the development of quantum information
processing, a series of quantum algorithms have been proposed, providing
advantages and speedups over classical algorithms in many fields. In this
paper, we propose quantum algorithms to solve these two problems based on the
idea of Gram-Schmidt process and quantum phase estimation. The complexity of
proposed quantum algorithms is also theoretically and numerically analyzed. We
find that our algorithms provide polynomial acceleration over the best-known
classical and quantum algorithms on these two problems, scaling
$O(N^2\mathrm{poly}(\log N))$ in the dimension $N$ of the system.",2024-12-26T07:04:34Z,http://arxiv.org/abs/2412.19090v1,"Zi-Ming Li, Yu-xi Liu"
"Assessing Pre-trained Models for Transfer Learning through Distribution
  of Spectral Components","Pre-trained model assessment for transfer learning aims to identify the
optimal candidate for the downstream tasks from a model hub, without the need
of time-consuming fine-tuning. Existing advanced works mainly focus on
analyzing the intrinsic characteristics of the entire features extracted by
each pre-trained model or how well such features fit the target labels. This
paper proposes a novel perspective for pre-trained model assessment through the
Distribution of Spectral Components (DISCO). Through singular value
decomposition of features extracted from pre-trained models, we investigate
different spectral components and observe that they possess distinct
transferability, contributing diversely to the fine-tuning performance.
Inspired by this, we propose an assessment method based on the distribution of
spectral components which measures the proportions of their corresponding
singular values. Pre-trained models with features concentrating on more
transferable components are regarded as better choices for transfer learning.
We further leverage the labels of downstream data to better estimate the
transferability of each spectral component and derive the final assessment
criterion. Our proposed method is flexible and can be applied to both
classification and regression tasks. We conducted comprehensive experiments
across three benchmarks and two tasks including image classification and object
detection, demonstrating that our method achieves state-of-the-art performance
in choosing proper pre-trained models from the model hub for transfer learning.",2024-12-26T06:54:22Z,http://arxiv.org/abs/2412.19085v1,"Tengxue Zhang, Yang Shu, Xinyang Chen, Yifei Long, Chenjuan Guo, Bin Yang"
"Social Optima in Linear Quadratic Graphon Field Control: Analysis via
  Infinite Dimensional Approach","This paper is concerned with linear quadratic graphon field social control
problem where the noises of individual agents are correlated. Compared with the
well-studied mean field system, the graphon field system consists of a large
number of agents coupled weakly via a weighted undirected graph where each node
represents an individual agent. Another notable feature of this paper is that
the dynamics of states of agents are driven by Brownian motions with a
correlation matrix. The infinite dimensional approach is adopted to design the
centralized and decentralized controls for our large population system. By
graphon theory, we prove that the linear quadratic (LQ) social optimum control
problem under the centralized information pattern is equivalent to an LQ
optimal control problem concerned with a stochastic evolution equation, and the
feedback-type optimal centralized control is obtained. Then, by designing an
auxiliary infinite dimensional optimal control problem through agent number
$N\rightarrow\infty$, a set of decentralized strategies are constructed, which
are further shown to be asymptotically social optimal.",2024-12-26T06:46:19Z,http://arxiv.org/abs/2412.19082v1,"De-xuan Xu, Zhun Gou, Nan-jing Huang"
"Graph-Enhanced Dual-Stream Feature Fusion with Pre-Trained Model for
  Acoustic Traffic Monitoring","Microphone array techniques are widely used in sound source localization and
smart city acoustic-based traffic monitoring, but these applications face
significant challenges due to the scarcity of labeled real-world traffic audio
data and the complexity and diversity of application scenarios. The DCASE
Challenge's Task 10 focuses on using multi-channel audio signals to count
vehicles (cars or commercial vehicles) and identify their directions
(left-to-right or vice versa). In this paper, we propose a graph-enhanced
dual-stream feature fusion network (GEDF-Net) for acoustic traffic monitoring,
which simultaneously considers vehicle type and direction to improve detection.
We propose a graph-enhanced dual-stream feature fusion strategy which consists
of a vehicle type feature extraction (VTFE) branch, a vehicle direction feature
extraction (VDFE) branch, and a frame-level feature fusion module to combine
the type and direction feature for enhanced performance. A pre-trained model
(PANNs) is used in the VTFE branch to mitigate data scarcity and enhance the
type features, followed by a graph attention mechanism to exploit temporal
relationships and highlight important audio events within these features. The
frame-level fusion of direction and type features enables fine-grained feature
representation, resulting in better detection performance. Experiments
demonstrate the effectiveness of our proposed method. GEDF-Net is our
submission that achieved 1st place in the DCASE 2024 Challenge Task 10.",2024-12-26T06:28:42Z,http://arxiv.org/abs/2412.19078v1,"Shitong Fan, Feiyang Xiao, Wenbo Wang, Shuhan Qi, Qiaoxi Zhu, Wenwu Wang, Jian Guan"
Effective and secure federated online learning to rank,"Online Learning to Rank (OLTR) optimises ranking models using implicit user
feedback, such as clicks. Unlike traditional Learning to Rank (LTR) methods
that rely on a static set of training data with relevance judgements to learn a
ranking model, OLTR methods update the model continually as new data arrives.
Thus, it addresses several drawbacks such as the high cost of human
annotations, potential misalignment between user preferences and human
judgments, and the rapid changes in user query intents. However, OLTR methods
typically require the collection of searchable data, user queries, and clicks,
which poses privacy concerns for users.
  Federated Online Learning to Rank (FOLTR) integrates OLTR within a Federated
Learning (FL) framework to enhance privacy by not sharing raw data. While
promising, FOLTR methods currently lag behind traditional centralised OLTR due
to challenges in ranking effectiveness, robustness with respect to data
distribution across clients, susceptibility to attacks, and the ability to
unlearn client interactions and data. This thesis presents a comprehensive
study on Federated Online Learning to Rank, addressing its effectiveness,
robustness, security, and unlearning capabilities, thereby expanding the
landscape of FOLTR.",2024-12-26T05:53:10Z,http://arxiv.org/abs/2412.19069v1,Shuyi Wang
Learning Monocular Depth from Events via Egomotion Compensation,"Event cameras are neuromorphically inspired sensors that sparsely and
asynchronously report brightness changes. Their unique characteristics of high
temporal resolution, high dynamic range, and low power consumption make them
well-suited for addressing challenges in monocular depth estimation (e.g.,
high-speed or low-lighting conditions). However, current existing methods
primarily treat event streams as black-box learning systems without
incorporating prior physical principles, thus becoming over-parameterized and
failing to fully exploit the rich temporal information inherent in event camera
data. To address this limitation, we incorporate physical motion principles to
propose an interpretable monocular depth estimation framework, where the
likelihood of various depth hypotheses is explicitly determined by the effect
of motion compensation. To achieve this, we propose a Focus Cost Discrimination
(FCD) module that measures the clarity of edges as an essential indicator of
focus level and integrates spatial surroundings to facilitate cost estimation.
Furthermore, we analyze the noise patterns within our framework and improve it
with the newly introduced Inter-Hypotheses Cost Aggregation (IHCA) module,
where the cost volume is refined through cost trend prediction and multi-scale
cost consistency constraints. Extensive experiments on real-world and synthetic
datasets demonstrate that our proposed framework outperforms cutting-edge
methods by up to 10\% in terms of the absolute relative error metric, revealing
superior performance in predicting accuracy.",2024-12-26T05:41:18Z,http://arxiv.org/abs/2412.19067v1,"Haitao Meng, Chonghao Zhong, Sheng Tang, Lian JunJia, Wenwei Lin, Zhenshan Bing, Yi Chang, Gang Chen, Alois Knoll"
Coarse-grained binning in Drell-Yan transverse momentum spectra,"We report a study of the determination of the intrinsic transverse momentum
of partons, the intrinsic $k_T$, from the dilepton transverse momentum $p_T$ in
Drell-Yan (DY) production at hadron colliders. The result shows that a good
sensitivity to the intrinsic $k_T$ distribution is achieved by measuring
relative ratios between the cross sections of suitably defined low-$p_T$ and
high-$p_T$ regions. The study is performed through both a pseudo-data test and
an extraction from measurements of the DY process by the CMS collaboration.
Since the methodology does not rely on any dedicated partition of bins, this
$p_T$-ratio observable requires less special treatment in very low $p_T$
regions, and propagates lower systematic uncertainties induced from unfolding
or momentum migration, in contrast with previous proposals of using a
fine-binning measurement of the differential cross section.",2024-12-26T05:13:39Z,http://arxiv.org/abs/2412.19060v1,"Wenxiao Zhan, Siqi Yang, Minghui Liu, Francesco Hautmann, Liang Han"
"SpectralKD: Understanding and Optimizing Vision Transformer Distillation
  through Spectral Analysis","Knowledge distillation effectively reduces model complexity while improving
performance, yet the underlying knowledge transfer mechanisms remain poorly
understood. We propose novel spectral analysis methods and guidelines to
optimize distillation, making the knowledge transfer process more
interpretable. Our analysis reveals that CaiT models concentrate information in
their first and last few layers, informing optimal layer selection for feature
map distillation. Surprisingly, we discover that Swin Transformer and CaiT
exhibit similar spectral encoding patterns despite their architectural
differences, enhancing our understanding of transformer architectures and
leading to improved feature map alignment strategies. Based on these insights,
we introduce a simple yet effective spectral alignment method named SpectralKD.
Experimental results demonstrate that following our guidelines enables
SpectralKD to achieve state-of-the-art performance (DeiT-Tiny: $+5.2\%$,
Swin-Tiny: $+1.4\%$ in ImageNet-1k Top-1 accuracy). Furthermore, through
spectral analysis of student models trained with and without distillation, we
show that distilled models mirror spectral patterns of their teachers,
providing a new lens for interpreting knowledge distillation dynamics. Our
code, pre-trained models, and experimental logs will be made publicly
available.",2024-12-26T04:45:05Z,http://arxiv.org/abs/2412.19055v1,"Huiyuan Tian, Bonan Xu, Shijian Li, Gang Pan"
Jasper and Stella: distillation of SOTA embedding models,"A crucial component of many deep learning applications (such as FAQ and RAG)
is dense retrieval, in which embedding models are used to convert raw text to
numerical vectors and then get the most similar text by MIPS (Maximum Inner
Product Search). Some text embedding benchmarks (e.g. MTEB, BEIR, and
AIR-Bench) have been established to evaluate embedding models accurately.
Thanks to these benchmarks, we can use SOTA models; however, the deployment and
application of these models in industry were hampered by their large vector
dimensions and numerous parameters. To alleviate this problem, 1) we present a
distillation technique that can enable a smaller student model to achieve good
performance. 2) Inspired by MRL we present a training approach of reducing the
vector dimensions based on its own vectors or its teacher vectors. 3) We do
simple yet effective alignment training between images and text to make our
model a multimodal encoder. We trained Stella and Jasper models using the
technologies above and achieved high scores on the MTEB leaderboard. We release
the model and data at Hugging Face Hub
(https://huggingface.co/infgrad/jasper_en_vision_language_v1) and the training
logs are at https://api.wandb.ai/links/dunnzhang0/z8jqoqpb.",2024-12-26T04:05:28Z,http://arxiv.org/abs/2412.19048v1,"Dun Zhang, FulongWang"
"Indonesian-English Code-Switching Speech Synthesizer Utilizing
  Multilingual STEN-TTS and Bert LID","Multilingual text-to-speech systems convert text into speech across multiple
languages. In many cases, text sentences may contain segments in different
languages, a phenomenon known as code-switching. This is particularly common in
Indonesia, especially between Indonesian and English. Despite its significance,
no research has yet developed a multilingual TTS system capable of handling
code-switching between these two languages. This study addresses
Indonesian-English code-switching in STEN-TTS. Key modifications include adding
a language identification component to the text-to-phoneme conversion using
finetuned BERT for per-word language identification, as well as removing
language embedding from the base model. Experimental results demonstrate that
the code-switching model achieves superior naturalness and improved speech
intelligibility compared to the Indonesian and English baseline STEN-TTS
models.",2024-12-26T03:37:40Z,http://arxiv.org/abs/2412.19043v1,"Ahmad Alfani Handoyo, Chung Tran, Dessi Puji Lestari, Sakriani Sakti"
"An experimental proposal certification for any three-qubit generalized
  Greenberger-Horne-Zeilinger states based on the fine-grained steering
  inequality","Multi-party quantum steering is an important concept in quantum information
theory and quantum mechanics, typically related to quantum entanglement and
quantum nonlocality. It enables precise manipulation of large quantum systems,
which is essential for large-scale quantum computing, simulations, and quantum
communication. Recently, a quantum steering certification for any three-qubit
generalized Greenberger-Horne-Zeilinger (GGHZ) states based on the fine-grained
steering inequality was proved [Quantum Studies: Mathematics and Foundations,
2022, 9(2): 175-198]. Here we provide an experimental proposal to prepare the
GGHZ states in photon system. The measurement observalbes in each party can be
realized by different polarization optical elements. By choosing the angles of
the waveplates, our experiment proposal can observe the maximum quantum
violation for any three-qubit GGHZ states. Our proposal can be easily extended
to high-dimensional qubits and multi-photon GHZ states, which provides a method
to study the complex multi-party quantum protocols.",2024-12-26T02:36:05Z,http://arxiv.org/abs/2412.19028v1,"Zhi-Hao Bian, Jia-Qi Sun, Yi Shen"
"Channel-Aware Optimal Transport: A Theoretical Framework for Generative
  Communication","Optimal transport has numerous applications, particularly in machine learning
tasks involving generative models. In practice, the transportation process
often encounters an information bottleneck, typically arising from the
conversion of a communication channel into a rate-limited bit pipeline using
error correction codes. While this conversion enables a channel-oblivious
approach to optimal transport, it fails to fully exploit the available degrees
of freedom. Motivated by the emerging paradigm of generative communication,
this paper examines the problem of channel-aware optimal transport, where a
block of i.i.d. random variables is transmitted through a memoryless channel to
generate another block of i.i.d. random variables with a prescribed marginal
distribution such that the end-to-end distortion is minimized. With unlimited
common randomness available to the encoder and decoder, the source-channel
separation architecture is shown to be asymptotically optimal as the
blocklength approaches infinity. On the other hand, in the absence of common
randomness, the source-channel separation architecture is generally suboptimal.
For this scenario, a hybrid coding scheme is proposed, which partially retains
the generative capabilities of the given channel while enabling reliable
transmission of digital information. It is demonstrated that the proposed
hybrid coding scheme can outperform both separation-based and uncoded schemes.",2024-12-26T02:23:08Z,http://arxiv.org/abs/2412.19025v1,"Xiqiang Qu, Ruibin Li, Jun Chen, Lei Yu, Xinbing Wang"
Adaptivity can help exponentially for shadow tomography,"In recent years there has been significant interest in understanding the
statistical complexity of learning from quantum data under the constraint that
one can only make unentangled measurements. While a key challenge in
establishing tight lower bounds in this setting is to deal with the fact that
the measurements can be chosen in an adaptive fashion, a recurring theme has
been that adaptivity offers little advantage over more straightforward,
nonadaptive protocols.
  In this note, we offer a counterpoint to this. We show that for the basic
task of shadow tomography, protocols that use adaptively chosen two-copy
measurements can be exponentially more sample-efficient than any protocol that
uses nonadaptive two-copy measurements.",2024-12-26T02:13:04Z,http://arxiv.org/abs/2412.19022v1,"Sitan Chen, Weiyuan Gong, Zhihan Zhang"
"Relation-aware Hierarchical Prompt for Open-vocabulary Scene Graph
  Generation","Open-vocabulary Scene Graph Generation (OV-SGG) overcomes the limitations of
the closed-set assumption by aligning visual relationship representations with
open-vocabulary textual representations. This enables the identification of
novel visual relationships, making it applicable to real-world scenarios with
diverse relationships. However, existing OV-SGG methods are constrained by
fixed text representations, limiting diversity and accuracy in image-text
alignment. To address these challenges, we propose the Relation-Aware
Hierarchical Prompting (RAHP) framework, which enhances text representation by
integrating subject-object and region-specific relation information. Our
approach utilizes entity clustering to address the complexity of relation
triplet categories, enabling the effective integration of subject-object
information. Additionally, we utilize a large language model (LLM) to generate
detailed region-aware prompts, capturing fine-grained visual interactions and
improving alignment between visual and textual modalities. RAHP also introduces
a dynamic selection mechanism within Vision-Language Models (VLMs), which
adaptively selects relevant text prompts based on the visual content, reducing
noise from irrelevant prompts. Extensive experiments on the Visual Genome and
Open Images v6 datasets demonstrate that our framework consistently achieves
state-of-the-art performance, demonstrating its effectiveness in addressing the
challenges of open-vocabulary scene graph generation.",2024-12-26T02:12:37Z,http://arxiv.org/abs/2412.19021v1,"Tao Liu, Rongjie Li, Chongyu Wang, Xuming He"
"Harnessing high-dimensional symmetric and anti-symmetric Bell states
  through quantum interference","High-dimensional quantum entanglement is an essential resource in quantum
technology since it provides benefits in increasing the information capacity
and processing speed. Thus, the controlled harnessing of high-dimensional
entanglement has long been hailed as a necessary prerequisite towards practical
quantum applications. By using a deterministic quantum state filter that
implemented through quantum interference, we present a generalised formulation
for the complete high-dimensional symmetric and anti-symmetric Bell basis, and
experimentally prepare four-dimensional orbital angular momentum Bell states
that provide the well-behaved symmetric or anti-symmetric properties.
Additionally, we use a concise yet efficient scan of temporal delay to directly
observe high-dimensional two-photon interference effects in spatial modes.
These results provide an alternative way for harnessing high-dimensional
entanglement, and may facilitate the use of quantum interference for more
complex quantum information processing tasks that beyond qubits.",2024-12-26T02:05:01Z,http://arxiv.org/abs/2412.19019v1,"Ling Hong, Yuning Zhang, Yuanyuan Chen, Lixiang Chen"
"Enhancing Audiovisual Speech Recognition through Bifocal Preference
  Optimization","Audiovisual Automatic Speech Recognition (AV-ASR) aims to improve speech
recognition accuracy by leveraging visual signals. It is particularly
challenging in unconstrained real-world scenarios across various domains due to
noisy acoustic environments, spontaneous speech, and the uncertain use of
visual information. Most previous works fine-tune audio-only ASR models on
audiovisual datasets, optimizing them for conventional ASR objectives. However,
they often neglect visual features and common errors in unconstrained video
scenarios. In this paper, we propose using a preference optimization strategy
to improve speech recognition accuracy for real-world videos. First, we create
preference data via simulating common errors that occurred in AV-ASR from two
focals: manipulating the audio or vision input and rewriting the output
transcript. Second, we propose BPO-AVASR, a Bifocal Preference Optimization
method to improve AV-ASR models by leveraging both input-side and output-side
preference. Extensive experiments demonstrate that our approach significantly
improves speech recognition accuracy across various domains, outperforming
previous state-of-the-art models on real-world video speech recognition.",2024-12-26T00:26:45Z,http://arxiv.org/abs/2412.19005v1,"Yihan Wu, Yichen Lu, Yifan Peng, Xihua Wang, Ruihua Song, Shinji Watanabe"
"Impact of resummation on the production and experimental bounds of
  scalar high-electric-charge objects","A one-loop Dyson-Schwinger-like resummation scheme is applied to scalar
High-Electric-Charge compact Objects (HECOs), extending previous work on
spin-1/2 case. The electromagnetic interactions of HECOs are considered within
the framework of strongly coupled scalar Quantun Electrodynamics. The
resummation amounts to determining non-trivial ultraviolet (UV) fixed points,
at which the effective Lagrangian, which will lead to the pertinent predictions
on the cross sections, is computed. In contrast to the fermionic HECO case, in
which the fixed point structure was determined solely by the interactions of
the HECOs with the photon field, in the scalar case the existence of
non-trivial UV fixed points requires the presence of additional strong self
interactions among the HECOs. Our resummation scheme, which is notably
different from a lattice strong-coupling approach, makes the computation of the
pertinent scalar-HECO-production cross sections reliable, thus allowing
revisiting the mass bounds obtained from searches for such objects in current
or future colliders. Our MadGraph implementation of the results leads to
enhanced (up to ~30%) lower bounds on the mass of scalar HECOs, as compared to
those extracted from the tree-level processes typically used in LHC collider
searches by ATLAS and MoEDAL experiments.",2024-12-25T23:13:36Z,http://arxiv.org/abs/2412.19001v1,"Jean Alexandre, Nick E. Mavromatos, Vasiliki A. Mitsou, Emanuela Musumeci"
"GeoMatch++: Morphology Conditioned Geometry Matching for
  Multi-Embodiment Grasping","Despite recent progress on multi-finger dexterous grasping, current methods
focus on single grippers and unseen objects, and even the ones that explore
cross-embodiment, often fail to generalize well to unseen end-effectors. This
work addresses the problem of dexterous grasping generalization to unseen
end-effectors via a unified policy that learns correlation between gripper
morphology and object geometry. Robot morphology contains rich information
representing how joints and links connect and move with respect to each other
and thus, we leverage it through attention to learn better end-effector
geometry features. Our experiments show an average of 9.64% increase in grasp
success rate across 3 out-of-domain end-effectors compared to previous methods.",2024-12-25T22:36:57Z,http://arxiv.org/abs/2412.18998v1,"Yunze Wei, Maria Attarian, Igor Gilitschenski"
"MiTREE: Multi-input Transformer Ecoregion Encoder for Species
  Distribution Modelling","Climate change poses an extreme threat to biodiversity, making it imperative
to efficiently model the geographical range of different species. The
availability of large-scale remote sensing images and environmental data has
facilitated the use of machine learning in Species Distribution Models (SDMs),
which aim to predict the presence of a species at any given location.
Traditional SDMs, reliant on expert observation, are labor-intensive, but
advancements in remote sensing and citizen science data have facilitated
machine learning approaches to SDM development. However, these models often
struggle with leveraging spatial relationships between different inputs -- for
instance, learning how climate data should inform the data present in satellite
imagery -- without upsampling or distorting the original inputs. Additionally,
location information and ecological characteristics at a location play a
crucial role in predicting species distribution models, but these aspects have
not yet been incorporated into state-of-the-art approaches. In this work, we
introduce MiTREE: a multi-input Vision-Transformer-based model with an
ecoregion encoder. MiTREE computes spatial cross-modal relationships without
upsampling as well as integrates location and ecological context. We evaluate
our model on the SatBird Summer and Winter datasets, the goal of which is to
predict bird species encounter rates, and we find that our approach improves
upon state-of-the-art baselines.",2024-12-25T22:20:47Z,http://arxiv.org/abs/2412.18995v1,"Theresa Chen, Yao-Yi Chiang"
"Geospatial Data Fusion: Combining Lidar, SAR, and Optical Imagery with
  AI for Enhanced Urban Mapping","This study explores the integration of Lidar, Synthetic Aperture Radar (SAR),
and optical imagery through advanced artificial intelligence techniques for
enhanced urban mapping. By fusing these diverse geospatial datasets, we aim to
overcome the limitations associated with single-sensor data, achieving a more
comprehensive representation of urban environments. The research employs Fully
Convolutional Networks (FCNs) as the primary deep learning model for urban
feature extraction, enabling precise pixel-wise classification of essential
urban elements, including buildings, roads, and vegetation. To optimize the
performance of the FCN model, we utilize Particle Swarm Optimization (PSO) for
hyperparameter tuning, significantly enhancing model accuracy. Key findings
indicate that the FCN-PSO model achieved a pixel accuracy of 92.3% and a mean
Intersection over Union (IoU) of 87.6%, surpassing traditional single-sensor
approaches. These results underscore the potential of fused geospatial data and
AI-driven methodologies in urban mapping, providing valuable insights for urban
planning and management. The implications of this research pave the way for
future developments in real-time mapping and adaptive urban infrastructure
planning.",2024-12-25T22:17:31Z,http://arxiv.org/abs/2412.18994v1,"Sajjad Afroosheh, Mohammadreza Askari"
"On the architecture of the Symplectic $(A_\infty,2)$-Category","This note relates to the author's construction of the Symplectic
$(A_\infty,2)$-Category, $\mathsf{Symp}$. Here we explain two ways of encoding
the information in $\mathsf{Symp}$, one topological, one algebraic. The
topological encoding is as an $(A_\infty,2)$-flow category, which we define
here. The algebraic encoding is as a linear $(A_\infty,2)$-category, which we
extract from the topological encoding. In upcoming work, the author and
Wehrheim plan to use the adiabatic Fredholm theory recently developed by
Bottman-Wehrheim to construct $\mathsf{Symp}$ as an $(A_\infty,2)$-flow
category.
  The definition of linear $(A_\infty,2)$-category that we give in this note is
different than the one proposed by Bottman-Carmeli. The recursive structure of
the 2-associahedra identifies faces with fiber products of 2-associahedra over
associahedra, and these fiber products led Bottman-Carmeli to associate
operations to singular chains on 2-associahedra. The innovation in our new
definition of linear $(A_\infty,2)$-category is to extend the family of
2-associahedra to include all fiber products of 2-associahedra over
associahedra. This allows us to associate operations to cellular chains, which
in particular enables us to produce a definition that involves only one
operation in each arity, governed by a collection of $(A_\infty,2)$-equations.",2024-12-25T22:11:18Z,http://arxiv.org/abs/2412.18993v1,Nathaniel Bottman
"Detection and classification of DDoS flooding attacks by machine
  learning method","This study focuses on a method for detecting and classifying distributed
denial of service (DDoS) attacks, such as SYN Flooding, ACK Flooding, HTTP
Flooding, and UDP Flooding, using neural networks. Machine learning,
particularly neural networks, is highly effective in detecting malicious
traffic. A dataset containing normal traffic and various DDoS attacks was used
to train a neural network model with a 24-106-5 architecture. The model
achieved high Accuracy (99.35%), Precision (99.32%), Recall (99.54%), and
F-score (0.99) in the classification task. All major attack types were
correctly identified. The model was also further tested in the lab using
virtual infrastructures to generate normal and DDoS traffic. The results showed
that the model can accurately classify attacks under near-real-world
conditions, demonstrating 95.05% accuracy and balanced F-score scores for all
attack types. This confirms that neural networks are an effective tool for
detecting DDoS attacks in modern information security systems.",2024-12-25T21:58:52Z,http://arxiv.org/abs/2412.18990v1,"Dmytro Tymoshchuk, Oleh Yasniy, Mykola Mytnyk, Nataliya Zagorodna, Vitaliy Tymoshchuk"
"HAND: Hierarchical Attention Network for Multi-Scale Handwritten
  Document Recognition and Layout Analysis","Handwritten document recognition (HDR) is one of the most challenging tasks
in the field of computer vision, due to the various writing styles and complex
layouts inherent in handwritten texts. Traditionally, this problem has been
approached as two separate tasks, handwritten text recognition and layout
analysis, and struggled to integrate the two processes effectively. This paper
introduces HAND (Hierarchical Attention Network for Multi-Scale Document), a
novel end-to-end and segmentation-free architecture for simultaneous text
recognition and layout analysis tasks. Our model's key components include an
advanced convolutional encoder integrating Gated Depth-wise Separable and
Octave Convolutions for robust feature extraction, a Multi-Scale Adaptive
Processing (MSAP) framework that dynamically adjusts to document complexity and
a hierarchical attention decoder with memory-augmented and sparse attention
mechanisms. These components enable our model to scale effectively from
single-line to triple-column pages while maintaining computational efficiency.
Additionally, HAND adopts curriculum learning across five complexity levels. To
improve the recognition accuracy of complex ancient manuscripts, we fine-tune
and integrate a Domain-Adaptive Pre-trained mT5 model for post-processing
refinement. Extensive evaluations on the READ 2016 dataset demonstrate the
superior performance of HAND, achieving up to 59.8% reduction in CER for
line-level recognition and 31.2% for page-level recognition compared to
state-of-the-art methods. The model also maintains a compact size of 5.60M
parameters while establishing new benchmarks in both text recognition and
layout analysis. Source code and pre-trained models are available at :
https://github.com/MHHamdan/HAND.",2024-12-25T20:36:29Z,http://arxiv.org/abs/2412.18981v1,"Mohammed Hamdan, Abderrahmane Rahiche, Mohamed Cheriet"
CGCOD: Class-Guided Camouflaged Object Detection,"Camouflaged Object Detection (COD) is designed to identify objects that blend
seamlessly with their surroundings. Due to the complexity of camouflaged
objects (such as shape, color, and texture), their semantic cues are often
blurred or completely lost, posing a significant challenge for COD. Existing
COD methods often rely on visual features, which are not stable enough in
changeable camouflage environments. This instability leads to false positives
and false negatives, resulting in incomplete or inaccurate segmentation
results. In this paper, to solve this problem, we propose a new task,
Class-Guided Camouflaged Object Detection (CG-COD), which extends the
traditional COD task by introducing object class knowledge, significantly
improving the robustness and segmentation accuracy of the model in complex
environments. Toward this end, we construct a dataset, CamoClass, containing
the camouflaged objects in the real scenes and their corresponding class
annotation. Based on this, we propose a multi-stage framework CGNet which
consists of a plug-and-play class prompt generator and a class-guided detector.
Under the guidance of textual information, CGNet enables efficient
segmentation. It is worth emphasizing that for the first time, we extend the
object class annotations on existing COD benchmark datasets, and introduce a
flexible framework to improve the performance of the existing COD model under
text guidance.",2024-12-25T19:38:32Z,http://arxiv.org/abs/2412.18977v1,"Chenxi Zhang, Qing Zhang, Jiayun Wu, Youwei Pang"
Injecting Bias into Text Classification Models using Backdoor Attacks,"The rapid growth of natural language processing (NLP) and pre-trained
language models have enabled accurate text classification in a variety of
settings. However, text classification models are susceptible to backdoor
attacks, where an attacker embeds a trigger into the victim model to make the
model predict attacker-desired labels in targeted scenarios. In this paper, we
propose to utilize backdoor attacks for a new purpose: bias injection. We
develop a backdoor attack in which a subset of the training dataset is poisoned
to associate strong male actors with negative sentiment. We execute our attack
on two popular text classification datasets (IMDb and SST) and seven different
models ranging from traditional Doc2Vec-based models to LSTM networks and
modern transformer-based BERT and RoBERTa models. Our results show that the
reduction in backdoored models' benign classification accuracy is limited,
implying that our attacks remain stealthy, whereas the models successfully
learn to associate strong male actors with negative sentiment (100% attack
success rate with &gt;= 3% poison rate). Attacks on BERT and RoBERTa are
particularly more stealthy and effective, demonstrating an increased risk of
using modern and larger models. We also measure the generalizability of our
bias injection by proposing two metrics: (i) U-BBSR which uses previously
unseen words when measuring attack success, and (ii) P-BBSR which measures
attack success using paraphrased test samples. U-BBSR and P-BBSR results show
that the bias injected by our attack can go beyond memorizing a trigger phrase.",2024-12-25T19:32:02Z,http://arxiv.org/abs/2412.18975v1,"A. Dilara Yavuz, M. Emre Gursoy"
"Don't Lose Yourself: Boosting Multimodal Recommendation via Reducing
  Node-neighbor Discrepancy in Graph Convolutional Network","The rapid expansion of multimedia contents has led to the emergence of
multimodal recommendation systems. It has attracted increasing attention in
recommendation systems because its full utilization of data from different
modalities alleviates the persistent data sparsity problem. As such, multimodal
recommendation models can learn personalized information about nodes in terms
of visual and textual. To further alleviate the data sparsity problem, some
previous works have introduced graph convolutional networks (GCNs) for
multimodal recommendation systems, to enhance the semantic representation of
users and items by capturing the potential relationships between them. However,
adopting GCNs inevitably introduces the over-smoothing problem, which make
nodes to be too similar. Unfortunately, incorporating multimodal information
will exacerbate this challenge because nodes that are too similar will lose the
personalized information learned through multimodal information. To address
this problem, we propose a novel model that retains the personalized
information of ego nodes during feature aggregation by Reducing Node-neighbor
Discrepancy (RedN^nD). Extensive experiments on three public datasets show that
RedN^nD achieves state-of-the-art performance on accuracy and robustness, with
significant improvements over existing GCN-based multimodal frameworks.",2024-12-25T18:41:36Z,http://arxiv.org/abs/2412.18962v1,"Zheyu Chen, Jinfeng Xu, Haibo Hu"
Musings About the Future of Search: A Return to the Past?,"When you have a question, the most effective way to have the question
answered is to directly connect with experts on the topic and have a
conversation with them. Prior to the invention of writing, this was the only
way. Although effective, this solution exhibits scalability challenges. Writing
allowed knowledge to be materialized, preserved, and replicated, enabling the
development of different technologies over the centuries to connect information
seekers with relevant information. This progression ultimately culminated in
the ten-blue-links web search paradigm we're familiar with, just before the
recent emergence of generative AI. However, we often forget that consuming
static content is an imperfect solution. With the advent of large language
models, it has become possible to develop a superior experience by allowing
users to directly engage with experts. These interactions can of course satisfy
information needs, but expert models can do so much more. This coming future
requires reimagining search.",2024-12-25T18:09:34Z,http://arxiv.org/abs/2412.18956v1,"Jimmy Lin, Pankaj Gupta, Will Horn, Gilad Mishne"
"Leave-One-EquiVariant: Alleviating invariance-related information loss
  in contrastive music representations","Contrastive learning has proven effective in self-supervised musical
representation learning, particularly for Music Information Retrieval (MIR)
tasks. However, reliance on augmentation chains for contrastive view generation
and the resulting learnt invariances pose challenges when different downstream
tasks require sensitivity to certain musical attributes. To address this, we
propose the Leave One EquiVariant (LOEV) framework, which introduces a
flexible, task-adaptive approach compared to previous work by selectively
preserving information about specific augmentations, allowing the model to
maintain task-relevant equivariances. We demonstrate that LOEV alleviates
information loss related to learned invariances, improving performance on
augmentation related tasks and retrieval without sacrificing general
representation quality. Furthermore, we introduce a variant of LOEV, LOEV++,
which builds a disentangled latent space by design in a self-supervised manner,
and enables targeted retrieval based on augmentation related attributes.",2024-12-25T18:06:44Z,http://arxiv.org/abs/2412.18955v1,"Julien Guinot, Elio Quinton, György Fazekas"
"MedHallBench: A New Benchmark for Assessing Hallucination in Medical
  Large Language Models","Medical Large Language Models (MLLMs) have demonstrated potential in
healthcare applications, yet their propensity for hallucinations -- generating
medically implausible or inaccurate information -- presents substantial risks
to patient care. This paper introduces MedHallBench, a comprehensive benchmark
framework for evaluating and mitigating hallucinations in MLLMs. Our
methodology integrates expert-validated medical case scenarios with established
medical databases to create a robust evaluation dataset. The framework employs
a sophisticated measurement system that combines automated ACHMI (Automatic
Caption Hallucination Measurement in Medical Imaging) scoring with rigorous
clinical expert evaluations and utilizes reinforcement learning methods to
achieve automatic annotation. Through an optimized reinforcement learning from
human feedback (RLHF) training pipeline specifically designed for medical
applications, MedHallBench enables thorough evaluation of MLLMs across diverse
clinical contexts while maintaining stringent accuracy standards. We conducted
comparative experiments involving various models, utilizing the benchmark to
establish a baseline for widely adopted large language models (LLMs). Our
findings indicate that ACHMI provides a more nuanced understanding of the
effects of hallucinations compared to traditional metrics, thereby highlighting
its advantages in hallucination assessment. This research establishes a
foundational framework for enhancing MLLMs' reliability in healthcare settings
and presents actionable strategies for addressing the critical challenge of AI
hallucinations in medical applications.",2024-12-25T16:51:29Z,http://arxiv.org/abs/2412.18947v1,"Kaiwen Zuo, Yirui Jiang"
"Label-free SERS Discrimination of Proline from Hydroxylated Proline at
  Single-molecule Level Assisted by a Deep Learning Model","Discriminating the low-abundance hydroxylated proline from hydroxylated
proline is crucial for monitoring diseases and eval-uating therapeutic outcomes
that require single-molecule sensors. While the plasmonic nanopore sensor can
detect the hydrox-ylation with single-molecule sensitivity by surface enhanced
Raman spectroscopy (SERS), it suffers from intrinsic fluctuations of
single-molecule signals as well as strong interference from citrates. Here, we
used the occurrence frequency histogram of the single-molecule SERS peaks to
extract overall dataset spectral features, overcome the signal fluctuations and
investigate the citrate-replaced plasmonic nanopore sensors for clean and
distinguishable signals of proline and hydroxylated proline. By ligand exchange
of the citrates by analyte molecules, the representative peaks of citrates
decreased with incubation time, prov-ing occupation of the plasmonic hot spot
by the analytes. As a result, the discrimination of the single-molecule SERS
signals of proline and hydroxylated proline was possible with the convolutional
neural network model with 96.6% accuracy.",2024-12-25T15:46:52Z,http://arxiv.org/abs/2412.18935v1,"Yingqi Zhao, Kuo Zhan, Pei-Lin Xin, Zuyan Chen, Shuai Li, Francesco De Angelis, Jianan Huang"
TINQ: Temporal Inconsistency Guided Blind Video Quality Assessment,"Blind video quality assessment (BVQA) has been actively researched for
user-generated content (UGC) videos. Recently, super-resolution (SR) techniques
have been widely applied in UGC. Therefore, an effective BVQA method for both
UGC and SR scenarios is essential. Temporal inconsistency, referring to
irregularities between consecutive frames, is relevant to video quality.
Current BVQA approaches typically model temporal relationships in UGC videos
using statistics of motion information, but inconsistencies remain unexplored.
Additionally, different from temporal inconsistency in UGC videos, such
inconsistency in SR videos is amplified due to upscaling algorithms. In this
paper, we introduce the Temporal Inconsistency Guided Blind Video Quality
Assessment (TINQ) metric, demonstrating that exploring temporal inconsistency
is crucial for effective BVQA. Since temporal inconsistencies vary between UGC
and SR videos, they are calculated in different ways. Based on this, a spatial
module highlights inconsistent areas across consecutive frames at coarse and
fine granularities. In addition, a temporal module aggregates features over
time in two stages. The first stage employs a visual memory capacity block to
adaptively segment the time dimension based on estimated complexity, while the
second stage focuses on selecting key features. The stages work together
through Consistency-aware Fusion Units to regress cross-time-scale video
quality. Extensive experiments on UGC and SR video quality datasets show that
our method outperforms existing state-of-the-art BVQA methods. Code is
available at https://github.com/Lighting-YXLI/TINQ.",2024-12-25T15:43:41Z,http://arxiv.org/abs/2412.18933v1,"Yixiao Li, Xiaoyuan Yang, Weide Liu, Xin Jin, Xu Jia, Yukun Lai, Haotao Liu, Paul L Rosin, Wei Zhou"
"Malware Classification using a Hybrid Hidden Markov Model-Convolutional
  Neural Network","The proliferation of malware variants poses a significant challenges to
traditional malware detection approaches, such as signature-based methods,
necessitating the development of advanced machine learning techniques. In this
research, we present a novel approach based on a hybrid architecture combining
features extracted using a Hidden Markov Model (HMM), with a Convolutional
Neural Network (CNN) then used for malware classification. Inspired by the
strong results in previous work using an HMM-Random Forest model, we propose
integrating HMMs, which serve to capture sequential patterns in opcode
sequences, with CNNs, which are adept at extracting hierarchical features. We
demonstrate the effectiveness of our approach on the popular Malicia dataset,
and we obtain superior performance, as compared to other machine learning
methods -- our results surpass the aforementioned HMM-Random Forest model. Our
findings underscore the potential of hybrid HMM-CNN architectures in bolstering
malware classification capabilities, offering several promising avenues for
further research in the field of cybersecurity.",2024-12-25T15:34:57Z,http://arxiv.org/abs/2412.18932v1,"Ritik Mehta, Olha Jureckova, Mark Stamp"
"Graph Cut-guided Maximal Coding Rate Reduction for Learning Image
  Embedding and Clustering","In the era of pre-trained models, image clustering task is usually addressed
by two relevant stages: a) to produce features from pre-trained vision models;
and b) to find clusters from the pre-trained features. However, these two
stages are often considered separately or learned by different paradigms,
leading to suboptimal clustering performance. In this paper, we propose a
unified framework, termed graph Cut-guided Maximal Coding Rate Reduction
(CgMCR$^2$), for jointly learning the structured embeddings and the clustering.
To be specific, we attempt to integrate an efficient clustering module into the
principled framework for learning structured representation, in which the
clustering module is used to provide partition information to guide the
cluster-wise compression and the learned embeddings is aligned to desired
geometric structures in turn to help for yielding more accurate partitions. We
conduct extensive experiments on both standard and out-of-domain image datasets
and experimental results validate the effectiveness of our approach.",2024-12-25T15:20:54Z,http://arxiv.org/abs/2412.18930v1,"W. He, Z. Huang, X. Meng, X. Qi, R. Xiao, C. -G. Li"
"UNIC-Adapter: Unified Image-instruction Adapter with Multi-modal
  Transformer for Image Generation","Recently, text-to-image generation models have achieved remarkable
advancements, particularly with diffusion models facilitating high-quality
image synthesis from textual descriptions. However, these models often struggle
with achieving precise control over pixel-level layouts, object appearances,
and global styles when using text prompts alone. To mitigate this issue,
previous works introduce conditional images as auxiliary inputs for image
generation, enhancing control but typically necessitating specialized models
tailored to different types of reference inputs. In this paper, we explore a
new approach to unify controllable generation within a single framework.
Specifically, we propose the unified image-instruction adapter (UNIC-Adapter)
built on the Multi-Modal-Diffusion Transformer architecture, to enable flexible
and controllable generation across diverse conditions without the need for
multiple specialized models. Our UNIC-Adapter effectively extracts multi-modal
instruction information by incorporating both conditional images and task
instructions, injecting this information into the image generation process
through a cross-attention mechanism enhanced by Rotary Position Embedding.
Experimental results across a variety of tasks, including pixel-level spatial
control, subject-driven image generation, and style-image-based image
synthesis, demonstrate the effectiveness of our UNIC-Adapter in unified
controllable image generation.",2024-12-25T15:19:02Z,http://arxiv.org/abs/2412.18928v1,"Lunhao Duan, Shanshan Zhao, Wenjun Yan, Yinglun Li, Qing-Guo Chen, Zhao Xu, Weihua Luo, Kaifu Zhang, Mingming Gong, Gui-Song Xia"
Exemplar-condensed Federated Class-incremental Learning,"We propose Exemplar-Condensed federated class-incremental learning (ECoral)
to distil the training characteristics of real images from streaming data into
informative rehearsal exemplars. The proposed method eliminates the limitations
of exemplar selection in replay-based approaches for mitigating catastrophic
forgetting in federated continual learning (FCL). The limitations particularly
related to the heterogeneity of information density of each summarized data.
Our approach maintains the consistency of training gradients and the
relationship to past tasks for the summarized exemplars to represent the
streaming data compared to the original images effectively. Additionally, our
approach reduces the information-level heterogeneity of the summarized data by
inter-client sharing of the disentanglement generative model. Extensive
experiments show that our ECoral outperforms several state-of-the-art methods
and can be seamlessly integrated with many existing approaches to enhance
performance.",2024-12-25T15:13:40Z,http://arxiv.org/abs/2412.18926v1,"Rui Sun, Yumin Zhang, Varun Ojha, Tejal Shah, Haoran Duan, Bo Wei, Rajiv Ranjan"
"An Attentive Dual-Encoder Framework Leveraging Multimodal Visual and
  Semantic Information for Automatic OSAHS Diagnosis","Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a common sleep disorder
caused by upper airway blockage, leading to oxygen deprivation and disrupted
sleep. Traditional diagnosis using polysomnography (PSG) is expensive,
time-consuming, and uncomfortable. Existing deep learning methods using facial
image analysis lack accuracy due to poor facial feature capture and limited
sample sizes. To address this, we propose a multimodal dual encoder model that
integrates visual and language inputs for automated OSAHS diagnosis. The model
balances data using randomOverSampler, extracts key facial features with
attention grids, and converts physiological data into meaningful text.
Cross-attention combines image and text data for better feature extraction, and
ordered regression loss ensures stable learning. Our approach improves
diagnostic efficiency and accuracy, achieving 91.3% top-1 accuracy in a
four-class severity classification task, demonstrating state-of-the-art
performance. Code will be released upon acceptance.",2024-12-25T14:42:17Z,http://arxiv.org/abs/2412.18919v1,"Yingchen Wei, Xihe Qiu, Xiaoyu Tan, Jingjing Huang, Wei Chu, Yinghui Xu, Yuan Qi"
"Open-Vocabulary Panoptic Segmentation Using BERT Pre-Training of
  Vision-Language Multiway Transformer Model","Open-vocabulary panoptic segmentation remains a challenging problem. One of
the biggest difficulties lies in training models to generalize to an unlimited
number of classes using limited categorized training data. Recent popular
methods involve large-scale vision-language pre-trained foundation models, such
as CLIP. In this paper, we propose OMTSeg for open-vocabulary segmentation
using another large-scale vision-language pre-trained model called BEiT-3 and
leveraging the cross-modal attention between visual and linguistic features in
BEiT-3 to achieve better performance. Experiments result demonstrates that
OMTSeg performs favorably against state-of-the-art models.",2024-12-25T14:31:00Z,http://arxiv.org/abs/2412.18917v1,"Yi-Chia Chen, Wei-Hua Li, Chu-Song Chen"
"Long-Range Tasks Using Short-Context LLMs: Incremental Reasoning With
  Structured Memories","Long-range tasks require reasoning over long inputs. Existing solutions
either need large compute budgets, training data, access to model weights, or
use complex, task-specific approaches. We present PRISM, which alleviates these
concerns by processing information as a stream of chunks, maintaining a
structured in-context memory specified by a typed hierarchy schema. This
approach demonstrates superior performance to baselines on diverse tasks while
using at least 4x smaller contexts than long-context models. Moreover, PRISM is
token-efficient. By producing short outputs and efficiently leveraging
key-value (KV) caches, it achieves up to 54% cost reduction when compared to
alternative short-context approaches. The method also scales down to tiny
information chunks (e.g., 500 tokens) without increasing the number of tokens
encoded or sacrificing quality. Furthermore, we show that it is possible to
generate schemas to generalize our approach to new tasks with minimal effort.",2024-12-25T14:14:31Z,http://arxiv.org/abs/2412.18914v1,"Dulhan Jayalath, James Bradley Wendt, Nicholas Monath, Sandeep Tata, Beliz Gunel"
Robust Target Speaker Direction of Arrival Estimation,"In multi-speaker environments the direction of arrival (DOA) of a target
speaker is key for improving speech clarity and extracting target speaker's
voice. However, traditional DOA estimation methods often struggle in the
presence of noise, reverberation, and particularly when competing speakers are
present. To address these challenges, we propose RTS-DOA, a robust real-time
DOA estimation system. This system innovatively uses the registered speech of
the target speaker as a reference and leverages full-band and sub-band spectral
information from a microphone array to estimate the DOA of the target speaker's
voice. Specifically, the system comprises a speech enhancement module for
initially improving speech quality, a spatial module for learning spatial
information, and a speaker module for extracting voiceprint features.
Experimental results on the LibriSpeech dataset demonstrate that our RTS-DOA
system effectively tackles multi-speaker scenarios and established new optimal
benchmarks.",2024-12-25T14:04:21Z,http://arxiv.org/abs/2412.18913v1,"Zixuan Li, Shulin He, Xueliang Zhang"
"Research Experiment on Multi-Model Comparison for Chinese Text
  Classification Tasks","With the explosive growth of Chinese text data and advancements in natural
language processing technologies, Chinese text classification has become one of
the key techniques in fields such as information retrieval and sentiment
analysis, attracting increasing attention. This paper conducts a comparative
study on three deep learning models:TextCNN, TextRNN, and FastText.specifically
for Chinese text classification tasks. By conducting experiments on the
THUCNews dataset, the performance of these models is evaluated, and their
applicability in different scenarios is discussed.",2024-12-25T13:54:40Z,http://arxiv.org/abs/2412.18908v1,JiaCheng Li
"FedCFA: Alleviating Simpson's Paradox in Model Aggregation with
  Counterfactual Federated Learning","Federated learning (FL) is a promising technology for data privacy and
distributed optimization, but it suffers from data imbalance and heterogeneity
among clients. Existing FL methods try to solve the problems by aligning client
with server model or by correcting client model with control variables. These
methods excel on IID and general Non-IID data but perform mediocrely in
Simpson's Paradox scenarios. Simpson's Paradox refers to the phenomenon that
the trend observed on the global dataset disappears or reverses on a subset,
which may lead to the fact that global model obtained through aggregation in FL
does not accurately reflect the distribution of global data. Thus, we propose
FedCFA, a novel FL framework employing counterfactual learning to generate
counterfactual samples by replacing local data critical factors with global
average data, aligning local data distributions with the global and mitigating
Simpson's Paradox effects. In addition, to improve the quality of
counterfactual samples, we introduce factor decorrelation (FDC) loss to reduce
the correlation among features and thus improve the independence of extracted
factors. We conduct extensive experiments on six datasets and verify that our
method outperforms other FL methods in terms of efficiency and global model
accuracy under limited communication rounds.",2024-12-25T13:35:54Z,http://arxiv.org/abs/2412.18904v1,"Zhonghua Jiang, Jimin Xu, Shengyu Zhang, Tao Shen, Jiwei Li, Kun Kuang, Haibin Cai, Fei Wu"
"Effects of chiral symmetry restoration on dilepton production in heavy
  ion collisions","Because of their weak interactions with the strongly interacting matter
produced in relativistic heavy-ion collisions, dileptons provide an ideal probe
of the early dynamics of these collisions. Here, we study dilepton production
using a partonic transport model that is based on an extended
Nambu-Jona-Lasinio (NJL) model. In this model, the in-medium quark masses
decrease with increasing temperature as a result of the restoration of chiral
symmetry. We find that the extracted temperature from dileptons of intermediate
masses agrees well with the temperature of the partonic matter, suggesting that
dilepton production can be used as a thermometer for the produced partonic
matter. Our results also indicate that the extracted in-medium quark masses
decrease with increasing dilepton temperature, implying that dilepton
production can further serve as a probe of chiral symmetry restoration in high
energy heavy-ion collisions.",2024-12-25T12:57:25Z,http://arxiv.org/abs/2412.18895v1,"Wen-Hao Zhou, Che Ming Ko, Kai-Jia Sun"
"CoEvo: Continual Evolution of Symbolic Solutions Using Large Language
  Models","Large Language Models (LLMs) have emerged as transformative tools in
artificial intelligence, capable of processing and understanding extensive
human knowledge to enhance problem-solving across various domains. This paper
explores the potential of LLMs to drive the discovery of symbolic solutions
within scientific and engineering disciplines, where such solutions are crucial
for advancing theoretical and practical applications. We propose a novel
framework that utilizes LLMs in an evolutionary search methodology, augmented
by a dynamic knowledge library that integrates and refines insights in an
\textit{open-ended manner}. This approach aims to tackle the dual challenges of
efficiently navigating complex symbolic representation spaces and leveraging
both existing and newly generated knowledge to foster open-ended innovation. By
enabling LLMs to interact with and expand upon a knowledge library, we
facilitate the continuous generation of novel solutions in diverse forms such
as language, code, and mathematical expressions. Our experimental results
demonstrate that this method not only enhances the efficiency of searching for
symbolic solutions but also supports the ongoing discovery process, akin to
human scientific endeavors. This study represents a first effort in
conceptualizing the search for symbolic solutions as a lifelong, iterative
process, marking a significant step towards harnessing AI in the perpetual
pursuit of scientific and engineering breakthroughs. We have open-sourced our
code and data, please visit \url{https://github.com/pgg3/CoEvo} for more
information.",2024-12-25T12:27:27Z,http://arxiv.org/abs/2412.18890v1,"Ping Guo, Qingfu Zhang, Xi Lin"
"HV-BEV: Decoupling Horizontal and Vertical Feature Sampling for
  Multi-View 3D Object Detection","The application of vision-based multi-view environmental perception system
has been increasingly recognized in autonomous driving technology, especially
the BEV-based models. Current state-of-the-art solutions primarily encode image
features from each camera view into the BEV space through explicit or implicit
depth prediction. However, these methods often focus on improving the accuracy
of projecting 2D features into corresponding depth regions, while overlooking
the highly structured information of real-world objects and the varying height
distributions of objects across different scenes. In this work, we propose
HV-BEV, a novel approach that decouples feature sampling in the BEV grid
queries paradigm into horizontal feature aggregation and vertical adaptive
height-aware reference point sampling, aiming to improve both the aggregation
of objects' complete information and generalization to diverse road
environments. Specifically, we construct a learnable graph structure in the
horizontal plane aligned with the ground for 3D reference points, reinforcing
the association of the same instance across different BEV grids, especially
when the instance spans multiple image views around the vehicle. Additionally,
instead of relying on uniform sampling within a fixed height range, we
introduce a height-aware module that incorporates historical information,
enabling the reference points to adaptively focus on the varying heights at
which objects appear in different scenes. Extensive experiments validate the
effectiveness of our proposed method, demonstrating its superior performance
over the baseline across the nuScenes dataset. Moreover, our best-performing
model achieves a remarkable 50.5% mAP and 59.8% NDS on the nuScenes testing
set.",2024-12-25T11:49:14Z,http://arxiv.org/abs/2412.18884v1,"Di Wu, Feng Yang, Benlian Xu, Pan Liao, Wenhui Zhao, Dingwen Zhang"
"Towards Compatible Semantic Communication: A Perspective on Digital
  Coding and Modulation","Semantic communication (SC) is emerging as a pivotal innovation within the 6G
framework, aimed at enabling more intelligent transmission. This development
has led to numerous studies focused on designing advanced systems through
powerful deep learning techniques. Nevertheless, many of these approaches
envision an analog transmission manner by formulating the transmitted signals
as continuous-valued semantic representation vectors, limiting their
compatibility with existing digital systems. To enhance compatibility, it is
essential to explore digitized SC systems. This article systematically
identifies two promising paradigms for designing digital SC: probabilistic and
deterministic approaches, according to the modulation strategies. For both, we
first provide a comprehensive analysis of the methodologies. Then, we put
forward the principles of designing digital SC systems with a specific focus on
informativeness and robustness of semantic representations to enhance
performance, along with constellation design. Additionally, we present a case
study to demonstrate the effectiveness of these methods. Moreover, this article
also explores the intrinsic advantages and opportunities provided by digital SC
systems, and then outlines several potential research directions for future
investigation.",2024-12-25T11:19:40Z,http://arxiv.org/abs/2412.18876v1,"Guangyi Zhang, Kequan Zhou, Yunlong Cai, Qiyu Hu, Guanding Yu"
Cross-PCR: A Robust Cross-Source Point Cloud Registration Framework,"Due to the density inconsistency and distribution difference between
cross-source point clouds, previous methods fail in cross-source point cloud
registration. We propose a density-robust feature extraction and matching
scheme to achieve robust and accurate cross-source registration. To address the
density inconsistency between cross-source data, we introduce a density-robust
encoder for extracting density-robust features. To tackle the issue of
challenging feature matching and few correct correspondences, we adopt a
loose-to-strict matching pipeline with a ``loose generation, strict selection''
idea. Under it, we employ a one-to-many strategy to loosely generate initial
correspondences. Subsequently, high-quality correspondences are strictly
selected to achieve robust registration through sparse matching and dense
matching. On the challenging Kinect-LiDAR scene in the cross-source 3DCSR
dataset, our method improves feature matching recall by 63.5 percentage points
(pp) and registration recall by 57.6 pp. It also achieves the best performance
on 3DMatch, while maintaining robustness under diverse downsampling densities.",2024-12-25T11:14:59Z,http://arxiv.org/abs/2412.18873v1,"Guiyu Zhao, Zhentao Guo, Zewen Du, Hongbin Ma"
"Enhancing Robustness in Manipulability Assessment: The Pseudo-Ellipsoid
  Approach","Manipulability analysis is a methodology employed to assess the capacity of
an articulated system, at a specific configuration, to produce motion or exert
force in diverse directions. The conventional method entails generating a
virtual ellipsoid using the system's configuration and model. Yet, this
approach poses challenges when applied to systems such as the human body, where
direct access to such information is limited, necessitating reliance on
estimations. Any inaccuracies in these estimations can distort the ellipsoid's
configuration, potentially compromising the accuracy of the manipulability
assessment. To address this issue, this article extends the standard approach
by introducing the concept of the manipulability pseudo-ellipsoid. Through a
series of theoretical analyses, simulations, and experiments, the article
demonstrates that the proposed method exhibits reduced sensitivity to noise in
sensory information, consequently enhancing the robustness of the approach.",2024-12-25T11:05:11Z,http://arxiv.org/abs/2412.18869v1,"Erfan Shahriari, Kim Kirstin Peper, Matej Hoffmann, Sami Haddadin"
"WeatherGS: 3D Scene Reconstruction in Adverse Weather Conditions via
  Gaussian Splatting","3D Gaussian Splatting (3DGS) has gained significant attention for 3D scene
reconstruction, but still suffers from complex outdoor environments, especially
under adverse weather. This is because 3DGS treats the artifacts caused by
adverse weather as part of the scene and will directly reconstruct them,
largely reducing the clarity of the reconstructed scene. To address this
challenge, we propose WeatherGS, a 3DGS-based framework for reconstructing
clear scenes from multi-view images under different weather conditions.
Specifically, we explicitly categorize the multi-weather artifacts into the
dense particles and lens occlusions that have very different characters, in
which the former are caused by snowflakes and raindrops in the air, and the
latter are raised by the precipitation on the camera lens. In light of this, we
propose a dense-to-sparse preprocess strategy, which sequentially removes the
dense particles by an Atmospheric Effect Filter (AEF) and then extracts the
relatively sparse occlusion masks with a Lens Effect Detector (LED). Finally,
we train a set of 3D Gaussians by the processed images and generated masks for
excluding occluded areas, and accurately recover the underlying clear scene by
Gaussian splatting. We conduct a diverse and challenging benchmark to
facilitate the evaluation of 3D reconstruction under complex weather scenarios.
Extensive experiments on this benchmark demonstrate that our WeatherGS
consistently produces high-quality, clean scenes across various weather
scenarios, outperforming existing state-of-the-art methods. See project
page:https://jumponthemoon.github.io/weather-gs.",2024-12-25T10:16:57Z,http://arxiv.org/abs/2412.18862v1,"Chenghao Qian, Yuhu Guo, Wenjing Li, Gustav Markkula"
Bootstrap Your Own Context Length,"We introduce a bootstrapping approach to train long-context language models
by exploiting their short-context capabilities only. Our method utilizes a
simple agent workflow to synthesize diverse long-context instruction tuning
data, thereby eliminating the necessity for manual data collection and
annotation. The proposed data synthesis workflow requires only a short-context
language model, a text retriever, and a document collection, all of which are
readily accessible within the open-source ecosystem. Subsequently, language
models are fine-tuned using the synthesized data to extend their context
lengths. In this manner, we effectively transfer the short-context capabilities
of language models to long-context scenarios through a bootstrapping process.
We conduct experiments with the open-source Llama-3 family of models and
demonstrate that our method can successfully extend the context length to up to
1M tokens, achieving superior performance across various benchmarks.",2024-12-25T10:08:54Z,http://arxiv.org/abs/2412.18860v1,"Liang Wang, Nan Yang, Xingxing Zhang, Xiaolong Huang, Furu Wei"
Identifiability of the spatial SEIR-HCD model of COVID-19 propagation,"This paper investigates the identifiability of a spatial mathematical model
of the spread of fast-moving epidemics based on the law of acting masses and
diffusion processes. The research algorithm is based on global methods of Sobol
sensitivity analysis and Bayesian approach, which together allowed to reduce
the variation boundaries of unknown parameters for further solving the problem
of parameter identification by measurements of the number of detected cases,
critical and dead. It is shown that for identification of diffusion
coefficients responsible for the rate of movement of individuals in space, it
is necessary to use additional information about the process.",2024-12-25T09:58:22Z,http://arxiv.org/abs/2412.18858v1,"Olga Krivorotko, Tatiana Zvonareva, Andrei Neverov"
"Digital Twin Enhanced Deep Reinforcement Learning for Intelligent
  Omni-Surface Configurations in MU-MIMO Systems","Intelligent omni-surface (IOS) is a promising technique to enhance the
capacity of wireless networks, by reflecting and refracting the incident signal
simultaneously. Traditional IOS configuration schemes, relying on all
sub-channels' channel state information and user equipments' mobility, are
difficult to implement in complex realistic systems. Existing works attempt to
address this issue employing deep reinforcement learning (DRL), but this method
requires a lot of trial-and-error interactions with the external environment
for efficient results and thus cannot satisfy the real-time decision-making. To
enable model-free and real-time IOS control, this paper puts forth a new
framework that integrates DRL and digital twins. DeepIOS, a DRL based IOS
configuration scheme with the goal of maximizing the sum data rate, is first
developed to jointly optimize the phase-shift and amplitude of IOS in
multi-user multiple-input-multiple-output systems. Thereafter, to further
reduce the computational complexity, DeepIOS introduces an action branch
architecture, which separately decides two optimization variables in parallel.
Finally, a digital twin module is constructed through supervised learning as a
pre-verification platform for DeepIOS, such that the decision-making's
real-time can be guaranteed. The formulated framework is a closed-loop system,
in which the physical space provides data to establish and calibrate the
digital space, while the digital space generates experience samples for DeepIOS
training and sends the trained parameters to the IOS controller for
configurations. Numerical results show that compared with random and MAB
schemes, the proposed framework attains a higher data rate and is more robust
to different settings. Furthermore, the action branch architecture reduces
DeepIOS's computational complexity, and the digital twin module improves the
convergence speed and run-time.",2024-12-25T09:53:07Z,http://arxiv.org/abs/2412.18856v1,"Xiaowen Ye, Xianghao Yu, Liqun Fu"
"Gravitational waves from equatorially eccentric extreme mass ratio
  inspirals around swirling Kerr black holes","We have studied the gravitational wave generated by extreme mass ratio
inspirals (EMRIs) along eccentric orbits on equatorial plane within the frame
of the swirling-Kerr black hole spacetime. The swirling-Kerr black hole has an
extra swirling parameter, which characterizes the rotation of universe
background. Our findings indicate that this swirling parameter leads to a delay
phase shift in the gravitational waveforms. The impact of the swirling
parameter on EMRI gravitational waves is suppressed by the black hole's spin
parameter. As a result, extracting information about the swirling parameter
from gravitational waves in a static black hole spacetime is much easier than
in the case of a rapidly rotating black hole. Our analysis also shows that a
high black hole spin leads to a greater overlap of gravitational waveforms for
different swirling parameters. We further investigate the potential issue of
waveform confusion caused by the orbital eccentricity and semi-latus rectum
parameters. As the swirling parameter increases, the relative variation in
eccentricity also increases, while the variation in the semi-latus rectum
decreases rapidly. The trends in these changes with the swirling parameter
resemble those observed with the MOG (Modified Gravity) parameter, though with
different rates of change. These results provide deeper insights into the
properties of EMRI gravitational waves and the swirling of the universe
background.",2024-12-25T09:51:58Z,http://arxiv.org/abs/2412.18854v1,"Yuhang Gu, Songbai Chen, Jiliang Jing"
Machine Learning-Based Detection of Pump-and-Dump Schemes in Real-Time,"Cryptocurrency markets often face manipulation through prevalent
pump-and-dump (P&amp;D) schemes, where self-organized Telegram groups, some
exceeding two million members, artificially inflate target cryptocurrency
prices. These groups sell premium access to inside information, worsening
information asymmetry and financial risks for subscribers and all investors.
This paper presents a real-time prediction pipeline to forecast target coins
and alert investors to possible P&amp;D schemes. In a Poloniex case study, the
model accurately identified the target coin among the top five from 50 random
coins in 24 out of 43 (55.81%) P&amp;D events. The pipeline uses advanced natural
language processing (NLP) to classify Telegram messages, identifying 2,079 past
pump events and detecting new ones in real-time. Our analysis also evaluates
the susceptibility of token standards - ERC-20, ERC-721, BRC-20, Inscriptions,
and Runes - to manipulation and identifies exchanges commonly involved in P&amp;D
schemes.",2024-12-25T09:23:36Z,http://arxiv.org/abs/2412.18848v1,"Manuel Bolz, Kevin Bründler, Liam Kane, Panagiotis Patsias, Liam Tessendorf, Krzysztof Gogol, Taehoon Kim, Claudio Tessone"
"TPCH: Tensor-interacted Projection and Cooperative Hashing for
  Multi-view Clustering","In recent years, anchor and hash-based multi-view clustering methods have
gained attention for their efficiency and simplicity in handling large-scale
data. However, existing methods often overlook the interactions among
multi-view data and higher-order cooperative relationships during projection,
negatively impacting the quality of hash representation in low-dimensional
spaces, clustering performance, and sensitivity to noise. To address this
issue, we propose a novel approach named Tensor-Interacted Projection and
Cooperative Hashing for Multi-View Clustering(TPCH). TPCH stacks multiple
projection matrices into a tensor, taking into account the synergies and
communications during the projection process. By capturing higher-order
multi-view information through dual projection and Hamming space, TPCH employs
an enhanced tensor nuclear norm to learn more compact and distinguishable hash
representations, promoting communication within and between views. Experimental
results demonstrate that this refined method significantly outperforms
state-of-the-art methods in clustering on five large-scale multi-view datasets.
Moreover, in terms of CPU time, TPCH achieves substantial acceleration compared
to the most advanced current methods. The code is available at
\textcolor{red}{\url{https://github.com/jankin-wang/TPCH}}.",2024-12-25T09:22:11Z,http://arxiv.org/abs/2412.18847v1,"Zhongwen Wang, Xingfeng Li, Yinghui Sun, Quansen Sun, Yuan Sun, Han Ling, Jian Dai, Zhenwen Ren"
"Enhancing Federated Graph Learning via Adaptive Fusion of Structural and
  Node Characteristics","Federated Graph Learning (FGL) has demonstrated the advantage of training a
global Graph Neural Network (GNN) model across distributed clients using their
local graph data. Unlike Euclidean data (\eg, images), graph data is composed
of nodes and edges, where the overall node-edge connections determine the
topological structure, and individual nodes along with their neighbors capture
local node features. However, existing studies tend to prioritize one aspect
over the other, leading to an incomplete understanding of the data and the
potential misidentification of key characteristics across varying graph
scenarios. Additionally, the non-independent and identically distributed
(non-IID) nature of graph data makes the extraction of these two data
characteristics even more challenging. To address the above issues, we propose
a novel FGL framework, named FedGCF, which aims to simultaneously extract and
fuse structural properties and node features to effectively handle diverse
graph scenarios. FedGCF first clusters clients by structural similarity,
performing model aggregation within each cluster to form the shared structural
model. Next, FedGCF selects the clients with common node features and
aggregates their models to generate a common node model. This model is then
propagated to all clients, allowing common node features to be shared. By
combining these two models with a proper ratio, FedGCF can achieve a
comprehensive understanding of the graph data and deliver better performance,
even under non-IID distributions. Experimental results show that FedGCF
improves accuracy by 4.94%-7.24% under different data distributions and reduces
communication cost by 64.18%-81.25% to reach the same accuracy compared to
baselines.",2024-12-25T09:20:06Z,http://arxiv.org/abs/2412.18845v1,"Xianjun Gao, Jianchun Liu, Hongli Xu, Shilong Wang, Liusheng Huang"
"Context-Based Semantic-Aware Alignment for Semi-Supervised Multi-Label
  Learning","Due to the lack of extensive precisely-annotated multi-label data in real
word, semi-supervised multi-label learning (SSMLL) has gradually gained
attention. Abundant knowledge embedded in vision-language models (VLMs)
pre-trained on large-scale image-text pairs could alleviate the challenge of
limited labeled data under SSMLL setting.Despite existing methods based on
fine-tuning VLMs have achieved advances in weakly-supervised multi-label
learning, they failed to fully leverage the information from labeled data to
enhance the learning of unlabeled data. In this paper, we propose a
context-based semantic-aware alignment method to solve the SSMLL problem by
leveraging the knowledge of VLMs. To address the challenge of handling multiple
semantics within an image, we introduce a novel framework design to extract
label-specific image features. This design allows us to achieve a more compact
alignment between text features and label-specific image features, leading the
model to generate high-quality pseudo-labels. To incorporate the model with
comprehensive understanding of image, we design a semi-supervised context
identification auxiliary task to enhance the feature representation by
capturing co-occurrence information. Extensive experiments on multiple
benchmark datasets demonstrate the effectiveness of our proposed method.",2024-12-25T09:06:54Z,http://arxiv.org/abs/2412.18842v1,"Heng-Bo Fan, Ming-Kun Xie, Jia-Hao Xiao, Sheng-Jun Huang"
DiFiC: Your Diffusion Model Holds the Secret to Fine-Grained Clustering,"Fine-grained clustering is a practical yet challenging task, whose essence
lies in capturing the subtle differences between instances of different
classes. Such subtle differences can be easily disrupted by data augmentation
or be overwhelmed by redundant information in data, leading to significant
performance degradation for existing clustering methods. In this work, we
introduce DiFiC a fine-grained clustering method building upon the conditional
diffusion model. Distinct from existing works that focus on extracting
discriminative features from images, DiFiC resorts to deducing the textual
conditions used for image generation. To distill more precise and
clustering-favorable object semantics, DiFiC further regularizes the diffusion
target and guides the distillation process utilizing neighborhood similarity.
Extensive experiments demonstrate that DiFiC outperforms both state-of-the-art
discriminative and generative clustering methods on four fine-grained image
clustering benchmarks. We hope the success of DiFiC will inspire future
research to unlock the potential of diffusion models in tasks beyond
generation. The code will be released.",2024-12-25T08:55:48Z,http://arxiv.org/abs/2412.18838v1,"Ruohong Yang, Peng Hu, Xi Peng, Xiting Liu, Yunfan Li"
"Experimental secure entanglement-free quantum remote sensing over 50 km
  of optical fiber","Secure quantum remote sensing (SQRS) uses quantum states to gather
information about distant objects or environments while ensuring secure data
transmission against eavesdropping. It has potential applications in various
fields, including environmental monitoring, military surveillance, and disaster
response, where both data accuracy and transmission security are critical.
Recent experiments have demonstrated the feasibility of SQRS using entanglement
states. Here, we experimentally demonstrate an SQRS that can estimate a phase
without requiring entanglement, offering the practical advantage that
single-qubit states are easier to prepare. We successfully estimate the preset
phase information at a remote site over a fiber distance of 50 km, which serves
as a key step toward long-distance applications.",2024-12-25T08:52:06Z,http://arxiv.org/abs/2412.18837v1,"Wenjie He, Chunfeng Huang, Rui Guan, Ye Chen, Zhenrong Zhang, Kejin Wei"
"Adaptive Rate Control for Deep Video Compression with Rate-Distortion
  Prediction","Deep video compression has made significant progress in recent years,
achieving rate-distortion performance that surpasses that of traditional video
compression methods. However, rate control schemes tailored for deep video
compression have not been well studied. In this paper, we propose a neural
network-based $\lambda$-domain rate control scheme for deep video compression,
which determines the coding parameter $\lambda$ for each to-be-coded frame
based on the rate-distortion-$\lambda$ (R-D-$\lambda$) relationships directly
learned from uncompressed frames, achieving high rate control accuracy
efficiently without the need for pre-encoding. Moreover, this content-aware
scheme is able to mitigate inter-frame quality fluctuations and adapt to abrupt
changes in video content. Specifically, we introduce two neural network-based
predictors to estimate the relationship between bitrate and $\lambda$, as well
as the relationship between distortion and $\lambda$ for each frame. Then we
determine the coding parameter $\lambda$ for each frame to achieve the target
bitrate. Experimental results demonstrate that our approach achieves high rate
control accuracy at the mini-GOP level with low time overhead and mitigates
inter-frame quality fluctuations across video content of varying resolutions.",2024-12-25T08:42:23Z,http://arxiv.org/abs/2412.18834v1,"Bowen Gu, Hao Chen, Ming Lu, Jie Yao, Zhan Ma"
"PhyloGen: Language Model-Enhanced Phylogenetic Inference via Graph
  Structure Generation","Phylogenetic trees elucidate evolutionary relationships among species, but
phylogenetic inference remains challenging due to the complexity of combining
continuous (branch lengths) and discrete parameters (tree topology).
Traditional Markov Chain Monte Carlo methods face slow convergence and
computational burdens. Existing Variational Inference methods, which require
pre-generated topologies and typically treat tree structures and branch lengths
independently, may overlook critical sequence features, limiting their accuracy
and flexibility. We propose PhyloGen, a novel method leveraging a pre-trained
genomic language model to generate and optimize phylogenetic trees without
dependence on evolutionary models or aligned sequence constraints. PhyloGen
views phylogenetic inference as a conditionally constrained tree structure
generation problem, jointly optimizing tree topology and branch lengths through
three core modules: (i) Feature Extraction, (ii) PhyloTree Construction, and
(iii) PhyloTree Structure Modeling. Meanwhile, we introduce a Scoring Function
to guide the model towards a more stable gradient descent. We demonstrate the
effectiveness and robustness of PhyloGen on eight real-world benchmark
datasets. Visualization results confirm PhyloGen provides deeper insights into
phylogenetic relationships.",2024-12-25T08:33:05Z,http://arxiv.org/abs/2412.18827v1,"ChenRui Duan, Zelin Zang, Siyuan Li, Yongjie Xu, Stan Z. Li"
"Conductance-Photoacoustic Spectroscopy for OneSignal Measurement of
  Multi-components","Ensuring safety and efficiency in emerging hydrogen-hydrocarbon fuel systems
requires accurate measurement of multiple gas components in real time. However,
existing detection techniques generally lack the capability to quantitatively
measure hydrogen and natural gas constituents simultaneously. Here, we present
a novel conductance-photoacoustic spectroscopy (CPAS) method that integrates
platinum-modified conductance measurements with beat-frequency photoacoustic
detection. By bridging a quartz tuning fork with a platinum microwire, our
approach enables direct monitoring of hydrogen concentration via frequency
modulation, while simultaneously capturing propane's photoacoustic signal with
a single detection channel. Experimental results confirm that the platinum
microwire effectively fine-tunes the tuning fork's mechanical properties for
high-sensitivity hydrogen measurement, and the beat-frequency photoacoustic
signals from propane absorption reveal complementary hydrocarbon concentration
information. This unified sensor design is inherently compact, rapid, and
calibration-free, making it particularly suitable for applications that demand
real-time multiparameter gas analysis, including industrial process control and
environmental monitoring. Taken together, these findings demonstrate that
combining conductance and photoacoustic spectroscopies into a single integrated
platform significantly advances the state of multi-component gas detection and
holds promise for further enhancements in sensitivity and adaptability.",2024-12-25T08:23:07Z,http://arxiv.org/abs/2412.18822v1,"Ruobin Zhuang, Jianfeng He, Huadan Zheng"
Quantifying the memory and dynamical stability of magnetar bursts,"The time series of energy and waiting time of magnetar bursts carry important
information about the source activity. In this paper, we investigate the memory
and dynamical stability of magnetar bursts from four soft gamma repeater (SGR)
sources: SGR 1806$-$20, SGR 1900+14, SGR J1935+2154 and SGR J1550$-$5418. Based
on the rescaled range analysis, we quantify the memory in magnetar bursts for
the first time and find that there exists long-term memory in the time series
of both waiting time and energy. We investigate the dynamical stability in the
context of randomness and chaos. For all the four SGR samples, we find that the
waiting time is not completely random, but the energy of two SGRs is consistent
with a total random organization. Furthermore, both waiting time and energy
exhibits weak chaos. We also find no significant difference between SGRs and
repeating fast radio bursts (FRBs) in the randomness-chaos phase space. The
statistical similarity between SGRs and repeating FRBs hints that there may be
potential physical connection between these two phenomena.",2024-12-25T08:22:36Z,http://arxiv.org/abs/2412.18821v1,"Yu Sang, Hai-Nan Lin"
LLM-assisted vector similarity search,"As data retrieval demands become increasingly complex, traditional search
methods often fall short in addressing nuanced and conceptual queries. Vector
similarity search has emerged as a promising technique for finding semantically
similar information efficiently. However, its effectiveness diminishes when
handling intricate queries with contextual nuances. This paper explores a
hybrid approach combining vector similarity search with Large Language Models
(LLMs) to enhance search accuracy and relevance. The proposed two-step solution
first employs vector similarity search to shortlist potential matches, followed
by an LLM for context-aware ranking of the results. Experiments on structured
datasets demonstrate that while vector similarity search alone performs well
for straightforward queries, the LLM-assisted approach excels in processing
complex queries involving constraints, negations, or conceptual requirements.
By leveraging the natural language understanding capabilities of LLMs, this
method improves the accuracy of search results for complex tasks without
sacrificing efficiency. We also discuss real-world applications and propose
directions for future research to refine and scale this technique for diverse
datasets and use cases.
  Original article:
https://engineering.grab.com/llm-assisted-vector-similarity-search",2024-12-25T08:17:37Z,http://arxiv.org/abs/2412.18819v1,"Md Riyadh, Muqi Li, Felix Haryanto Lie, Jia Long Loh, Haotian Mi, Sayam Bohra"
