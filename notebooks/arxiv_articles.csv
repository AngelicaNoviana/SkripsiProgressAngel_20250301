Title,Summary,Published,Link,Authors,Institutions
"Behave-XAI: Deep Explainable Learning of Behavioral Representational
  Data","  According to the latest trend of artificial intelligence, AI-systems needs to
clarify regarding general,specific decisions,services provided by it. Only
consumer is satisfied, with explanation , for example, why any classification
result is the outcome of any given time. This actually motivates us using
explainable or human understandable AI for a behavioral mining scenario, where
users engagement on digital platform is determined from context, such as
emotion, activity, weather, etc. However, the output of AI-system is not always
systematically correct, and often systematically correct, but apparently
not-perfect and thereby creating confusions, such as, why the decision is
given? What is the reason underneath? In this context, we first formulate the
behavioral mining problem in deep convolutional neural network architecture.
Eventually, we apply a recursive neural network due to the presence of
time-series data from users physiological and environmental sensor-readings.
Once the model is developed, explanations are presented with the advent of XAI
models in front of users. This critical step involves extensive trial with
users preference on explanations over conventional AI, judgement of credibility
of explanation.
",2022-12-30T18:08:48Z,http://arxiv.org/abs/2301.00016v2,"Rossi Kamal, Zuzana Kubincova",Unknown
Deep Neural Mobile Networking,"  The next generation of mobile networks is set to become increasingly complex,
as these struggle to accommodate tremendous data traffic demands generated by
ever-more connected devices that have diverse performance requirements in terms
of throughput, latency, and reliability. This makes monitoring and managing the
multitude of network elements intractable with existing tools and impractical
for traditional machine learning algorithms that rely on hand-crafted feature
engineering. In this context, embedding machine intelligence into mobile
networks becomes necessary, as this enables systematic mining of valuable
information from mobile big data and automatically uncovering correlations that
would otherwise have been too difficult to extract by human experts. In
particular, deep learning based solutions can automatically extract features
from raw data, without human expertise. The performance of artificial
intelligence (AI) has achieved in other domains draws unprecedented interest
from both academia and industry in employing deep learning approaches to
address technical challenges in mobile networks. This thesis attacks important
problems in the mobile networking area from various perspectives by harnessing
recent advances in deep neural networks.
",2020-10-23T09:23:36Z,http://arxiv.org/abs/2011.05267v1,Chaoyun Zhang,Unknown
"Learning Random Numbers to Realize Appendable Memory System for
  Artificial Intelligence to Acquire New Knowledge after Deployment","  In this study, we developed a learning method for constructing a neural
network system capable of memorizing data and recalling it without parameter
updates. The system we built using this method is called the Appendable Memory
system. The Appendable Memory system enables an artificial intelligence (AI) to
acquire new knowledge even after deployment. It consists of two AIs: the
Memorizer and the Recaller. This system is a key-value store built using neural
networks. The Memorizer receives data and stores it in the Appendable Memory
vector, which is dynamically updated when the AI acquires new knowledge.
Meanwhile, the Recaller retrieves information from the Appendable Memory
vector. What we want to teach AI in this study are the operations of memorizing
and recalling information. However, traditional machine learning methods make
AI learn features inherent in the learning dataset. We demonstrate that the
systems we intend to create cannot be realized by current machine learning
methods, that is, by merely repeating the input and output learning sequences
with AI. Instead, we propose a method to teach AI to learn operations, by
completely removing the features contained in the learning dataset.
Specifically, we probabilized all the data involved in learning. This measure
prevented AI from learning the features of the data. The learning method
proposed in the study differs from traditional machine learning methods and
provides fundamental approaches for building an AI system that can store
information in a finite memory and recall it at a later date.
",2024-07-29T17:24:35Z,http://arxiv.org/abs/2407.20197v1,Kazunori D Yamada,Unknown
Modeling the EdNet Dataset with Logistic Regression,"  Many of these challenges are won by neural network models created by
full-time artificial intelligence scientists. Due to this origin, they have a
black-box character that makes their use and application less clear to learning
scientists. We describe our experience with competition from the perspective of
educational data mining, a field founded in the learning sciences and connected
with roots in psychology and statistics. We describe our efforts from the
perspectives of learning scientists and the challenges to our methods, some
real and some imagined. We also discuss some basic results in the Kaggle system
and our thoughts on how those results may have been improved. Finally, we
describe how learner model predictions are used to make pedagogical decisions
for students. Their practical use entails a) model predictions and b) a
decision rule (based on the predictions). We point out how increased model
accuracy can be of limited practical utility, especially when paired with
simple decision rules and argue instead for the need to further investigate
optimal decision rules.
",2021-05-17T20:30:36Z,http://arxiv.org/abs/2105.08150v1,"Philip I. Pavlik Jr, Luke G. Eglington",Unknown
"Causal Relationship Network of Risk Factors Impacting Workday Loss in
  Underground Coal Mines","  This study aims to establish the causal relationship network between various
factors leading to workday loss in underground coal mines using a novel causal
artificial intelligence (AI) method. The analysis utilizes data obtained from
the National Institute for Occupational Safety and Health (NIOSH). A total of
101,010 injury records from 3,982 unique underground coal mines spanning the
years from 1990 to 2020 were extracted from the NIOSH database. Causal
relationships were analyzed and visualized using a novel causal AI method
called Grouped Greedy Equivalence Search (GGES). The impact of each variable on
workday loss was assessed through intervention do-calculus adjustment (IDA)
scores. Model training and validation were performed using the 10-fold
cross-validation technique. Performance metrics, including adjacency precision
(AP), adjacency recall (AR), arrowhead precision (AHP), and arrowhead recall
(AHR), were utilized to evaluate the models. Findings revealed that after 2006,
key direct causes of workday loss among mining employees included total mining
experience, mean office employees, mean underground employees, county, and
total mining experience (years). Total mining experience emerged as the most
influential factor, whereas mean employees per mine exhibited the least
influence. The analyses emphasized the significant role of total mining
experience in determining workday loss. The models achieved optimal
performance, with AP, AR, AHP, and AHR values measuring 0.694, 0.653, 0.386,
and 0.345, respectively. This study demonstrates the feasibility of utilizing
the new GGES method to clarify the causal factors behind the workday loss by
analyzing employment demographics and injury records and establish their causal
relationship network.
",2024-01-24T22:45:34Z,http://arxiv.org/abs/2402.05940v1,"Shangsi Ren, Cameron A. Beeche, Zhiyi Shi, Maria Acevedo Garcia, Katherine Zychowski, Shuguang Leng, Pedram Roghanchi, Jiantao Pu",Unknown
A brief network analysis of Artificial Intelligence publication,"  In this paper, we present an illustration to the history of Artificial
Intelligence(AI) with a statistical analysis of publish since 1940. We
collected and mined through the IEEE publish data base to analysis the
geological and chronological variance of the activeness of research in AI. The
connections between different institutes are showed. The result shows that the
leading community of AI research are mainly in the USA, China, the Europe and
Japan. The key institutes, authors and the research hotspots are revealed. It
is found that the research institutes in the fields like Data Mining, Computer
Vision, Pattern Recognition and some other fields of Machine Learning are quite
consistent, implying a strong interaction between the community of each field.
It is also showed that the research of Electronic Engineering and Industrial or
Commercial applications are very active in California. Japan is also publishing
a lot of papers in robotics. Due to the limitation of data source, the result
might be overly influenced by the number of published articles, which is to our
best improved by applying network keynode analysis on the research community
instead of merely count the number of publish.
",2013-11-23T13:54:36Z,http://arxiv.org/abs/1311.5998v1,"Yunpeng Li, Jie Liu, Yong Deng",Unknown
"Towards Explainable Artificial Intelligence (XAI): A Data Mining
  Perspective","  Given the complexity and lack of transparency in deep neural networks (DNNs),
extensive efforts have been made to make these systems more interpretable or
explain their behaviors in accessible terms. Unlike most reviews, which focus
on algorithmic and model-centric perspectives, this work takes a ""data-centric""
view, examining how data collection, processing, and analysis contribute to
explainable AI (XAI). We categorize existing work into three categories subject
to their purposes: interpretations of deep models, referring to feature
attributions and reasoning processes that correlate data points with model
outputs; influences of training data, examining the impact of training data
nuances, such as data valuation and sample anomalies, on decision-making
processes; and insights of domain knowledge, discovering latent patterns and
fostering new knowledge from data and models to advance social values and
scientific discovery. Specifically, we distill XAI methodologies into data
mining operations on training and testing data across modalities, such as
images, text, and tabular data, as well as on training logs, checkpoints,
models and other DNN behavior descriptors. In this way, our study offers a
comprehensive, data-centric examination of XAI from a lens of data mining
methods and applications.
",2024-01-09T06:27:09Z,http://arxiv.org/abs/2401.04374v2,"Haoyi Xiong, Xuhong Li, Xiaofei Zhang, Jiamin Chen, Xinhao Sun, Yuchen Li, Zeyi Sun, Mengnan Du",Unknown
Petroleum prices prediction using data mining techniques -- A Review,"  Over the past 20 years, Kenya's demand for petroleum products has
proliferated. This is mainly because this particular commodity is used in many
sectors of the country's economy. Exchange rates are impacted by constantly
shifting prices, which also impact Kenya's industrial output of commodities.
The cost of other items produced and even the expansion of the economy is
significantly impacted by any change in the price of petroleum products.
Therefore, accurate petroleum price forecasting is critical for devising
policies that are suitable to curb fuel-related shocks. Data mining techniques
are the tools used to find valuable patterns in data. Data mining techniques
used in petroleum price prediction, including artificial neural networks
(ANNs), support vector machines (SVMs), and intelligent optimization techniques
like the genetic algorithm (GA), have grown increasingly popular. This study
provides a comprehensive review of the existing data mining techniques for
making predictions on petroleum prices. The data mining techniques are
classified into regression models, deep neural network models, fuzzy sets and
logic, and hybrid models. A detailed discussion of how these models are
developed and the accuracy of the models is provided.
",2022-11-20T19:33:02Z,http://arxiv.org/abs/2211.12964v1,"Kiplang'at Weldon, John Ngechu, Ngatho Everlyne, Nancy Njambi, Kinyua Gikunda",Unknown
"Artificial intelligence for partial differential equations in
  computational mechanics: A review","  In recent years, Artificial intelligence (AI) has become ubiquitous,
empowering various fields, especially integrating artificial intelligence and
traditional science (AI for Science: Artificial intelligence for science),
which has attracted widespread attention. In AI for Science, using artificial
intelligence algorithms to solve partial differential equations (AI for PDEs:
Artificial intelligence for partial differential equations) has become a focal
point in computational mechanics. The core of AI for PDEs is the fusion of data
and partial differential equations (PDEs), which can solve almost any PDEs.
Therefore, this article provides a comprehensive review of the research on AI
for PDEs, summarizing the existing algorithms and theories. The article
discusses the applications of AI for PDEs in computational mechanics, including
solid mechanics, fluid mechanics, and biomechanics. The existing AI for PDEs
algorithms include those based on Physics-Informed Neural Networks (PINNs),
Deep Energy Methods (DEM), Operator Learning, and Physics-Informed Neural
Operator (PINO). AI for PDEs represents a new method of scientific simulation
that provides approximate solutions to specific problems using large amounts of
data, then fine-tuning according to specific physical laws, avoiding the need
to compute from scratch like traditional algorithms. Thus, AI for PDEs is the
prototype for future foundation models in computational mechanics, capable of
significantly accelerating traditional numerical algorithms.
",2024-10-21T10:12:33Z,http://arxiv.org/abs/2410.19843v2,"Yizheng Wang, Jinshuai Bai, Zhongya Lin, Qimin Wang, Cosmin Anitescu, Jia Sun, Mohammad Sadegh Eshaghi, Yuantong Gu, Xi-Qiao Feng, Xiaoying Zhuang, Timon Rabczuk, Yinghua Liu",Unknown
"Fair Differentiable Neural Network Architecture Search for Long-Tailed
  Data with Self-Supervised Learning","  Recent advancements in artificial intelligence (AI) have positioned deep
learning (DL) as a pivotal technology in fields like computer vision, data
mining, and natural language processing. A critical factor in DL performance is
the selection of neural network architecture. Traditional predefined
architectures often fail to adapt to different data distributions, making it
challenging to achieve optimal performance. Neural architecture search (NAS)
offers a solution by automatically designing architectures tailored to specific
datasets. However, the effectiveness of NAS diminishes on long-tailed datasets,
where a few classes have abundant samples, and many have few, leading to biased
models.In this paper, we explore to improve the searching and training
performance of NAS on long-tailed datasets. Specifically, we first discuss the
related works about NAS and the deep learning method for long-tailed
datasets.Then, we focus on an existing work, called SSF-NAS, which integrates
the self-supervised learning and fair differentiable NAS to making NAS achieve
better performance on long-tailed datasets.An detailed description about the
fundamental techniques for SSF-NAS is provided in this paper, including DARTS,
FairDARTS, and Barlow Twins. Finally, we conducted a series of experiments on
the CIFAR10-LT dataset for performance evaluation, where the results are align
with our expectation.
",2024-06-19T12:39:02Z,http://arxiv.org/abs/2406.16949v1,Jiaming Yan,Unknown
"A clarification of misconceptions, myths and desired status of
  artificial intelligence","  The field artificial intelligence (AI) has been founded over 65 years ago.
Starting with great hopes and ambitious goals the field progressed though
various stages of popularity and received recently a revival in the form of
deep neural networks. Some problems of AI are that so far neither
'intelligence' nor the goals of AI are formally defined causing confusion when
comparing AI to other fields. In this paper, we present a perspective on the
desired and current status of AI in relation to machine learning and statistics
and clarify common misconceptions and myths. Our discussion is intended to
uncurtain the veil of vagueness surrounding AI to see its true countenance.
",2020-08-03T17:22:53Z,http://arxiv.org/abs/2008.05607v1,"Frank Emmert-Streib, Olli Yli-Harja, Matthias Dehmer",Unknown
"Ball Mill Fault Prediction Based on Deep Convolutional Auto-Encoding
  Network","  Ball mills play a critical role in modern mining operations, making their
bearing failures a significant concern due to the potential loss of production
efficiency and economic consequences. This paper presents an anomaly detection
method based on Deep Convolutional Auto-encoding Neural Networks (DCAN) for
addressing the issue of ball mill bearing fault detection. The proposed
approach leverages vibration data collected during normal operation for
training, overcoming challenges such as labeling issues and data imbalance
often encountered in supervised learning methods. DCAN includes the modules of
convolutional feature extraction and transposed convolutional feature
reconstruction, demonstrating exceptional capabilities in signal processing and
feature extraction. Additionally, the paper describes the practical deployment
of the DCAN-based anomaly detection model for bearing fault detection,
utilizing data from the ball mill bearings of Wuhan Iron & Steel Resources
Group and fault data from NASA's bearing vibration dataset. Experimental
results validate the DCAN model's reliability in recognizing fault vibration
patterns. This method holds promise for enhancing bearing fault detection
efficiency, reducing production interruptions, and lowering maintenance costs.
",2023-11-09T17:49:07Z,http://arxiv.org/abs/2311.13571v1,"Xinkun Ai, Kun Liu, Wei Zheng, Yonggang Fan, Xinwu Wu, Peilong Zhang, LiYe Wang, JanFeng Zhu, Yuan Pan",Unknown
"Split Federated Learning Empowered Vehicular Edge Intelligence: Adaptive
  Parellel Design and Future Directions","  To realize ubiquitous intelligence of future vehicular networks, artificial
intelligence (AI) is critical since it can mine knowledge from vehicular data
to improve the quality of many AI driven vehicular services. By combining AI
techniques with vehicular networks, Vehicular Edge Intelligence (VEI) can
utilize the computing, storage, and communication resources of vehicles to
train the AI models. Nevertheless, when executing the model training, the
traditional centralized learning paradigm requires vehicles to upload their raw
data to a central server, which results in significant communication overheads
and the risk of privacy leakage. In this article, we first overview the system
architectures, performance metrics and challenges ahead of VEI design. Then we
propose to utilize distribute machine learning scheme, namely split federated
learning (SFL), to boost the development of VEI. We present a novel adaptive
and parellel SFL scheme and conduct corresponding analysis on its performance.
Future research directions are highlighted to shed light on the efficient
design of SFL.
",2024-06-22T10:15:15Z,http://arxiv.org/abs/2406.15804v2,"Xianke Qiang, Zheng Chang, Chaoxiong Ye, Timo Hamalainen, Geyong Min",Unknown
Artificial Intelligence in the Creative Industries: A Review,"  This paper reviews the current state of the art in Artificial Intelligence
(AI) technologies and applications in the context of the creative industries. A
brief background of AI, and specifically Machine Learning (ML) algorithms, is
provided including Convolutional Neural Network (CNNs), Generative Adversarial
Networks (GANs), Recurrent Neural Networks (RNNs) and Deep Reinforcement
Learning (DRL). We categorise creative applications into five groups related to
how AI technologies are used: i) content creation, ii) information analysis,
iii) content enhancement and post production workflows, iv) information
extraction and enhancement, and v) data compression. We critically examine the
successes and limitations of this rapidly advancing technology in each of these
areas. We further differentiate between the use of AI as a creative tool and
its potential as a creator in its own right. We foresee that, in the near
future, machine learning-based AI will be adopted widely as a tool or
collaborative assistant for creativity. In contrast, we observe that the
successes of machine learning in domains with fewer constraints, where AI is
the `creator', remain modest. The potential of AI (or its developers) to win
awards for its original creations in competition with human creatives is also
limited, based on contemporary technologies. We therefore conclude that, in the
context of creative industries, maximum benefit from AI will be derived where
its focus is human centric -- where it is designed to augment, rather than
replace, human creativity.
",2020-07-24T07:29:52Z,http://arxiv.org/abs/2007.12391v6,"Nantheera Anantrasirichai, David Bull",Unknown
"Surveying the reach and maturity of machine learning and artificial
  intelligence in astronomy","  Machine learning (automated processes that learn by example in order to
classify, predict, discover or generate new data) and artificial intelligence
(methods by which a computer makes decisions or discoveries that would usually
require human intelligence) are now firmly established in astronomy. Every
week, new applications of machine learning and artificial intelligence are
added to a growing corpus of work. Random forests, support vector machines, and
neural networks (artificial, deep, and convolutional) are now having a genuine
impact for applications as diverse as discovering extrasolar planets, transient
objects, quasars, and gravitationally-lensed systems, forecasting solar
activity, and distinguishing between signals and instrumental effects in
gravitational wave astronomy. This review surveys contemporary, published
literature on machine learning and artificial intelligence in astronomy and
astrophysics. Applications span seven main categories of activity:
classification, regression, clustering, forecasting, generation, discovery, and
the development of new scientific insight. These categories form the basis of a
hierarchy of maturity, as the use of machine learning and artificial
intelligence emerges, progresses or becomes established.
",2019-12-06T00:40:12Z,http://arxiv.org/abs/1912.02934v1,"Christopher J. Fluke, Colin Jacobs",Unknown
"Learning Description Logic Ontologies. Five Approaches. Where Do They
  Stand?","  The quest for acquiring a formal representation of the knowledge of a domain
of interest has attracted researchers with various backgrounds into a diverse
field called ontology learning. We highlight classical machine learning and
data mining approaches that have been proposed for (semi-)automating the
creation of description logic (DL) ontologies. These are based on association
rule mining, formal concept analysis, inductive logic programming,
computational learning theory, and neural networks. We provide an overview of
each approach and how it has been adapted for dealing with DL ontologies.
Finally, we discuss the benefits and limitations of each of them for learning
DL ontologies.
",2021-04-02T18:36:45Z,http://arxiv.org/abs/2104.01193v1,Ana Ozaki,Unknown
Neural Insights for Digital Marketing Content Design,"  In digital marketing, experimenting with new website content is one of the
key levers to improve customer engagement. However, creating successful
marketing content is a manual and time-consuming process that lacks clear
guiding principles. This paper seeks to close the loop between content creation
and online experimentation by offering marketers AI-driven actionable insights
based on historical data to improve their creative process. We present a
neural-network-based system that scores and extracts insights from a marketing
content design, namely, a multimodal neural network predicts the attractiveness
of marketing contents, and a post-hoc attribution method generates actionable
insights for marketers to improve their content in specific marketing
locations. Our insights not only point out the advantages and drawbacks of a
given current content, but also provide design recommendations based on
historical data. We show that our scoring model and insights work well both
quantitatively and qualitatively.
",2023-02-02T21:04:47Z,http://arxiv.org/abs/2302.01416v3,"Fanjie Kong, Yuan Li, Houssam Nassif, Tanner Fiez, Ricardo Henao, Shreya Chakrabarti",Unknown
Player-AI Interaction: What Neural Network Games Reveal About AI as Play,"  The advent of artificial intelligence (AI) and machine learning (ML) bring
human-AI interaction to the forefront of HCI research. This paper argues that
games are an ideal domain for studying and experimenting with how humans
interact with AI. Through a systematic survey of neural network games (n = 38),
we identified the dominant interaction metaphors and AI interaction patterns in
these games. In addition, we applied existing human-AI interaction guidelines
to further shed light on player-AI interaction in the context of AI-infused
systems. Our core finding is that AI as play can expand current notions of
human-AI interaction, which are predominantly productivity-based. In
particular, our work suggests that game and UX designers should consider flow
to structure the learning curve of human-AI interaction, incorporate
discovery-based learning to play around with the AI and observe the
consequences, and offer users an invitation to play to explore new forms of
human-AI interaction.
",2021-01-15T17:07:03Z,http://arxiv.org/abs/2101.06220v2,"Jichen Zhu, Jennifer Villareale, Nithesh Javvaji, Sebastian Risi, Mathias LÃ¶we, Rush Weigelt, Casper Harteveld",Unknown
Towards Reliable Neural Specifications,"  Having reliable specifications is an unavoidable challenge in achieving
verifiable correctness, robustness, and interpretability of AI systems.
Existing specifications for neural networks are in the paradigm of data as
specification. That is, the local neighborhood centering around a reference
input is considered to be correct (or robust). While existing specifications
contribute to verifying adversarial robustness, a significant problem in many
research domains, our empirical study shows that those verified regions are
somewhat tight, and thus fail to allow verification of test set inputs, making
them impractical for some real-world applications. To this end, we propose a
new family of specifications called neural representation as specification,
which uses the intrinsic information of neural networks - neural activation
patterns (NAPs), rather than input data to specify the correctness and/or
robustness of neural network predictions. We present a simple statistical
approach to mining neural activation patterns. To show the effectiveness of
discovered NAPs, we formally verify several important properties, such as
various types of misclassifications will never happen for a given NAP, and
there is no ambiguity between different NAPs. We show that by using NAP, we can
verify a significant region of the input space, while still recalling 84% of
the data on MNIST. Moreover, we can push the verifiable bound to 10 times
larger on the CIFAR10 benchmark. Thus, we argue that NAPs can potentially be
used as a more reliable and extensible specification for neural network
verification.
",2022-10-28T13:21:28Z,http://arxiv.org/abs/2210.16114v5,"Chuqin Geng, Nham Le, Xiaojie Xu, Zhaoyue Wang, Arie Gurfinkel, Xujie Si",Unknown
"Proof of Training (PoT): Harnessing Crypto Mining Power for Distributed
  AI Training","  In the midst of the emerging trend of integrating artificial intelligence
(AI) with crypto mining, we identify three major challenges that create a gap
between these two fields. To bridge this gap, we introduce the
proof-of-training (PoT) protocol, an approach that combines the strengths of
both AI and blockchain technology. The PoT protocol utilizes the practical
Byzantine fault tolerance (PBFT) consensus mechanism to synchronize global
states. To evaluate the performance of the protocol design, we present an
implementation of a decentralized training network (DTN) that adopts the PoT
protocol. Our results indicate that the protocol exhibits considerable
potential in terms of task throughput, system robustness, and network security.
",2023-07-13T21:14:46Z,http://arxiv.org/abs/2307.07066v1,Peihao Li,Unknown
