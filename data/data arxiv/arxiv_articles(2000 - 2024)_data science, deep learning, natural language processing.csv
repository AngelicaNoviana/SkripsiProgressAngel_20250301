Title,Summary,Published,Link,Authors
"Sequential Interpretability: Methods, Applications, and Future Direction
  for Understanding Deep Learning Models in the Context of Sequential Data","  Deep learning continues to revolutionize an ever-growing number of critical
application areas including healthcare, transportation, finance, and basic
sciences. Despite their increased predictive power, model transparency and
human explainability remain a significant challenge due to the ""black box""
nature of modern deep learning models. In many cases the desired balance
between interpretability and performance is predominately task specific.
Human-centric domains such as healthcare necessitate a renewed focus on
understanding how and why these frameworks are arriving at critical and
potentially life-or-death decisions. Given the quantity of research and
empirical successes of deep learning for computer vision, most of the existing
interpretability research has focused on image processing techniques.
Comparatively, less attention has been paid to interpreting deep learning
frameworks using sequential data. Given recent deep learning advancements in
highly sequential domains such as natural language processing and physiological
signal processing, the need for deep sequential explanations is at an all-time
high. In this paper, we review current techniques for interpreting deep
learning techniques involving sequential data, identify similarities to
non-sequential methods, and discuss current limitations and future avenues of
sequential interpretability research.
",2020-04-27T00:58:42Z,http://arxiv.org/abs/2004.12524v1,"Benjamin Shickel, Parisa Rashidi"
Putting Natural in Natural Language Processing,"  Human language is firstly spoken and only secondarily written. Text, however,
is a very convenient and efficient representation of language, and modern
civilization has made it ubiquitous. Thus the field of NLP has overwhelmingly
focused on processing written rather than spoken language. Work on spoken
language, on the other hand, has been siloed off within the largely separate
speech processing community which has been inordinately preoccupied with
transcribing speech into text. Recent advances in deep learning have led to a
fortuitous convergence in methods between speech processing and mainstream NLP.
Arguably, the time is ripe for a unification of these two fields, and for
starting to take spoken language seriously as the primary mode of human
communication. Truly natural language processing could lead to better
integration with the rest of language science and could lead to systems which
are more data-efficient and more human-like, and which can communicate beyond
the textual modality.
",2023-05-08T09:29:31Z,http://arxiv.org/abs/2305.04572v2,Grzegorz Chrupa≈Ça
Deep Learning for Political Science,"  Political science, and social science in general, have traditionally been
using computational methods to study areas such as voting behavior, policy
making, international conflict, and international development. More recently,
increasingly available quantities of data are being combined with improved
algorithms and affordable computational resources to predict, learn, and
discover new insights from data that is large in volume and variety. New
developments in the areas of machine learning, deep learning, natural language
processing (NLP), and, more generally, artificial intelligence (AI) are opening
up new opportunities for testing theories and evaluating the impact of
interventions and programs in a more dynamic and effective way. Applications
using large volumes of structured and unstructured data are becoming common in
government and industry, and increasingly also in social science research. This
chapter offers an introduction to such methods drawing examples from political
science. Focusing on the areas where the strengths of the methods coincide with
challenges in these fields, the chapter first presents an introduction to AI
and its core technology - machine learning, with its rapidly developing
subfield of deep learning. The discussion of deep neural networks is
illustrated with the NLP tasks that are relevant to political science. The
latest advances in deep learning methods for NLP are also reviewed, together
with their potential for improving information extraction and pattern
recognition from political science texts.
",2020-05-13T19:14:37Z,http://arxiv.org/abs/2005.06540v1,"Kakia Chatsiou, Slava Jankin Mikhaylov"
"Identifying Semantically Duplicate Questions Using Data Science
  Approach: A Quora Case Study","  Identifying semantically identical questions on, Question and Answering
social media platforms like Quora is exceptionally significant to ensure that
the quality and the quantity of content are presented to users, based on the
intent of the question and thus enriching overall user experience. Detecting
duplicate questions is a challenging problem because natural language is very
expressive, and a unique intent can be conveyed using different words, phrases,
and sentence structuring. Machine learning and deep learning methods are known
to have accomplished superior results over traditional natural language
processing techniques in identifying similar texts. In this paper, taking Quora
for our case study, we explored and applied different machine learning and deep
learning techniques on the task of identifying duplicate questions on Quora's
dataset. By using feature engineering, feature importance techniques, and
experimenting with seven selected machine learning classifiers, we demonstrated
that our models outperformed previous studies on this task. Xgboost model with
character level term frequency and inverse term frequency is our best machine
learning model that has also outperformed a few of the Deep learning baseline
models. We applied deep learning techniques to model four different deep neural
networks of multiple layers consisting of Glove embeddings, Long Short Term
Memory, Convolution, Max pooling, Dense, Batch Normalization, Activation
functions, and model merge. Our deep learning models achieved better accuracy
than machine learning models. Three out of four proposed architectures
outperformed the accuracy from previous machine learning and deep learning
research work, two out of four models outperformed accuracy from previous deep
learning study on Quora's question pair dataset, and our best model achieved
accuracy of 85.82% which is close to Quora state of the art accuracy.
",2020-04-18T19:39:58Z,http://arxiv.org/abs/2004.11694v1,"Navedanjum Ansari, Rajesh Sharma"
Vulgar Remarks Detection in Chittagonian Dialect of Bangla,"  The negative effects of online bullying and harassment are increasing with
Internet popularity, especially in social media. One solution is using natural
language processing (NLP) and machine learning (ML) methods for the automatic
detection of harmful remarks, but these methods are limited in low-resource
languages like the Chittagonian dialect of Bangla.This study focuses on
detecting vulgar remarks in social media using supervised ML and deep learning
algorithms.Logistic Regression achieved promising accuracy (0.91) while simple
RNN with Word2vec and fastTex had lower accuracy (0.84-0.90), highlighting the
issue that NN algorithms require more data.
",2023-08-29T17:19:32Z,http://arxiv.org/abs/2308.15448v1,"Tanjim Mahmud, Michal Ptaszynski, Fumito Masui"
"Development of Deep Learning Based Natural Language Processing Model for
  Turkish","  Natural language is one of the most fundamental features that distinguish
people from other living things and enable people to communicate each other.
Language is a tool that enables people to express their feelings and thoughts
and to transfers cultures through generations. Texts and audio are examples of
natural language in daily life. In the natural language, many words disappear
in time, on the other hand new words are derived. Therefore, while the process
of natural language processing (NLP) is complex even for human, it is difficult
to process in computer system. The area of linguistics examines how people use
language. NLP, which requires the collaboration of linguists and computer
scientists, plays an important role in human computer interaction. Studies in
NLP have increased with the use of artificial intelligence technologies in the
field of linguistics. With the deep learning methods which are one of the
artificial intelligence study areas, platforms close to natural language are
being developed. Developed platforms for language comprehension, machine
translation and part of speech (POS) tagging benefit from deep learning
methods. Recurrent Neural Network (RNN), one of the deep learning
architectures, is preferred for processing sequential data such as text or
audio data. In this study, Turkish POS tagging model has been proposed by using
Bidirectional Long-Short Term Memory (BLSTM) which is an RNN type. The proposed
POS tagging model is provided to natural language researchers with a platform
that allows them to perform and use their own analysis. In the development
phase of the platform developed by using BLSTM, the error rate of the POS
tagger has been reduced by taking feedback with expert opinion.
",2019-05-07T21:09:49Z,http://arxiv.org/abs/1905.05699v1,"Baris Baburoglu, Adem Tekerek, Mehmet Tekerek"
"Deep Learning Based Natural Language Processing for End to End Speech
  Translation","  Deep Learning methods employ multiple processing layers to learn hierarchial
representations of data. They have already been deployed in a humongous number
of applications and have produced state-of-the-art results. Recently with the
growth in processing power of computers to be able to do high dimensional
tensor calculations, Natural Language Processing (NLP) applications have been
given a significant boost in terms of efficiency as well as accuracy. In this
paper, we will take a look at various signal processing techniques and then
application of them to produce a speech-to-text system using Deep Recurrent
Neural Networks.
",2018-08-09T14:21:35Z,http://arxiv.org/abs/1808.04459v1,Sarvesh Patil
"Scientific Language Modeling: A Quantitative Review of Large Language
  Models in Molecular Science","  Efficient molecular modeling and design are crucial for the discovery and
exploration of novel molecules, and the incorporation of deep learning methods
has revolutionized this field. In particular, large language models (LLMs)
offer a fresh approach to tackle scientific problems from a natural language
processing (NLP) perspective, introducing a research paradigm called scientific
language modeling (SLM). However, two key issues remain: how to quantify the
match between model and data modalities and how to identify the
knowledge-learning preferences of models. To address these challenges, we
propose a multi-modal benchmark, named ChEBI-20-MM, and perform 1263
experiments to assess the model's compatibility with data modalities and
knowledge acquisition. Through the modal transition probability matrix, we
provide insights into the most suitable modalities for tasks. Furthermore, we
introduce a statistically interpretable approach to discover context-specific
knowledge mapping by localized feature filtering. Our pioneering analysis
offers an exploration of the learning mechanism and paves the way for advancing
SLM in molecular science.
",2024-02-06T16:12:36Z,http://arxiv.org/abs/2402.04119v1,"Pengfei Liu, Jun Tao, Zhixiang Ren"
Natural Language Understanding with Distributed Representation,"  This is a lecture note for the course DS-GA 3001 <Natural Language
Understanding with Distributed Representation> at the Center for Data Science ,
New York University in Fall, 2015. As the name of the course suggests, this
lecture note introduces readers to a neural network based approach to natural
language understanding/processing. In order to make it as self-contained as
possible, I spend much time on describing basics of machine learning and neural
networks, only after which how they are used for natural languages is
introduced. On the language front, I almost solely focus on language modelling
and machine translation, two of which I personally find most fascinating and
most fundamental to natural language understanding.
",2015-11-24T23:23:13Z,http://arxiv.org/abs/1511.07916v1,Kyunghyun Cho
A Review of Deep Learning Techniques for Protein Function Prediction,"  Deep Learning and big data have shown tremendous success in bioinformatics
and computational biology in recent years; artificial intelligence methods have
also significantly contributed in the task of protein function classification.
This review paper analyzes the recent developments in approaches for the task
of predicting protein function using deep learning. We explain the importance
of determining the protein function and why automating the following task is
crucial. Then, after reviewing the widely used deep learning techniques for
this task, we continue our review and highlight the emergence of the modern
State of The Art (SOTA) deep learning models which have achieved groundbreaking
results in the field of computer vision, natural language processing and
multi-modal learning in the last few years. We hope that this review will
provide a broad view of the current role and advances of deep learning in
biological sciences, especially in predicting protein function tasks and
encourage new researchers to contribute to this area.
",2022-10-27T20:30:25Z,http://arxiv.org/abs/2211.09705v1,"Divyanshu Aggarwal, Yasha Hasija"
"Text Analysis Using Deep Neural Networks in Digital Humanities and
  Information Science","  Combining computational technologies and humanities is an ongoing effort
aimed at making resources such as texts, images, audio, video, and other
artifacts digitally available, searchable, and analyzable. In recent years,
deep neural networks (DNN) dominate the field of automatic text analysis and
natural language processing (NLP), in some cases presenting a super-human
performance. DNNs are the state-of-the-art machine learning algorithms solving
many NLP tasks that are relevant for Digital Humanities (DH) research, such as
spell checking, language detection, entity extraction, author detection,
question answering, and other tasks. These supervised algorithms learn patterns
from a large number of ""right"" and ""wrong"" examples and apply them to new
examples. However, using DNNs for analyzing the text resources in DH research
presents two main challenges: (un)availability of training data and a need for
domain adaptation. This paper explores these challenges by analyzing multiple
use-cases of DH studies in recent literature and their possible solutions and
lays out a practical decision model for DH experts for when and how to choose
the appropriate deep learning approaches for their research. Moreover, in this
paper, we aim to raise awareness of the benefits of utilizing deep learning
models in the DH community.
",2023-07-30T12:54:39Z,http://arxiv.org/abs/2307.16217v1,"Omri Suissa, Avshalom Elmalech, Maayan Zhitomirsky-Geffet"
"Modular Mechanistic Networks: On Bridging Mechanistic and
  Phenomenological Models with Deep Neural Networks in Natural Language
  Processing","  Natural language processing (NLP) can be done using either top-down (theory
driven) and bottom-up (data driven) approaches, which we call mechanistic and
phenomenological respectively. The approaches are frequently considered to
stand in opposition to each other. Examining some recent approaches in deep
learning we argue that deep neural networks incorporate both perspectives and,
furthermore, that leveraging this aspect of deep learning may help in solving
complex problems within language technology, such as modelling language and
perception in the domain of spatial cognition.
",2018-07-21T11:37:15Z,http://arxiv.org/abs/1807.09844v2,"Simon Dobnik, John D. Kelleher"
Application Specific Compression of Deep Learning Models,"  Large Deep Learning models are compressed and deployed for specific
applications. However, current Deep Learning model compression methods do not
utilize the information about the target application. As a result, the
compressed models are application agnostic. Our goal is to customize the model
compression process to create a compressed model that will perform better for
the target application. Our method, Application Specific Compression (ASC),
identifies and prunes components of the large Deep Learning model that are
redundant specifically for the given target application. The intuition of our
work is to prune the parts of the network that do not contribute significantly
to updating the data representation for the given application. We have
experimented with the BERT family of models for three applications: Extractive
QA, Natural Language Inference, and Paraphrase Identification. We observe that
customized compressed models created using ASC method perform better than
existing model compression methods and off-the-shelf compressed models.
",2024-09-09T06:55:38Z,http://arxiv.org/abs/2409.05368v1,"Rohit Raj Rai, Angana Borah, Amit Awekar"
"Deep learning for nano-photonic materials -- The solution to
  everything!?","  Deep learning is currently being hyped as an almost magical tool for solving
all kinds of difficult problems that computers have not been able to solve in
the past. Particularly in the fields of computer vision and natural language
processing, spectacular results have been achieved. The hype has now
infiltrated several scientific communities. In (nano-)photonics, researchers
are trying to apply deep learning to all kinds of forward and inverse problems.
A particularly challenging problem is for instance the rational design of
nanophotonic materials and devices. In this opinion article, I will first
discuss the public expectations of deep learning and give an overview of the
quite different scales at which actors from industry and research are operating
their deep learning models. I then examine the weaknesses and dangers
associated with deep learning. Finally, I'll discuss the key strengths that
make this new set of statistical methods so attractive, and review a personal
selection of opportunities that shouldn't be missed in the current
developments.
",2023-10-12T16:13:25Z,http://arxiv.org/abs/2310.08618v2,Peter R. Wiecha
"Integrating AI Planning with Natural Language Processing: A Combination
  of Explicit and Tacit Knowledge","  Natural language processing (NLP) aims at investigating the interactions
between agents and humans, processing and analyzing large amounts of natural
language data. Large-scale language models play an important role in current
natural language processing. However, the challenges of explainability and
complexity come along with the developments of language models. One way is to
introduce logical relations and rules into natural language processing models,
such as making use of Automated Planning. Automated planning (AI planning)
focuses on building symbolic domain models and synthesizing plans to transit
initial states to goals based on domain models. Recently, there have been
plenty of works related to these two fields, which have the abilities to
generate explicit knowledge, e.g., preconditions and effects of action models,
and learn from tacit knowledge, e.g., neural models, respectively. Integrating
AI planning and natural language processing effectively improves the
communication between human and intelligent agents. This paper outlines the
commons and relations between AI planning and natural language processing,
argues that each of them can effectively impact on the other one by five areas:
(1) planning-based text understanding, (2) planning-based natural language
processing, (3) planning-based explainability, (4) text-based human-robot
interaction, and (5) applications. We also explore some potential future issues
between AI planning and natural language processing. To the best of our
knowledge, this survey is the first work that addresses the deep connections
between AI planning and Natural language processing.
",2022-02-15T02:19:09Z,http://arxiv.org/abs/2202.07138v2,"Kebing Jin, Hankz Hankui Zhuo"
Changes from Classical Statistics to Modern Statistics and Data Science,"  A coordinate system is a foundation for every quantitative science,
engineering, and medicine. Classical physics and statistics are based on the
Cartesian coordinate system. The classical probability and hypothesis testing
theory can only be applied to Euclidean data. However, modern data in the real
world are from natural language processing, mathematical formulas, social
networks, transportation and sensor networks, computer visions, automations,
and biomedical measurements. The Euclidean assumption is not appropriate for
non Euclidean data. This perspective addresses the urgent need to overcome
those fundamental limitations and encourages extensions of classical
probability theory and hypothesis testing , diffusion models and stochastic
differential equations from Euclidean space to non Euclidean space. Artificial
intelligence such as natural language processing, computer vision, graphical
neural networks, manifold regression and inference theory, manifold learning,
graph neural networks, compositional diffusion models for automatically
compositional generations of concepts and demystifying machine learning
systems, has been rapidly developed. Differential manifold theory is the
mathematic foundations of deep learning and data science as well. We urgently
need to shift the paradigm for data analysis from the classical Euclidean data
analysis to both Euclidean and non Euclidean data analysis and develop more and
more innovative methods for describing, estimating and inferring non Euclidean
geometries of modern real datasets. A general framework for integrated analysis
of both Euclidean and non Euclidean data, composite AI, decision intelligence
and edge AI provide powerful innovative ideas and strategies for fundamentally
advancing AI. We are expected to marry statistics with AI, develop a unified
theory of modern statistics and drive next generation of AI and data science.
",2022-10-30T21:35:53Z,http://arxiv.org/abs/2211.03756v1,"Kai Zhang, Shan Liu, Momiao Xiong"
"Recent Advances and Applications of Deep Learning Methods in Materials
  Science","  Deep learning (DL) is one of the fastest growing topics in materials data
science, with rapidly emerging applications spanning atomistic, image-based,
spectral, and textual data modalities. DL allows analysis of unstructured data
and automated identification of features. Recent development of large materials
databases has fueled the application of DL methods in atomistic prediction in
particular. In contrast, advances in image and spectral data have largely
leveraged synthetic data enabled by high quality forward models as well as by
generative unsupervised DL methods. In this article, we present a high-level
overview of deep-learning methods followed by a detailed discussion of recent
developments of deep learning in atomistic simulation, materials imaging,
spectral analysis, and natural language processing. For each modality we
discuss applications involving both theoretical and experimental data, typical
modeling approaches with their strengths and limitations, and relevant publicly
available software and datasets. We conclude the review with a discussion of
recent cross-cutting work related to uncertainty quantification in this field
and a brief perspective on limitations, challenges, and potential growth areas
for DL methods in materials science. The application of DL methods in materials
science presents an exciting avenue for future materials discovery and design.
",2021-10-28T00:09:04Z,http://arxiv.org/abs/2110.14820v1,"Kamal Choudhary, Brian DeCost, Chi Chen, Anubhav Jain, Francesca Tavazza, Ryan Cohn, Cheol WooPark, Alok Choudhary, Ankit Agrawal, Simon J. L. Billinge, Elizabeth Holm, Shyue Ping Ong, Chris Wolverton"
Data Augmentation Approaches in Natural Language Processing: A Survey,"  As an effective strategy, data augmentation (DA) alleviates data scarcity
scenarios where deep learning techniques may fail. It is widely applied in
computer vision then introduced to natural language processing and achieves
improvements in many tasks. One of the main focuses of the DA methods is to
improve the diversity of training data, thereby helping the model to better
generalize to unseen testing data. In this survey, we frame DA methods into
three categories based on the diversity of augmented data, including
paraphrasing, noising, and sampling. Our paper sets out to analyze DA methods
in detail according to the above categories. Further, we also introduce their
applications in NLP tasks as well as the challenges. Some helpful resources are
provided in the appendix.
",2021-10-05T07:35:32Z,http://arxiv.org/abs/2110.01852v3,"Bohan Li, Yutai Hou, Wanxiang Che"
"Few-Shot Learning for Clinical Natural Language Processing Using Siamese
  Neural Networks","  Clinical Natural Language Processing (NLP) has become an emerging technology
in healthcare that leverages a large amount of free-text data in electronic
health records (EHRs) to improve patient care, support clinical decisions, and
facilitate clinical and translational science research. Recently, deep learning
has achieved state-of-the-art performance in many clinical NLP tasks. However,
training deep learning models usually requires large annotated datasets, which
are normally not publicly available and can be time-consuming to build in
clinical domains. Working with smaller annotated datasets is typical in
clinical NLP and therefore, ensuring that deep learning models perform well is
crucial for the models to be used in real-world applications. A widely adopted
approach is fine-tuning existing Pre-trained Language Models (PLMs), but these
attempts fall short when the training dataset contains only a few annotated
samples. Few-Shot Learning (FSL) has recently been investigated to tackle this
problem. Siamese Neural Network (SNN) has been widely utilized as an FSL
approach in computer vision, but has not been studied well in NLP. Furthermore,
the literature on its applications in clinical domains is scarce. In this
paper, we propose two SNN-based FSL approaches for clinical NLP, including
Pre-Trained SNN (PT-SNN) and SNN with Second-Order Embeddings (SOE-SNN). We
evaluated the proposed approaches on two clinical tasks, namely clinical text
classification and clinical named entity recognition. We tested three few-shot
settings including 4-shot, 8-shot, and 16-shot learning. Both clinical NLP
tasks were benchmarked using three PLMs, including BERT,BioBERT, and
BioClinicalBERT. The experimental results verified the effectiveness of the
proposed SNN-based FSL approaches in both NLP tasks.
",2022-08-31T15:36:27Z,http://arxiv.org/abs/2208.14923v2,"David Oniani, Sonish Sivarajkumar, Yanshan Wang"
Federated Learning Meets Natural Language Processing: A Survey,"  Federated Learning aims to learn machine learning models from multiple
decentralized edge devices (e.g. mobiles) or servers without sacrificing local
data privacy. Recent Natural Language Processing techniques rely on deep
learning and large pre-trained language models. However, both big deep neural
and language models are trained with huge amounts of data which often lies on
the server side. Since text data is widely originated from end users, in this
work, we look into recent NLP models and techniques which use federated
learning as the learning framework. Our survey discusses major challenges in
federated natural language processing, including the algorithm challenges,
system challenges as well as the privacy issues. We also provide a critical
review of the existing Federated NLP evaluation methods and tools. Finally, we
highlight the current research gaps and future directions.
",2021-07-27T05:07:48Z,http://arxiv.org/abs/2107.12603v1,"Ming Liu, Stella Ho, Mengqi Wang, Longxiang Gao, Yuan Jin, He Zhang"
AllenNLP: A Deep Semantic Natural Language Processing Platform,"  This paper describes AllenNLP, a platform for research on deep learning
methods in natural language understanding. AllenNLP is designed to support
researchers who want to build novel language understanding models quickly and
easily. It is built on top of PyTorch, allowing for dynamic computation graphs,
and provides (1) a flexible data API that handles intelligent batching and
padding, (2) high-level abstractions for common operations in working with
text, and (3) a modular and extensible experiment framework that makes doing
good science easy. It also includes reference implementations of high quality
approaches for both core semantic problems (e.g. semantic role labeling (Palmer
et al., 2005)) and language understanding applications (e.g. machine
comprehension (Rajpurkar et al., 2016)). AllenNLP is an ongoing open-source
effort maintained by engineers and researchers at the Allen Institute for
Artificial Intelligence.
",2018-03-20T20:32:07Z,http://arxiv.org/abs/1803.07640v2,"Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Peters, Michael Schmitz, Luke Zettlemoyer"
DeepZensols: Deep Natural Language Processing Framework,"  Reproducing results in publications by distributing publicly available source
code is becoming ever more popular. Given the difficulty of reproducing machine
learning (ML) experiments, there have been significant efforts in reducing the
variance of these results. As in any science, the ability to consistently
reproduce results effectively strengthens the underlying hypothesis of the
work, and thus, should be regarded as important as the novel aspect of the
research itself. The contribution of this work is a framework that is able to
reproduce consistent results and provides a means of easily creating, training,
and evaluating natural language processing (NLP) deep learning (DL) models.
",2021-09-08T01:16:05Z,http://arxiv.org/abs/2109.03383v1,"Paul Landes, Barbara Di Eugenio, Cornelia Caragea"
"Semi-Supervised Neural Text Generation by Joint Learning of Natural
  Language Generation and Natural Language Understanding Models","  In Natural Language Generation (NLG), End-to-End (E2E) systems trained
through deep learning have recently gained a strong interest. Such deep models
need a large amount of carefully annotated data to reach satisfactory
performance. However, acquiring such datasets for every new NLG application is
a tedious and time-consuming task. In this paper, we propose a semi-supervised
deep learning scheme that can learn from non-annotated data and annotated data
when available. It uses an NLG and a Natural Language Understanding (NLU)
sequence-to-sequence models which are learned jointly to compensate for the
lack of annotation. Experiments on two benchmark datasets show that, with
limited amount of annotated data, the method can achieve very competitive
results while not using any pre-processing or re-scoring tricks. These findings
open the way to the exploitation of non-annotated datasets which is the current
bottleneck for the E2E NLG system development to new applications.
",2019-09-29T11:37:18Z,http://arxiv.org/abs/1910.03484v1,"Raheel Qader, Fran√ßois Portet, Cyril Labb√©"
Opening the black box of language acquisition,"  Recent advances in large language models using deep learning techniques have
renewed interest on how languages can be learned from data. However, it is
unclear whether or how these models represent grammatical information from the
learned languages. In addition, the models must be pre-trained on large corpora
before they can be used. In this work, we propose an alternative, more
transparent and cognitively plausible architecture for learning language.
Instead of using deep learning, our approach uses a minimal cognitive
architecture based on sequence memory and chunking. The learning mechanism is
based on the principles of reinforcement learning. We test our architecture on
a number of natural-like toy languages. Results show that the model can learn
these artificial languages from scratch and extract grammatical information
that supports learning. Our study demonstrates the power of this simple
architecture and stresses the importance of sequence memory as a key component
of the language learning process. Since other animals do not seem to have a
faithful sequence memory, this may explain why only humans have developed
complex languages.
",2024-02-18T19:11:58Z,http://arxiv.org/abs/2402.11681v1,"J√©r√¥me Michaud, Anna Jon-and"
Can Transformers Reason in Fragments of Natural Language?,"  State-of-the-art deep-learning-based approaches to Natural Language
Processing (NLP) are credited with various capabilities that involve reasoning
with natural language texts. In this paper we carry out a large-scale empirical
study investigating the detection of formally valid inferences in controlled
fragments of natural language for which the satisfiability problem becomes
increasingly complex. We find that, while transformer-based language models
perform surprisingly well in these scenarios, a deeper analysis re-veals that
they appear to overfit to superficial patterns in the data rather than
acquiring the logical principles governing the reasoning in these fragments.
",2022-11-10T08:46:53Z,http://arxiv.org/abs/2211.05417v1,"Viktor Schlegel, Kamen V. Pavlov, Ian Pratt-Hartmann"
"Evolution of Natural Language Processing Technology: Not Just Language
  Processing Towards General Purpose AI","  Since the invention of computers, communication through natural language
(actual human language) has been a dream technology. However, natural language
is extremely difficult to mathematically formulate, making it difficult to
realize as an algorithm without considering programming. While there have been
numerous technological developments, one cannot say that any results allowing
free utilization have been achieved thus far. In the case of language learning
in humans, for instance when learning one's mother tongue or foreign language,
one must admit that this process is similar to the adage ""practice makes
perfect"" in principle, even though the learning method is significant up to a
point. Deep learning has played a central role in contemporary AI technology in
recent years. When applied to natural language processing (NLP), this produced
unprecedented results. Achievements exceeding the initial predictions have been
reported from the results of learning vast amounts of textual data using deep
learning. For instance, four arithmetic operations could be performed without
explicit learning, thereby enabling the explanation of complex images and the
generation of images from corresponding explanatory texts. It is an accurate
example of the learner embodying the concept of ""practice makes perfect"" by
using vast amounts of textual data. This report provides a technological
explanation of how cutting-edge NLP has made it possible to realize the
""practice makes perfect"" principle. Additionally, examples of how this can be
applied to business are provided. We reported in June 2022 in Japanese on the
NLP movement from late 2021 to early 2022. We would like to summarize this as a
memorandum since this is just the initial movement leading to the current large
language models (LLMs).
",2023-10-10T00:41:38Z,http://arxiv.org/abs/2310.06228v1,Masahiro Yamamoto
"FinLangNet: A Novel Deep Learning Framework for Credit Risk Prediction
  Using Linguistic Analogy in Financial Data","  Recent industrial applications in risk prediction still heavily rely on
extensively manually-tuned, statistical learning methods. Real-world financial
data, characterized by its high dimensionality, sparsity, high noise levels,
and significant imbalance, poses unique challenges for the effective
application of deep neural network models. In this work, we introduce a novel
deep learning risk prediction framework, FinLangNet, which conceptualizes
credit loan trajectories in a structure that mirrors linguistic constructs.
This framework is tailored for credit risk prediction using real-world
financial data, drawing on structural similarities to language by adapting
natural language processing techniques. It particularly emphasizes analyzing
the development and forecastability of mid-term credit histories through
multi-head and sequences of detailed financial events. Our research
demonstrates that FinLangNet surpasses traditional statistical methods in
predicting credit risk and that its integration with these methods enhances
credit overdue prediction models, achieving a significant improvement of over
4.24\% in the Kolmogorov-Smirnov metric.
",2024-04-19T17:01:46Z,http://arxiv.org/abs/2404.13004v2,"Yu Lei, Zixuan Wang, Chu Liu, Tongyao Wang, Dongyang Lee"
Deep Learning for Hindi Text Classification: A Comparison,"  Natural Language Processing (NLP) and especially natural language text
analysis have seen great advances in recent times. Usage of deep learning in
text processing has revolutionized the techniques for text processing and
achieved remarkable results. Different deep learning architectures like CNN,
LSTM, and very recent Transformer have been used to achieve state of the art
results variety on NLP tasks. In this work, we survey a host of deep learning
architectures for text classification tasks. The work is specifically concerned
with the classification of Hindi text. The research in the classification of
morphologically rich and low resource Hindi language written in Devanagari
script has been limited due to the absence of large labeled corpus. In this
work, we used translated versions of English data-sets to evaluate models based
on CNN, LSTM and Attention. Multilingual pre-trained sentence embeddings based
on BERT and LASER are also compared to evaluate their effectiveness for the
Hindi language. The paper also serves as a tutorial for popular text
classification techniques.
",2020-01-19T09:29:12Z,http://arxiv.org/abs/2001.10340v1,"Ramchandra Joshi, Purvi Goel, Raviraj Joshi"
"Prediction Algorithm for Heat Demand of Science and Technology Topics
  Based on Time Convolution Network","  Thanks to the rapid development of deep learning, big data analysis
technology is not only widely used in the field of natural language processing,
but also more mature in the field of numerical prediction. It is of great
significance for the subject heat prediction and analysis of science and
technology demand data. How to apply theme features to accurately predict the
theme heat of science and technology demand is the core to solve this problem.
In this paper, a prediction method of subject heat of science and technology
demand based on time convolution network (TCN) is proposed to obtain the
subject feature representation of science and technology demand. Time series
prediction is carried out based on TCN network and self attention mechanism,
which increases the accuracy of subject heat prediction of science and
technology demand data Experiments show that the prediction accuracy of this
algorithm is better than other time series prediction methods on the real
science and technology demand datasets.
",2022-03-21T03:30:05Z,http://arxiv.org/abs/2203.10718v1,"Cui Haiyan, Li Yawen, Xu Xin"
"A Data-Driven Study of Commonsense Knowledge using the ConceptNet
  Knowledge Base","  Acquiring commonsense knowledge and reasoning is recognized as an important
frontier in achieving general Artificial Intelligence (AI). Recent research in
the Natural Language Processing (NLP) community has demonstrated significant
progress in this problem setting. Despite this progress, which is mainly on
multiple-choice question answering tasks in limited settings, there is still a
lack of understanding (especially at scale) of the nature of commonsense
knowledge itself. In this paper, we propose and conduct a systematic study to
enable a deeper understanding of commonsense knowledge by doing an empirical
and structural analysis of the ConceptNet knowledge base. ConceptNet is a
freely available knowledge base containing millions of commonsense assertions
presented in natural language. Detailed experimental results on three carefully
designed research questions, using state-of-the-art unsupervised graph
representation learning ('embedding') and clustering techniques, reveal deep
substructures in ConceptNet relations, allowing us to make data-driven and
computational claims about the meaning of phenomena such as 'context' that are
traditionally discussed only in qualitative terms. Furthermore, our methodology
provides a case study in how to use data-science and computational
methodologies for understanding the nature of an everyday (yet complex)
psychological phenomenon that is an essential feature of human intelligence.
",2020-11-28T08:08:25Z,http://arxiv.org/abs/2011.14084v2,"Ke Shen, Mayank Kejriwal"
"Deep Learning, Natural Language Processing, and Explainable Artificial
  Intelligence in the Biomedical Domain","  In this article, we first give an introduction to artificial intelligence and
its applications in biology and medicine in Section 1. Deep learning methods
are then described in Section 2. We narrow down the focus of the study on
textual data in Section 3, where natural language processing and its
applications in the biomedical domain are described. In Section 4, we give an
introduction to explainable artificial intelligence and discuss the importance
of explainability of artificial intelligence systems, especially in the
biomedical domain.
",2022-02-25T13:30:51Z,http://arxiv.org/abs/2202.12678v2,"Milad Moradi, Matthias Samwald"
"Surveying the Landscape of Text Summarization with Deep Learning: A
  Comprehensive Review","  In recent years, deep learning has revolutionized natural language processing
(NLP) by enabling the development of models that can learn complex
representations of language data, leading to significant improvements in
performance across a wide range of NLP tasks. Deep learning models for NLP
typically use large amounts of data to train deep neural networks, allowing
them to learn the patterns and relationships in language data. This is in
contrast to traditional NLP approaches, which rely on hand-engineered features
and rules to perform NLP tasks. The ability of deep neural networks to learn
hierarchical representations of language data, handle variable-length input
sequences, and perform well on large datasets makes them well-suited for NLP
applications. Driven by the exponential growth of textual data and the
increasing demand for condensed, coherent, and informative summaries, text
summarization has been a critical research area in the field of NLP. Applying
deep learning to text summarization refers to the use of deep neural networks
to perform text summarization tasks. In this survey, we begin with a review of
fashionable text summarization tasks in recent years, including extractive,
abstractive, multi-document, and so on. Next, we discuss most deep
learning-based models and their experimental results on these tasks. The paper
also covers datasets and data representation for summarization tasks. Finally,
we delve into the opportunities and challenges associated with summarization
tasks and their corresponding methodologies, aiming to inspire future research
efforts to advance the field further. A goal of our survey is to explain how
these methods differ in their requirements as understanding them is essential
for choosing a technique suited for a specific setting.
",2023-10-13T21:24:37Z,http://arxiv.org/abs/2310.09411v1,"Guanghua Wang, Weili Wu"
"Neural translation and automated recognition of ICD10 medical entities
  from natural language","  The recognition of medical entities from natural language is an ubiquitous
problem in the medical field, with applications ranging from medical act coding
to the analysis of electronic health data for public health. It is however a
complex task usually requiring human expert intervention, thus making it
expansive and time consuming. The recent advances in artificial intelligence,
specifically the raise of deep learning methods, has enabled computers to make
efficient decisions on a number of complex problems, with the notable example
of neural sequence models and their powerful applications in natural language
processing. They however require a considerable amount of data to learn from,
which is typically their main limiting factor. However, the C\'epiDc stores an
exhaustive database of death certificates at the French national scale,
amounting to several millions of natural language examples provided with their
associated human coded medical entities available to the machine learning
practitioner. This article investigates the applications of deep neural
sequence models to the medical entity recognition from natural language
problem.
",2020-03-27T18:17:53Z,http://arxiv.org/abs/2004.13839v2,"Louis Falissard, Claire Morgand, Sylvie Roussel, Claire Imbaud, Walid Ghosn, Karim Bounebache, Gr√©goire Rey"
Do learned speech symbols follow Zipf's law?,"  In this study, we investigate whether speech symbols, learned through deep
learning, follow Zipf's law, akin to natural language symbols. Zipf's law is an
empirical law that delineates the frequency distribution of words, forming
fundamentals for statistical analysis in natural language processing. Natural
language symbols, which are invented by humans to symbolize speech content, are
recognized to comply with this law. On the other hand, recent breakthroughs in
spoken language processing have given rise to the development of learned speech
symbols; these are data-driven symbolizations of speech content. Our objective
is to ascertain whether these data-driven speech symbols follow Zipf's law, as
the same as natural language symbols. Through our investigation, we aim to
forge new ways for the statistical analysis of spoken language processing.
",2023-09-18T11:56:10Z,http://arxiv.org/abs/2309.09690v1,"Shinnosuke Takamichi, Hiroki Maeda, Joonyong Park, Daisuke Saito, Hiroshi Saruwatari"
"A Comprehensive Python Library for Deep Learning-Based Event Detection
  in Multivariate Time Series Data and Information Retrieval in NLP","  Event detection in time series data is crucial in various domains, including
finance, healthcare, cybersecurity, and science. Accurately identifying events
in time series data is vital for making informed decisions, detecting
anomalies, and predicting future trends. Despite extensive research exploring
diverse methods for event detection in time series, with deep learning
approaches being among the most advanced, there is still room for improvement
and innovation in this field. In this paper, we present a new deep learning
supervised method for detecting events in multivariate time series data. Our
method combines four distinct novelties compared to existing deep-learning
supervised methods. Firstly, it is based on regression instead of binary
classification. Secondly, it does not require labeled datasets where each point
is labeled; instead, it only requires reference events defined as time points
or intervals of time. Thirdly, it is designed to be robust by using a stacked
ensemble learning meta-model that combines deep learning models, ranging from
classic feed-forward neural networks (FFNs) to state-of-the-art architectures
like transformers. This ensemble approach can mitigate individual model
weaknesses and biases, resulting in more robust predictions. Finally, to
facilitate practical implementation, we have developed a Python package to
accompany our proposed method. The package, called eventdetector-ts, can be
installed through the Python Package Index (PyPI). In this paper, we present
our method and provide a comprehensive guide on the usage of the package. We
showcase its versatility and effectiveness through different real-world use
cases from natural language processing (NLP) to financial security domains.
",2023-10-25T09:13:19Z,http://arxiv.org/abs/2310.16485v2,"Menouar Azib, Benjamin Renard, Philippe Garnier, Vincent G√©not, Nicolas Andr√©"
Deep Learning Works in Practice. But Does it Work in Theory?,"  Deep learning relies on a very specific kind of neural networks: those
superposing several neural layers. In the last few years, deep learning
achieved major breakthroughs in many tasks such as image analysis, speech
recognition, natural language processing, and so on. Yet, there is no
theoretical explanation of this success. In particular, it is not clear why the
deeper the network, the better it actually performs.
  We argue that the explanation is intimately connected to a key feature of the
data collected from our surrounding universe to feed the machine learning
algorithms: large non-parallelizable logical depth. Roughly speaking, we
conjecture that the shortest computational descriptions of the universe are
algorithms with inherently large computation times, even when a large number of
computers are available for parallelization. Interestingly, this conjecture,
combined with the folklore conjecture in theoretical computer science that $ P
\neq NC$, explains the success of deep learning.
",2018-01-31T13:12:30Z,http://arxiv.org/abs/1801.10437v1,"L√™ Nguy√™n Hoang, Rachid Guerraoui"
Identifying and Exploiting Structures for Reliable Deep Learning,"  Deep learning research has recently witnessed an impressively fast-paced
progress in a wide range of tasks including computer vision, natural language
processing, and reinforcement learning. The extraordinary performance of these
systems often gives the impression that they can be used to revolutionise our
lives for the better. However, as recent works point out, these systems suffer
from several issues that make them unreliable for use in the real world,
including vulnerability to adversarial attacks (Szegedy et al. [248]), tendency
to memorise noise (Zhang et al. [292]), being over-confident on incorrect
predictions (miscalibration) (Guo et al. [99]), and unsuitability for handling
private data (Gilad-Bachrach et al. [88]). In this thesis, we look at each of
these issues in detail, investigate their causes, and propose computationally
cheap algorithms for mitigating them in practice. To do this, we identify
structures in deep neural networks that can be exploited to mitigate the above
causes of unreliability of deep learning algorithms.
",2021-08-16T13:40:01Z,http://arxiv.org/abs/2108.07083v1,Amartya Sanyal
Text Classification: A Perspective of Deep Learning Methods,"  In recent years, with the rapid development of information on the Internet,
the number of complex texts and documents has increased exponentially, which
requires a deeper understanding of deep learning methods in order to accurately
classify texts using deep learning techniques, and thus deep learning methods
have become increasingly important in text classification. Text classification
is a class of tasks that automatically classifies a set of documents into
multiple predefined categories based on their content and subject matter. Thus,
the main goal of text classification is to enable users to extract information
from textual resources and process processes such as retrieval, classification,
and machine learning techniques together in order to classify different
categories. Many new techniques of deep learning have already achieved
excellent results in natural language processing. The success of these learning
algorithms relies on their ability to understand complex models and non-linear
relationships in data. However, finding the right structure, architecture, and
techniques for text classification is a challenge for researchers. This paper
introduces deep learning-based text classification algorithms, including
important steps required for text classification tasks such as feature
extraction, feature reduction, and evaluation strategies and methods. At the
end of the article, different deep learning text classification methods are
compared and summarized.
",2023-09-24T21:49:51Z,http://arxiv.org/abs/2309.13761v1,Zhongwei Wan
Data Augmentation for Neural NLP,"  Data scarcity is a problem that occurs in languages and tasks where we do not
have large amounts of labeled data but want to use state-of-the-art models.
Such models are often deep learning models that require a significant amount of
data to train. Acquiring data for various machine learning problems is
accompanied by high labeling costs. Data augmentation is a low-cost approach
for tackling data scarcity. This paper gives an overview of current
state-of-the-art data augmentation methods used for natural language
processing, with an emphasis on methods for neural and transformer-based
models. Furthermore, it discusses the practical challenges of data
augmentation, possible mitigations, and directions for future research.
",2023-02-22T14:47:15Z,http://arxiv.org/abs/2302.11412v1,"Domagoj Plu≈°ƒçec, Jan ≈†najder"
Natural Language Processing Advancements By Deep Learning: A Survey,"  Natural Language Processing (NLP) helps empower intelligent machines by
enhancing a better understanding of the human language for linguistic-based
human-computer communication. Recent developments in computational power and
the advent of large amounts of linguistic data have heightened the need and
demand for automating semantic analysis using data-driven approaches. The
utilization of data-driven strategies is pervasive now due to the significant
improvements demonstrated through the usage of deep learning methods in areas
such as Computer Vision, Automatic Speech Recognition, and in particular, NLP.
This survey categorizes and addresses the different aspects and applications of
NLP that have benefited from deep learning. It covers core NLP tasks and
applications and describes how deep learning methods and models advance these
areas. We further analyze and compare different approaches and state-of-the-art
models.
",2020-03-02T21:32:05Z,http://arxiv.org/abs/2003.01200v4,"Amirsina Torfi, Rouzbeh A. Shirvani, Yaser Keneshloo, Nader Tavaf, Edward A. Fox"
"Application of Transfer Learning to Sign Language Recognition using an
  Inflated 3D Deep Convolutional Neural Network","  Sign language is the primary language for people with a hearing loss. Sign
language recognition (SLR) is the automatic recognition of sign language, which
represents a challenging problem for computers, though some progress has been
made recently using deep learning. Huge amounts of data are generally required
to train deep learning models. However, corresponding datasets are missing for
the majority of sign languages. Transfer learning is a technique to utilize a
related task with an abundance of data available to help solve a target task
lacking sufficient data. Transfer learning has been applied highly successfully
in computer vision and natural language processing. However, much less research
has been conducted in the field of SLR. This paper investigates how effectively
transfer learning can be applied to isolated SLR using an inflated 3D
convolutional neural network as the deep learning architecture. Transfer
learning is implemented by pre-training a network on the American Sign Language
dataset MS-ASL and subsequently fine-tuning it separately on three different
sizes of the German Sign Language dataset SIGNUM. The results of the
experiments give clear empirical evidence that transfer learning can be
effectively applied to isolated SLR. The accuracy performances of the networks
applying transfer learning increased substantially by up to 21% as compared to
the baseline models that were not pre-trained on the MS-ASL dataset.
",2021-02-25T13:37:39Z,http://arxiv.org/abs/2103.05111v1,Roman T√∂ngi
"Deep Learning Algorithms with Applications to Video Analytics for A
  Smart City: A Survey","  Deep learning has recently achieved very promising results in a wide range of
areas such as computer vision, speech recognition and natural language
processing. It aims to learn hierarchical representations of data by using deep
architecture models. In a smart city, a lot of data (e.g. videos captured from
many distributed sensors) need to be automatically processed and analyzed. In
this paper, we review the deep learning algorithms applied to video analytics
of smart city in terms of different research topics: object detection, object
tracking, face recognition, image classification and scene labeling.
",2015-12-10T03:23:54Z,http://arxiv.org/abs/1512.03131v1,"Li Wang, Dennis Sng"
Three-Class Text Sentiment Analysis Based on LSTM,"  Sentiment analysis is a crucial task in natural language processing (NLP)
with applications in public opinion monitoring, market research, and beyond.
This paper introduces a three-class sentiment classification method for Weibo
comments using Long Short-Term Memory (LSTM) networks to discern positive,
neutral, and negative sentiments. LSTM, as a deep learning model, excels at
capturing long-distance dependencies in text data, providing significant
advantages over traditional machine learning approaches. Through preprocessing
and feature extraction from Weibo comment texts, our LSTM model achieves
precise sentiment prediction. Experimental results demonstrate superior
performance, achieving an accuracy of 98.31% and an F1 score of 98.28%, notably
outperforming conventional models and other deep learning methods. This
underscores the effectiveness of LSTM in capturing nuanced sentiment
information within text, thereby enhancing classification accuracy. Despite its
strengths, the LSTM model faces challenges such as high computational
complexity and slower processing times for lengthy texts. Moreover, complex
emotional expressions like sarcasm and humor pose additional difficulties.
Future work could explore combining pre-trained models or advancing feature
engineering techniques to further improve both accuracy and practicality.
Overall, this study provides an effective solution for sentiment analysis on
Weibo comments.
",2024-12-23T07:21:07Z,http://arxiv.org/abs/2412.17347v1,Yin Qixuan
What Really is Deep Learning Doing?,"  Deep learning has achieved a great success in many areas, from computer
vision to natural language processing, to game playing, and much more. Yet,
what deep learning is really doing is still an open question. There are a lot
of works in this direction. For example, [5] tried to explain deep learning by
group renormalization, and [6] tried to explain deep learning from the view of
functional approximation. In order to address this very crucial question, here
we see deep learning from perspective of mechanical learning and learning
machine (see [1], [2]). From this particular angle, we can see deep learning
much better and answer with confidence: What deep learning is really doing? why
it works well, how it works, and how much data is necessary for learning. We
also will discuss advantages and disadvantages of deep learning at the end of
this work.
",2017-11-06T23:00:13Z,http://arxiv.org/abs/1711.03577v1,Chuyu Xiong
Geometric deep learning: going beyond Euclidean data,"  Many scientific fields study data with an underlying structure that is a
non-Euclidean space. Some examples include social networks in computational
social sciences, sensor networks in communications, functional networks in
brain imaging, regulatory networks in genetics, and meshed surfaces in computer
graphics. In many applications, such geometric data are large and complex (in
the case of social networks, on the scale of billions), and are natural targets
for machine learning techniques. In particular, we would like to use deep
neural networks, which have recently proven to be powerful tools for a broad
range of problems from computer vision, natural language processing, and audio
analysis. However, these tools have been most successful on data with an
underlying Euclidean or grid-like structure, and in cases where the invariances
of these structures are built into networks used to model them. Geometric deep
learning is an umbrella term for emerging techniques attempting to generalize
(structured) deep neural models to non-Euclidean domains such as graphs and
manifolds. The purpose of this paper is to overview different examples of
geometric deep learning problems and present available solutions, key
difficulties, applications, and future research directions in this nascent
field.
",2016-11-24T08:45:01Z,http://arxiv.org/abs/1611.08097v2,"Michael M. Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, Pierre Vandergheynst"
"Large Language Models are not Models of Natural Language: they are
  Corpus Models","  Natural Language Processing (NLP) has become one of the leading application
areas in the current Artificial Intelligence boom. Transfer learning has
enabled large deep learning neural networks trained on the language modeling
task to vastly improve performance in almost all downstream language tasks.
Interestingly, when the language models are trained with data that includes
software code, they demonstrate remarkable abilities in generating functioning
computer code from natural language specifications. We argue that this creates
a conundrum for the claim that eliminative neural models are a radical
restructuring in our understanding of cognition in that they eliminate the need
for symbolic abstractions like generative phrase structure grammars. Because
the syntax of programming languages is by design determined by phrase structure
grammars, neural models that produce syntactic code are apparently
uninformative about the theoretical foundations of programming languages. The
demonstration that neural models perform well on tasks that involve clearly
symbolic systems, proves that they cannot be used as an argument that language
and other cognitive systems are not symbolic. Finally, we argue as a corollary
that the term language model is misleading and propose the adoption of the
working term corpus model instead, which better reflects the genesis and
contents of the model.
",2021-12-13T22:39:46Z,http://arxiv.org/abs/2112.07055v2,Csaba Veres
"Semantic and Relational Spaces in Science of Science: Deep Learning
  Models for Article Vectorisation","  Over the last century, we observe a steady and exponentially growth of
scientific publications globally. The overwhelming amount of available
literature makes a holistic analysis of the research within a field and between
fields based on manual inspection impossible. Automatic techniques to support
the process of literature review are required to find the epistemic and social
patterns that are embedded in scientific publications. In computer sciences,
new tools have been developed to deal with large volumes of data. In
particular, deep learning techniques open the possibility of automated
end-to-end models to project observations to a new, low-dimensional space where
the most relevant information of each observation is highlighted. Using deep
learning to build new representations of scientific publications is a growing
but still emerging field of research. The aim of this paper is to discuss the
potential and limits of deep learning for gathering insights about scientific
research articles. We focus on document-level embeddings based on the semantic
and relational aspects of articles, using Natural Language Processing (NLP) and
Graph Neural Networks (GNNs). We explore the different outcomes generated by
those techniques. Our results show that using NLP we can encode a semantic
space of articles, while with GNN we are able to build a relational space where
the social practices of a research community are also encoded.
",2020-11-05T14:57:41Z,http://arxiv.org/abs/2011.02887v1,"Diego Kozlowski, Jennifer Dusdal, Jun Pang, Andreas Zilian"
A Short Review on Data Modelling for Vector Fields,"  Machine learning methods based on statistical principles have proven highly
successful in dealing with a wide variety of data analysis and analytics tasks.
Traditional data models are mostly concerned with independent identically
distributed data. The recent success of end-to-end modelling scheme using deep
neural networks equipped with effective structures such as convolutional layers
or skip connections allows the extension to more sophisticated and structured
practical data, such as natural language, images, videos, etc. On the
application side, vector fields are an extremely useful type of data in
empirical sciences, as well as signal processing, e.g. non-parametric
transformations of 3D point clouds using 3D vector fields, the modelling of the
fluid flow in earth science, and the modelling of physical fields.
  This review article is dedicated to recent computational tools of vector
fields, including vector data representations, predictive model of spatial
data, as well as applications in computer vision, signal processing, and
empirical sciences.
",2020-09-01T17:07:29Z,http://arxiv.org/abs/2009.00577v1,"Jun Li, Wanrong Hong, Yusheng Xiang"
Machine Learning and Big Scientific Data,"  This paper reviews some of the challenges posed by the huge growth of
experimental data generated by the new generation of large-scale experiments at
UK national facilities at the Rutherford Appleton Laboratory site at Harwell
near Oxford. Such ""Big Scientific Data"" comes from the Diamond Light Source and
Electron Microscopy Facilities, the ISIS Neutron and Muon Facility, and the
UK's Central Laser Facility. Increasingly, scientists are now needing to use
advanced machine learning and other AI technologies both to automate parts of
the data pipeline and also to help find new scientific discoveries in the
analysis of their data. For commercially important applications, such as object
recognition, natural language processing and automatic translation, deep
learning has made dramatic breakthroughs. Google's DeepMind has now also used
deep learning technology to develop their AlphaFold tool to make predictions
for protein folding. Remarkably, they have been able to achieve some
spectacular results for this specific scientific problem. Can deep learning be
similarly transformative for other scientific problems? After a brief review of
some initial applications of machine learning at the Rutherford Appleton
Laboratory, we focus on challenges and opportunities for AI in advancing
materials science. Finally, we discuss the importance of developing some
realistic machine learning benchmarks using Big Scientific Data coming from a
number of different scientific domains. We conclude with some initial examples
of our ""SciML"" benchmark suite and of the research challenges these benchmarks
will enable.
",2019-10-12T15:02:13Z,http://arxiv.org/abs/1910.07631v1,"Tony Hey, Keith Butler, Sam Jackson, Jeyarajan Thiyagalingam"
Sentiment Analysis Challenges in Persian Language,"  The rapid growth in data on the internet requires a data mining process to
reach a decision to support insight. The Persian language has strong potential
for deep research in any aspect of natural language processing, especially
sentimental analysis approach. Thousands of websites and blogs updates and
modifies by Persian users around the world that contains millions of Persian
context. This range of application requires a comprehensive structured
framework to extract beneficial information for helping enterprises to enhance
their business and initiate a customer-centric management process by producing
effective recommender systems. Sentimental analysis is an intelligent approach
for extracting useful information from huge amounts of data to help an
enterprise for smart management process. In this road, machine learning and
deep learning techniques will become very helpful but there is the number of
challenges which are face to them. This paper tried to present and assert the
most important challenges of sentimental analysis in the Persian language. This
language is an Indo-European language which spoken by over 110 million people
around the world and is an official language in Iran, Tajikistan, and
Afghanistan. Its also widely used in Uzbekistan, Pakistan and Turkish by order.
",2019-07-09T20:46:37Z,http://arxiv.org/abs/1907.04407v2,Mohammad Heydari
"SDW-ASL: A Dynamic System to Generate Large Scale Dataset for Continuous
  American Sign Language","  Despite tremendous progress in natural language processing using deep
learning techniques in recent years, sign language production and comprehension
has advanced very little. One critical barrier is the lack of largescale
datasets available to the public due to the unbearable cost of labeled data
generation. Efforts to provide public data for American Sign Language (ASL)
comprehension have yielded two datasets, comprising more than thousand video
clips. These datasets are large enough to enable a meaningful start to deep
learning research on sign languages but are far too small to lead to any
solution that can be practically deployed. So far, there is still no suitable
dataset for ASL production. We proposed a system that can generate large scale
ASL datasets for continuous ASL. It is suitable for general ASL processing and
is particularly useful for ASL production. The continuous ASL dataset contains
English labeled human articulations in condensed body pose data formats. To
better serve the research community, we are releasing the first version of our
ASL dataset, which contains 30k sentences, 416k words, a vocabulary of 18k
words, in a total of 104 hours. This is the largest continuous sign language
dataset published to date in terms of video duration. We also describe a system
that can evolve and expand the dataset to incorporate better data processing
techniques and more contents when available. It is our hope that the release of
this ASL dataset and the sustainable dataset generation system to the public
will propel better deep-learning research in ASL natural language processing.
",2022-10-13T07:08:00Z,http://arxiv.org/abs/2210.06791v1,Yehong Jiang
Engineering A Large Language Model From Scratch,"  The proliferation of deep learning in natural language processing (NLP) has
led to the development and release of innovative technologies capable of
understanding and generating human language with remarkable proficiency.
Atinuke, a Transformer-based neural network, optimises performance across
various language tasks by utilising a unique configuration. The architecture
interweaves layers for processing sequential data with attention mechanisms to
draw meaningful affinities between inputs and outputs. Due to the configuration
of its topology and hyperparameter tuning, it can emulate human-like language
by extracting features and learning complex mappings. Atinuke is modular,
extensible, and integrates seamlessly with existing machine learning pipelines.
Advanced matrix operations like softmax, embeddings, and multi-head attention
enable nuanced handling of textual, acoustic, and visual signals. By unifying
modern deep learning techniques with software design principles and
mathematical theory, the system achieves state-of-the-art results on natural
language tasks whilst remaining interpretable and robust.
",2024-01-30T04:29:48Z,http://arxiv.org/abs/2401.16736v3,Abiodun Finbarrs Oketunji
A Deep Learning Approach to Create DNS Amplification Attacks,"  In recent years, deep learning has shown itself to be an incredibly valuable
tool in cybersecurity as it helps network intrusion detection systems to
classify attacks and detect new ones. Adversarial learning is the process of
utilizing machine learning to generate a perturbed set of inputs to then feed
to the neural network to misclassify it. Much of the current work in the field
of adversarial learning has been conducted in image processing and natural
language processing with a wide variety of algorithms. Two algorithms of
interest are the Elastic-Net Attack on Deep Neural Networks and TextAttack. In
our experiment the EAD and TextAttack algorithms are applied to a Domain Name
System amplification classifier. The algorithms are used to generate malicious
Distributed Denial of Service adversarial examples to then feed as inputs to
the network intrusion detection systems neural network to classify as valid
traffic. We show in this work that both image processing and natural language
processing adversarial learning algorithms can be applied against a network
intrusion detection neural network.
",2022-06-29T01:11:48Z,http://arxiv.org/abs/2206.14346v1,"Jared Mathews, Prosenjit Chatterjee, Shankar Banik, Cory Nance"
"Comprehensive Implementation of TextCNN for Enhanced Collaboration
  between Natural Language Processing and System Recommendation","  Natural Language Processing (NLP) is an important branch of artificial
intelligence that studies how to enable computers to understand, process, and
generate human language. Text classification is a fundamental task in NLP,
which aims to classify text into different predefined categories. Text
classification is the most basic and classic task in natural language
processing, and most of the tasks in natural language processing can be
regarded as classification tasks. In recent years, deep learning has achieved
great success in many research fields, and today, it has also become a standard
technology in the field of NLP, which is widely integrated into text
classification tasks. Unlike numbers and images, text processing emphasizes
fine-grained processing ability. Traditional text classification methods
generally require preprocessing the input model's text data. Additionally, they
also need to obtain good sample features through manual annotation and then use
classical machine learning algorithms for classification. Therefore, this paper
analyzes the application status of deep learning in the three core tasks of NLP
(including text representation, word order modeling, and knowledge
representation). This content explores the improvement and synergy achieved
through natural language processing in the context of text classification,
while also taking into account the challenges posed by adversarial techniques
in text generation, text classification, and semantic parsing. An empirical
study on text classification tasks demonstrates the effectiveness of
interactive integration training, particularly in conjunction with TextCNN,
highlighting the significance of these advancements in text classification
augmentation and enhancement.
",2024-03-12T07:25:53Z,http://arxiv.org/abs/2403.09718v1,"Xiaonan Xu, Zheng Xu, Zhipeng Ling, Zhengyu Jin, ShuQian Du"
Quantifying Uncertainties in Natural Language Processing Tasks,"  Reliable uncertainty quantification is a first step towards building
explainable, transparent, and accountable artificial intelligent systems.
Recent progress in Bayesian deep learning has made such quantification
realizable. In this paper, we propose novel methods to study the benefits of
characterizing model and data uncertainties for natural language processing
(NLP) tasks. With empirical experiments on sentiment analysis, named entity
recognition, and language modeling using convolutional and recurrent neural
network models, we show that explicitly modeling uncertainties is not only
necessary to measure output confidence levels, but also useful at enhancing
model performances in various NLP tasks.
",2018-11-18T01:36:05Z,http://arxiv.org/abs/1811.07253v1,"Yijun Xiao, William Yang Wang"
Sentiment Analysis for Sinhala Language using Deep Learning Techniques,"  Due to the high impact of the fast-evolving fields of machine learning and
deep learning, Natural Language Processing (NLP) tasks have further obtained
comprehensive performances for highly resourced languages such as English and
Chinese. However Sinhala, which is an under-resourced language with a rich
morphology, has not experienced these advancements. For sentiment analysis,
there exists only two previous research with deep learning approaches, which
focused only on document-level sentiment analysis for the binary case. They
experimented with only three types of deep learning models. In contrast, this
paper presents a much comprehensive study on the use of standard sequence
models such as RNN, LSTM, Bi-LSTM, as well as more recent state-of-the-art
models such as hierarchical attention hybrid neural networks, and capsule
networks. Classification is done at document-level but with more granularity by
considering POSITIVE, NEGATIVE, NEUTRAL, and CONFLICT classes. A data set of
15059 Sinhala news comments, annotated with these four classes and a corpus
consists of 9.48 million tokens are publicly released. This is the largest
sentiment annotated data set for Sinhala so far.
",2020-11-14T12:02:30Z,http://arxiv.org/abs/2011.07280v1,"Lahiru Senevirathne, Piyumal Demotte, Binod Karunanayake, Udyogi Munasinghe, Surangika Ranathunga"
"Navigating the Kaleidoscope of COVID-19 Misinformation Using Deep
  Learning","  Irrespective of the success of the deep learning-based mixed-domain transfer
learning approach for solving various Natural Language Processing tasks, it
does not lend a generalizable solution for detecting misinformation from
COVID-19 social media data. Due to the inherent complexity of this type of
data, caused by its dynamic (context evolves rapidly), nuanced (misinformation
types are often ambiguous), and diverse (skewed, fine-grained, and overlapping
categories) nature, it is imperative for an effective model to capture both the
local and global context of the target domain. By conducting a systematic
investigation, we show that: (i) the deep Transformer-based pre-trained models,
utilized via the mixed-domain transfer learning, are only good at capturing the
local context, thus exhibits poor generalization, and (ii) a combination of
shallow network-based domain-specific models and convolutional neural networks
can efficiently extract local as well as global context directly from the
target data in a hierarchical fashion, enabling it to offer a more
generalizable solution.
",2021-09-19T15:49:25Z,http://arxiv.org/abs/2110.15703v1,"Yuanzhi Chen, Mohammad Rashedul Hasan"
Knowledge Efficient Deep Learning for Natural Language Processing,"  Deep learning has become the workhorse for a wide range of natural language
processing applications. But much of the success of deep learning relies on
annotated examples. Annotation is time-consuming and expensive to produce at
scale. Here we are interested in methods for reducing the required quantity of
annotated data -- by making the learning methods more knowledge efficient so as
to make them more applicable in low annotation (low resource) settings. There
are various classical approaches to making the models more knowledge efficient
such as multi-task learning, transfer learning, weakly supervised and
unsupervised learning etc. This thesis focuses on adapting such classical
methods to modern deep learning models and algorithms.
  This thesis describes four works aimed at making machine learning models more
knowledge efficient. First, we propose a knowledge rich deep learning model
(KRDL) as a unifying learning framework for incorporating prior knowledge into
deep models. In particular, we apply KRDL built on Markov logic networks to
denoise weak supervision. Second, we apply a KRDL model to assist the machine
reading models to find the correct evidence sentences that can support their
decision. Third, we investigate the knowledge transfer techniques in
multilingual setting, where we proposed a method that can improve pre-trained
multilingual BERT based on the bilingual dictionary. Fourth, we present an
episodic memory network for language modelling, in which we encode the large
external knowledge for the pre-trained GPT.
",2020-08-28T23:32:33Z,http://arxiv.org/abs/2008.12878v1,Hai Wang
"Hierarchical Representation in Neural Language Models: Suppression and
  Recovery of Expectations","  Deep learning sequence models have led to a marked increase in performance
for a range of Natural Language Processing tasks, but it remains an open
question whether they are able to induce proper hierarchical generalizations
for representing natural language from linear input alone. Work using
artificial languages as training input has shown that LSTMs are capable of
inducing the stack-like data structures required to represent context-free and
certain mildly context-sensitive languages---formal language classes which
correspond in theory to the hierarchical structures of natural language. Here
we present a suite of experiments probing whether neural language models
trained on linguistic data induce these stack-like data structures and deploy
them while incrementally predicting words. We study two natural language
phenomena: center embedding sentences and syntactic island constraints on the
filler--gap dependency. In order to properly predict words in these structures,
a model must be able to temporarily suppress certain expectations and then
recover those expectations later, essentially pushing and popping these
expectations on a stack. Our results provide evidence that models can
successfully suppress and recover expectations in many cases, but do not fully
recover their previous grammatical state.
",2019-06-10T15:20:32Z,http://arxiv.org/abs/1906.04068v1,"Ethan Wilcox, Roger Levy, Richard Futrell"
"Fast and Scalable Expansion of Natural Language Understanding
  Functionality for Intelligent Agents","  Fast expansion of natural language functionality of intelligent virtual
agents is critical for achieving engaging and informative interactions.
However, developing accurate models for new natural language domains is a time
and data intensive process. We propose efficient deep neural network
architectures that maximally re-use available resources through transfer
learning. Our methods are applied for expanding the understanding capabilities
of a popular commercial agent and are evaluated on hundreds of new domains,
designed by internal or external developers. We demonstrate that our proposed
methods significantly increase accuracy in low resource settings and enable
rapid development of accurate models with less data.
",2018-05-03T21:21:16Z,http://arxiv.org/abs/1805.01542v1,"Anuj Goyal, Angeliki Metallinou, Spyros Matsoukas"
"DeCLUTR: Deep Contrastive Learning for Unsupervised Textual
  Representations","  Sentence embeddings are an important component of many natural language
processing (NLP) systems. Like word embeddings, sentence embeddings are
typically learned on large text corpora and then transferred to various
downstream tasks, such as clustering and retrieval. Unlike word embeddings, the
highest performing solutions for learning sentence embeddings require labelled
data, limiting their usefulness to languages and domains where labelled data is
abundant. In this paper, we present DeCLUTR: Deep Contrastive Learning for
Unsupervised Textual Representations. Inspired by recent advances in deep
metric learning (DML), we carefully design a self-supervised objective for
learning universal sentence embeddings that does not require labelled training
data. When used to extend the pretraining of transformer-based language models,
our approach closes the performance gap between unsupervised and supervised
pretraining for universal sentence encoders. Importantly, our experiments
suggest that the quality of the learned embeddings scale with both the number
of trainable parameters and the amount of unlabelled training data. Our code
and pretrained models are publicly available and can be easily adapted to new
domains or used to embed unseen text.
",2020-06-05T20:00:28Z,http://arxiv.org/abs/2006.03659v4,"John Giorgi, Osvald Nitski, Bo Wang, Gary Bader"
Towards Explainable Fact Checking,"  The past decade has seen a substantial rise in the amount of mis- and
disinformation online, from targeted disinformation campaigns to influence
politics, to the unintentional spreading of misinformation about public health.
This development has spurred research in the area of automatic fact checking,
from approaches to detect check-worthy claims and determining the stance of
tweets towards claims, to methods to determine the veracity of claims given
evidence documents. These automatic methods are often content-based, using
natural language processing methods, which in turn utilise deep neural networks
to learn higher-order features from text in order to make predictions. As deep
neural networks are black-box models, their inner workings cannot be easily
explained. At the same time, it is desirable to explain how they arrive at
certain decisions, especially if they are to be used for decision making. While
this has been known for some time, the issues this raises have been exacerbated
by models increasing in size, and by EU legislation requiring models to be used
for decision making to provide explanations, and, very recently, by legislation
requiring online platforms operating in the EU to provide transparent reporting
on their services. Despite this, current solutions for explainability are still
lacking in the area of fact checking. This thesis presents my research on
automatic fact checking, including claim check-worthiness detection, stance
detection and veracity prediction. Its contributions go beyond fact checking,
with the thesis proposing more general machine learning solutions for natural
language processing in the area of learning with limited labelled data.
Finally, the thesis presents some first solutions for explainable fact
checking.
",2021-08-23T16:22:50Z,http://arxiv.org/abs/2108.10274v2,Isabelle Augenstein
Geometric deep learning on graphs and manifolds using mixture model CNNs,"  Deep learning has achieved a remarkable performance breakthrough in several
fields, most notably in speech recognition, natural language processing, and
computer vision. In particular, convolutional neural network (CNN)
architectures currently produce state-of-the-art performance on a variety of
image analysis tasks such as object detection and recognition. Most of deep
learning research has so far focused on dealing with 1D, 2D, or 3D
Euclidean-structured data such as acoustic signals, images, or videos.
Recently, there has been an increasing interest in geometric deep learning,
attempting to generalize deep learning methods to non-Euclidean structured data
such as graphs and manifolds, with a variety of applications from the domains
of network analysis, computational social science, or computer graphics. In
this paper, we propose a unified framework allowing to generalize CNN
architectures to non-Euclidean domains (graphs and manifolds) and learn local,
stationary, and compositional task-specific features. We show that various
non-Euclidean CNN methods previously proposed in the literature can be
considered as particular instances of our framework. We test the proposed
method on standard tasks from the realms of image-, graph- and 3D shape
analysis and show that it consistently outperforms previous approaches.
",2016-11-25T10:05:03Z,http://arxiv.org/abs/1611.08402v3,"Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodol√†, Jan Svoboda, Michael M. Bronstein"
"Unveiling the frontiers of deep learning: innovations shaping diverse
  domains","  Deep learning (DL) enables the development of computer models that are
capable of learning, visualizing, optimizing, refining, and predicting data. In
recent years, DL has been applied in a range of fields, including audio-visual
data processing, agriculture, transportation prediction, natural language,
biomedicine, disaster management, bioinformatics, drug design, genomics, face
recognition, and ecology. To explore the current state of deep learning, it is
necessary to investigate the latest developments and applications of deep
learning in these disciplines. However, the literature is lacking in exploring
the applications of deep learning in all potential sectors. This paper thus
extensively investigates the potential applications of deep learning across all
major fields of study as well as the associated benefits and challenges. As
evidenced in the literature, DL exhibits accuracy in prediction and analysis,
makes it a powerful computational tool, and has the ability to articulate
itself and optimize, making it effective in processing data with no prior
training. Given its independence from training data, deep learning necessitates
massive amounts of data for effective analysis and processing, much like data
volume. To handle the challenge of compiling huge amounts of medical,
scientific, healthcare, and environmental data for use in deep learning, gated
architectures like LSTMs and GRUs can be utilized. For multimodal learning,
shared neurons in the neural network for all activities and specialized neurons
for particular tasks are necessary.
",2023-09-06T04:50:39Z,http://arxiv.org/abs/2309.02712v1,"Shams Forruque Ahmed, Md. Sakib Bin Alam, Maliha Kabir, Shaila Afrin, Sabiha Jannat Rafa, Aanushka Mehjabin, Amir H. Gandomi"
Recent Trends in Deep Learning Based Natural Language Processing,"  Deep learning methods employ multiple processing layers to learn hierarchical
representations of data and have produced state-of-the-art results in many
domains. Recently, a variety of model designs and methods have blossomed in the
context of natural language processing (NLP). In this paper, we review
significant deep learning related models and methods that have been employed
for numerous NLP tasks and provide a walk-through of their evolution. We also
summarize, compare and contrast the various models and put forward a detailed
understanding of the past, present and future of deep learning in NLP.
",2017-08-09T04:02:17Z,http://arxiv.org/abs/1708.02709v8,"Tom Young, Devamanyu Hazarika, Soujanya Poria, Erik Cambria"
"Breaking the Curse of Dimensionality in Deep Neural Networks by Learning
  Invariant Representations","  Artificial intelligence, particularly the subfield of machine learning, has
seen a paradigm shift towards data-driven models that learn from and adapt to
data. This has resulted in unprecedented advancements in various domains such
as natural language processing and computer vision, largely attributed to deep
learning, a special class of machine learning models. Deep learning arguably
surpasses traditional approaches by learning the relevant features from raw
data through a series of computational layers.
  This thesis explores the theoretical foundations of deep learning by studying
the relationship between the architecture of these models and the inherent
structures found within the data they process. In particular, we ask What
drives the efficacy of deep learning algorithms and allows them to beat the
so-called curse of dimensionality-i.e. the difficulty of generally learning
functions in high dimensions due to the exponentially increasing need for data
points with increased dimensionality? Is it their ability to learn relevant
representations of the data by exploiting their structure? How do different
architectures exploit different data structures? In order to address these
questions, we push forward the idea that the structure of the data can be
effectively characterized by its invariances-i.e. aspects that are irrelevant
for the task at hand.
  Our methodology takes an empirical approach to deep learning, combining
experimental studies with physics-inspired toy models. These simplified models
allow us to investigate and interpret the complex behaviors we observe in deep
learning systems, offering insights into their inner workings, with the
far-reaching goal of bridging the gap between theory and practice.
",2023-10-24T19:50:41Z,http://arxiv.org/abs/2310.16154v1,Leonardo Petrini
Deep Learning-based Sentiment Analysis in Persian Language,"  Recently, there has been a growing interest in the use of deep learning
techniques for tasks in natural language processing (NLP), with sentiment
analysis being one of the most challenging areas, particularly in the Persian
language. The vast amounts of content generated by Persian users on thousands
of websites, blogs, and social networks such as Telegram, Instagram, and
Twitter present a rich resource of information. Deep learning techniques have
become increasingly favored for extracting insights from this extensive pool of
raw data, although they face several challenges. In this study, we introduced
and implemented a hybrid deep learning-based model for sentiment analysis,
using customer review data from the Digikala Online Retailer website. We
employed a variety of deep learning networks and regularization techniques as
classifiers. Ultimately, our hybrid approach yielded an impressive performance,
achieving an F1 score of 78.3 across three sentiment categories: positive,
negative, and neutral.
",2024-03-17T03:15:29Z,http://arxiv.org/abs/2403.11069v1,"Mohammad Heydari, Mohsen Khazeni, Mohammad Ali Soltanshahi"
"Optimized Three Deep Learning Models Based-PSO Hyperparameters for
  Beijing PM2.5 Prediction","  Deep learning is a machine learning approach that produces excellent
performance in various applications, including natural language processing,
image identification, and forecasting. Deep learning network performance
depends on the hyperparameter settings. This research attempts to optimize the
deep learning architecture of Long short term memory (LSTM), Convolutional
neural network (CNN), and Multilayer perceptron (MLP) for forecasting tasks
using Particle swarm optimization (PSO), a swarm intelligence-based
metaheuristic optimization methodology: Proposed M-1 (PSO-LSTM), M-2 (PSO-CNN),
and M-3 (PSO-MLP). Beijing PM2.5 datasets was analyzed to measure the
performance of the proposed models. PM2.5 as a target variable was affected by
dew point, pressure, temperature, cumulated wind speed, hours of snow, and
hours of rain. The deep learning network inputs consist of three different
scenarios: daily, weekly, and monthly. The results show that the proposed M-1
with three hidden layers produces the best results of RMSE and MAPE compared to
the proposed M-2, M-3, and all the baselines. A recommendation for air
pollution management could be generated by using these optimized models
",2023-06-10T16:06:44Z,http://arxiv.org/abs/2306.07296v1,"Andri Pranolo, Yingchi Mao, Aji Prasetya Wibawa, Agung Bella Putra Utama, Felix Andika Dwiyanto"
"Deep Learning in Proteomics Informatics: Applications, Challenges, and
  Future Directions","  Deep learning is an advanced technology that relies on large-scale data and
complex models for feature extraction and pattern recognition. It has been
widely applied across various fields, including computer vision, natural
language processing, and speech recognition. In recent years, deep learning has
demonstrated significant potential in the realm of proteomics informatics,
particularly in deciphering complex biological information. The introduction of
this technology not only accelerates the processing speed of protein data but
also enhances the accuracy of predictions regarding protein structure and
function. This provides robust support for both fundamental biology research
and applied biotechnological studies. Currently, deep learning is primarily
focused on applications such as protein sequence analysis, three-dimensional
structure prediction, functional annotation, and the construction of protein
interaction networks. These applications offer numerous advantages to proteomic
research. Despite its growing prevalence in this field, deep learning faces
several challenges including data scarcity, insufficient model
interpretability, and computational complexity; these factors hinder its
further advancement within proteomics. This paper comprehensively reviews the
applications of deep learning in proteomics along with the challenges it
encounters. The aim is to provide a systematic theoretical discussion and
practical basis for research in this domain to facilitate ongoing development
and innovation of deep learning technologies within proteomics.
",2024-12-23T07:21:27Z,http://arxiv.org/abs/2412.17349v1,"Yindan Luo, Jiaxin Cai"
Tamil Language Computing: the Present and the Future,"  This paper delves into the text processing aspects of Language Computing,
which enables computers to understand, interpret, and generate human language.
Focusing on tasks such as speech recognition, machine translation, sentiment
analysis, text summarization, and language modelling, language computing
integrates disciplines including linguistics, computer science, and cognitive
psychology to create meaningful human-computer interactions. Recent
advancements in deep learning have made computers more accessible and capable
of independent learning and adaptation. In examining the landscape of language
computing, the paper emphasises foundational work like encoding, where Tamil
transitioned from ASCII to Unicode, enhancing digital communication. It
discusses the development of computational resources, including raw data,
dictionaries, glossaries, annotated data, and computational grammars, necessary
for effective language processing. The challenges of linguistic annotation, the
creation of treebanks, and the training of large language models are also
covered, emphasising the need for high-quality, annotated data and advanced
language models. The paper underscores the importance of building practical
applications for languages like Tamil to address everyday communication needs,
highlighting gaps in current technology. It calls for increased research
collaboration, digitization of historical texts, and fostering digital usage to
ensure the comprehensive development of Tamil language processing, ultimately
enhancing global communication and access to digital services.
",2024-07-11T15:56:02Z,http://arxiv.org/abs/2407.08618v2,Kengatharaiyer Sarveswaran
A Survey on State-of-the-art Deep Learning Applications and Challenges,"  Deep learning, a branch of artificial intelligence, is a data-driven method
that uses multiple layers of interconnected units (neurons) to learn intricate
patterns and representations directly from raw input data. Empowered by this
learning capability, it has become a powerful tool for solving complex problems
and is the core driver of many groundbreaking technologies and innovations.
Building a deep learning model is challenging due to the algorithm's complexity
and the dynamic nature of real-world problems. Several studies have reviewed
deep learning concepts and applications. However, the studies mostly focused on
the types of deep learning models and convolutional neural network
architectures, offering limited coverage of the state-of-the-art deep learning
models and their applications in solving complex problems across different
domains. Therefore, motivated by the limitations, this study aims to
comprehensively review the state-of-the-art deep learning models in computer
vision, natural language processing, time series analysis and pervasive
computing. We highlight the key features of the models and their effectiveness
in solving the problems within each domain. Furthermore, this study presents
the fundamentals of deep learning, various deep learning model types and
prominent convolutional neural network architectures. Finally, challenges and
future directions in deep learning research are discussed to offer a broader
perspective for future researchers.
",2024-03-26T10:10:53Z,http://arxiv.org/abs/2403.17561v5,"Mohd Halim Mohd Noor, Ayokunle Olalekan Ige"
Semantic Labeling Using a Deep Contextualized Language Model,"  Generating schema labels automatically for column values of data tables has
many data science applications such as schema matching, and data discovery and
linking. For example, automatically extracted tables with missing headers can
be filled by the predicted schema labels which significantly minimizes human
effort. Furthermore, the predicted labels can reduce the impact of inconsistent
names across multiple data tables. Understanding the connection between column
values and contextual information is an important yet neglected aspect as
previously proposed methods treat each column independently. In this paper, we
propose a context-aware semantic labeling method using both the column values
and context. Our new method is based on a new setting for semantic labeling,
where we sequentially predict labels for an input table with missing headers.
We incorporate both the values and context of each data column using the
pre-trained contextualized language model, BERT, that has achieved significant
improvements in multiple natural language processing tasks. To our knowledge,
we are the first to successfully apply BERT to solve the semantic labeling
task. We evaluate our approach using two real-world datasets from different
domains, and we demonstrate substantial improvements in terms of evaluation
metrics over state-of-the-art feature-based methods.
",2020-10-30T03:04:22Z,http://arxiv.org/abs/2010.16037v1,"Mohamed Trabelsi, Jin Cao, Jeff Heflin"
"HealthPrompt: A Zero-shot Learning Paradigm for Clinical Natural
  Language Processing","  Deep learning algorithms are dependent on the availability of large-scale
annotated clinical text datasets. The lack of such publicly available datasets
is the biggest bottleneck for the development of clinical Natural Language
Processing(NLP) systems. Zero-Shot Learning(ZSL) refers to the use of deep
learning models to classify instances from new classes of which no training
data have been seen before. Prompt-based learning is an emerging ZSL technique
where we define task-based templates for NLP tasks. We developed a novel
prompt-based clinical NLP framework called HealthPrompt and applied the
paradigm of prompt-based learning on clinical texts. In this technique, rather
than fine-tuning a Pre-trained Language Model(PLM), the task definitions are
tuned by defining a prompt template. We performed an in-depth analysis of
HealthPrompt on six different PLMs in a no-data setting. Our experiments prove
that prompts effectively capture the context of clinical texts and perform
remarkably well without any training data.
",2022-03-09T21:44:28Z,http://arxiv.org/abs/2203.05061v1,"Sonish Sivarajkumar, Yanshan Wang"
Text classification dataset and analysis for Uzbek language,"  Text classification is an important task in Natural Language Processing
(NLP), where the goal is to categorize text data into predefined classes. In
this study, we analyse the dataset creation steps and evaluation techniques of
multi-label news categorisation task as part of text classification. We first
present a newly obtained dataset for Uzbek text classification, which was
collected from 10 different news and press websites and covers 15 categories of
news, press and law texts. We also present a comprehensive evaluation of
different models, ranging from traditional bag-of-words models to deep learning
architectures, on this newly created dataset. Our experiments show that the
Recurrent Neural Network (RNN) and Convolutional Neural Network (CNN) based
models outperform the rule-based models. The best performance is achieved by
the BERTbek model, which is a transformer-based BERT model trained on the Uzbek
corpus. Our findings provide a good baseline for further research in Uzbek text
classification.
",2023-02-28T11:21:24Z,http://arxiv.org/abs/2302.14494v1,"Elmurod Kuriyozov, Ulugbek Salaev, Sanatbek Matlatipov, Gayrat Matlatipov"
"ArNLI: Arabic Natural Language Inference for Entailment and
  Contradiction Detection","  Natural Language Inference (NLI) is a hot topic research in natural language
processing, contradiction detection between sentences is a special case of NLI.
This is considered a difficult NLP task which has a big influence when added as
a component in many NLP applications, such as Question Answering Systems, text
Summarization. Arabic Language is one of the most challenging low-resources
languages in detecting contradictions due to its rich lexical, semantics
ambiguity. We have created a data set of more than 12k sentences and named
ArNLI, that will be publicly available. Moreover, we have applied a new model
inspired by Stanford contradiction detection proposed solutions on English
language. We proposed an approach to detect contradictions between pairs of
sentences in Arabic language using contradiction vector combined with language
model vector as an input to machine learning model. We analyzed results of
different traditional machine learning classifiers and compared their results
on our created data set (ArNLI) and on an automatic translation of both PHEME,
SICK English data sets. Best results achieved using Random Forest classifier
with an accuracy of 99%, 60%, 75% on PHEME, SICK and ArNLI respectively.
",2022-09-28T09:37:16Z,http://arxiv.org/abs/2209.13953v1,"Khloud Al Jallad, Nada Ghneim"
"Data Science Kitchen at GermEval 2021: A Fine Selection of Hand-Picked
  Features, Delivered Fresh from the Oven","  This paper presents the contribution of the Data Science Kitchen at GermEval
2021 shared task on the identification of toxic, engaging, and fact-claiming
comments. The task aims at extending the identification of offensive language,
by including additional subtasks that identify comments which should be
prioritized for fact-checking by moderators and community managers. Our
contribution focuses on a feature-engineering approach with a conventional
classification backend. We combine semantic and writing style embeddings
derived from pre-trained deep neural networks with additional numerical
features, specifically designed for this task. Classifier ensembles are used to
derive predictions for each subtask via a majority voting scheme. Our best
submission achieved macro-averaged F1-scores of 66.8\%,\,69.9\% and 72.5\% for
the identification of toxic, engaging, and fact-claiming comments.
",2021-09-06T12:00:29Z,http://arxiv.org/abs/2109.02383v2,"Niclas Hildebrandt, Benedikt Boenninghoff, Dennis Orth, Christopher Schymura"
"Learning beyond datasets: Knowledge Graph Augmented Neural Networks for
  Natural language Processing","  Machine Learning has been the quintessential solution for many AI problems,
but learning is still heavily dependent on the specific training data. Some
learning models can be incorporated with a prior knowledge in the Bayesian set
up, but these learning models do not have the ability to access any organised
world knowledge on demand. In this work, we propose to enhance learning models
with world knowledge in the form of Knowledge Graph (KG) fact triples for
Natural Language Processing (NLP) tasks. Our aim is to develop a deep learning
model that can extract relevant prior support facts from knowledge graphs
depending on the task using attention mechanism. We introduce a
convolution-based model for learning representations of knowledge graph entity
and relation clusters in order to reduce the attention space. We show that the
proposed method is highly scalable to the amount of prior information that has
to be processed and can be applied to any generic NLP task. Using this method
we show significant improvement in performance for text classification with
News20, DBPedia datasets and natural language inference with Stanford Natural
Language Inference (SNLI) dataset. We also demonstrate that a deep learning
model can be trained well with substantially less amount of labeled training
data, when it has access to organised world knowledge in the form of knowledge
graph.
",2018-02-16T13:38:00Z,http://arxiv.org/abs/1802.05930v2,"K M Annervaz, Somnath Basu Roy Chowdhury, Ambedkar Dukkipati"
"Review and Prospect: Deep Learning in Nuclear Magnetic Resonance
  Spectroscopy","  Since the concept of Deep Learning (DL) was formally proposed in 2006, it had
a major impact on academic research and industry. Nowadays, DL provides an
unprecedented way to analyze and process data with demonstrated great results
in computer vision, medical imaging, natural language processing, etc. In this
Minireview, we summarize applications of DL in Nuclear Magnetic Resonance (NMR)
spectroscopy and outline a perspective for DL as entirely new approaches that
are likely to transform NMR spectroscopy into a much more efficient and
powerful technique in chemistry and life science.
",2020-01-13T05:13:20Z,http://arxiv.org/abs/2001.04813v2,"Dicheng Chen, Zi Wang, Di Guo, Vladislav Orekhov, Xiaobo Qu"
"Deep Bayesian Active Learning for Natural Language Processing: Results
  of a Large-Scale Empirical Study","  Several recent papers investigate Active Learning (AL) for mitigating the
data dependence of deep learning for natural language processing. However, the
applicability of AL to real-world problems remains an open question. While in
supervised learning, practitioners can try many different methods, evaluating
each against a validation set before selecting a model, AL affords no such
luxury. Over the course of one AL run, an agent annotates its dataset
exhausting its labeling budget. Thus, given a new task, an active learner has
no opportunity to compare models and acquisition functions. This paper provides
a large scale empirical study of deep active learning, addressing multiple
tasks and, for each, multiple datasets, multiple models, and a full suite of
acquisition functions. We find that across all settings, Bayesian active
learning by disagreement, using uncertainty estimates provided either by
Dropout or Bayes-by Backprop significantly improves over i.i.d. baselines and
usually outperforms classic uncertainty sampling.
",2018-08-16T22:46:40Z,http://arxiv.org/abs/1808.05697v3,"Aditya Siddhant, Zachary C. Lipton"
Generalization Error in Deep Learning,"  Deep learning models have lately shown great performance in various fields
such as computer vision, speech recognition, speech translation, and natural
language processing. However, alongside their state-of-the-art performance, it
is still generally unclear what is the source of their generalization ability.
Thus, an important question is what makes deep neural networks able to
generalize well from the training set to new data. In this article, we provide
an overview of the existing theory and bounds for the characterization of the
generalization error of deep neural networks, combining both classical and more
recent theoretical and empirical results.
",2018-08-03T12:57:12Z,http://arxiv.org/abs/1808.01174v3,"Daniel Jakubovitz, Raja Giryes, Miguel R. D. Rodrigues"
"An exact mapping between the Variational Renormalization Group and Deep
  Learning","  Deep learning is a broad set of techniques that uses multiple layers of
representation to automatically learn relevant features directly from
structured data. Recently, such techniques have yielded record-breaking results
on a diverse set of difficult machine learning tasks in computer vision, speech
recognition, and natural language processing. Despite the enormous success of
deep learning, relatively little is understood theoretically about why these
techniques are so successful at feature learning and compression. Here, we show
that deep learning is intimately related to one of the most important and
successful techniques in theoretical physics, the renormalization group (RG).
RG is an iterative coarse-graining scheme that allows for the extraction of
relevant features (i.e. operators) as a physical system is examined at
different length scales. We construct an exact mapping from the variational
renormalization group, first introduced by Kadanoff, and deep learning
architectures based on Restricted Boltzmann Machines (RBMs). We illustrate
these ideas using the nearest-neighbor Ising Model in one and two-dimensions.
Our results suggests that deep learning algorithms may be employing a
generalized RG-like scheme to learn relevant features from data.
",2014-10-14T20:00:09Z,http://arxiv.org/abs/1410.3831v1,"Pankaj Mehta, David J. Schwab"
"Attention versus Contrastive Learning of Tabular Data -- A Data-centric
  Benchmarking","  Despite groundbreaking success in image and text learning, deep learning has
not achieved significant improvements against traditional machine learning (ML)
when it comes to tabular data. This performance gap underscores the need for
data-centric treatment and benchmarking of learning algorithms. Recently,
attention and contrastive learning breakthroughs have shifted computer vision
and natural language processing paradigms. However, the effectiveness of these
advanced deep models on tabular data is sparsely studied using a few data sets
with very large sample sizes, reporting mixed findings after benchmarking
against a limited number of baselines. We argue that the heterogeneity of
tabular data sets and selective baselines in the literature can bias the
benchmarking outcomes. This article extensively evaluates state-of-the-art
attention and contrastive learning methods on a wide selection of 28 tabular
data sets (14 easy and 14 hard-to-classify) against traditional deep and
machine learning. Our data-centric benchmarking demonstrates when traditional
ML is preferred over deep learning and vice versa because no best learning
method exists for all tabular data sets. Combining between-sample and
between-feature attentions conquers the invincible traditional ML on tabular
data sets by a significant margin but fails on high dimensional data, where
contrastive learning takes a robust lead. While a hybrid attention-contrastive
learning strategy mostly wins on hard-to-classify data sets, traditional
methods are frequently superior on easy-to-classify data sets with presumably
simpler decision boundaries. To the best of our knowledge, this is the first
benchmarking paper with statistical analyses of attention and contrastive
learning performances on a diverse selection of tabular data sets against
traditional deep and machine learning baselines to facilitate further advances
in this field.
",2024-01-08T22:36:05Z,http://arxiv.org/abs/2401.04266v1,"Shourav B. Rabbani, Ivan V. Medri, Manar D. Samad"
Deep Natural Language Processing for LinkedIn Search Systems,"  Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles and documents, where deep learning based natural
language processing techniques (deep NLP) can be of great help. In this paper,
we introduce a comprehensive study of applying deep NLP techniques to five
representative tasks in search engines. Through the model design and
experiments of the five tasks, readers can find answers to three important
questions: (1) When is deep NLP helpful/not helpful in search systems? (2) How
to address latency challenges? (3) How to ensure model robustness? This work
builds on existing efforts of LinkedIn search, and is tested at scale on a
commercial search engine. We believe our experiences can provide useful
insights for the industry and research communities.
",2021-07-30T17:40:36Z,http://arxiv.org/abs/2108.08252v1,"Weiwei Guo, Xiaowei Liu, Sida Wang, Michaeel Kazi, Zhoutong Fu, Huiji Gao, Jun Jia, Liang Zhang, Bo Long"
Contextual Text Denoising with Masked Language Models,"  Recently, with the help of deep learning models, significant advances have
been made in different Natural Language Processing (NLP) tasks. Unfortunately,
state-of-the-art models are vulnerable to noisy texts. We propose a new
contextual text denoising algorithm based on the ready-to-use masked language
model. The proposed algorithm does not require retraining of the model and can
be integrated into any NLP system without additional training on paired
cleaning training data. We evaluate our method under synthetic noise and
natural noise and show that the proposed algorithm can use context information
to correct noise text and improve the performance of noisy inputs in several
downstream tasks.
",2019-10-30T18:47:37Z,http://arxiv.org/abs/1910.14080v2,"Yifu Sun, Haoming Jiang"
"BERT: A Review of Applications in Natural Language Processing and
  Understanding","  In this review, we describe the application of one of the most popular deep
learning-based language models - BERT. The paper describes the mechanism of
operation of this model, the main areas of its application to the tasks of text
analytics, comparisons with similar models in each task, as well as a
description of some proprietary models. In preparing this review, the data of
several dozen original scientific articles published over the past few years,
which attracted the most attention in the scientific community, were
systematized. This survey will be useful to all students and researchers who
want to get acquainted with the latest advances in the field of natural
language text analysis.
",2021-03-22T15:34:39Z,http://arxiv.org/abs/2103.11943v1,M. V. Koroteev
Deep learning systems as complex networks,"  Thanks to the availability of large scale digital datasets and massive
amounts of computational power, deep learning algorithms can learn
representations of data by exploiting multiple levels of abstraction. These
machine learning methods have greatly improved the state-of-the-art in many
challenging cognitive tasks, such as visual object recognition, speech
processing, natural language understanding and automatic translation. In
particular, one class of deep learning models, known as deep belief networks,
can discover intricate statistical structure in large data sets in a completely
unsupervised fashion, by learning a generative model of the data using
Hebbian-like learning mechanisms. Although these self-organizing systems can be
conveniently formalized within the framework of statistical mechanics, their
internal functioning remains opaque, because their emergent dynamics cannot be
solved analytically. In this article we propose to study deep belief networks
using techniques commonly employed in the study of complex networks, in order
to gain some insights into the structural and functional properties of the
computational graph resulting from the learning process.
",2018-09-28T10:06:36Z,http://arxiv.org/abs/1809.10941v1,"Alberto Testolin, Michele Piccolini, Samir Suweis"
"A Hybrid Approach to Dependency Parsing: Combining Rules and Morphology
  with Deep Learning","  Fully data-driven, deep learning-based models are usually designed as
language-independent and have been shown to be successful for many natural
language processing tasks. However, when the studied language is low-resourced
and the amount of training data is insufficient, these models can benefit from
the integration of natural language grammar-based information. We propose two
approaches to dependency parsing especially for languages with restricted
amount of training data. Our first approach combines a state-of-the-art deep
learning-based parser with a rule-based approach and the second one
incorporates morphological information into the parser. In the rule-based
approach, the parsing decisions made by the rules are encoded and concatenated
with the vector representations of the input words as additional information to
the deep network. The morphology-based approach proposes different methods to
include the morphological structure of words into the parser network.
Experiments are conducted on the IMST-UD Treebank and the results suggest that
integration of explicit knowledge about the target language to a neural parser
through a rule-based parsing system and morphological analysis leads to more
accurate annotations and hence, increases the parsing performance in terms of
attachment scores. The proposed methods are developed for Turkish, but can be
adapted to other languages as well.
",2020-02-24T08:34:33Z,http://arxiv.org/abs/2002.10116v1,"≈ûaziye Bet√ºl √ñzate≈ü, Arzucan √ñzg√ºr, Tunga G√ºng√∂r, Balkƒ±z √ñzt√ºrk"
"Exploring transfer learning for Deep NLP systems on rarely annotated
  languages","  Natural language processing (NLP) has experienced rapid advancements with the
rise of deep learning, significantly outperforming traditional rule-based
methods. By capturing hidden patterns and underlying structures within data,
deep learning has improved performance across various NLP tasks, overcoming the
limitations of rule-based systems. However, most research and development in
NLP has been concentrated on a select few languages, primarily those with large
numbers of speakers or financial significance, leaving many others
underexplored. This lack of research is often attributed to the scarcity of
adequately annotated datasets essential for training deep learning models.
Despite this challenge, there is potential in leveraging the linguistic
similarities between unexplored and well-studied languages, particularly those
in close geographic and linguistic proximity. This thesis investigates the
application of transfer learning for Part-of-Speech (POS) tagging between Hindi
and Nepali, two highly similar languages belonging to the Indo-Aryan language
family. Specifically, the work explores whether joint training of a POS tagging
model for both languages enhances performance. Additionally, we assess whether
multitask learning in Hindi, with auxiliary tasks such as gender and
singular/plural tagging, can contribute to improved POS tagging accuracy. The
deep learning architecture employed is the BLSTM-CNN-CRF model, trained under
different conditions: monolingual word embeddings, vector-mapped embeddings,
and jointly trained Hindi-Nepali word embeddings. Varying dropout rates (0.25
to 0.5) and optimizers (ADAM and AdaDelta) are also evaluated. Results indicate
that jointly trained Hindi-Nepali word embeddings improve performance across
all models compared to monolingual and vector-mapped embeddings.
",2024-10-15T13:33:54Z,http://arxiv.org/abs/2410.12879v1,"Dipendra Yadav, Tobias Strau√ü, Kristina Yordanova"
"SBNet: Segmentation-based Network for Natural Language-based Vehicle
  Search","  Natural language-based vehicle retrieval is a task to find a target vehicle
within a given image based on a natural language description as a query. This
technology can be applied to various areas including police searching for a
suspect vehicle. However, it is challenging due to the ambiguity of language
descriptions and the difficulty of processing multi-modal data. To tackle this
problem, we propose a deep neural network called SBNet that performs natural
language-based segmentation for vehicle retrieval. We also propose two
task-specific modules to improve performance: a substitution module that helps
features from different domains to be embedded in the same space and a future
prediction module that learns temporal information. SBnet has been trained
using the CityFlow-NL dataset that contains 2,498 tracks of vehicles with three
unique natural language descriptions each and tested 530 unique vehicle tracks
and their corresponding query sets. SBNet achieved a significant improvement
over the baseline in the natural language-based vehicle tracking track in the
AI City Challenge 2021.
",2021-04-22T08:06:17Z,http://arxiv.org/abs/2104.11589v1,"Sangrok Lee, Taekang Woo, Sang Hun Lee"
"Lifelong Learning Natural Language Processing Approach for Multilingual
  Data Classification","  The abundance of information in digital media, which in today's world is the
main source of knowledge about current events for the masses, makes it possible
to spread disinformation on a larger scale than ever before. Consequently,
there is a need to develop novel fake news detection approaches capable of
adapting to changing factual contexts and generalizing previously or
concurrently acquired knowledge. To deal with this problem, we propose a
lifelong learning-inspired approach, which allows for fake news detection in
multiple languages and the mutual transfer of knowledge acquired in each of
them. Both classical feature extractors, such as Term frequency-inverse
document frequency or Latent Dirichlet Allocation, and integrated deep NLP
(Natural Language Processing) BERT (Bidirectional Encoder Representations from
Transformers) models paired with MLP (Multilayer Perceptron) classifier, were
employed. The results of experiments conducted on two datasets dedicated to the
fake news classification task (in English and Spanish, respectively), supported
by statistical analysis, confirmed that utilization of additional languages
could improve performance for traditional methods. Also, in some cases
supplementing the deep learning method with classical ones can positively
impact obtained results. The ability of models to generalize the knowledge
acquired between the analyzed languages was also observed.
",2022-05-25T10:34:04Z,http://arxiv.org/abs/2206.11867v1,"Jƒôdrzej Kozal, Micha≈Ç Le≈õ, Pawe≈Ç Zyblewski, Pawe≈Ç Ksieniewicz, Micha≈Ç Wo≈∫niak"
Review of Text Style Transfer Based on Deep Learning,"  Text style transfer is a hot issue in recent natural language
processing,which mainly studies the text to adapt to different specific
situations, audiences and purposes by making some changes. The style of the
text usually includes many aspects such as morphology, grammar, emotion,
complexity, fluency, tense, tone and so on. In the traditional text style
transfer model, the text style is generally relied on by experts knowledge and
hand-designed rules, but with the application of deep learning in the field of
natural language processing, the text style transfer method based on deep
learning Started to be heavily researched. In recent years, text style transfer
is becoming a hot issue in natural language processing research. This article
summarizes the research on the text style transfer model based on deep learning
in recent years, and summarizes, analyzes and compares the main research
directions and progress. In addition, the article also introduces public data
sets and evaluation indicators commonly used for text style transfer. Finally,
the existing characteristics of the text style transfer model are summarized,
and the future development trend of the text style transfer model based on deep
learning is analyzed and forecasted.
",2020-05-06T15:35:53Z,http://arxiv.org/abs/2005.02914v3,"Xiangyang Li, Guo Pu, Keyu Ming, Pu Li, Jie Wang, Yuxuan Wang"
"Explaining the Deep Natural Language Processing by Mining Textual
  Interpretable Features","  Despite the high accuracy offered by state-of-the-art deep natural-language
models (e.g. LSTM, BERT), their application in real-life settings is still
widely limited, as they behave like a black-box to the end-user. Hence,
explainability is rapidly becoming a fundamental requirement of
future-generation data-driven systems based on deep-learning approaches.
Several attempts to fulfill the existing gap between accuracy and
interpretability have been done. However, robust and specialized xAI
(Explainable Artificial Intelligence) solutions tailored to deep
natural-language models are still missing. We propose a new framework, named
T-EBAnO, which provides innovative prediction-local and class-based
model-global explanation strategies tailored to black-box deep natural-language
models. Given a deep NLP model and the textual input data, T-EBAnO provides an
objective, human-readable, domain-specific assessment of the reasons behind the
automatic decision-making process. Specifically, the framework extracts sets of
interpretable features mining the inner knowledge of the model. Then, it
quantifies the influence of each feature during the prediction process by
exploiting the novel normalized Perturbation Influence Relation index at the
local level and the novel Global Absolute Influence and Global Relative
Influence indexes at the global level. The effectiveness and the quality of the
local and global explanations obtained with T-EBAnO are proved on (i) a
sentiment analysis task performed by a fine-tuned BERT model, and (ii) a toxic
comment classification task performed by an LSTM model.
",2021-06-12T06:25:09Z,http://arxiv.org/abs/2106.06697v1,"Francesco Ventura, Salvatore Greco, Daniele Apiletti, Tania Cerquitelli"
A Combined CNN and LSTM Model for Arabic Sentiment Analysis,"  Deep neural networks have shown good data modelling capabilities when dealing
with challenging and large datasets from a wide range of application areas.
Convolutional Neural Networks (CNNs) offer advantages in selecting good
features and Long Short-Term Memory (LSTM) networks have proven good abilities
of learning sequential data. Both approaches have been reported to provide
improved results in areas such image processing, voice recognition, language
translation and other Natural Language Processing (NLP) tasks. Sentiment
classification for short text messages from Twitter is a challenging task, and
the complexity increases for Arabic language sentiment classification tasks
because Arabic is a rich language in morphology. In addition, the availability
of accurate pre-processing tools for Arabic is another current limitation,
along with limited research available in this area. In this paper, we
investigate the benefits of integrating CNNs and LSTMs and report obtained
improved accuracy for Arabic sentiment analysis on different datasets.
Additionally, we seek to consider the morphological diversity of particular
Arabic words by using different sentiment classification levels.
",2018-07-09T01:41:20Z,http://arxiv.org/abs/1807.02911v3,"Abdulaziz M. Alayba, Vasile Palade, Matthew England, Rahat Iqbal"
A Deep Learning Approach to Analyzing Continuous-Time Systems,"  Scientists often use observational time series data to study complex natural
processes, but regression analyses often assume simplistic dynamics. Recent
advances in deep learning have yielded startling improvements to the
performance of models of complex processes, but deep learning is generally not
used for scientific analysis. Here we show that deep learning can be used to
analyze complex processes, providing flexible function approximation while
preserving interpretability. Our approach relaxes standard simplifying
assumptions (e.g., linearity, stationarity, and homoscedasticity) that are
implausible for many natural systems and may critically affect the
interpretation of data. We evaluate our model on incremental human language
processing, a domain with complex continuous dynamics. We demonstrate
substantial improvements on behavioral and neuroimaging data, and we show that
our model enables discovery of novel patterns in exploratory analyses, controls
for diverse confounds in confirmatory analyses, and opens up research questions
that are otherwise hard to study.
",2022-09-25T03:02:31Z,http://arxiv.org/abs/2209.12128v2,"Cory Shain, William Schuler"
Urdu Poetry Generated by Using Deep Learning Techniques,"  This study provides Urdu poetry generated using different deep-learning
techniques and algorithms. The data was collected through the Rekhta website,
containing 1341 text files with several couplets. The data on poetry was not
from any specific genre or poet. Instead, it was a collection of mixed Urdu
poems and Ghazals. Different deep learning techniques, such as the model
applied Long Short-term Memory Networks (LSTM) and Gated Recurrent Unit (GRU),
have been used. Natural Language Processing (NLP) may be used in machine
learning to understand, analyze, and generate a language humans may use and
understand. Much work has been done on generating poetry for different
languages using different techniques. The collection and use of data were also
different for different researchers. The primary purpose of this project is to
provide a model that generates Urdu poems by using data completely, not by
sampling data. Also, this may generate poems in pure Urdu, not Roman Urdu, as
in the base paper. The results have shown good accuracy in the poems generated
by the model.
",2023-09-25T15:44:24Z,http://arxiv.org/abs/2309.14233v1,"Muhammad Shoaib Farooq, Ali Abbas"
"Research on color recipe recommendation based on unstructured data using
  TENN","  Recently, services and business models based on large language models, such
as OpenAI Chatgpt, Google BARD, and Microsoft copilot, have been introduced,
and the applications utilizing natural language processing with deep learning
are increasing, and it is one of the natural language preprocessing methods.
Conversion to machine language through tokenization and processing of
unstructured data are increasing. Although algorithms that can understand and
apply human language are becoming increasingly sophisticated, it is difficult
to apply them to processes that rely on human emotions and senses in industries
that still mainly deal with standardized data. In particular, in processes
where brightness, saturation, and color information are essential, such as
painting and injection molding, most small and medium-sized companies,
excluding large corporations, rely on the tacit knowledge and sensibility of
color mixers, and even customer companies often present non-standardized
requirements. . In this paper, we proposed TENN to infer color recipe based on
unstructured data with emotional natural language, and demonstrated it.
",2024-08-17T04:45:48Z,http://arxiv.org/abs/2408.09094v1,"Seongsu Jhang, Donghwi Yoo, Jaeyong Kown"
"A Survey on Recent Approaches for Natural Language Processing in
  Low-Resource Scenarios","  Deep neural networks and huge language models are becoming omnipresent in
natural language applications. As they are known for requiring large amounts of
training data, there is a growing body of work to improve the performance in
low-resource settings. Motivated by the recent fundamental changes towards
neural models and the popular pre-train and fine-tune paradigm, we survey
promising approaches for low-resource natural language processing. After a
discussion about the different dimensions of data availability, we give a
structured overview of methods that enable learning when training data is
sparse. This includes mechanisms to create additional labeled data like data
augmentation and distant supervision as well as transfer learning settings that
reduce the need for target supervision. A goal of our survey is to explain how
these methods differ in their requirements as understanding them is essential
for choosing a technique suited for a specific low-resource setting. Further
key aspects of this work are to highlight open issues and to outline promising
directions for future research.
",2020-10-23T11:22:01Z,http://arxiv.org/abs/2010.12309v3,"Michael A. Hedderich, Lukas Lange, Heike Adel, Jannik Str√∂tgen, Dietrich Klakow"
A Survey of Deep Learning for Mathematical Reasoning,"  Mathematical reasoning is a fundamental aspect of human intelligence and is
applicable in various fields, including science, engineering, finance, and
everyday life. The development of artificial intelligence (AI) systems capable
of solving math problems and proving theorems has garnered significant interest
in the fields of machine learning and natural language processing. For example,
mathematics serves as a testbed for aspects of reasoning that are challenging
for powerful deep learning models, driving new algorithmic and modeling
advances. On the other hand, recent advances in large-scale neural language
models have opened up new benchmarks and opportunities to use deep learning for
mathematical reasoning. In this survey paper, we review the key tasks,
datasets, and methods at the intersection of mathematical reasoning and deep
learning over the past decade. We also evaluate existing benchmarks and
methods, and discuss future research directions in this domain.
",2022-12-20T18:46:16Z,http://arxiv.org/abs/2212.10535v2,"Pan Lu, Liang Qiu, Wenhao Yu, Sean Welleck, Kai-Wei Chang"
Macromolecule Classification Based on the Amino-acid Sequence,"  Deep learning is playing a vital role in every field which involves data. It
has emerged as a strong and efficient framework that can be applied to a broad
spectrum of complex learning problems which were difficult to solve using
traditional machine learning techniques in the past. In this study we focused
on classification of protein sequences with deep learning techniques. The study
of amino acid sequence is vital in life sciences. We used different word
embedding techniques from Natural Language processing to represent the amino
acid sequence as vectors. Our main goal was to classify sequences to four group
of classes, that are DNA, RNA, Protein and hybrid. After several tests we have
achieved almost 99% of train and test accuracy. We have experimented on CNN,
LSTM, Bidirectional LSTM, and GRU.
",2020-01-06T08:33:50Z,http://arxiv.org/abs/2001.01717v2,"Faisal Ghaffar, Sarwar Khan, Gaddisa O., Chen Yu-jhen"
Sketch-based Creativity Support Tools using Deep Learning,"  Sketching is a natural and effective visual communication medium commonly
used in creative processes. Recent developments in deep-learning models
drastically improved machines' ability in understanding and generating visual
content. An exciting area of development explores deep-learning approaches used
to model human sketches, opening opportunities for creative applications. This
chapter describes three fundamental steps in developing deep-learning-driven
creativity support tools that consumes and generates sketches: 1) a data
collection effort that generated a new paired dataset between sketches and
mobile user interfaces; 2) a sketch-based user interface retrieval system
adapted from state-of-the-art computer vision techniques; and, 3) a
conversational sketching system that supports the novel interaction of a
natural-language-based sketch/critique authoring process. In this chapter, we
survey relevant prior work in both the deep-learning and
human-computer-interaction communities, document the data collection process
and the systems' architectures in detail, present qualitative and quantitative
results, and paint the landscape of several future research directions in this
exciting area.
",2021-11-19T00:57:43Z,http://arxiv.org/abs/2111.09991v1,"Forrest Huang, Eldon Schoop, David Ha, Jeffrey Nichols, John Canny"
"A Review of the Applications of Deep Learning-Based Emergent
  Communication","  Emergent communication, or emergent language, is the field of research which
studies how human language-like communication systems emerge de novo in deep
multi-agent reinforcement learning environments. The possibilities of
replicating the emergence of a complex behavior like language have strong
intuitive appeal, yet it is necessary to complement this with clear notions of
how such research can be applicable to other fields of science, technology, and
engineering. This paper comprehensively reviews the applications of emergent
communication research across machine learning, natural language processing,
linguistics, and cognitive science. Each application is illustrated with a
description of its scope, an explication of emergent communication's unique
role in addressing it, a summary of the extant literature working towards the
application, and brief recommendations for near-term research directions.
",2024-07-03T17:43:54Z,http://arxiv.org/abs/2407.03302v1,"Brendon Boldt, David Mortensen"
"Nonlinear functional regression by functional deep neural network with
  kernel embedding","  With the rapid development of deep learning in various fields of science and
technology, such as speech recognition, image classification, and natural
language processing, recently it is also widely applied in the functional data
analysis (FDA) with some empirical success. However, due to the infinite
dimensional input, we need a powerful dimension reduction method for functional
learning tasks, especially for the nonlinear functional regression. In this
paper, based on the idea of smooth kernel integral transformation, we propose a
functional deep neural network with an efficient and fully data-dependent
dimension reduction method. The architecture of our functional net consists of
a kernel embedding step: an integral transformation with a data-dependent
smooth kernel; a projection step: a dimension reduction by projection with
eigenfunction basis based on the embedding kernel; and finally an expressive
deep ReLU neural network for the prediction. The utilization of smooth kernel
embedding enables our functional net to be discretization invariant, efficient,
and robust to noisy observations, capable of utilizing information in both
input functions and responses data, and have a low requirement on the number of
discrete points for an unimpaired generalization performance. We conduct
theoretical analysis including approximation error and generalization error
analysis, and numerical simulations to verify these advantages of our
functional net.
",2024-01-05T16:43:39Z,http://arxiv.org/abs/2401.02890v1,"Zhongjie Shi, Jun Fan, Linhao Song, Ding-Xuan Zhou, Johan A. K. Suykens"
Deep Lake: a Lakehouse for Deep Learning,"  Traditional data lakes provide critical data infrastructure for analytical
workloads by enabling time travel, running SQL queries, ingesting data with
ACID transactions, and visualizing petabyte-scale datasets on cloud storage.
They allow organizations to break down data silos, unlock data-driven
decision-making, improve operational efficiency, and reduce costs. However, as
deep learning usage increases, traditional data lakes are not well-designed for
applications such as natural language processing (NLP), audio processing,
computer vision, and applications involving non-tabular datasets. This paper
presents Deep Lake, an open-source lakehouse for deep learning applications
developed at Activeloop. Deep Lake maintains the benefits of a vanilla data
lake with one key difference: it stores complex data, such as images, videos,
annotations, as well as tabular data, in the form of tensors and rapidly
streams the data over the network to (a) Tensor Query Language, (b) in-browser
visualization engine, or (c) deep learning frameworks without sacrificing GPU
utilization. Datasets stored in Deep Lake can be accessed from PyTorch,
TensorFlow, JAX, and integrate with numerous MLOps tools.
",2022-09-22T05:04:09Z,http://arxiv.org/abs/2209.10785v2,"Sasun Hambardzumyan, Abhinav Tuli, Levon Ghukasyan, Fariz Rahman, Hrant Topchyan, David Isayan, Mark McQuade, Mikayel Harutyunyan, Tatevik Hakobyan, Ivo Stranic, Davit Buniatyan"
"A Survey on Deep Reinforcement Learning for Data Processing and
  Analytics","  Data processing and analytics are fundamental and pervasive. Algorithms play
a vital role in data processing and analytics where many algorithm designs have
incorporated heuristics and general rules from human knowledge and experience
to improve their effectiveness. Recently, reinforcement learning, deep
reinforcement learning (DRL) in particular, is increasingly explored and
exploited in many areas because it can learn better strategies in complicated
environments it is interacting with than statically designed algorithms.
Motivated by this trend, we provide a comprehensive review of recent works
focusing on utilizing DRL to improve data processing and analytics. First, we
present an introduction to key concepts, theories, and methods in DRL. Next, we
discuss DRL deployment on database systems, facilitating data processing and
analytics in various aspects, including data organization, scheduling, tuning,
and indexing. Then, we survey the application of DRL in data processing and
analytics, ranging from data preparation, natural language processing to
healthcare, fintech, etc. Finally, we discuss important open challenges and
future research directions of using DRL in data processing and analytics.
",2021-08-10T09:14:03Z,http://arxiv.org/abs/2108.04526v3,"Qingpeng Cai, Can Cui, Yiyuan Xiong, Wei Wang, Zhongle Xie, Meihui Zhang"
"Case Studies on using Natural Language Processing Techniques in Customer
  Relationship Management Software","  How can a text corpus stored in a customer relationship management (CRM)
database be used for data mining and segmentation? In order to answer this
question we inherited the state of the art methods commonly used in natural
language processing (NLP) literature, such as word embeddings, and deep
learning literature, such as recurrent neural networks (RNN). We used the text
notes from a CRM system which are taken by customer representatives of an
internet ads consultancy agency between years 2009 and 2020. We trained word
embeddings by using the corresponding text corpus and showed that these word
embeddings can not only be used directly for data mining but also be used in
RNN architectures, which are deep learning frameworks built with long short
term memory (LSTM) units, for more comprehensive segmentation objectives. The
results prove that structured text data in a CRM can be used to mine out very
valuable information and any CRM can be equipped with useful NLP features once
the problem definitions are properly built and the solution methods are
conveniently implemented.
",2021-06-09T16:07:07Z,http://arxiv.org/abs/2106.05160v1,≈û√ºkr√º Ozan
"From the digital data revolution to digital health and digital economy
  toward a digital society: Pervasiveness of Artificial Intelligence","  Technological progress has led to powerful computers and communication
technologies that penetrate nowadays all areas of science, industry and our
private lives. As a consequence, all these areas are generating digital traces
of data amounting to big data resources. This opens unprecedented opportunities
but also challenges toward the analysis, management, interpretation and
utilization of these data. Fortunately, recent breakthroughs in deep learning
algorithms complement now machine learning and statistics methods for an
efficient analysis of such data. Furthermore, advances in text mining and
natural language processing, e.g., word-embedding methods, enable also the
processing of large amounts of text data from diverse sources as governmental
reports, blog entries in social media or clinical health records of patients.
In this paper, we present a perspective on the role of artificial intelligence
in these developments and discuss also potential problems we are facing in a
digital society.
",2020-08-03T17:15:18Z,http://arxiv.org/abs/2008.12672v2,Frank Emmert-Streib
"What Averages Do Not Tell -- Predicting Real Life Processes with
  Sequential Deep Learning","  Deep Learning is proven to be an effective tool for modeling sequential data
as shown by the success in Natural Language, Computer Vision and Signal
Processing. Process Mining concerns discovering insights on business processes
from their execution data that are logged by supporting information systems.
The logged data (event log) is formed of event sequences (traces) that
correspond to executions of a process. Many Deep Learning techniques have been
successfully adapted for predictive Process Mining that aims to predict process
outcomes, remaining time, the next event, or even the suffix of running traces.
Traces in Process Mining are multimodal sequences and very differently
structured than natural language sentences or images. This may require a
different approach to processing. So far, there has been little focus on these
differences and the challenges introduced. Looking at suffix prediction as the
most challenging of these tasks, the performance of Deep Learning models was
evaluated only on average measures and for a small number of real-life event
logs. Comparing the results between papers is difficult due to different
pre-processing and evaluation strategies. Challenges that may be relevant are
the skewness of trace-length distribution and the skewness of the activity
distribution in real-life event logs. We provide an end-to-end framework which
enables to compare the performance of seven state-of-the-art sequential
architectures in common settings. Results show that sequence modeling still has
a lot of room for improvement for majority of the more complex datasets.
Further research and insights are required to get consistent performance not
just in average measures but additionally over all the prefixes.
",2021-10-19T19:45:05Z,http://arxiv.org/abs/2110.10225v2,"Istv√°n Ketyk√≥, Felix Mannhardt, Marwan Hassani, Boudewijn van Dongen"
Phonology Recognition in American Sign Language,"  Inspired by recent developments in natural language processing, we propose a
novel approach to sign language processing based on phonological properties
validated by American Sign Language users. By taking advantage of datasets
composed of phonological data and people speaking sign language, we use a
pretrained deep model based on mesh reconstruction to extract the 3D
coordinates of the signers keypoints. Then, we train standard statistical and
deep machine learning models in order to assign phonological classes to each
temporal sequence of coordinates.
  Our paper introduces the idea of exploiting the phonological properties
manually assigned by sign language users to classify videos of people
performing signs by regressing a 3D mesh. We establish a new baseline for this
problem based on the statistical distribution of 725 different signs. Our
best-performing models achieve a micro-averaged F1-score of 58% for the major
location class and 70% for the sign type using statistical and deep learning
algorithms, compared to their corresponding baselines of 35% and 39%.
",2021-10-01T14:38:47Z,http://arxiv.org/abs/2110.00453v1,"Federico Tavella, Aphrodite Galata, Angelo Cangelosi"
Transfer Learning Between Related Tasks Using Expected Label Proportions,"  Deep learning systems thrive on abundance of labeled training data but such
data is not always available, calling for alternative methods of supervision.
One such method is expectation regularization (XR) (Mann and McCallum, 2007),
where models are trained based on expected label proportions. We propose a
novel application of the XR framework for transfer learning between related
tasks, where knowing the labels of task A provides an estimation of the label
proportion of task B. We then use a model trained for A to label a large
corpus, and use this corpus with an XR loss to train a model for task B. To
make the XR framework applicable to large-scale deep-learning setups, we
propose a stochastic batched approximation procedure. We demonstrate the
approach on the task of Aspect-based Sentiment classification, where we
effectively use a sentence-level sentiment predictor to train accurate
aspect-based predictor. The method improves upon fully supervised neural system
trained on aspect-level data, and is also cumulative with LM-based pretraining,
as we demonstrate by improving a BERT-based Aspect-based Sentiment model.
",2019-09-01T17:11:35Z,http://arxiv.org/abs/1909.00430v1,"Matan Ben Noach, Yoav Goldberg"
DeText: A Deep Text Ranking Framework with BERT,"  Ranking is the most important component in a search system. Mostsearch
systems deal with large amounts of natural language data,hence an effective
ranking system requires a deep understandingof text semantics. Recently, deep
learning based natural languageprocessing (deep NLP) models have generated
promising results onranking systems. BERT is one of the most successful models
thatlearn contextual embedding, which has been applied to capturecomplex
query-document relations for search ranking. However,this is generally done by
exhaustively interacting each query wordwith each document word, which is
inefficient for online servingin search product systems. In this paper, we
investigate how tobuild an efficient BERT-based ranking model for industry use
cases.The solution is further extended to a general ranking framework,DeText,
that is open sourced and can be applied to various rankingproductions. Offline
and online experiments of DeText on threereal-world search systems present
significant improvement overstate-of-the-art approaches.
",2020-08-06T05:12:11Z,http://arxiv.org/abs/2008.02460v1,"Weiwei Guo, Xiaowei Liu, Sida Wang, Huiji Gao, Ananth Sankar, Zimeng Yang, Qi Guo, Liang Zhang, Bo Long, Bee-Chung Chen, Deepak Agarwal"
Meta-Reinforcement Learning via Language Instructions,"  Although deep reinforcement learning has recently been very successful at
learning complex behaviors, it requires a tremendous amount of data to learn a
task. One of the fundamental reasons causing this limitation lies in the nature
of the trial-and-error learning paradigm of reinforcement learning, where the
agent communicates with the environment and progresses in the learning only
relying on the reward signal. This is implicit and rather insufficient to learn
a task well. On the contrary, humans are usually taught new skills via natural
language instructions. Utilizing language instructions for robotic motion
control to improve the adaptability is a recently emerged topic and
challenging. In this paper, we present a meta-RL algorithm that addresses the
challenge of learning skills with language instructions in multiple
manipulation tasks. On the one hand, our algorithm utilizes the language
instructions to shape its interpretation of the task, on the other hand, it
still learns to solve task in a trial-and-error process. We evaluate our
algorithm on the robotic manipulation benchmark (Meta-World) and it
significantly outperforms state-of-the-art methods in terms of training and
testing task success rates. Codes are available at
\url{https://tumi6robot.wixsite.com/million}.
",2022-09-11T19:42:48Z,http://arxiv.org/abs/2209.04924v2,"Zhenshan Bing, Alexander Koch, Xiangtong Yao, Kai Huang, Alois Knoll"
"Privacy-Preserving Serverless Edge Learning with Decentralized Small
  Data","  In the last decade, data-driven algorithms outperformed traditional
optimization-based algorithms in many research areas, such as computer vision,
natural language processing, etc. However, extensive data usages bring a new
challenge or even threat to deep learning algorithms, i.e., privacy-preserving.
Distributed training strategies have recently become a promising approach to
ensure data privacy when training deep models. This paper extends conventional
serverless platforms with serverless edge learning architectures and provides
an efficient distributed training framework from the networking perspective.
This framework dynamically orchestrates available resources among heterogeneous
physical units to efficiently fulfill deep learning objectives. The design
jointly considers learning task requests and underlying infrastructure
heterogeneity, including last-mile transmissions, computation abilities of
mobile devices, edge and cloud computing centers, and devices battery status.
Furthermore, to significantly reduce distributed training overheads,
small-scale data training is proposed by integrating with a general, simple
data classifier. This low-load enhancement can seamlessly work with various
distributed deep models to improve communications and computation efficiencies
during the training phase. Finally, open challenges and future research
directions encourage the research community to develop efficient distributed
deep learning techniques.
",2021-11-29T21:04:49Z,http://arxiv.org/abs/2111.14955v2,"Shih-Chun Lin, Chia-Hung Lin"
"Lessons Learned from a Citizen Science Project for Natural Language
  Processing","  Many Natural Language Processing (NLP) systems use annotated corpora for
training and evaluation. However, labeled data is often costly to obtain and
scaling annotation projects is difficult, which is why annotation tasks are
often outsourced to paid crowdworkers. Citizen Science is an alternative to
crowdsourcing that is relatively unexplored in the context of NLP. To
investigate whether and how well Citizen Science can be applied in this
setting, we conduct an exploratory study into engaging different groups of
volunteers in Citizen Science for NLP by re-annotating parts of a pre-existing
crowdsourced dataset. Our results show that this can yield high-quality
annotations and attract motivated volunteers, but also requires considering
factors such as scalability, participation over time, and legal and ethical
issues. We summarize lessons learned in the form of guidelines and provide our
code and data to aid future work on Citizen Science.
",2023-04-25T14:08:53Z,http://arxiv.org/abs/2304.12836v1,"Jan-Christoph Klie, Ji-Ung Lee, Kevin Stowe, G√∂zde G√ºl ≈ûahin, Nafise Sadat Moosavi, Luke Bates, Dominic Petrak, Richard Eckart de Castilho, Iryna Gurevych"
WikiBERT models: deep transfer learning for many languages,"  Deep neural language models such as BERT have enabled substantial recent
advances in many natural language processing tasks. Due to the effort and
computational cost involved in their pre-training, language-specific models are
typically introduced only for a small number of high-resource languages such as
English. While multilingual models covering large numbers of languages are
available, recent work suggests monolingual training can produce better models,
and our understanding of the tradeoffs between mono- and multilingual training
is incomplete. In this paper, we introduce a simple, fully automated pipeline
for creating language-specific BERT models from Wikipedia data and introduce 42
new such models, most for languages up to now lacking dedicated deep neural
language models. We assess the merits of these models using the
state-of-the-art UDify parser on Universal Dependencies data, contrasting
performance with results using the multilingual BERT model. We find that UDify
using WikiBERT models outperforms the parser using mBERT on average, with the
language-specific models showing substantially improved performance for some
languages, yet limited improvement or a decrease in performance for others. We
also present preliminary results as first steps toward an understanding of the
conditions under which language-specific models are most beneficial. All of the
methods and models introduced in this work are available under open licenses
from https://github.com/turkunlp/wikibert.
",2020-06-02T11:57:53Z,http://arxiv.org/abs/2006.01538v1,"Sampo Pyysalo, Jenna Kanerva, Antti Virtanen, Filip Ginter"
A Neural Approach for Detecting Morphological Analogies,"  Analogical proportions are statements of the form ""A is to B as C is to D""
that are used for several reasoning and classification tasks in artificial
intelligence and natural language processing (NLP). For instance, there are
analogy based approaches to semantics as well as to morphology. In fact,
symbolic approaches were developed to solve or to detect analogies between
character strings, e.g., the axiomatic approach as well as that based on
Kolmogorov complexity. In this paper, we propose a deep learning approach to
detect morphological analogies, for instance, with reinflexion or conjugation.
We present empirical results that show that our framework is competitive with
the above-mentioned state of the art symbolic approaches. We also explore
empirically its transferability capacity across languages, which highlights
interesting similarities between them.
",2021-08-09T11:21:55Z,http://arxiv.org/abs/2108.03945v1,"Safa Alsaidi, Amandine Decker, Puthineath Lay, Esteban Marquer, Pierre-Alexandre Murena, Miguel Couceiro"
Meta Learning for Natural Language Processing: A Survey,"  Deep learning has been the mainstream technique in natural language
processing (NLP) area. However, the techniques require many labeled data and
are less generalizable across domains. Meta-learning is an arising field in
machine learning studying approaches to learn better learning algorithms.
Approaches aim at improving algorithms in various aspects, including data
efficiency and generalizability. Efficacy of approaches has been shown in many
NLP tasks, but there is no systematic survey of these approaches in NLP, which
hinders more researchers from joining the field. Our goal with this survey
paper is to offer researchers pointers to relevant meta-learning works in NLP
and attract more attention from the NLP community to drive future innovation.
This paper first introduces the general concepts of meta-learning and the
common approaches. Then we summarize task construction settings and application
of meta-learning for various NLP problems and review the development of
meta-learning in NLP community.
",2022-05-03T13:58:38Z,http://arxiv.org/abs/2205.01500v2,"Hung-yi Lee, Shang-Wen Li, Ngoc Thang Vu"
Towards Fully Bilingual Deep Language Modeling,"  Language models based on deep neural networks have facilitated great advances
in natural language processing and understanding tasks in recent years. While
models covering a large number of languages have been introduced, their
multilinguality has come at a cost in terms of monolingual performance, and the
best-performing models at most tasks not involving cross-lingual transfer
remain monolingual. In this paper, we consider the question of whether it is
possible to pre-train a bilingual model for two remotely related languages
without compromising performance at either language. We collect pre-training
data, create a Finnish-English bilingual BERT model and evaluate its
performance on datasets used to evaluate the corresponding monolingual models.
Our bilingual model performs on par with Google's original English BERT on GLUE
and nearly matches the performance of monolingual Finnish BERT on a range of
Finnish NLP tasks, clearly outperforming multilingual BERT. We find that when
the model vocabulary size is increased, the BERT-Base architecture has
sufficient capacity to learn two remotely related languages to a level where it
achieves comparable performance with monolingual models, demonstrating the
feasibility of training fully bilingual deep language models. The model and all
tools involved in its creation are freely available at
https://github.com/TurkuNLP/biBERT
",2020-10-22T12:22:50Z,http://arxiv.org/abs/2010.11639v1,"Li-Hsin Chang, Sampo Pyysalo, Jenna Kanerva, Filip Ginter"
"Relational Weight Priors in Neural Networks for Abstract Pattern
  Learning and Language Modelling","  Deep neural networks have become the dominant approach in natural language
processing (NLP). However, in recent years, it has become apparent that there
are shortcomings in systematicity that limit the performance and data
efficiency of deep learning in NLP. These shortcomings can be clearly shown in
lower-level artificial tasks, mostly on synthetic data. Abstract patterns are
the best known examples of a hard problem for neural networks in terms of
generalisation to unseen data. They are defined by relations between items,
such as equality, rather than their values. It has been argued that these
low-level problems demonstrate the inability of neural networks to learn
systematically. In this study, we propose Embedded Relation Based Patterns
(ERBP) as a novel way to create a relational inductive bias that encourages
learning equality and distance-based relations for abstract patterns. ERBP is
based on Relation Based Patterns (RBP), but modelled as a Bayesian prior on
network weights and implemented as a regularisation term in otherwise standard
network learning. ERBP is is easy to integrate into standard neural networks
and does not affect their learning capacity. In our experiments, ERBP priors
lead to almost perfect generalisation when learning abstract patterns from
synthetic noise-free sequences. ERBP also improves natural language models on
the word and character level and pitch prediction in melodies with RNN, GRU and
LSTM networks. We also find improvements in in the more complex tasks of
learning of graph edit distance and compositional sentence entailment. ERBP
consistently improves over RBP and over standard networks, showing that it
enables abstract pattern learning which contributes to performance in natural
language tasks.
",2021-03-10T17:21:16Z,http://arxiv.org/abs/2103.06198v1,"Radha Kopparti, Tillman Weyde"
"Off-the-shelf deep learning is not enough: parsimony, Bayes and
  causality","  Deep neural networks (""deep learning"") have emerged as a technology of choice
to tackle problems in natural language processing, computer vision, speech
recognition and gameplay, and in just a few years has led to superhuman level
performance and ushered in a new wave of ""AI."" Buoyed by these successes,
researchers in the physical sciences have made steady progress in incorporating
deep learning into their respective domains. However, such adoption brings
substantial challenges that need to be recognized and confronted. Here, we
discuss both opportunities and roadblocks to implementation of deep learning
within materials science, focusing on the relationship between correlative
nature of machine learning and causal hypothesis driven nature of physical
sciences. We argue that deep learning and AI are now well positioned to
revolutionize fields where causal links are known, as is the case for
applications in theory. When confounding factors are frozen or change only
weakly, this leaves open the pathway for effective deep learning solutions in
experimental domains. Similarly, these methods offer a pathway towards
understanding the physics of real-world systems, either via deriving reduced
representations, deducing algorithmic complexity, or recovering generative
physical models. However, extending deep learning and ""AI"" for models with
unclear causal relationship can produce misleading and potentially incorrect
results. Here, we argue the broad adoption of Bayesian methods incorporating
prior knowledge, development of DL solutions with incorporated physical
constraints, and ultimately adoption of causal models, offers a path forward
for fundamental and applied research. Most notably, while these advances can
change the way science is carried out in ways we cannot imagine, machine
learning is not going to substitute science any time soon.
",2020-05-04T15:16:30Z,http://arxiv.org/abs/2005.01557v1,"Rama K. Vasudevan, Maxim Ziatdinov, Lukas Vlcek, Sergei V. Kalinin"
Improving Retrieval-Based Question Answering with Deep Inference Models,"  Question answering is one of the most important and difficult applications at
the border of information retrieval and natural language processing, especially
when we talk about complex science questions which require some form of
inference to determine the correct answer. In this paper, we present a two-step
method that combines information retrieval techniques optimized for question
answering with deep learning models for natural language inference in order to
tackle the multi-choice question answering in the science domain. For each
question-answer pair, we use standard retrieval-based models to find relevant
candidate contexts and decompose the main problem into two different
sub-problems. First, assign correctness scores for each candidate answer based
on the context using retrieval models from Lucene. Second, we use deep learning
architectures to compute if a candidate answer can be inferred from some
well-chosen context consisting of sentences retrieved from the knowledge base.
In the end, all these solvers are combined using a simple neural network to
predict the correct answer. This proposed two-step model outperforms the best
retrieval-based solver by over 3% in absolute accuracy.
",2018-12-07T10:44:14Z,http://arxiv.org/abs/1812.02971v2,"George-Sebastian Pirtoaca, Traian Rebedea, Stefan Ruseti"
"An inclusive review on deep learning techniques and their scope in
  handwriting recognition","  Deep learning expresses a category of machine learning algorithms that have
the capability to combine raw inputs into intermediate features layers. These
deep learning algorithms have demonstrated great results in different fields.
Deep learning has particularly witnessed for a great achievement of human level
performance across a number of domains in computer vision and pattern
recognition. For the achievement of state-of-the-art performances in diverse
domains, the deep learning used different architectures and these architectures
used activation functions to perform various computations between hidden and
output layers of any architecture. This paper presents a survey on the existing
studies of deep learning in handwriting recognition field. Even though the
recent progress indicates that the deep learning methods has provided valuable
means for speeding up or proving accurate results in handwriting recognition,
but following from the extensive literature survey, the present study finds
that the deep learning has yet to revolutionize more and has to resolve many of
the most pressing challenges in this field, but promising advances have been
made on the prior state of the art. Additionally, an inadequate availability of
labelled data to train presents problems in this domain. Nevertheless, the
present handwriting recognition survey foresees deep learning enabling changes
at both bench and bedside with the potential to transform several domains as
image processing, speech recognition, computer vision, machine translation,
robotics and control, medical imaging, medical information processing,
bio-informatics, natural language processing, cyber security, and many others.
",2024-04-10T06:30:33Z,http://arxiv.org/abs/2404.08011v1,"Sukhdeep Singh, Sudhir Rohilla, Anuj Sharma"
Tackling Vision Language Tasks Through Learning Inner Monologues,"  Visual language tasks require AI models to comprehend and reason with both
visual and textual content. Driven by the power of Large Language Models
(LLMs), two prominent methods have emerged: (1) the hybrid integration between
LLMs and Vision-Language Models (VLMs), where visual inputs are firstly
converted into language descriptions by VLMs, serving as inputs for LLMs to
generate final answer(s); (2) visual feature alignment in language space, where
visual inputs are encoded as embeddings and projected to LLMs' language space
via further supervised fine-tuning. The first approach provides light training
costs and interpretability but is hard to be optimized in an end-to-end
fashion. The second approach presents decent performance, but feature alignment
usually requires large amounts of training data and lacks interpretability. To
tackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal
Optimization (IMMO), to solve complex vision language problems by simulating
inner monologue processes, a cognitive process in which an individual engages
in silent verbal communication with themselves. We enable LLMs and VLMs to
interact through natural language conversation and propose to use a two-stage
training process to learn how to do the inner monologue (self-asking questions
and answering questions). IMMO is evaluated on two popular tasks and the
results suggest by emulating the cognitive phenomenon of internal dialogue, our
approach can enhance reasoning and explanation abilities, contributing to the
more effective fusion of vision and language models. More importantly, instead
of using predefined human-crafted monologues, IMMO learns this process within
the deep learning models, promising wider applicability to many different AI
problems beyond vision language tasks.
",2023-08-19T10:10:49Z,http://arxiv.org/abs/2308.09970v1,"Diji Yang, Kezhen Chen, Jinmeng Rao, Xiaoyuan Guo, Yawen Zhang, Jie Yang, Yi Zhang"
"Developing Linguistic Patterns to Mitigate Inherent Human Bias in
  Offensive Language Detection","  With the proliferation of social media, there has been a sharp increase in
offensive content, particularly targeting vulnerable groups, exacerbating
social problems such as hatred, racism, and sexism. Detecting offensive
language use is crucial to prevent offensive language from being widely shared
on social media. However, the accurate detection of irony, implication, and
various forms of hate speech on social media remains a challenge. Natural
language-based deep learning models require extensive training with large,
comprehensive, and labeled datasets. Unfortunately, manually creating such
datasets is both costly and error-prone. Additionally, the presence of
human-bias in offensive language datasets is a major concern for deep learning
models. In this paper, we propose a linguistic data augmentation approach to
reduce bias in labeling processes, which aims to mitigate the influence of
human bias by leveraging the power of machines to improve the accuracy and
fairness of labeling processes. This approach has the potential to improve
offensive language classification tasks across multiple languages and reduce
the prevalence of offensive content on social media.
",2023-12-04T10:20:36Z,http://arxiv.org/abs/2312.01787v1,"Toygar Tanyel, Besher Alkurdi, Serkan Ayvaz"
Learning to Automatically Generate Fill-In-The-Blank Quizzes,"  In this paper we formalize the problem automatic fill-in-the-blank question
generation using two standard NLP machine learning schemes, proposing concrete
deep learning models for each. We present an empirical study based on data
obtained from a language learning platform showing that both of our proposed
settings offer promising results.
",2018-06-12T13:53:22Z,http://arxiv.org/abs/1806.04524v1,"Edison Marrese-Taylor, Ai Nakajima, Yutaka Matsuo, Ono Yuichi"
Procedural Text Mining with Large Language Models,"  Recent advancements in the field of Natural Language Processing, particularly
the development of large-scale language models that are pretrained on vast
amounts of knowledge, are creating novel opportunities within the realm of
Knowledge Engineering. In this paper, we investigate the usage of large
language models (LLMs) in both zero-shot and in-context learning settings to
tackle the problem of extracting procedures from unstructured PDF text in an
incremental question-answering fashion. In particular, we leverage the current
state-of-the-art GPT-4 (Generative Pre-trained Transformer 4) model,
accompanied by two variations of in-context learning that involve an ontology
with definitions of procedures and steps and a limited number of samples of
few-shot learning. The findings highlight both the promise of this approach and
the value of the in-context learning customisations. These modifications have
the potential to significantly address the challenge of obtaining sufficient
training data, a hurdle often encountered in deep learning-based Natural
Language Processing techniques for procedure extraction.
",2023-10-05T08:27:33Z,http://arxiv.org/abs/2310.03376v1,"Anisa Rula, Jennifer D'Souza"
Data Curation with Deep Learning [Vision],"  Data curation - the process of discovering, integrating, and cleaning data -
is one of the oldest, hardest, yet inevitable data management problems. Despite
decades of efforts from both researchers and practitioners, it is still one of
the most time consuming and least enjoyable work of data scientists. In most
organizations, data curation plays an important role so as to fully unlock the
value of big data. Unfortunately, the current solutions are not keeping up with
the ever-changing data ecosystem, because they often require substantially high
human cost. Meanwhile, deep learning is making strides in achieving remarkable
successes in multiple areas, such as image recognition, natural language
processing, and speech recognition. In this vision paper, we explore how some
of the fundamental innovations in deep learning could be leveraged to improve
existing data curation solutions and to help build new ones. In particular, we
provide a thorough overview of the current deep learning landscape, and
identify interesting research opportunities and dispel common myths. We hope
that the synthesis of these important domains will unleash a series of research
activities that will lead to significantly improved solutions for many data
curation tasks.
",2018-03-04T17:08:45Z,http://arxiv.org/abs/1803.01384v2,"Saravanan Thirumuruganathan, Nan Tang, Mourad Ouzzani, AnHai Doan"
"Unsupervised pre-training of graph transformers on patient population
  graphs","  Pre-training has shown success in different areas of machine learning, such
as Computer Vision, Natural Language Processing (NLP), and medical imaging.
However, it has not been fully explored for clinical data analysis. An immense
amount of clinical records are recorded, but still, data and labels can be
scarce for data collected in small hospitals or dealing with rare diseases. In
such scenarios, pre-training on a larger set of unlabelled clinical data could
improve performance. In this paper, we propose novel unsupervised pre-training
techniques designed for heterogeneous, multi-modal clinical data for patient
outcome prediction inspired by masked language modeling (MLM), by leveraging
graph deep learning over population graphs. To this end, we further propose a
graph-transformer-based network, designed to handle heterogeneous clinical
data. By combining masking-based pre-training with a transformer-based network,
we translate the success of masking-based pre-training in other domains to
heterogeneous clinical data. We show the benefit of our pre-training method in
a self-supervised and a transfer learning setting, utilizing three medical
datasets TADPOLE, MIMIC-III, and a Sepsis Prediction Dataset. We find that our
proposed pre-training methods help in modeling the data at a patient and
population level and improve performance in different fine-tuning tasks on all
datasets.
",2022-07-21T16:59:09Z,http://arxiv.org/abs/2207.10603v2,"Chantal Pellegrini, Nassir Navab, Anees Kazi"
Deep Graph Matching and Searching for Semantic Code Retrieval,"  Code retrieval is to find the code snippet from a large corpus of source code
repositories that highly matches the query of natural language description.
Recent work mainly uses natural language processing techniques to process both
query texts (i.e., human natural language) and code snippets (i.e., machine
programming language), however neglecting the deep structured features of query
texts and source codes, both of which contain rich semantic information. In
this paper, we propose an end-to-end deep graph matching and searching (DGMS)
model based on graph neural networks for the task of semantic code retrieval.
To this end, we first represent both natural language query texts and
programming language code snippets with the unified graph-structured data, and
then use the proposed graph matching and searching model to retrieve the best
matching code snippet. In particular, DGMS not only captures more structural
information for individual query texts or code snippets but also learns the
fine-grained similarity between them by cross-attention based semantic matching
operations. We evaluate the proposed DGMS model on two public code retrieval
datasets with two representative programming languages (i.e., Java and Python).
Experiment results demonstrate that DGMS significantly outperforms
state-of-the-art baseline models by a large margin on both datasets. Moreover,
our extensive ablation studies systematically investigate and illustrate the
impact of each part of DGMS.
",2020-10-24T14:16:50Z,http://arxiv.org/abs/2010.12908v2,"Xiang Ling, Lingfei Wu, Saizhuo Wang, Gaoning Pan, Tengfei Ma, Fangli Xu, Alex X. Liu, Chunming Wu, Shouling Ji"
Automatic Summarization of Natural Language,"  Automatic summarization of natural language is a current topic in computer
science research and industry, studied for decades because of its usefulness
across multiple domains. For example, summarization is necessary to create
reviews such as this one. Research and applications have achieved some success
in extractive summarization (where key sentences are curated), however,
abstractive summarization (synthesis and re-stating) is a hard problem and
generally unsolved in computer science. This literature review contrasts
historical progress up through current state of the art, comparing dimensions
such as: extractive vs. abstractive, supervised vs. unsupervised, NLP (Natural
Language Processing) vs Knowledge-based, deep learning vs algorithms,
structured vs. unstructured sources, and measurement metrics such as Rouge and
BLEU. Multiple dimensions are contrasted since current research uses
combinations of approaches as seen in the review matrix. Throughout this
summary, synthesis and critique is provided. This review concludes with
insights for improved abstractive summarization measurement, with surprising
implications for detecting understanding and comprehension in general.
",2018-12-18T14:17:56Z,http://arxiv.org/abs/1812.10549v1,Marc Everett Johnson
Sparse Deep Learning for Time Series Data: Theory and Applications,"  Sparse deep learning has become a popular technique for improving the
performance of deep neural networks in areas such as uncertainty
quantification, variable selection, and large-scale network compression.
However, most existing research has focused on problems where the observations
are independent and identically distributed (i.i.d.), and there has been little
work on the problems where the observations are dependent, such as time series
data and sequential data in natural language processing. This paper aims to
address this gap by studying the theory for sparse deep learning with dependent
data. We show that sparse recurrent neural networks (RNNs) can be consistently
estimated, and their predictions are asymptotically normally distributed under
appropriate assumptions, enabling the prediction uncertainty to be correctly
quantified. Our numerical results show that sparse deep learning outperforms
state-of-the-art methods, such as conformal predictions, in prediction
uncertainty quantification for time series data. Furthermore, our results
indicate that the proposed method can consistently identify the autoregressive
order for time series data and outperform existing methods in large-scale model
compression. Our proposed method has important practical implications in fields
such as finance, healthcare, and energy, where both accurate point estimates
and prediction uncertainty quantification are of concern.
",2023-10-05T01:26:13Z,http://arxiv.org/abs/2310.03243v1,"Mingxuan Zhang, Yan Sun, Faming Liang"
"Differentially Private Natural Language Models: Recent Advances and
  Future Directions","  Recent developments in deep learning have led to great success in various
natural language processing (NLP) tasks. However, these applications may
involve data that contain sensitive information. Therefore, how to achieve good
performance while also protecting the privacy of sensitive data is a crucial
challenge in NLP. To preserve privacy, Differential Privacy (DP), which can
prevent reconstruction attacks and protect against potential side knowledge, is
becoming a de facto technique for private data analysis. In recent years, NLP
in DP models (DP-NLP) has been studied from different perspectives, which
deserves a comprehensive review. In this paper, we provide the first systematic
review of recent advances in DP deep learning models in NLP. In particular, we
first discuss some differences and additional challenges of DP-NLP compared
with the standard DP deep learning. Then, we investigate some existing work on
DP-NLP and present its recent developments from three aspects: gradient
perturbation based methods, embedding vector perturbation based methods, and
ensemble model based methods. We also discuss some challenges and future
directions.
",2023-01-22T12:29:03Z,http://arxiv.org/abs/2301.09112v2,"Lijie Hu, Ivan Habernal, Lei Shen, Di Wang"
Do Large Language Models Mirror Cognitive Language Processing?,"  Large Language Models (LLMs) have demonstrated remarkable abilities in text
comprehension and logical reasoning, indicating that the text representations
learned by LLMs can facilitate their language processing capabilities. In
cognitive science, brain cognitive processing signals are typically utilized to
study human language processing. Therefore, it is natural to ask how well the
text embeddings from LLMs align with the brain cognitive processing signals,
and how training strategies affect the LLM-brain alignment? In this paper, we
employ Representational Similarity Analysis (RSA) to measure the alignment
between 23 mainstream LLMs and fMRI signals of the brain to evaluate how
effectively LLMs simulate cognitive language processing. We empirically
investigate the impact of various factors (e.g., pre-training data size, model
scaling, alignment training, and prompts) on such LLM-brain alignment.
Experimental results indicate that pre-training data size and model scaling are
positively correlated with LLM-brain similarity, and alignment training can
significantly improve LLM-brain similarity. Explicit prompts contribute to the
consistency of LLMs with brain cognitive language processing, while nonsensical
noisy prompts may attenuate such alignment. Additionally, the performance of a
wide range of LLM evaluations (e.g., MMLU, Chatbot Arena) is highly correlated
with the LLM-brain similarity.
",2024-02-28T03:38:20Z,http://arxiv.org/abs/2402.18023v2,"Yuqi Ren, Renren Jin, Tongxuan Zhang, Deyi Xiong"
"Social and environmental impact of recent developments in machine
  learning on biology and chemistry research","  Potential societal and environmental effects such as the rapidly increasing
resource use and the associated environmental impact, reproducibility issues,
and exclusivity, the privatization of ML research leading to a public research
brain-drain, a narrowing of the research effort caused by a focus on deep
learning, and the introduction of biases through a lack of sociodemographic
diversity in data and personnel caused by recent developments in machine
learning are a current topic of discussion and scientific publications.
However, these discussions and publications focus mainly on computer
science-adjacent fields, including computer vision and natural language
processing or basic ML research. Using bibliometric analysis of the complete
and full-text analysis of the open-access literature, we show that the same
observations can be made for applied machine learning in chemistry and biology.
These developments can potentially affect basic and applied research, such as
drug discovery and development, beyond the known issue of biased data sets.
",2022-10-01T20:29:01Z,http://arxiv.org/abs/2210.00356v1,Daniel Probst
"This Reads Like That: Deep Learning for Interpretable Natural Language
  Processing","  Prototype learning, a popular machine learning method designed for inherently
interpretable decisions, leverages similarities to learned prototypes for
classifying new data. While it is mainly applied in computer vision, in this
work, we build upon prior research and further explore the extension of
prototypical networks to natural language processing. We introduce a learned
weighted similarity measure that enhances the similarity computation by
focusing on informative dimensions of pre-trained sentence embeddings.
Additionally, we propose a post-hoc explainability mechanism that extracts
prediction-relevant words from both the prototype and input sentences. Finally,
we empirically demonstrate that our proposed method not only improves
predictive performance on the AG News and RT Polarity datasets over a previous
prototype-based approach, but also improves the faithfulness of explanations
compared to rationale-based recurrent convolutions.
",2023-10-25T21:18:35Z,http://arxiv.org/abs/2310.17010v1,"Claudio Fanconi, Moritz Vandenhirtz, Severin Husmann, Julia E. Vogt"
"SPASS: Scientific Prominence Active Search System with Deep Image
  Captioning Network","  Planetary exploration missions with Mars rovers are complicated, which
generally require elaborated task planning by human experts, from the path to
take to the images to capture. NASA has been using this process to acquire over
22 million images from the planet Mars. In order to improve the degree of
automation and thus efficiency in this process, we propose a system for
planetary rovers to actively search for prominence of prespecified scientific
features in captured images. Scientists can prespecify such search tasks in
natural language and upload them to a rover, on which the deployed system
constantly captions captured images with a deep image captioning network and
compare the auto-generated captions to the prespecified search tasks by certain
metrics so as to prioritize those images for transmission. As a beneficial side
effect, the proposed system can also be deployed to ground-based planetary data
systems as a content-based search engine.
",2018-09-10T15:18:37Z,http://arxiv.org/abs/1809.03385v1,Dicong Qiu
Applications of Deep Neural Networks with Keras,"  Deep learning is a group of exciting new technologies for neural networks.
Through a combination of advanced training techniques and neural network
architectural components, it is now possible to create neural networks that can
handle tabular data, images, text, and audio as both input and output. Deep
learning allows a neural network to learn hierarchies of information in a way
that is like the function of the human brain. This course will introduce the
student to classic neural network structures, Convolution Neural Networks
(CNN), Long Short-Term Memory (LSTM), Gated Recurrent Neural Networks (GRU),
General Adversarial Networks (GAN), and reinforcement learning. Application of
these architectures to computer vision, time series, security, natural language
processing (NLP), and data generation will be covered. High-Performance
Computing (HPC) aspects will demonstrate how deep learning can be leveraged
both on graphical processing units (GPUs), as well as grids. Focus is primarily
upon the application of deep learning to problems, with some introduction to
mathematical foundations. Readers will use the Python programming language to
implement deep learning using Google TensorFlow and Keras. It is not necessary
to know Python prior to this book; however, familiarity with at least one
programming language is assumed.
",2020-09-11T22:09:10Z,http://arxiv.org/abs/2009.05673v5,Jeff Heaton
On the Efficiency of NLP-Inspired Methods for Tabular Deep Learning,"  Recent advancements in tabular deep learning (DL) have led to substantial
performance improvements, surpassing the capabilities of traditional models.
With the adoption of techniques from natural language processing (NLP), such as
language model-based approaches, DL models for tabular data have also grown in
complexity and size. Although tabular datasets do not typically pose
scalability issues, the escalating size of these models has raised efficiency
concerns. Despite its importance, efficiency has been relatively underexplored
in tabular DL research. This paper critically examines the latest innovations
in tabular DL, with a dual focus on performance and computational efficiency.
The source code is available at https://github.com/basf/mamba-tabular.
",2024-11-26T08:23:29Z,http://arxiv.org/abs/2411.17207v1,"Anton Frederik Thielmann, Soheila Samiee"
Deep learning and sub-word-unit approach in written art generation,"  Automatic poetry generation is novel and interesting application of natural
language processing research. It became more popular during the last few years
due to the rapid development of technology and neural computing power. This
line of research can be applied to the study of linguistics and literature, for
social science experiments, or simply for entertainment. The most effective
known method of artificial poem generation uses recurrent neural networks
(RNN). We also used RNNs to generate poems in the style of Adam Mickiewicz. Our
network was trained on the Sir Thaddeus poem. For data pre-processing, we used
a specialized stemming tool, which is one of the major innovations and
contributions of this work. Our experiment was conducted on the source text,
divided into sub-word units (at a level of resolution close to syllables). This
approach is novel and is not often employed in the published literature. The
subwords units seem to be a natural choice for analysis of the Polish language,
as the language is morphologically rich due to cases, gender forms and a large
vocabulary. Moreover, Sir Thaddeus contains rhymes, so the analysis of
syllables can be meaningful. We verified our model with different settings for
the temperature parameter, which controls the randomness of the generated text.
We also compared our results with similar models trained on the same text but
divided into characters (which is the most common approach alongside the use of
full word units). The differences were tremendous. Our solution generated much
better poems that were able to follow the metre and vocabulary of the source
data text.
",2019-01-22T15:42:51Z,http://arxiv.org/abs/1901.07426v1,"Krzysztof Wo≈Çk, Emilia Zawadzka-Gosk, Wojciech Czarnowski"
"Rare Words: A Major Problem for Contextualized Embeddings And How to Fix
  it by Attentive Mimicking","  Pretraining deep neural network architectures with a language modeling
objective has brought large improvements for many natural language processing
tasks. Exemplified by BERT, a recently proposed such architecture, we
demonstrate that despite being trained on huge amounts of data, deep language
models still struggle to understand rare words. To fix this problem, we adapt
Attentive Mimicking, a method that was designed to explicitly learn embeddings
for rare words, to deep language models. In order to make this possible, we
introduce one-token approximation, a procedure that enables us to use Attentive
Mimicking even when the underlying language model uses subword-based
tokenization, i.e., it does not assign embeddings to all words. To evaluate our
method, we create a novel dataset that tests the ability of language models to
capture semantic properties of words without any task-specific fine-tuning.
Using this dataset, we show that adding our adapted version of Attentive
Mimicking to BERT does indeed substantially improve its understanding of rare
words.
",2019-04-14T15:26:52Z,http://arxiv.org/abs/1904.06707v4,"Timo Schick, Hinrich Sch√ºtze"
"Improving historical spelling normalization with bi-directional LSTMs
  and multi-task learning","  Natural-language processing of historical documents is complicated by the
abundance of variant spellings and lack of annotated data. A common approach is
to normalize the spelling of historical words to modern forms. We explore the
suitability of a deep neural network architecture for this task, particularly a
deep bi-LSTM network applied on a character level. Our model compares well to
previously established normalization algorithms when evaluated on a diverse set
of texts from Early New High German. We show that multi-task learning with
additional normalization data can improve our model's performance further.
",2016-10-25T12:30:26Z,http://arxiv.org/abs/1610.07844v1,"Marcel Bollmann, Anders S√∏gaard"
"Protein sequence classification using natural language processing
  techniques","  Proteins are essential to numerous biological functions, with their sequences
determining their roles within organisms. Traditional methods for determining
protein function are time-consuming and labor-intensive. This study addresses
the increasing demand for precise, effective, and automated protein sequence
classification methods by employing natural language processing (NLP)
techniques on a dataset comprising 75 target protein classes. We explored
various machine learning and deep learning models, including K-Nearest
Neighbors (KNN), Multinomial Na\""ive Bayes, Logistic Regression, Multi-Layer
Perceptron (MLP), Decision Tree, Random Forest, XGBoost, Voting and Stacking
classifiers, Convolutional Neural Network (CNN), Long Short-Term Memory (LSTM),
and transformer models (BertForSequenceClassification, DistilBERT, and
ProtBert). Experiments were conducted using amino acid ranges of 1-4 grams for
machine learning models and different sequence lengths for CNN and LSTM models.
The KNN algorithm performed best on tri-gram data with 70.0% accuracy and a
macro F1 score of 63.0%. The Voting classifier achieved best performance with
74.0% accuracy and an F1 score of 65.0%, while the Stacking classifier reached
75.0% accuracy and an F1 score of 64.0%. ProtBert demonstrated the highest
performance among transformer models, with a accuracy 76.0% and F1 score 61.0%
which is same for all three transformer models. Advanced NLP techniques,
particularly ensemble methods and transformer models, show great potential in
protein classification. Our results demonstrate that ensemble methods,
particularly Voting Soft classifiers, achieved superior results, highlighting
the importance of sufficient training data and addressing sequence similarity
across different classes.
",2024-09-06T13:16:16Z,http://arxiv.org/abs/2409.04491v1,"Huma Perveen, Julie Weeds"
Benchmark of Deep Learning Models on Large Healthcare MIMIC Datasets,"  Deep learning models (aka Deep Neural Networks) have revolutionized many
fields including computer vision, natural language processing, speech
recognition, and is being increasingly used in clinical healthcare
applications. However, few works exist which have benchmarked the performance
of the deep learning models with respect to the state-of-the-art machine
learning models and prognostic scoring systems on publicly available healthcare
datasets. In this paper, we present the benchmarking results for several
clinical prediction tasks such as mortality prediction, length of stay
prediction, and ICD-9 code group prediction using Deep Learning models,
ensemble of machine learning models (Super Learner algorithm), SAPS II and SOFA
scores. We used the Medical Information Mart for Intensive Care III (MIMIC-III)
(v1.4) publicly available dataset, which includes all patients admitted to an
ICU at the Beth Israel Deaconess Medical Center from 2001 to 2012, for the
benchmarking tasks. Our results show that deep learning models consistently
outperform all the other approaches especially when the `raw' clinical time
series data is used as input features to the models.
",2017-10-23T22:23:34Z,http://arxiv.org/abs/1710.08531v1,"Sanjay Purushotham, Chuizheng Meng, Zhengping Che, Yan Liu"
Uzbek Sentiment Analysis based on local Restaurant Reviews,"  Extracting useful information for sentiment analysis and classification
problems from a big amount of user-generated feedback, such as restaurant
reviews, is a crucial task of natural language processing, which is not only
for customer satisfaction where it can give personalized services, but can also
influence the further development of a company. In this paper, we present a
work done on collecting restaurant reviews data as a sentiment analysis dataset
for the Uzbek language, a member of the Turkic family which is heavily affected
by the low-resource constraint, and provide some further analysis of the novel
dataset by evaluation using different techniques, from logistic regression
based models, to support vector machines, and even deep learning models, such
as recurrent neural networks, as well as convolutional neural networks. The
paper includes detailed information on how the data was collected, how it was
pre-processed for better quality optimization, as well as experimental setups
for the evaluation process. The overall evaluation results indicate that by
performing pre-processing steps, such as stemming for agglutinative languages,
the system yields better results, eventually achieving 91% accuracy result in
the best performing model
",2022-05-31T16:21:00Z,http://arxiv.org/abs/2205.15930v1,"Sanatbek Matlatipov, Hulkar Rahimboeva, Jaloliddin Rajabov, Elmurod Kuriyozov"
Knowledge Graph Extraction from Videos,"  Nearly all existing techniques for automated video annotation (or captioning)
describe videos using natural language sentences. However, this has several
shortcomings: (i) it is very hard to then further use the generated natural
language annotations in automated data processing, (ii) generating natural
language annotations requires to solve the hard subtask of generating
semantically precise and syntactically correct natural language sentences,
which is actually unrelated to the task of video annotation, (iii) it is
difficult to quantitatively measure performance, as standard metrics (e.g.,
accuracy and F1-score) are inapplicable, and (iv) annotations are
language-specific. In this paper, we propose the new task of knowledge graph
extraction from videos, i.e., producing a description in the form of a
knowledge graph of the contents of a given video. Since no datasets exist for
this task, we also include a method to automatically generate them, starting
from datasets where videos are annotated with natural language. We then
describe an initial deep-learning model for knowledge graph extraction from
videos, and report results on MSVD* and MSR-VTT*, two datasets obtained from
MSVD and MSR-VTT using our method.
",2020-07-20T12:23:39Z,http://arxiv.org/abs/2007.10040v1,"Louis Mahon, Eleonora Giunchiglia, Bowen Li, Thomas Lukasiewicz"
TensorLayer: A Versatile Library for Efficient Deep Learning Development,"  Deep learning has enabled major advances in the fields of computer vision,
natural language processing, and multimedia among many others. Developing a
deep learning system is arduous and complex, as it involves constructing neural
network architectures, managing training/trained models, tuning optimization
process, preprocessing and organizing data, etc. TensorLayer is a versatile
Python library that aims at helping researchers and engineers efficiently
develop deep learning systems. It offers rich abstractions for neural networks,
model and data management, and parallel workflow mechanism. While boosting
efficiency, TensorLayer maintains both performance and scalability. TensorLayer
was released in September 2016 on GitHub, and has helped people from academia
and industry develop real-world applications of deep learning.
",2017-07-26T17:29:49Z,http://arxiv.org/abs/1707.08551v3,"Hao Dong, Akara Supratak, Luo Mai, Fangde Liu, Axel Oehmichen, Simiao Yu, Yike Guo"
Deviation bound for non-causal machine learning,"  Concentration inequalities are widely used for analyzing machine learning
algorithms. However, current concentration inequalities cannot be applied to
some of the most popular deep neural networks, notably in natural language
processing. This is mostly due to the non-causal nature of such involved data,
in the sense that each data point depends on other neighbor data points. In
this paper, a framework for modeling non-causal random fields is provided and a
Hoeffding-type concentration inequality is obtained for this framework. The
proof of this result relies on a local approximation of the non-causal random
field by a function of a finite number of i.i.d. random variables.
",2020-09-18T15:57:59Z,http://arxiv.org/abs/2009.08905v2,"R√©my Garnier, Rapha√´l Langhendries"
"Natural Language Processing 4 All (NLP4All): A New Online Platform for
  Teaching and Learning NLP Concepts","  Natural Language Processing offers new insights into language data across
almost all disciplines and domains, and allows us to corroborate and/or
challenge existing knowledge. The primary hurdles to widening participation in
and use of these new research tools are, first, a lack of coding skills in
students across K-16, and in the population at large, and second, a lack of
knowledge of how NLP-methods can be used to answer questions of disciplinary
interest outside of linguistics and/or computer science. To broaden
participation in NLP and improve NLP-literacy, we introduced a new tool
web-based tool called Natural Language Processing 4 All (NLP4All). The intended
purpose of NLP4All is to help teachers facilitate learning with and about NLP,
by providing easy-to-use interfaces to NLP-methods, data, and analyses, making
it possible for non- and novice-programmers to learn NLP concepts
interactively.
",2021-05-28T09:57:22Z,http://arxiv.org/abs/2105.13704v1,"Rebekah Baglini, Arthur Hjorth"
"Evaluating the Translation Performance of Large Language Models Based on
  Euas-20","  In recent years, with the rapid development of deep learning technology,
large language models (LLMs) such as BERT and GPT have achieved breakthrough
results in natural language processing tasks. Machine translation (MT), as one
of the core tasks of natural language processing, has also benefited from the
development of large language models and achieved a qualitative leap. Despite
the significant progress in translation performance achieved by large language
models, machine translation still faces many challenges. Therefore, in this
paper, we construct the dataset Euas-20 to evaluate the performance of large
language models on translation tasks, the translation ability on different
languages, and the effect of pre-training data on the translation ability of
LLMs for researchers and developers.
",2024-08-06T11:49:11Z,http://arxiv.org/abs/2408.03119v1,"Yan Huang, Wei Liu"
"Learning Convolutional Text Representations for Visual Question
  Answering","  Visual question answering is a recently proposed artificial intelligence task
that requires a deep understanding of both images and texts. In deep learning,
images are typically modeled through convolutional neural networks, and texts
are typically modeled through recurrent neural networks. While the requirement
for modeling images is similar to traditional computer vision tasks, such as
object recognition and image classification, visual question answering raises a
different need for textual representation as compared to other natural language
processing tasks. In this work, we perform a detailed analysis on natural
language questions in visual question answering. Based on the analysis, we
propose to rely on convolutional neural networks for learning textual
representations. By exploring the various properties of convolutional neural
networks specialized for text data, such as width and depth, we present our
""CNN Inception + Gate"" model. We show that our model improves question
representations and thus the overall accuracy of visual question answering
models. We also show that the text representation requirement in visual
question answering is more complicated and comprehensive than that in
conventional natural language processing tasks, making it a better task to
evaluate textual representation methods. Shallow models like fastText, which
can obtain comparable results with deep learning models in tasks like text
classification, are not suitable in visual question answering.
",2017-05-18T22:51:44Z,http://arxiv.org/abs/1705.06824v2,"Zhengyang Wang, Shuiwang Ji"
"Deep Learning-based Software Engineering: Progress, Challenges, and
  Opportunities","  Researchers have recently achieved significant advances in deep learning
techniques, which in turn has substantially advanced other research
disciplines, such as natural language processing, image processing, speech
recognition, and software engineering. Various deep learning techniques have
been successfully employed to facilitate software engineering tasks, including
code generation, software refactoring, and fault localization. Many papers have
also been presented in top conferences and journals, demonstrating the
applications of deep learning techniques in resolving various software
engineering tasks. However, although several surveys have provided overall
pictures of the application of deep learning techniques in software
engineering, they focus more on learning techniques, that is, what kind of deep
learning techniques are employed and how deep models are trained or fine-tuned
for software engineering tasks. We still lack surveys explaining the advances
of subareas in software engineering driven by deep learning techniques, as well
as challenges and opportunities in each subarea. To this end, in this paper, we
present the first task-oriented survey on deep learning-based software
engineering. It covers twelve major software engineering subareas significantly
impacted by deep learning techniques. Such subareas spread out the through the
whole lifecycle of software development and maintenance, including requirements
engineering, software development, testing, maintenance, and developer
collaboration. As we believe that deep learning may provide an opportunity to
revolutionize the whole discipline of software engineering, providing one
survey covering as many subareas as possible in software engineering can help
future research push forward the frontier of deep learning-based software
engineering more systematically.
",2024-10-17T00:46:00Z,http://arxiv.org/abs/2410.13110v1,"Xiangping Chen, Xing Hu, Yuan Huang, He Jiang, Weixing Ji, Yanjie Jiang, Yanyan Jiang, Bo Liu, Hui Liu, Xiaochen Li, Xiaoli Lian, Guozhu Meng, Xin Peng, Hailong Sun, Lin Shi, Bo Wang, Chong Wang, Jiayi Wang, Tiantian Wang, Jifeng Xuan, Xin Xia, Yibiao Yang, Yixin Yang, Li Zhang, Yuming Zhou, Lu Zhang"
"Proceedings 36th International Conference on Logic Programming
  (Technical Communications)","  Since the first conference held in Marseille in 1982, ICLP has been the
premier international event for presenting research in logic programming.
Contributions are solicited in all areas of logic programming and related
areas, including but not restricted to:
  - Foundations: Semantics, Formalisms, Answer-Set Programming, Non-monotonic
Reasoning, Knowledge Representation.
  - Declarative Programming: Inference engines, Analysis, Type and mode
inference, Partial evaluation, Abstract interpretation, Transformation,
Validation, Verification, Debugging, Profiling, Testing, Logic-based
domain-specific languages, constraint handling rules.
  - Related Paradigms and Synergies: Inductive and Co-inductive Logic
Programming, Constraint Logic Programming, Interaction with SAT, SMT and CSP
solvers, Logic programming techniques for type inference and theorem proving,
Argumentation, Probabilistic Logic Programming, Relations to object-oriented
and Functional programming, Description logics, Neural-Symbolic Machine
Learning, Hybrid Deep Learning and Symbolic Reasoning.
  - Implementation: Concurrency and distribution, Objects, Coordination,
Mobility, Virtual machines, Compilation, Higher Order, Type systems, Modules,
Constraint handling rules, Meta-programming, Foreign interfaces, User
interfaces.
  - Applications: Databases, Big Data, Data Integration and Federation,
Software Engineering, Natural Language Processing, Web and Semantic Web,
Agents, Artificial Intelligence, Bioinformatics, Education, Computational life
sciences, Education, Cybersecurity, and Robotics.
",2020-09-19T04:18:41Z,http://arxiv.org/abs/2009.09158v1,"Francesco Ricca, Alessandra Russo, Sergio Greco, Nicola Leone, Alexander Artikis, Gerhard Friedrich, Paul Fodor, Angelika Kimmig, Francesca Lisi, Marco Maratea, Alessandra Mileo, Fabrizio Riguzzi"
NegDL: Privacy-Preserving Deep Learning Based on Negative Database,"  In the era of big data, deep learning has become an increasingly popular
topic. It has outstanding achievements in the fields of image recognition,
object detection, and natural language processing et al. The first priority of
deep learning is exploiting valuable information from a large amount of data,
which will inevitably induce privacy issues that are worthy of attention.
Presently, several privacy-preserving deep learning methods have been proposed,
but most of them suffer from a non-negligible degradation of either efficiency
or accuracy. Negative database (\textit{NDB}) is a new type of data
representation which can protect data privacy by storing and utilizing the
complementary form of original data. In this paper, we propose a
privacy-preserving deep learning method named NegDL based on \textit{NDB}.
Specifically, private data are first converted to \textit{NDB} as the input of
deep learning models by a generation algorithm called \textit{QK}-hidden
algorithm, and then the sketches of \textit{NDB} are extracted for training and
inference. We demonstrate that the computational complexity of NegDL is the
same as the original deep learning model without privacy protection.
Experimental results on Breast Cancer, MNIST, and CIFAR-10 benchmark datasets
demonstrate that the accuracy of NegDL could be comparable to the original deep
learning model in most cases, and it performs better than the method based on
differential privacy.
",2021-03-10T03:34:03Z,http://arxiv.org/abs/2103.05854v5,"Dongdong Zhao, Pingchuan Zhang, Jianwen Xiang, Jing Tian"
"A Novel Method for improving accuracy in neural network by reinstating
  traditional back propagation technique","  Deep learning has revolutionized industries like computer vision, natural
language processing, and speech recognition. However, back propagation, the
main method for training deep neural networks, faces challenges like
computational overhead and vanishing gradients. In this paper, we propose a
novel instant parameter update methodology that eliminates the need for
computing gradients at each layer. Our approach accelerates learning, avoids
the vanishing gradient problem, and outperforms state-of-the-art methods on
benchmark data sets. This research presents a promising direction for efficient
and effective deep neural network training.
",2023-08-09T16:41:00Z,http://arxiv.org/abs/2308.05059v1,Gokulprasath R
"A Survey of Methods for Addressing Class Imbalance in Deep-Learning
  Based Natural Language Processing","  Many natural language processing (NLP) tasks are naturally imbalanced, as
some target categories occur much more frequently than others in the real
world. In such scenarios, current NLP models still tend to perform poorly on
less frequent classes. Addressing class imbalance in NLP is an active research
topic, yet, finding a good approach for a particular task and imbalance
scenario is difficult.
  With this survey, the first overview on class imbalance in deep-learning
based NLP, we provide guidance for NLP researchers and practitioners dealing
with imbalanced data. We first discuss various types of controlled and
real-world class imbalance. Our survey then covers approaches that have been
explicitly proposed for class-imbalanced NLP tasks or, originating in the
computer vision community, have been evaluated on them. We organize the methods
by whether they are based on sampling, data augmentation, choice of loss
function, staged learning, or model design. Finally, we discuss open problems
such as dealing with multi-label scenarios, and propose systematic benchmarking
and reporting in order to move forward on this problem as a community.
",2022-10-10T13:26:40Z,http://arxiv.org/abs/2210.04675v2,"Sophie Henning, William Beluch, Alexander Fraser, Annemarie Friedrich"
Deep Active Learning for Named Entity Recognition,"  Deep learning has yielded state-of-the-art performance on many natural
language processing tasks including named entity recognition (NER). However,
this typically requires large amounts of labeled data. In this work, we
demonstrate that the amount of labeled training data can be drastically reduced
when deep learning is combined with active learning. While active learning is
sample-efficient, it can be computationally expensive since it requires
iterative retraining. To speed this up, we introduce a lightweight architecture
for NER, viz., the CNN-CNN-LSTM model consisting of convolutional character and
word encoders and a long short term memory (LSTM) tag decoder. The model
achieves nearly state-of-the-art performance on standard datasets for the task
while being computationally much more efficient than best performing models. We
carry out incremental active learning, during the training process, and are
able to nearly match state-of-the-art performance with just 25\% of the
original training data.
",2017-07-19T03:18:40Z,http://arxiv.org/abs/1707.05928v3,"Yanyao Shen, Hyokun Yun, Zachary C. Lipton, Yakov Kronrod, Animashree Anandkumar"
Low-Rank Deep Convolutional Neural Network for Multi-Task Learning,"  In this paper, we propose a novel multi-task learning method based on the
deep convolutional network. The proposed deep network has four convolutional
layers, three max-pooling layers, and two parallel fully connected layers. To
adjust the deep network to multi-task learning problem, we propose to learn a
low-rank deep network so that the relation among different tasks can be
explored. We proposed to minimize the number of independent parameter rows of
one fully connected layer to explore the relations among different tasks, which
is measured by the nuclear norm of the parameter of one fully connected layer,
and seek a low-rank parameter matrix. Meanwhile, we also propose to regularize
another fully connected layer by sparsity penalty, so that the useful features
learned by the lower layers can be selected. The learning problem is solved by
an iterative algorithm based on gradient descent and back-propagation
algorithms. The proposed algorithm is evaluated over benchmark data sets of
multiple face attribute prediction, multi-task natural language processing, and
joint economics index predictions. The evaluation results show the advantage of
the low-rank deep CNN model over multi-task problems.
",2019-04-12T14:20:01Z,http://arxiv.org/abs/1904.07320v1,"Fang Su, Hai-Yang Shang, Jing-Yan Wang"
An End-to-end Neural Natural Language Interface for Databases,"  The ability to extract insights from new data sets is critical for decision
making. Visual interactive tools play an important role in data exploration
since they provide non-technical users with an effective way to visually
compose queries and comprehend the results. Natural language has recently
gained traction as an alternative query interface to databases with the
potential to enable non-expert users to formulate complex questions and
information needs efficiently and effectively. However, understanding natural
language questions and translating them accurately to SQL is a challenging
task, and thus Natural Language Interfaces for Databases (NLIDBs) have not yet
made their way into practical tools and commercial products.
  In this paper, we present DBPal, a novel data exploration tool with a natural
language interface. DBPal leverages recent advances in deep models to make
query understanding more robust in the following ways: First, DBPal uses a deep
model to translate natural language statements to SQL, making the translation
process more robust to paraphrasing and other linguistic variations. Second, to
support the users in phrasing questions without knowing the database schema and
the query features, DBPal provides a learned auto-completion model that
suggests partial query extensions to users during query formulation and thus
helps to write complex queries.
",2018-04-02T05:36:38Z,http://arxiv.org/abs/1804.00401v1,"Prasetya Utama, Nathaniel Weir, Fuat Basik, Carsten Binnig, Ugur Cetintemel, Benjamin H√§ttasch, Amir Ilkhechi, Shekar Ramaswamy, Arif Usta"
"Subsentence Extraction from Text Using Coverage-Based Deep Learning
  Language Models","  Sentiment prediction remains a challenging and unresolved task in various
research fields, including psychology, neuroscience, and computer science. This
stems from its high degree of subjectivity and limited input sources that can
effectively capture the actual sentiment. This can be even more challenging
with only text-based input. Meanwhile, the rise of deep learning and an
unprecedented large volume of data have paved the way for artificial
intelligence to perform impressively accurate predictions or even human-level
reasoning. Drawing inspiration from this, we propose a coverage-based sentiment
and subsentence extraction system that estimates a span of input text and
recursively feeds this information back to the networks. The predicted
subsentence consists of auxiliary information expressing a sentiment. This is
an important building block for enabling vivid and epic sentiment delivery
(within the scope of this paper) and for other natural language processing
tasks such as text summarisation and Q&A. Our approach outperforms the
state-of-the-art approaches by a large margin in subsentence prediction (i.e.,
Average Jaccard scores from 0.72 to 0.89). For the evaluation, we designed
rigorous experiments consisting of 24 ablation studies. Finally, our learned
lessons are returned to the community by sharing software packages and a public
dataset that can reproduce the results presented in this paper.
",2021-04-20T06:24:49Z,http://arxiv.org/abs/2104.09777v2,"JongYoon Lim, Inkyu Sa, Ho Seok Ahn, Norina Gasteiger, Sanghyub John Lee, Bruce MacDonald"
"Frontiers of Deep Learning: From Novel Application to Real-World
  Deployment","  Deep learning continues to re-shape numerous fields, from natural language
processing and imaging to data analytics and recommendation systems. This
report studies two research papers that represent recent progress on deep
learning from two largely different aspects: The first paper applied the
transformer networks, which are typically used in language models, to improve
the quality of synthetic aperture radar image by effectively reducing the
speckle noise. The second paper presents an in-storage computing design
solution to enable cost-efficient and high-performance implementations of deep
learning recommendation systems. In addition to summarizing each paper in terms
of motivation, key ideas and techniques, and evaluation results, this report
also presents thoughts and discussions about possible future research
directions. By carrying out in-depth study on these two representative papers
and related references, this doctoral candidate has developed better
understanding on the far-reaching impact and efficient implementation of deep
learning models.
",2024-07-19T15:11:55Z,http://arxiv.org/abs/2407.14386v1,Rui Xie
"Superiorities of Deep Extreme Learning Machines against Convolutional
  Neural Networks","  Deep Learning (DL) is a machine learning procedure for artificial
intelligence that analyzes the input data in detail by increasing neuron sizes
and number of the hidden layers. DL has a popularity with the common
improvements on the graphical processing unit capabilities. Increasing number
of the neuron sizes at each layer and hidden layers is directly related to the
computation time and training speed of the classifier models. The
classification parameters including neuron weights, output weights, and biases
need to be optimized for obtaining an optimum model. Most of the popular DL
algorithms require long training times for optimization of the parameters with
feature learning progresses and back-propagated training procedures. Reducing
the training time and providing a real-time decision system are the basic focus
points of the novel approaches. Deep Extreme Learning machines (Deep ELM)
classifier model is one of the fastest and effective way to meet fast
classification problems. In this study, Deep ELM model, its superiorities and
weaknesses are discussed, the problems that are more suitable for the
classifiers against Convolutional neural network based DL algorithms.
",2021-01-21T08:22:18Z,http://arxiv.org/abs/2101.10265v1,"Gokhan Altan, Yakup Kutlu"
Ranking Creative Language Characteristics in Small Data Scenarios,"  The ability to rank creative natural language provides an important general
tool for downstream language understanding and generation. However, current
deep ranking models require substantial amounts of labeled data that are
difficult and expensive to obtain for different domains, languages and creative
characteristics. A recent neural approach, the DirectRanker, promises to reduce
the amount of training data needed but its application to text isn't fully
explored. We therefore adapt the DirectRanker to provide a new deep model for
ranking creative language with small data. We compare DirectRanker with a
Bayesian approach, Gaussian process preference learning (GPPL), which has
previously been shown to work well with sparse data. Our experiments with
sparse training data show that while the performance of standard neural ranking
approaches collapses with small training datasets, DirectRanker remains
effective. We find that combining DirectRanker with GPPL increases performance
across different settings by leveraging the complementary benefits of both
models. Our combined approach outperforms the previous state-of-the-art on
humor and metaphor novelty tasks, increasing Spearman's $\rho$ by 14% and 16%
on average.
",2020-10-23T18:57:47Z,http://arxiv.org/abs/2010.12613v1,"Julia Siekiera, Marius K√∂ppel, Edwin Simpson, Kevin Stowe, Iryna Gurevych, Stefan Kramer"
Deep Reinforcement Learning: An Overview,"  In recent years, a specific machine learning method called deep learning has
gained huge attraction, as it has obtained astonishing results in broad
applications such as pattern recognition, speech recognition, computer vision,
and natural language processing. Recent research has also been shown that deep
learning techniques can be combined with reinforcement learning methods to
learn useful representations for the problems with high dimensional raw data
input. This chapter reviews the recent advances in deep reinforcement learning
with a focus on the most used deep architectures such as autoencoders,
convolutional neural networks and recurrent neural networks which have
successfully been come together with the reinforcement learning framework.
",2018-06-23T02:18:26Z,http://arxiv.org/abs/1806.08894v1,"Seyed Sajad Mousavi, Michael Schukat, Enda Howley"
The Natural Language Decathlon: Multitask Learning as Question Answering,"  Deep learning has improved performance on many natural language processing
(NLP) tasks individually. However, general NLP models cannot emerge within a
paradigm that focuses on the particularities of a single metric, dataset, and
task. We introduce the Natural Language Decathlon (decaNLP), a challenge that
spans ten tasks: question answering, machine translation, summarization,
natural language inference, sentiment analysis, semantic role labeling,
zero-shot relation extraction, goal-oriented dialogue, semantic parsing, and
commonsense pronoun resolution. We cast all tasks as question answering over a
context. Furthermore, we present a new Multitask Question Answering Network
(MQAN) jointly learns all tasks in decaNLP without any task-specific modules or
parameters in the multitask setting. MQAN shows improvements in transfer
learning for machine translation and named entity recognition, domain
adaptation for sentiment analysis and natural language inference, and zero-shot
capabilities for text classification. We demonstrate that the MQAN's
multi-pointer-generator decoder is key to this success and performance further
improves with an anti-curriculum training strategy. Though designed for
decaNLP, MQAN also achieves state of the art results on the WikiSQL semantic
parsing task in the single-task setting. We also release code for procuring and
processing data, training and evaluating models, and reproducing all
experiments for decaNLP.
",2018-06-20T16:39:26Z,http://arxiv.org/abs/1806.08730v1,"Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, Richard Socher"
Transformers for scientific data: a pedagogical review for astronomers,"  The deep learning architecture associated with ChatGPT and related generative
AI products is known as transformers. Initially applied to Natural Language
Processing, transformers and the self-attention mechanism they exploit have
gained widespread interest across the natural sciences. The goal of this
pedagogical and informal review is to introduce transformers to scientists. The
review includes the mathematics underlying the attention mechanism, a
description of the original transformer architecture, and a section on
applications to time series and imaging data in astronomy. We include a
Frequently Asked Questions section for readers who are curious about generative
AI or interested in getting started with transformers for their research
problem.
",2023-10-18T16:02:32Z,http://arxiv.org/abs/2310.12069v2,"Dimitrios Tanoglidis, Bhuvnesh Jain, Helen Qu"
"Harnessing Transfer Learning from Swahili: Advancing Solutions for
  Comorian Dialects","  If today some African languages like Swahili have enough resources to develop
high-performing Natural Language Processing (NLP) systems, many other languages
spoken on the continent are still lacking such support. For these languages,
still in their infancy, several possibilities exist to address this critical
lack of data. Among them is Transfer Learning, which allows low-resource
languages to benefit from the good representation of other languages that are
similar to them. In this work, we adopt a similar approach, aiming to pioneer
NLP technologies for Comorian, a group of four languages or dialects belonging
to the Bantu family.
  Our approach is initially motivated by the hypothesis that if a human can
understand a different language from their native language with little or no
effort, it would be entirely possible to model this process on a machine. To
achieve this, we consider ways to construct Comorian datasets mixed with
Swahili. One thing to note here is that in terms of Swahili data, we only focus
on elements that are closest to Comorian by calculating lexical distances
between candidate and source data. We empirically test this hypothesis in two
use cases: Automatic Speech Recognition (ASR) and Machine Translation (MT). Our
MT model achieved ROUGE-1, ROUGE-2, and ROUGE-L scores of 0.6826, 0.42, and
0.6532, respectively, while our ASR system recorded a WER of 39.50\% and a CER
of 13.76\%. This research is crucial for advancing NLP in underrepresented
languages, with potential to preserve and promote Comorian linguistic heritage
in the digital age.
",2024-12-09T22:47:41Z,http://arxiv.org/abs/2412.12143v1,"Naira Abdou Mohamed, Zakarya Erraji, Abdessalam Bahafid, Imade Benelallam"
"Robustness Evaluation of Deep Unsupervised Learning Algorithms for
  Intrusion Detection Systems","  Recently, advances in deep learning have been observed in various fields,
including computer vision, natural language processing, and cybersecurity.
Machine learning (ML) has demonstrated its ability as a potential tool for
anomaly detection-based intrusion detection systems to build secure computer
networks. Increasingly, ML approaches are widely adopted than heuristic
approaches for cybersecurity because they learn directly from data. Data is
critical for the development of ML systems, and becomes potential targets for
attackers. Basically, data poisoning or contamination is one of the most common
techniques used to fool ML models through data. This paper evaluates the
robustness of six recent deep learning algorithms for intrusion detection on
contaminated data. Our experiments suggest that the state-of-the-art algorithms
used in this study are sensitive to data contamination and reveal the
importance of self-defense against data perturbation when developing novel
models, especially for intrusion detection systems.
",2022-06-25T02:28:39Z,http://arxiv.org/abs/2207.03576v2,"D'Jeff Kanda Nkashama, Arian Soltani, Jean-Charles Verdier, Marc Frappier, Pierre-Martin Tardif, Froduald Kabanza"
Deep Natural Language Processing for LinkedIn Search,"  Many search systems work with large amounts of natural language data, e.g.,
search queries, user profiles, and documents. Building a successful search
system requires a thorough understanding of textual data semantics, where deep
learning based natural language processing techniques (deep NLP) can be of
great help. In this paper, we introduce a comprehensive study for applying deep
NLP techniques to five representative tasks in search systems: query intent
prediction (classification), query tagging (sequential tagging), document
ranking (ranking), query auto completion (language modeling), and query
suggestion (sequence to sequence). We also introduce BERT pre-training as a
sixth task that can be applied to many of the other tasks. Through the model
design and experiments of the six tasks, readers can find answers to four
important questions: (1). When is deep NLP helpful/not helpful in search
systems? (2). How to address latency challenges? (3). How to ensure model
robustness? This work builds on existing efforts of LinkedIn search, and is
tested at scale on LinkedIn's commercial search engines. We believe our
experiences can provide useful insights for the industry and research
communities.
",2021-08-16T23:37:33Z,http://arxiv.org/abs/2108.13300v1,"Weiwei Guo, Xiaowei Liu, Sida Wang, Michaeel Kazi, Zhiwei Wang, Zhoutong Fu, Jun Jia, Liang Zhang, Huiji Gao, Bo Long"
Deep Learning on Graphs: A Survey,"  Deep learning has been shown to be successful in a number of domains, ranging
from acoustics, images, to natural language processing. However, applying deep
learning to the ubiquitous graph data is non-trivial because of the unique
characteristics of graphs. Recently, substantial research efforts have been
devoted to applying deep learning methods to graphs, resulting in beneficial
advances in graph analysis techniques. In this survey, we comprehensively
review the different types of deep learning methods on graphs. We divide the
existing methods into five categories based on their model architectures and
training strategies: graph recurrent neural networks, graph convolutional
networks, graph autoencoders, graph reinforcement learning, and graph
adversarial methods. We then provide a comprehensive overview of these methods
in a systematic manner mainly by following their development history. We also
analyze the differences and compositions of different methods. Finally, we
briefly outline the applications in which they have been used and discuss
potential future research directions.
",2018-12-11T03:16:57Z,http://arxiv.org/abs/1812.04202v3,"Ziwei Zhang, Peng Cui, Wenwu Zhu"
Towards More Robust Natural Language Understanding,"  Natural Language Understanding (NLU) is a branch of Natural Language
Processing (NLP) that uses intelligent computer software to understand texts
that encode human knowledge. Recent years have witnessed notable progress
across various NLU tasks with deep learning techniques, especially with
pretrained language models. Besides proposing more advanced model
architectures, constructing more reliable and trustworthy datasets also plays a
huge role in improving NLU systems, without which it would be impossible to
train a decent NLU model. It's worth noting that the human ability of
understanding natural language is flexible and robust. On the contrary, most of
existing NLU systems fail to achieve desirable performance on out-of-domain
data or struggle on handling challenging items (e.g., inherently ambiguous
items, adversarial items) in the real world. Therefore, in order to have NLU
models understand human language more effectively, it is expected to prioritize
the study on robust natural language understanding. In this thesis, we deem
that NLU systems are consisting of two components: NLU models and NLU datasets.
As such, we argue that, to achieve robust NLU, the model architecture/training
and the dataset are equally important. Specifically, we will focus on three NLU
tasks to illustrate the robustness problem in different NLU tasks and our
contributions (i.e., novel models and new datasets) to help achieve more robust
natural language understanding. Moving forward, the ultimate goal for robust
natural language understanding is to build NLU models which can behave humanly.
That is, it's expected that robust NLU systems are capable to transfer the
knowledge from training corpus to unseen documents more reliably and survive
when encountering challenging items even if the system doesn't know a priori of
users' inputs.
",2021-12-01T17:27:19Z,http://arxiv.org/abs/2112.02992v2,Xinliang Frederick Zhang
"Robotic Planning under Uncertainty in Spatiotemporal Environments in
  Expeditionary Science","  In the expeditionary sciences, spatiotemporally varying environments --
hydrothermal plumes, algal blooms, lava flows, or animal migrations -- are
ubiquitous. Mobile robots are uniquely well-suited to study these dynamic,
mesoscale natural environments. We formalize expeditionary science as a
sequential decision-making problem, modeled using the language of
partially-observable Markov decision processes (POMDPs). Solving the
expeditionary science POMDP under real-world constraints requires efficient
probabilistic modeling and decision-making in problems with complex dynamics
and observational models. Previous work in informative path planning, adaptive
sampling, and experimental design have shown compelling results, largely in
static environments, using data-driven models and information-based rewards.
However, these methodologies do not trivially extend to expeditionary science
in spatiotemporal environments: they generally do not make use of scientific
knowledge such as equations of state dynamics, they focus on information
gathering as opposed to scientific task execution, and they make use of
decision-making approaches that scale poorly to large, continuous problems with
long planning horizons and real-time operational constraints. In this work, we
discuss these and other challenges related to probabilistic modeling and
decision-making in expeditionary science, and present some of our preliminary
work that addresses these gaps. We ground our results in a real expeditionary
science deployment of an autonomous underwater vehicle (AUV) in the deep ocean
for hydrothermal vent discovery and characterization. Our concluding thoughts
highlight remaining work to be done, and the challenges that merit
consideration by the reinforcement learning and decision-making community.
",2022-06-03T02:04:15Z,http://arxiv.org/abs/2206.01364v1,"Victoria Preston, Genevieve Flaspohler, Anna P. M. Michel, John W. Fisher III, Nicholas Roy"
"Surf at MEDIQA 2019: Improving Performance of Natural Language Inference
  in the Clinical Domain by Adopting Pre-trained Language Model","  While deep learning techniques have shown promising results in many natural
language processing (NLP) tasks, it has not been widely applied to the clinical
domain. The lack of large datasets and the pervasive use of domain-specific
language (i.e. abbreviations and acronyms) in the clinical domain causes slower
progress in NLP tasks than that of the general NLP tasks. To fill this gap, we
employ word/subword-level based models that adopt large-scale data-driven
methods such as pre-trained language models and transfer learning in analyzing
text for the clinical domain. Empirical results demonstrate the superiority of
the proposed methods by achieving 90.6% accuracy in medical domain natural
language inference task. Furthermore, we inspect the independent strengths of
the proposed approaches in quantitative and qualitative manners. This analysis
will help researchers to select necessary components in building models for the
medical domain.
",2019-06-19T00:13:04Z,http://arxiv.org/abs/1906.07854v1,"Jiin Nam, Seunghyun Yoon, Kyomin Jung"
"Uncertainty over Uncertainty: Investigating the Assumptions,
  Annotations, and Text Measurements of Economic Policy Uncertainty","  Methods and applications are inextricably linked in science, and in
particular in the domain of text-as-data. In this paper, we examine one such
text-as-data application, an established economic index that measures economic
policy uncertainty from keyword occurrences in news. This index, which is shown
to correlate with firm investment, employment, and excess market returns, has
had substantive impact in both the private sector and academia. Yet, as we
revisit and extend the original authors' annotations and text measurements we
find interesting text-as-data methodological research questions: (1) Are
annotator disagreements a reflection of ambiguity in language? (2) Do
alternative text measurements correlate with one another and with measures of
external predictive validity? We find for this application (1) some annotator
disagreements of economic policy uncertainty can be attributed to ambiguity in
language, and (2) switching measurements from keyword-matching to supervised
machine learning classifiers results in low correlation, a concerning
implication for the validity of the index.
",2020-10-09T17:50:29Z,http://arxiv.org/abs/2010.04706v1,"Katherine A. Keith, Christoph Teichmann, Brendan O'Connor, Edgar Meij"
Deep Reinforcement Learning,"  We discuss deep reinforcement learning in an overview style. We draw a big
picture, filled with details. We discuss six core elements, six important
mechanisms, and twelve applications, focusing on contemporary work, and in
historical contexts. We start with background of artificial intelligence,
machine learning, deep learning, and reinforcement learning (RL), with
resources. Next we discuss RL core elements, including value function, policy,
reward, model, exploration vs. exploitation, and representation. Then we
discuss important mechanisms for RL, including attention and memory,
unsupervised learning, hierarchical RL, multi-agent RL, relational RL, and
learning to learn. After that, we discuss RL applications, including games,
robotics, natural language processing (NLP), computer vision, finance, business
management, healthcare, education, energy, transportation, computer systems,
and, science, engineering, and art. Finally we summarize briefly, discuss
challenges and opportunities, and close with an epilogue.
",2018-10-15T13:20:56Z,http://arxiv.org/abs/1810.06339v1,Yuxi Li
"To lemmatize or not to lemmatize: how word normalisation affects ELMo
  performance in word sense disambiguation","  We critically evaluate the widespread assumption that deep learning NLP
models do not require lemmatized input. To test this, we trained versions of
contextualised word embedding ELMo models on raw tokenized corpora and on the
corpora with word tokens replaced by their lemmas. Then, these models were
evaluated on the word sense disambiguation task. This was done for the English
and Russian languages.
  The experiments showed that while lemmatization is indeed not necessary for
English, the situation is different for Russian. It seems that for
rich-morphology languages, using lemmatized training and testing data yields
small but consistent improvements: at least for word sense disambiguation. This
means that the decisions about text pre-processing before training ELMo should
consider the linguistic nature of the language in question.
",2019-09-06T21:49:47Z,http://arxiv.org/abs/1909.03135v1,"Andrey Kutuzov, Elizaveta Kuzmenko"
"Leveraging Large Language Models for Knowledge-free Weak Supervision in
  Clinical Natural Language Processing","  The performance of deep learning-based natural language processing systems is
based on large amounts of labeled training data which, in the clinical domain,
are not easily available or affordable. Weak supervision and in-context
learning offer partial solutions to this issue, particularly using large
language models (LLMs), but their performance still trails traditional
supervised methods with moderate amounts of gold-standard data. In particular,
inferencing with LLMs is computationally heavy. We propose an approach
leveraging fine-tuning LLMs and weak supervision with virtually no domain
knowledge that still achieves consistently dominant performance. Using a
prompt-based approach, the LLM is used to generate weakly-labeled data for
training a downstream BERT model. The weakly supervised model is then further
fine-tuned on small amounts of gold standard data. We evaluate this approach
using Llama2 on three different n2c2 datasets. With no more than 10 gold
standard notes, our final BERT models weakly supervised by fine-tuned
Llama2-13B consistently outperformed out-of-the-box PubMedBERT by 4.7% to 47.9%
in F1 scores. With only 50 gold standard notes, our models achieved close
performance to fully fine-tuned systems.
",2024-06-10T18:34:48Z,http://arxiv.org/abs/2406.06723v1,"Enshuo Hsu, Kirk Roberts"
"RECKONition: a NLP-based system for Industrial Accidents at Work
  Prevention","  Extracting patterns and useful information from Natural Language datasets is
a challenging task, especially when dealing with data written in a language
different from English, like Italian. Machine and Deep Learning, together with
Natural Language Processing (NLP) techniques have widely spread and improved
lately, providing a plethora of useful methods to address both Supervised and
Unsupervised problems on textual information. We propose RECKONition, a
NLP-based system for Industrial Accidents at Work Prevention. RECKONition,
which is meant to provide Natural Language Understanding, Clustering and
Inference, is the result of a joint partnership with the Italian National
Institute for Insurance against Accidents at Work (INAIL). The obtained results
showed the ability to process textual data written in Italian describing
industrial accidents dynamics and consequences.
",2021-04-29T07:13:07Z,http://arxiv.org/abs/2104.14150v1,"Patrizia Agnello, Silvia M. Ansaldi, Emilia Lenzi, Alessio Mongelluzzo, Manuel Roveri"
"A Survey of Deep Graph Clustering: Taxonomy, Challenge, Application, and
  Open Resource","  Graph clustering, which aims to divide nodes in the graph into several
distinct clusters, is a fundamental yet challenging task. Benefiting from the
powerful representation capability of deep learning, deep graph clustering
methods have achieved great success in recent years. However, the corresponding
survey paper is relatively scarce, and it is imminent to make a summary of this
field. From this motivation, we conduct a comprehensive survey of deep graph
clustering. Firstly, we introduce formulaic definition, evaluation, and
development in this field. Secondly, the taxonomy of deep graph clustering
methods is presented based on four different criteria, including graph type,
network architecture, learning paradigm, and clustering method. Thirdly, we
carefully analyze the existing methods via extensive experiments and summarize
the challenges and opportunities from five perspectives, including graph data
quality, stability, scalability, discriminative capability, and unknown cluster
number. Besides, the applications of deep graph clustering methods in six
domains, including computer vision, natural language processing, recommendation
systems, social network analyses, bioinformatics, and medical science, are
presented. Last but not least, this paper provides open resource supports,
including 1) a collection
(\url{https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering}) of
state-of-the-art deep graph clustering methods (papers, codes, and datasets)
and 2) a unified framework
(\url{https://github.com/Marigoldwu/A-Unified-Framework-for-Deep-Attribute-Graph-Clustering})
of deep graph clustering. We hope this work can serve as a quick guide and help
researchers overcome challenges in this vibrant field.
",2022-11-23T11:31:11Z,http://arxiv.org/abs/2211.12875v4,"Yue Liu, Jun Xia, Sihang Zhou, Xihong Yang, Ke Liang, Chenchen Fan, Yan Zhuang, Stan Z. Li, Xinwang Liu, Kunlun He"
"Large language models can be zero-shot anomaly detectors for time
  series?","  Recent studies have shown the ability of large language models to perform a
variety of tasks, including time series forecasting. The flexible nature of
these models allows them to be used for many applications. In this paper, we
present a novel study of large language models used for the challenging task of
time series anomaly detection. This problem entails two aspects novel for LLMs:
the need for the model to identify part of the input sequence (or multiple
parts) as anomalous; and the need for it to work with time series data rather
than the traditional text input. We introduce sigllm, a framework for time
series anomaly detection using large language models. Our framework includes a
time-series-to-text conversion module, as well as end-to-end pipelines that
prompt language models to perform time series anomaly detection. We investigate
two paradigms for testing the abilities of large language models to perform the
detection task. First, we present a prompt-based detection method that directly
asks a language model to indicate which elements of the input are anomalies.
Second, we leverage the forecasting capability of a large language model to
guide the anomaly detection process. We evaluated our framework on 11 datasets
spanning various sources and 10 pipelines. We show that the forecasting method
significantly outperformed the prompting method in all 11 datasets with respect
to the F1 score. Moreover, while large language models are capable of finding
anomalies, state-of-the-art deep learning models are still superior in
performance, achieving results 30% better than large language models.
",2024-05-23T16:21:57Z,http://arxiv.org/abs/2405.14755v3,"Sarah Alnegheimish, Linh Nguyen, Laure Berti-Equille, Kalyan Veeramachaneni"
RPC Considered Harmful: Fast Distributed Deep Learning on RDMA,"  Deep learning emerges as an important new resource-intensive workload and has
been successfully applied in computer vision, speech, natural language
processing, and so on. Distributed deep learning is becoming a necessity to
cope with growing data and model sizes. Its computation is typically
characterized by a simple tensor data abstraction to model multi-dimensional
matrices, a data-flow graph to model computation, and iterative executions with
relatively frequent synchronizations, thereby making it substantially different
from Map/Reduce style distributed big data computation.
  RPC, commonly used as the communication primitive, has been adopted by
popular deep learning frameworks such as TensorFlow, which uses gRPC. We show
that RPC is sub-optimal for distributed deep learning computation, especially
on an RDMA-capable network. The tensor abstraction and data-flow graph, coupled
with an RDMA network, offers the opportunity to reduce the unnecessary overhead
(e.g., memory copy) without sacrificing programmability and generality. In
particular, from a data access point of view, a remote machine is abstracted
just as a ""device"" on an RDMA channel, with a simple memory interface for
allocating, reading, and writing memory regions. Our graph analyzer looks at
both the data flow graph and the tensors to optimize memory allocation and
remote data access using this interface. The result is up to 25 times speedup
in representative deep learning benchmarks against the standard gRPC in
TensorFlow and up to 169% improvement even against an RPC implementation
optimized for RDMA, leading to faster convergence in the training process.
",2018-05-22T07:42:33Z,http://arxiv.org/abs/1805.08430v1,"Jilong Xue, Youshan Miao, Cheng Chen, Ming Wu, Lintao Zhang, Lidong Zhou"
"Deep Learning and Machine Learning -- Natural Language Processing: From
  Theory to Application","  With a focus on natural language processing (NLP) and the role of large
language models (LLMs), we explore the intersection of machine learning, deep
learning, and artificial intelligence. As artificial intelligence continues to
revolutionize fields from healthcare to finance, NLP techniques such as
tokenization, text classification, and entity recognition are essential for
processing and understanding human language. This paper discusses advanced data
preprocessing techniques and the use of frameworks like Hugging Face for
implementing transformer-based models. Additionally, it highlights challenges
such as handling multilingual data, reducing bias, and ensuring model
robustness. By addressing key aspects of data processing and model fine-tuning,
this work aims to provide insights into deploying effective and ethically sound
AI solutions.
",2024-10-30T09:35:35Z,http://arxiv.org/abs/2411.05026v2,"Keyu Chen, Cheng Fei, Ziqian Bi, Junyu Liu, Benji Peng, Sen Zhang, Xuanhe Pan, Jiawei Xu, Jinlang Wang, Caitlyn Heqi Yin, Yichao Zhang, Pohsun Feng, Yizhu Wen, Tianyang Wang, Ming Li, Jintao Ren, Qian Niu, Silin Chen, Weiche Hsieh, Lawrence K. Q. Yan, Chia Xin Liang, Han Xu, Hong-Ming Tseng, Xinyuan Song, Ming Liu"
"Enhancing Essay Scoring with Adversarial Weights Perturbation and
  Metric-specific AttentionPooling","  The objective of this study is to improve automated feedback tools designed
for English Language Learners (ELLs) through the utilization of data science
techniques encompassing machine learning, natural language processing, and
educational data analytics. Automated essay scoring (AES) research has made
strides in evaluating written essays, but it often overlooks the specific needs
of English Language Learners (ELLs) in language development. This study
explores the application of BERT-related techniques to enhance the assessment
of ELLs' writing proficiency within AES.
  To address the specific needs of ELLs, we propose the use of DeBERTa, a
state-of-the-art neural language model, for improving automated feedback tools.
DeBERTa, pretrained on large text corpora using self-supervised learning,
learns universal language representations adaptable to various natural language
understanding tasks. The model incorporates several innovative techniques,
including adversarial training through Adversarial Weights Perturbation (AWP)
and Metric-specific AttentionPooling (6 kinds of AP) for each label in the
competition.
  The primary focus of this research is to investigate the impact of
hyperparameters, particularly the adversarial learning rate, on the performance
of the model. By fine-tuning the hyperparameter tuning process, including the
influence of 6AP and AWP, the resulting models can provide more accurate
evaluations of language proficiency and support tailored learning tasks for
ELLs. This work has the potential to significantly benefit ELLs by improving
their English language proficiency and facilitating their educational journey.
",2024-01-06T06:05:12Z,http://arxiv.org/abs/2401.05433v1,"Jiaxin Huang, Xinyu Zhao, Chang Che, Qunwei Lin, Bo Liu"
"Recent Trends in the Use of Deep Learning Models for Grammar Error
  Handling","  Grammar error handling (GEH) is an important topic in natural language
processing (NLP). GEH includes both grammar error detection and grammar error
correction. Recent advances in computation systems have promoted the use of
deep learning (DL) models for NLP problems such as GEH. In this survey we focus
on two main DL approaches for GEH: neural machine translation models and editor
models. We describe the three main stages of the pipeline for these models:
data preparation, training, and inference. Additionally, we discuss different
techniques to improve the performance of these models at each stage of the
pipeline. We compare the performance of different models and conclude with
proposed future directions.
",2020-09-04T18:50:13Z,http://arxiv.org/abs/2009.02358v1,"Mina Naghshnejad, Tarun Joshi, Vijayan N. Nair"
"Potrika: Raw and Balanced Newspaper Datasets in the Bangla Language with
  Eight Topics and Five Attributes","  Knowledge is central to human and scientific developments. Natural Language
Processing (NLP) allows automated analysis and creation of knowledge. Data is a
crucial NLP and machine learning ingredient. The scarcity of open datasets is a
well-known problem in machine and deep learning research. This is very much the
case for textual NLP datasets in English and other major world languages. For
the Bangla language, the situation is even more challenging and the number of
large datasets for NLP research is practically nil. We hereby present Potrika,
a large single-label Bangla news article textual dataset curated for NLP
research from six popular online news portals in Bangladesh (Jugantor,
Jaijaidin, Ittefaq, Kaler Kontho, Inqilab, and Somoyer Alo) for the period
2014-2020. The articles are classified into eight distinct categories
(National, Sports, International, Entertainment, Economy, Education, Politics,
and Science \& Technology) providing five attributes (News Article, Category,
Headline, Publication Date, and Newspaper Source). The raw dataset contains
185.51 million words and 12.57 million sentences contained in 664,880 news
articles. Moreover, using NLP augmentation techniques, we create from the raw
(unbalanced) dataset another (balanced) dataset comprising 320,000 news
articles with 40,000 articles in each of the eight news categories. Potrika
contains both the datasets (raw and balanced) to suit a wide range of NLP
research. By far, to the best of our knowledge, Potrika is the largest and the
most extensive dataset for news classification.
",2022-10-17T19:37:42Z,http://arxiv.org/abs/2210.09389v1,"Istiak Ahmad, Fahad AlQurashi, Rashid Mehmood"
"Deep learning model for Mongolian Citizens Feedback Analysis using Word
  Vector Embeddings","  A large amount of feedback was collected over the years. Many feedback
analysis models have been developed focusing on the English language.
Recognizing the concept of feedback is challenging and crucial in languages
which do not have applicable corpus and tools employed in Natural Language
Processing (i.e., vocabulary corpus, sentence structure rules, etc). However,
in this paper, we study a feedback classification in Mongolian language using
two different word embeddings for deep learning. We compare the results of
proposed approaches. We use feedback data in Cyrillic collected from 2012-2018.
The result indicates that word embeddings using their own dataset improve the
deep learning based proposed model with the best accuracy of 80.1% and 82.7%
for two classification tasks.
",2023-02-23T14:49:31Z,http://arxiv.org/abs/2302.12069v1,"Zolzaya Dashdorj, Tsetsentsengel Munkhbayar, Stanislav Grigorev"
A Perspective on Deep Learning for Molecular Modeling and Simulations,"  Deep learning is transforming many areas in science, and it has great
potential in modeling molecular systems. However, unlike the mature deployment
of deep learning in computer vision and natural language processing, its
development in molecular modeling and simulations is still at an early stage,
largely because the inductive biases of molecules are completely different from
those of images or texts. Footed on these differences, we first reviewed the
limitations of traditional deep learning models from the perspective of
molecular physics, and wrapped up some relevant technical advancement at the
interface between molecular modeling and deep learning. We do not focus merely
on the ever more complex neural network models, instead, we emphasize the
theories and ideas behind modern deep learning. We hope that transacting these
ideas into molecular modeling will create new opportunities. For this purpose,
we summarized several representative applications, ranging from supervised to
unsupervised and reinforcement learning, and discussed their connections with
the emerging trends in deep learning. Finally, we outlook promising directions
which may help address the existing issues in the current framework of deep
molecular modeling.
",2020-04-25T22:58:25Z,http://arxiv.org/abs/2004.13011v1,"Jun Zhang, Yao-Kun Lei, Zhen Zhang, Junhan Chang, Maodong Li, Xu Han, Lijiang Yang, Yi Isaac Yang, Yi Qin Gao"
"Natural Language Processing Methods to Identify Oncology Patients at
  High Risk for Acute Care with Clinical Notes","  Clinical notes are an essential component of a health record. This paper
evaluates how natural language processing (NLP) can be used to identify the
risk of acute care use (ACU) in oncology patients, once chemotherapy starts.
Risk prediction using structured health data (SHD) is now standard, but
predictions using free-text formats are complex. This paper explores the use of
free-text notes for the prediction of ACU instead of SHD. Deep Learning models
were compared to manually engineered language features. Results show that SHD
models minimally outperform NLP models; an l1-penalised logistic regression
with SHD achieved a C-statistic of 0.748 (95%-CI: 0.735, 0.762), while the same
model with language features achieved 0.730 (95%-CI: 0.717, 0.745) and a
transformer-based model achieved 0.702 (95%-CI: 0.688, 0.717). This paper shows
how language models can be used in clinical applications and underlines how
risk bias is different for diverse patient groups, even using only free-text
data.
",2022-09-28T06:31:19Z,http://arxiv.org/abs/2209.13860v2,"Claudio Fanconi, Marieke van Buchem, Tina Hernandez-Boussard"
"A Legal Framework for Natural Language Processing Model Training in
  Portugal","  Recent advances in deep learning have promoted the advent of many
computational systems capable of performing intelligent actions that, until
then, were restricted to the human intellect. In the particular case of human
languages, these advances allowed the introduction of applications like ChatGPT
that are capable of generating coherent text without being explicitly
programmed to do so. Instead, these models use large volumes of textual data to
learn meaningful representations of human languages. Associated with these
advances, concerns about copyright and data privacy infringements caused by
these applications have emerged. Despite these concerns, the pace at which new
natural language processing applications continued to be developed largely
outperformed the introduction of new regulations. Today, communication barriers
between legal experts and computer scientists motivate many unintentional legal
infringements during the development of such applications. In this paper, a
multidisciplinary team intends to bridge this communication gap and promote
more compliant Portuguese NLP research by presenting a series of everyday NLP
use cases, while highlighting the Portuguese legislation that may arise during
its development.
",2024-05-01T14:18:50Z,http://arxiv.org/abs/2405.00536v1,"R√∫ben Almeida, Evelin Amorim"
A Robust Hybrid Approach for Textual Document Classification,"  Text document classification is an important task for diverse natural
language processing based applications. Traditional machine learning approaches
mainly focused on reducing dimensionality of textual data to perform
classification. This although improved the overall classification accuracy, the
classifiers still faced sparsity problem due to lack of better data
representation techniques. Deep learning based text document classification, on
the other hand, benefitted greatly from the invention of word embeddings that
have solved the sparsity problem and researchers focus mainly remained on the
development of deep architectures. Deeper architectures, however, learn some
redundant features that limit the performance of deep learning based solutions.
In this paper, we propose a two stage text document classification methodology
which combines traditional feature engineering with automatic feature
engineering (using deep learning). The proposed methodology comprises a filter
based feature selection (FSE) algorithm followed by a deep convolutional neural
network. This methodology is evaluated on the two most commonly used public
datasets, i.e., 20 Newsgroups data and BBC news data. Evaluation results reveal
that the proposed methodology outperforms the state-of-the-art of both the
(traditional) machine learning and deep learning based text document
classification methodologies with a significant margin of 7.7% on 20 Newsgroups
and 6.6% on BBC news datasets.
",2019-09-12T06:39:07Z,http://arxiv.org/abs/1909.05478v1,"Muhammad Nabeel Asim, Muhammad Usman Ghani Khan, Muhammad Imran Malik, Andreas Dengel, Sheraz Ahmed"
"Text-to-Battery Recipe: A language modeling-based protocol for automatic
  battery recipe extraction and retrieval","  Recent studies have increasingly applied natural language processing (NLP) to
automatically extract experimental research data from the extensive battery
materials literature. Despite the complex process involved in battery
manufacturing -- from material synthesis to cell assembly -- there has been no
comprehensive study systematically organizing this information. In response, we
propose a language modeling-based protocol, Text-to-Battery Recipe (T2BR), for
the automatic extraction of end-to-end battery recipes, validated using a case
study on batteries containing LiFePO4 cathode material. We report machine
learning-based paper filtering models, screening 2,174 relevant papers from the
keyword-based search results, and unsupervised topic models to identify 2,876
paragraphs related to cathode synthesis and 2,958 paragraphs related to cell
assembly. Then, focusing on the two topics, two deep learning-based named
entity recognition models are developed to extract a total of 30 entities --
including precursors, active materials, and synthesis methods -- achieving F1
scores of 88.18% and 94.61%. The accurate extraction of entities enables the
systematic generation of 165 end-toend recipes of LiFePO4 batteries. Our
protocol and results offer valuable insights into specific trends, such as
associations between precursor materials and synthesis methods, or combinations
between different precursor materials. We anticipate that our findings will
serve as a foundational knowledge base for facilitating battery-recipe
information retrieval. The proposed protocol will significantly accelerate the
review of battery material literature and catalyze innovations in battery
design and development.
",2024-07-22T08:15:02Z,http://arxiv.org/abs/2407.15459v1,"Daeun Lee, Jaewoong Choi, Hiroshi Mizuseki, Byungju Lee"
"Multimodal Quantum Natural Language Processing: A Novel Framework for
  using Quantum Methods to Analyse Real Data","  Despite significant advances in quantum computing across various domains,
research on applying quantum approaches to language compositionality - such as
modeling linguistic structures and interactions - remains limited. This gap
extends to the integration of quantum language data with real-world data from
sources like images, video, and audio. This thesis explores how quantum
computational methods can enhance the compositional modeling of language
through multimodal data integration. Specifically, it advances Multimodal
Quantum Natural Language Processing (MQNLP) by applying the Lambeq toolkit to
conduct a comparative analysis of four compositional models and evaluate their
influence on image-text classification tasks. Results indicate that
syntax-based models, particularly DisCoCat and TreeReader, excel in effectively
capturing grammatical structures, while bag-of-words and sequential models
struggle due to limited syntactic awareness. These findings underscore the
potential of quantum methods to enhance language modeling and drive
breakthroughs as quantum technology evolves.
",2024-10-29T19:03:43Z,http://arxiv.org/abs/2411.05023v1,Hala Hawashin
"Feature Extraction of Text for Deep Learning Algorithms: Application on
  Fake News Detection","  Feature extraction is an important process of machine learning and deep
learning, as the process make algorithms function more efficiently, and also
accurate. In natural language processing used in deception detection such as
fake news detection, several ways of feature extraction in statistical aspect
had been introduced (e.g. N-gram). In this research, it will be shown that by
using deep learning algorithms and alphabet frequencies of the original text of
a news without any information about the sequence of the alphabet can actually
be used to classify fake news and trustworthy ones in high accuracy (85\%). As
this pre-processing method makes the data notably compact but also include the
feature that is needed for the classifier, it seems that alphabet frequencies
contains some useful features for understanding complex context or meaning of
the original text.
",2020-10-12T07:43:01Z,http://arxiv.org/abs/2010.05496v2,HyeonJun Kim
A streamable large-scale clinical EEG dataset for Deep Learning,"  Deep Learning has revolutionized various fields, including Computer Vision,
Natural Language Processing, as well as Biomedical research. Within the field
of neuroscience, specifically in electrophysiological neuroimaging, researchers
are starting to explore leveraging deep learning to make predictions on their
data without extensive feature engineering. The availability of large-scale
datasets is a crucial aspect of allowing the experimentation of Deep Learning
models. We are publishing the first large-scale clinical EEG dataset that
simplifies data access and management for Deep Learning. This dataset contains
eyes-closed EEG data prepared from a collection of 1,574 juvenile participants
from the Healthy Brain Network. We demonstrate a use case integrating this
framework, and discuss why providing such neuroinformatics infrastructure to
the community is critical for future scientific discoveries.
",2022-03-04T20:05:50Z,http://arxiv.org/abs/2203.02552v2,"Dung Truong, Manisha Sinha, Kannan Umadevi Venkataraju, Michael Milham, Arnaud Delorme"
"A Natural Language Processing Pipeline for Detecting Informal Data
  References in Academic Literature","  Discovering authoritative links between publications and the datasets that
they use can be a labor-intensive process. We introduce a natural language
processing pipeline that retrieves and reviews publications for informal
references to research datasets, which complements the work of data librarians.
We first describe the components of the pipeline and then apply it to expand an
authoritative bibliography linking thousands of social science studies to the
data-related publications in which they are used. The pipeline increases recall
for literature to review for inclusion in data-related collections of
publications and makes it possible to detect informal data references at scale.
We contribute (1) a novel Named Entity Recognition (NER) model that reliably
detects informal data references and (2) a dataset connecting items from social
science literature with datasets they reference. Together, these contributions
enable future work on data reference, data citation networks, and data reuse.
",2022-05-23T22:06:46Z,http://arxiv.org/abs/2205.11651v1,"Sara Lafia, Lizhou Fan, Libby Hemphill"
Deep Latent-Variable Models for Text Generation,"  Text generation aims to produce human-like natural language output for
down-stream tasks. It covers a wide range of applications like machine
translation, document summarization, dialogue generation and so on. Recently
deep neural network-based end-to-end architectures have been widely adopted.
The end-to-end approach conflates all sub-modules, which used to be designed by
complex handcrafted rules, into a holistic encode-decode architecture. Given
enough training data, it is able to achieve state-of-the-art performance yet
avoiding the need of language/domain-dependent knowledge. Nonetheless, deep
learning models are known to be extremely data-hungry, and text generated from
them usually suffer from low diversity, interpretability and controllability.
As a result, it is difficult to trust the output from them in real-life
applications. Deep latent-variable models, by specifying the probabilistic
distribution over an intermediate latent process, provide a potential way of
addressing these problems while maintaining the expressive power of deep neural
networks. This dissertation presents how deep latent-variable models can
improve over the standard encoder-decoder model for text generation.
",2022-03-03T23:06:39Z,http://arxiv.org/abs/2203.02055v1,Xiaoyu Shen
"Development of deep learning algorithms to categorize free-text notes
  pertaining to diabetes: convolution neural networks achieve higher accuracy
  than support vector machines","  Health professionals can use natural language processing (NLP) technologies
when reviewing electronic health records (EHR). Machine learning free-text
classifiers can help them identify problems and make critical decisions. We aim
to develop deep learning neural network algorithms that identify EHR progress
notes pertaining to diabetes and validate the algorithms at two institutions.
The data used are 2,000 EHR progress notes retrieved from patients with
diabetes and all notes were annotated manually as diabetic or non-diabetic.
Several deep learning classifiers were developed, and their performances were
evaluated with the area under the ROC curve (AUC). The convolutional neural
network (CNN) model with a separable convolution layer accurately identified
diabetes-related notes in the Brigham and Womens Hospital testing set with the
highest AUC of 0.975. Deep learning classifiers can be used to identify EHR
progress notes pertaining to diabetes. In particular, the CNN-based classifier
can achieve a higher AUC than an SVM-based classifier.
",2018-09-16T04:21:38Z,http://arxiv.org/abs/1809.05814v1,"Boyi Yang, Adam Wright"
Proactive Schemes: A Survey of Adversarial Attacks for Social Good,"  Adversarial attacks in computer vision exploit the vulnerabilities of machine
learning models by introducing subtle perturbations to input data, often
leading to incorrect predictions or classifications. These attacks have evolved
in sophistication with the advent of deep learning, presenting significant
challenges in critical applications, which can be harmful for society. However,
there is also a rich line of research from a transformative perspective that
leverages adversarial techniques for social good. Specifically, we examine the
rise of proactive schemes-methods that encrypt input data using additional
signals termed templates, to enhance the performance of deep learning models.
By embedding these imperceptible templates into digital media, proactive
schemes are applied across various applications, from simple image enhancements
to complicated deep learning frameworks to aid performance, as compared to the
passive schemes, which don't change the input data distribution for their
framework. The survey delves into the methodologies behind these proactive
schemes, the encryption and learning processes, and their application to modern
computer vision and natural language processing applications. Additionally, it
discusses the challenges, potential vulnerabilities, and future directions for
proactive schemes, ultimately highlighting their potential to foster the
responsible and secure advancement of deep learning technologies.
",2024-09-24T22:31:56Z,http://arxiv.org/abs/2409.16491v1,"Vishal Asnani, Xi Yin, Xiaoming Liu"
Towards Zero-Shot Knowledge Distillation for Natural Language Processing,"  Knowledge Distillation (KD) is a common knowledge transfer algorithm used for
model compression across a variety of deep learning based natural language
processing (NLP) solutions. In its regular manifestations, KD requires access
to the teacher's training data for knowledge transfer to the student network.
However, privacy concerns, data regulations and proprietary reasons may prevent
access to such data. We present, to the best of our knowledge, the first work
on Zero-Shot Knowledge Distillation for NLP, where the student learns from the
much larger teacher without any task specific data. Our solution combines out
of domain data and adversarial training to learn the teacher's output
distribution. We investigate six tasks from the GLUE benchmark and demonstrate
that we can achieve between 75% and 92% of the teacher's classification score
(accuracy or F1) while compressing the model 30 times.
",2020-12-31T08:16:29Z,http://arxiv.org/abs/2012.15495v1,"Ahmad Rashid, Vasileios Lioutas, Abbas Ghaddar, Mehdi Rezagholizadeh"
"MatSci-NLP: Evaluating Scientific Language Models on Materials Science
  Language Tasks Using Text-to-Schema Modeling","  We present MatSci-NLP, a natural language benchmark for evaluating the
performance of natural language processing (NLP) models on materials science
text. We construct the benchmark from publicly available materials science text
data to encompass seven different NLP tasks, including conventional NLP tasks
like named entity recognition and relation classification, as well as NLP tasks
specific to materials science, such as synthesis action retrieval which relates
to creating synthesis procedures for materials. We study various BERT-based
models pretrained on different scientific text corpora on MatSci-NLP to
understand the impact of pretraining strategies on understanding materials
science text. Given the scarcity of high-quality annotated data in the
materials science domain, we perform our fine-tuning experiments with limited
training data to encourage the generalize across MatSci-NLP tasks. Our
experiments in this low-resource training setting show that language models
pretrained on scientific text outperform BERT trained on general text. MatBERT,
a model pretrained specifically on materials science journals, generally
performs best for most tasks. Moreover, we propose a unified text-to-schema for
multitask learning on \benchmark and compare its performance with traditional
fine-tuning methods. In our analysis of different training methods, we find
that our proposed text-to-schema methods inspired by question-answering
consistently outperform single and multitask NLP fine-tuning methods. The code
and datasets are publicly available at
\url{https://github.com/BangLab-UdeM-Mila/NLP4MatSci-ACL23}.
",2023-05-14T22:01:24Z,http://arxiv.org/abs/2305.08264v1,"Yu Song, Santiago Miret, Bang Liu"
"Requirement Formalisation using Natural Language Processing and Machine
  Learning: A Systematic Review","  Improvement of software development methodologies attracts developers to
automatic Requirement Formalisation (RF) in the Requirement Engineering (RE)
field. The potential advantages by applying Natural Language Processing (NLP)
and Machine Learning (ML) in reducing the ambiguity and incompleteness of
requirement written in natural languages is reported in different studies. The
goal of this paper is to survey and classify existing work on NLP and ML for
RF, identifying challenges in this domain and providing promising future
research directions. To achieve this, we conducted a systematic literature
review to outline the current state-of-the-art of NLP and ML techniques in RF
by selecting 257 papers from common used libraries. The search result is
filtered by defining inclusion and exclusion criteria and 47 relevant studies
between 2012 and 2022 are selected. We found that heuristic NLP approaches are
the most common NLP techniques used for automatic RF, primary operating on
structured and semi-structured data. This study also revealed that Deep
Learning (DL) technique are not widely used, instead classical ML techniques
are predominant in the surveyed studies. More importantly, we identified the
difficulty of comparing the performance of different approaches due to the lack
of standard benchmark cases for RF.
",2023-03-18T17:36:21Z,http://arxiv.org/abs/2303.13365v1,"Shekoufeh Kolahdouz-Rahimi, Kevin Lano, Chenghua Lin"
"Automatic Detection of Industry Sectors in Legal Articles Using Machine
  Learning Approaches","  The ability to automatically identify industry sector coverage in articles on
legal developments, or any kind of news articles for that matter, can bring
plentiful of benefits both to the readers and the content creators themselves.
By having articles tagged based on industry coverage, readers from all around
the world would be able to get to legal news that are specific to their region
and professional industry. Simultaneously, writers would benefit from
understanding which industries potentially lack coverage or which industries
readers are currently mostly interested in and thus, they would focus their
writing efforts towards more inclusive and relevant legal news coverage. In
this paper, a Machine Learning-powered industry analysis approach which
combined Natural Language Processing (NLP) with Statistical and Machine
Learning (ML) techniques was investigated. A dataset consisting of over 1,700
annotated legal articles was created for the identification of six industry
sectors. Text and legal based features were extracted from the text. Both
traditional ML methods (e.g. gradient boosting machine algorithms, and
decision-tree based algorithms) and deep neural network (e.g. transformer
models) were applied for performance comparison of predictive models. The
system achieved promising results with area under the receiver operating
characteristic curve scores above 0.90 and F-scores above 0.81 with respect to
the six industry sectors. The experimental results show that the suggested
automated industry analysis which employs ML techniques allows the processing
of large collections of text data in an easy, efficient, and scalable way.
Traditional ML methods perform better than deep neural networks when only a
small and domain-specific training data is available for the study.
",2023-03-08T12:41:56Z,http://arxiv.org/abs/2303.05387v1,"Hui Yang, Stella Hadjiantoni, Yunfei Long, Ruta Petraityte, Berthold Lausen"
"Is Word Segmentation Necessary for Deep Learning of Chinese
  Representations?","  Segmenting a chunk of text into words is usually the first step of processing
Chinese text, but its necessity has rarely been explored. In this paper, we ask
the fundamental question of whether Chinese word segmentation (CWS) is
necessary for deep learning-based Chinese Natural Language Processing. We
benchmark neural word-based models which rely on word segmentation against
neural char-based models which do not involve word segmentation in four
end-to-end NLP benchmark tasks: language modeling, machine translation,
sentence matching/paraphrase and text classification. Through direct
comparisons between these two types of models, we find that char-based models
consistently outperform word-based models. Based on these observations, we
conduct comprehensive experiments to study why word-based models underperform
char-based models in these deep learning-based NLP tasks. We show that it is
because word-based models are more vulnerable to data sparsity and the presence
of out-of-vocabulary (OOV) words, and thus more prone to overfitting. We hope
this paper could encourage researchers in the community to rethink the
necessity of word segmentation in deep learning-based Chinese Natural Language
Processing. \footnote{Yuxian Meng and Xiaoya Li contributed equally to this
paper.}
",2019-05-14T11:39:43Z,http://arxiv.org/abs/1905.05526v2,"Xiaoya Li, Yuxian Meng, Xiaofei Sun, Qinghong Han, Arianna Yuan, Jiwei Li"
Emergence of Numeric Concepts in Multi-Agent Autonomous Communication,"  With the rapid development of deep learning, most of current state-of-the-art
techniques in natural langauge processing are based on deep learning models
trained with argescaled static textual corpora. However, we human beings learn
and understand in a different way. Thus, grounded language learning argues that
models need to learn and understand language by the experience and perceptions
obtained by interacting with enviroments, like how humans do. With the help of
deep reinforcement learning techniques, there are already lots of works
focusing on facilitating the emergence of communication protocols that have
compositionalities like natural languages among computational agents
population. Unlike these works, we, on the other hand, focus on the numeric
concepts which correspond to abstractions in cognition and function words in
natural language. Based on a specifically designed language game, we verify
that computational agents are capable of transmitting numeric concepts during
autonomous communication, and the emergent communication protocols can reflect
the underlying structure of meaning space. Although their encodeing method is
not compositional like natural languages from a perspective of human beings,
the emergent languages can be generalised to unseen inputs and, more
importantly, are easier for models to learn. Besides, iterated learning can
help further improving the compositionality of the emergent languages, under
the measurement of topological similarity. Furthermore, we experiment another
representation method, i.e. directly encode numerals into concatenations of
one-hot vectors, and find that the emergent languages would become
compositional like human natural languages. Thus, we argue that there are 2
important factors for the emergence of compositional languages.
",2019-11-04T09:58:23Z,http://arxiv.org/abs/1911.01098v1,Shangmin Guo
"Compressible Dynamics in Deep Overparameterized Low-Rank Learning &
  Adaptation","  While overparameterization in machine learning models offers great benefits
in terms of optimization and generalization, it also leads to increased
computational requirements as model sizes grow. In this work, we show that by
leveraging the inherent low-dimensional structures of data and compressible
dynamics within the model parameters, we can reap the benefits of
overparameterization without the computational burdens. In practice, we
demonstrate the effectiveness of this approach for deep low-rank matrix
completion as well as fine-tuning language models. Our approach is grounded in
theoretical findings for deep overparameterized low-rank matrix recovery, where
we show that the learning dynamics of each weight matrix are confined to an
invariant low-dimensional subspace. Consequently, we can construct and train
compact, highly compressed factorizations possessing the same benefits as their
overparameterized counterparts. In the context of deep matrix completion, our
technique substantially improves training efficiency while retaining the
advantages of overparameterization. For language model fine-tuning, we propose
a method called ""Deep LoRA"", which improves the existing low-rank adaptation
(LoRA) technique, leading to reduced overfitting and a simplified
hyperparameter setup, while maintaining comparable efficiency. We validate the
effectiveness of Deep LoRA on natural language tasks, particularly when
fine-tuning with limited data. Our code is available at
https://github.com/cjyaras/deep-lora-transformers.
",2024-06-06T14:29:49Z,http://arxiv.org/abs/2406.04112v2,"Can Yaras, Peng Wang, Laura Balzano, Qing Qu"
Word and Document Embeddings based on Neural Network Approaches,"  Data representation is a fundamental task in machine learning. The
representation of data affects the performance of the whole machine learning
system. In a long history, the representation of data is done by feature
engineering, and researchers aim at designing better features for specific
tasks. Recently, the rapid development of deep learning and representation
learning has brought new inspiration to various domains.
  In natural language processing, the most widely used feature representation
is the Bag-of-Words model. This model has the data sparsity problem and cannot
keep the word order information. Other features such as part-of-speech tagging
or more complex syntax features can only fit for specific tasks in most cases.
This thesis focuses on word representation and document representation. We
compare the existing systems and present our new model.
  First, for generating word embeddings, we make comprehensive comparisons
among existing word embedding models. In terms of theory, we figure out the
relationship between the two most important models, i.e., Skip-gram and GloVe.
In our experiments, we analyze three key points in generating word embeddings,
including the model construction, the training corpus and parameter design. We
evaluate word embeddings with three types of tasks, and we argue that they
cover the existing use of word embeddings. Through theory and practical
experiments, we present some guidelines for how to generate a good word
embedding.
  Second, in Chinese character or word representation. We introduce the joint
training of Chinese character and word. ...
  Third, for document representation, we analyze the existing document
representation models, including recursive NNs, recurrent NNs and convolutional
NNs. We point out the drawbacks of these models and present our new model, the
recurrent convolutional neural networks. ...
",2016-11-18T03:21:28Z,http://arxiv.org/abs/1611.05962v1,Siwei Lai
Deep Learning Models to Study Sentence Comprehension in the Human Brain,"  Recent artificial neural networks that process natural language achieve
unprecedented performance in tasks requiring sentence-level understanding. As
such, they could be interesting models of the integration of linguistic
information in the human brain. We review works that compare these artificial
language models with human brain activity and we assess the extent to which
this approach has improved our understanding of the neural processes involved
in natural language comprehension. Two main results emerge. First, the neural
representation of word meaning aligns with the context-dependent, dense word
vectors used by the artificial neural networks. Second, the processing
hierarchy that emerges within artificial neural networks broadly matches the
brain, but is surprisingly inconsistent across studies. We discuss current
challenges in establishing artificial neural networks as process models of
natural language comprehension. We suggest exploiting the highly structured
representational geometry of artificial neural networks when mapping
representations to brain data.
",2023-01-16T10:31:25Z,http://arxiv.org/abs/2301.06340v2,"Sophie Arana, Jacques Pesnot Lerousseau, Peter Hagoort"
Fine-tuning BERT-based models for Plant Health Bulletin Classification,"  In the era of digitization, different actors in agriculture produce numerous
data. Such data contains already latent historical knowledge in the domain.
This knowledge enables us to precisely study natural hazards within global or
local aspects, and then improve the risk prevention tasks and augment the
yield, which helps to tackle the challenge of growing population and changing
alimentary habits. In particular, French Plants Health Bulletins (BSV, for its
name in French Bulletin de Sant{\'e} du V{\'e}g{\'e}tal) give information about
the development stages of phytosanitary risks in agricultural production.
However, they are written in natural language, thus, machines and human cannot
exploit them as efficiently as it could be. Natural language processing (NLP)
technologies aim to automatically process and analyze large amounts of natural
language data. Since the 2010s, with the increases in computational power and
parallelization, representation learning and deep learning methods became
widespread in NLP. Recent advancements Bidirectional Encoder Representations
from Transformers (BERT) inspire us to rethink of knowledge representation and
natural language understanding in plant health management domain. The goal in
this work is to propose a BERT-based approach to automatically classify the BSV
to make their data easily indexable. We sampled 200 BSV to finetune the
pretrained BERT language models and classify them as pest or/and disease and we
show preliminary results.
",2021-01-29T08:14:35Z,http://arxiv.org/abs/2102.00838v1,"Shufan Jiang, Rafael Angarita, Stephane Cormier, Francis Rousseaux"
"Adversarial Robustness for Machine Learning Cyber Defenses Using Log
  Data","  There has been considerable and growing interest in applying machine learning
for cyber defenses. One promising approach has been to apply natural language
processing techniques to analyze logs data for suspicious behavior. A natural
question arises to how robust these systems are to adversarial attacks. Defense
against sophisticated attack is of particular concern for cyber defenses. In
this paper, we develop a testing framework to evaluate adversarial robustness
of machine learning cyber defenses, particularly those focused on log data. Our
framework uses techniques from deep reinforcement learning and adversarial
natural language processing. We validate our framework using a publicly
available dataset and demonstrate that our adversarial attack does succeed
against the target systems, revealing a potential vulnerability. We apply our
framework to analyze the influence of different levels of dropout
regularization and find that higher dropout levels increases robustness.
Moreover 90% dropout probability exhibited the highest level of robustness by a
significant margin, which suggests unusually high dropout may be necessary to
properly protect against adversarial attacks.
",2020-07-29T17:51:29Z,http://arxiv.org/abs/2007.14983v1,"Kai Steverson, Jonathan Mullin, Metin Ahiskali"
"Deep Cross-Modal Correlation Learning for Audio and Lyrics in Music
  Retrieval","  Little research focuses on cross-modal correlation learning where temporal
structures of different data modalities such as audio and lyrics are taken into
account. Stemming from the characteristic of temporal structures of music in
nature, we are motivated to learn the deep sequential correlation between audio
and lyrics. In this work, we propose a deep cross-modal correlation learning
architecture involving two-branch deep neural networks for audio modality and
text modality (lyrics). Different modality data are converted to the same
canonical space where inter modal canonical correlation analysis is utilized as
an objective function to calculate the similarity of temporal structures. This
is the first study on understanding the correlation between language and music
audio through deep architectures for learning the paired temporal correlation
of audio and lyrics. Pre-trained Doc2vec model followed by fully-connected
layers (fully-connected deep neural network) is used to represent lyrics. Two
significant contributions are made in the audio branch, as follows: i)
pre-trained CNN followed by fully-connected layers is investigated for
representing music audio. ii) We further suggest an end-to-end architecture
that simultaneously trains convolutional layers and fully-connected layers to
better learn temporal structures of music audio. Particularly, our end-to-end
deep architecture contains two properties: simultaneously implementing feature
learning and cross-modal correlation learning, and learning joint
representation by considering temporal structures. Experimental results, using
audio to retrieve lyrics or using lyrics to retrieve audio, verify the
effectiveness of the proposed deep correlation learning architectures in
cross-modal music retrieval.
",2017-11-24T14:21:46Z,http://arxiv.org/abs/1711.08976v2,"Yi Yu, Suhua Tang, Francisco Raposo, Lei Chen"
"Arabic Speech Emotion Recognition Employing Wav2vec2.0 and HuBERT Based
  on BAVED Dataset","  Recently, there have been tremendous research outcomes in the fields of
speech recognition and natural language processing. This is due to the
well-developed multi-layers deep learning paradigms such as wav2vec2.0,
Wav2vecU, WavBERT, and HuBERT that provide better representation learning and
high information capturing. Such paradigms run on hundreds of unlabeled data,
then fine-tuned on a small dataset for specific tasks. This paper introduces a
deep learning constructed emotional recognition model for Arabic speech
dialogues. The developed model employs the state of the art audio
representations include wav2vec2.0 and HuBERT. The experiment and performance
results of our model overcome the previous known outcomes.
",2021-10-09T00:58:12Z,http://arxiv.org/abs/2110.04425v1,"Omar Mohamed, Salah A. Aly"
Low-Resource Text Classification using Domain-Adversarial Learning,"  Deep learning techniques have recently shown to be successful in many natural
language processing tasks forming state-of-the-art systems. They require,
however, a large amount of annotated data which is often missing. This paper
explores the use of domain-adversarial learning as a regularizer to avoid
overfitting when training domain invariant features for deep, complex neural
networks in low-resource and zero-resource settings in new target domains or
languages. In case of new languages, we show that monolingual word vectors can
be directly used for training without prealignment. Their projection into a
common space can be learnt ad-hoc at training time reaching the final
performance of pretrained multilingual word vectors.
",2018-07-13T17:30:32Z,http://arxiv.org/abs/1807.05195v2,"Daniel Grie√ühaber, Ngoc Thang Vu, Johannes Maucher"
"Spatio-temporal Storytelling? Leveraging Generative Models for Semantic
  Trajectory Analysis","  In this paper, we lay out a vision for analysing semantic trajectory traces
and generating synthetic semantic trajectory data (SSTs) using generative
language model. Leveraging the advancements in deep learning, as evident by
progress in the field of natural language processing (NLP), computer vision,
etc. we intend to create intelligent models that can study the semantic
trajectories in various contexts, predicting future trends, increasing machine
understanding of the movement of animals, humans, goods, etc. enhancing
human-computer interactions, and contributing to an array of applications
ranging from urban-planning to personalized recommendation engines and business
strategy.
",2023-06-24T08:45:47Z,http://arxiv.org/abs/2306.13905v1,"Shreya Ghosh, Saptarshi Sengupta, Prasenjit Mitra"
"A Comprehensive Review on Sentiment Analysis: Tasks, Approaches and
  Applications","  Sentiment analysis (SA) is an emerging field in text mining. It is the
process of computationally identifying and categorizing opinions expressed in a
piece of text over different social media platforms. Social media plays an
essential role in knowing the customer mindset towards a product, services, and
the latest market trends. Most organizations depend on the customer's response
and feedback to upgrade their offered products and services. SA or opinion
mining seems to be a promising research area for various domains. It plays a
vital role in analyzing big data generated daily in structured and unstructured
formats over the internet. This survey paper defines sentiment and its recent
research and development in different domains, including voice, images, videos,
and text. The challenges and opportunities of sentiment analysis are also
discussed in the paper.
  \keywords{Sentiment Analysis, Machine Learning, Lexicon-based approach, Deep
Learning, Natural Language Processing}
",2023-11-19T06:29:41Z,http://arxiv.org/abs/2311.11250v1,"Sudhanshu Kumar, Partha Pratim Roy, Debi Prosad Dogra, Byung-Gyu Kim"
Grammar-based Game Description Generation using Large Language Models,"  To lower the barriers to game design development, automated game design,
which generates game designs through computational processes, has been
explored. In automated game design, machine learning-based techniques such as
evolutionary algorithms have achieved success. Benefiting from the remarkable
advancements in deep learning, applications in computer vision and natural
language processing have progressed in level generation. However, due to the
limited amount of data in game design, the application of deep learning has
been insufficient for tasks such as game description generation. To pioneer a
new approach for handling limited data in automated game design, we focus on
the in-context learning of large language models (LLMs). LLMs can capture the
features of a task from a few demonstration examples and apply the capabilities
acquired during pre-training. We introduce the grammar of game descriptions,
which effectively structures the game design space, into the LLMs' reasoning
process. Grammar helps LLMs capture the characteristics of the complex task of
game description generation. Furthermore, we propose a decoding method that
iteratively improves the generated output by leveraging the grammar. Our
experiments demonstrate that this approach performs well in generating game
descriptions.
",2024-07-24T16:36:02Z,http://arxiv.org/abs/2407.17404v1,"Tsunehiko Tanaka, Edgar Simo-Serra"
On Uncertainty In Natural Language Processing,"  The last decade in deep learning has brought on increasingly capable systems
that are deployed on a wide variety of applications. In natural language
processing, the field has been transformed by a number of breakthroughs
including large language models, which are used in increasingly many
user-facing applications. In order to reap the benefits of this technology and
reduce potential harms, it is important to quantify the reliability of model
predictions and the uncertainties that shroud their development.
  This thesis studies how uncertainty in natural language processing can be
characterized from a linguistic, statistical and neural perspective, and how it
can be reduced and quantified through the design of the experimental pipeline.
We further explore uncertainty quantification in modeling by theoretically and
empirically investigating the effect of inductive model biases in text
classification tasks. The corresponding experiments include data for three
different languages (Danish, English and Finnish) and tasks as well as a large
set of different uncertainty quantification approaches. Additionally, we
propose a method for calibrated sampling in natural language generation based
on non-exchangeable conformal prediction, which provides tighter token sets
with better coverage of the actual continuation. Lastly, we develop an approach
to quantify confidence in large black-box language models using auxiliary
predictors, where the confidence is predicted from the input to and generated
output text of the target model alone.
",2024-10-04T14:08:02Z,http://arxiv.org/abs/2410.03446v1,Dennis Ulmer
"A Systematic Literature Review about Idea Mining: The Use of
  Machine-driven Analytics to Generate Ideas","  Idea generation is the core activity of innovation. Digital data sources,
which are sources of innovation, such as patents, publications, social media,
websites, etc., are increasingly growing at unprecedented volume. Manual idea
generation is time-consuming and is affected by the subjectivity of the
individuals involved. Therefore, the use machine-driven data analytics
techniques to analyze data to generate ideas and support idea generation by
serving users is useful. The objective of this study is to study state-of
the-art machine-driven analytics for idea generation and data sources, hence
the result of this study will generally server as a guideline for choosing
techniques and data sources. A systematic literature review is conducted to
identify relevant scholarly literature from IEEE, Scopus, Web of Science and
Google Scholar. We selected a total of 71 articles and analyzed them
thematically. The results of this study indicate that idea generation through
machine-driven analytics applies text mining, information retrieval (IR),
artificial intelligence (AI), deep learning, machine learning, statistical
techniques, natural language processing (NLP), NLP-based morphological
analysis, network analysis, and bibliometric to support idea generation. The
results include a list of techniques and procedures in idea generation through
machine-driven idea analytics. Additionally, characterization and heuristics
used in idea generation are summarized. For the future, tools designed to
generate ideas could be explored.
",2022-01-30T21:46:21Z,http://arxiv.org/abs/2202.12826v1,"Workneh Y. Ayele, Gustaf Juell-Skielse"
Deep learning for photoacoustic imaging: a survey,"  Machine learning has been developed dramatically and witnessed a lot of
applications in various fields over the past few years. This boom originated in
2009, when a new model emerged, that is, the deep artificial neural network,
which began to surpass other established mature models on some important
benchmarks. Later, it was widely used in academia and industry. Ranging from
image analysis to natural language processing, it fully exerted its magic and
now become the state-of-the-art machine learning models. Deep neural networks
have great potential in medical imaging technology, medical data analysis,
medical diagnosis and other healthcare issues, and is promoted in both
pre-clinical and even clinical stages. In this review, we performed an overview
of some new developments and challenges in the application of machine learning
to medical image analysis, with a special focus on deep learning in
photoacoustic imaging. The aim of this review is threefold: (i) introducing
deep learning with some important basics, (ii) reviewing recent works that
apply deep learning in the entire ecological chain of photoacoustic imaging,
from image reconstruction to disease diagnosis, (iii) providing some open
source materials and other resources for researchers interested in applying
deep learning to photoacoustic imaging.
",2020-08-10T15:53:30Z,http://arxiv.org/abs/2008.04221v4,"Changchun Yang, Hengrong Lan, Feng Gao, Fei Gao"
Continual Lifelong Learning in Natural Language Processing: A Survey,"  Continual learning (CL) aims to enable information systems to learn from a
continuous data stream across time. However, it is difficult for existing deep
learning architectures to learn a new task without largely forgetting
previously acquired knowledge. Furthermore, CL is particularly challenging for
language learning, as natural language is ambiguous: it is discrete,
compositional, and its meaning is context-dependent. In this work, we look at
the problem of CL through the lens of various NLP tasks. Our survey discusses
major challenges in CL and current methods applied in neural network models. We
also provide a critical review of the existing CL evaluation methods and
datasets in NLP. Finally, we present our outlook on future research directions.
",2020-12-17T18:44:36Z,http://arxiv.org/abs/2012.09823v1,"Magdalena Biesialska, Katarzyna Biesialska, Marta R. Costa-juss√†"
Not Enough Data? Deep Learning to the Rescue!,"  Based on recent advances in natural language modeling and those in text
generation capabilities, we propose a novel data augmentation method for text
classification tasks. We use a powerful pre-trained neural network model to
artificially synthesize new labeled data for supervised learning. We mainly
focus on cases with scarce labeled data. Our method, referred to as
language-model-based data augmentation (LAMBADA), involves fine-tuning a
state-of-the-art language generator to a specific task through an initial
training phase on the existing (usually small) labeled data. Using the
fine-tuned model and given a class label, new sentences for the class are
generated. Our process then filters these new sentences by using a classifier
trained on the original data. In a series of experiments, we show that LAMBADA
improves classifiers' performance on a variety of datasets. Moreover, LAMBADA
significantly improves upon the state-of-the-art techniques for data
augmentation, specifically those applicable to text classification tasks with
little data.
",2019-11-08T08:30:22Z,http://arxiv.org/abs/1911.03118v2,"Ateret Anaby-Tavor, Boaz Carmeli, Esther Goldbraich, Amir Kantor, George Kour, Segev Shlomov, Naama Tepper, Naama Zwerdling"
"Deep Learning in the Automotive Industry: Recent Advances and
  Application Examples","  One of the most exciting technology breakthroughs in the last few years has
been the rise of deep learning. State-of-the-art deep learning models are being
widely deployed in academia and industry, across a variety of areas, from image
analysis to natural language processing. These models have grown from fledgling
research subjects to mature techniques in real-world use. The increasing scale
of data, computational power and the associated algorithmic innovations are the
main drivers for the progress we see in this field. These developments also
have a huge potential for the automotive industry and therefore the interest in
deep learning-based technology is growing. A lot of the product innovations,
such as self-driving cars, parking and lane-change assist or safety functions,
such as autonomous emergency braking, are powered by deep learning algorithms.
Deep learning is poised to offer gains in performance and functionality for
most ADAS (Advanced Driver Assistance System) solutions. Virtual sensing for
vehicle dynamics application, vehicle inspection/heath monitoring, automated
driving and data-driven product development are key areas that are expected to
get the most attention. This article provides an overview of the recent
advances and some associated challenges in deep learning techniques in the
context of automotive applications.
",2019-06-20T20:30:39Z,http://arxiv.org/abs/1906.08834v2,"Kanwar Bharat Singh, Mustafa Ali Arat"
"LiPCoT: Linear Predictive Coding based Tokenizer for Self-supervised
  Learning of Time Series Data via Language Models","  Language models have achieved remarkable success in various natural language
processing tasks. However, their application to time series data, a crucial
component in many domains, remains limited. This paper proposes LiPCoT (Linear
Predictive Coding based Tokenizer for time series), a novel tokenizer that
encodes time series data into a sequence of tokens, enabling self-supervised
learning of time series using existing Language model architectures such as
BERT. Unlike traditional time series tokenizers that rely heavily on CNN
encoder for time series feature generation, LiPCoT employs stochastic modeling
through linear predictive coding to create a latent space for time series
providing a compact yet rich representation of the inherent stochastic nature
of the data. Furthermore, LiPCoT is computationally efficient and can
effectively handle time series data with varying sampling rates and lengths,
overcoming common limitations of existing time series tokenizers. In this
proof-of-concept work, we present the effectiveness of LiPCoT in classifying
Parkinson's disease (PD) using an EEG dataset from 46 participants. In
particular, we utilize LiPCoT to encode EEG data into a small vocabulary of
tokens and then use BERT for self-supervised learning and the downstream task
of PD classification. We benchmark our approach against several
state-of-the-art CNN-based deep learning architectures for PD detection. Our
results reveal that BERT models utilizing self-supervised learning outperformed
the best-performing existing method by 7.1% in precision, 2.3% in recall, 5.5%
in accuracy, 4% in AUC, and 5% in F1-score highlighting the potential for
self-supervised learning even on small datasets. Our work will inform future
foundational models for time series, particularly for self-supervised learning.
",2024-08-14T04:51:33Z,http://arxiv.org/abs/2408.07292v1,Md Fahim Anjum
Combining Representation Learning with Logic for Language Processing,"  The current state-of-the-art in many natural language processing and
automated knowledge base completion tasks is held by representation learning
methods which learn distributed vector representations of symbols via
gradient-based optimization. They require little or no hand-crafted features,
thus avoiding the need for most preprocessing steps and task-specific
assumptions. However, in many cases representation learning requires a large
amount of annotated training data to generalize well to unseen data. Such
labeled training data is provided by human annotators who often use formal
logic as the language for specifying annotations. This thesis investigates
different combinations of representation learning methods with logic for
reducing the need for annotated training data, and for improving
generalization.
",2017-12-27T21:09:36Z,http://arxiv.org/abs/1712.09687v1,Tim Rockt√§schel
Lecture Notes on Neural Information Retrieval,"  These lecture notes focus on the recent advancements in neural information
retrieval, with particular emphasis on the systems and models exploiting
transformer networks. These networks, originally proposed by Google in 2017,
have seen a large success in many natural language processing and information
retrieval tasks. While there are many fantastic textbook on information
retrieval and natural language processing as well as specialised books for a
more advanced audience, these lecture notes target people aiming at developing
a basic understanding of the main information retrieval techniques and
approaches based on deep learning. These notes have been prepared for a IR
graduate course of the MSc program in Artificial Intelligence and Data
Engineering at the University of Pisa, Italy.
",2022-07-27T10:43:27Z,http://arxiv.org/abs/2207.13443v2,Nicola Tonellotto
Deep Learning Based Speech Beamforming,"  Multi-channel speech enhancement with ad-hoc sensors has been a challenging
task. Speech model guided beamforming algorithms are able to recover natural
sounding speech, but the speech models tend to be oversimplified or the
inference would otherwise be too complicated. On the other hand, deep learning
based enhancement approaches are able to learn complicated speech distributions
and perform efficient inference, but they are unable to deal with variable
number of input channels. Also, deep learning approaches introduce a lot of
errors, particularly in the presence of unseen noise types and settings. We
have therefore proposed an enhancement framework called DEEPBEAM, which
combines the two complementary classes of algorithms. DEEPBEAM introduces a
beamforming filter to produce natural sounding speech, but the filter
coefficients are determined with the help of a monaural speech enhancement
neural network. Experiments on synthetic and real-world data show that DEEPBEAM
is able to produce clean, dry and natural sounding speech, and is robust
against unseen noise.
",2018-02-15T02:00:54Z,http://arxiv.org/abs/1802.05383v1,"Kaizhi Qian, Yang Zhang, Shiyu Chang, Xuesong Yang, Dinei Florencio, Mark Hasegawa-Johnson"
"Deep Learning versus Traditional Classifiers on Vietnamese Students'
  Feedback Corpus","  Student's feedback is an important source of collecting students' opinions to
improve the quality of training activities. Implementing sentiment analysis
into student feedback data, we can determine sentiments polarities which
express all problems in the institution since changes necessary will be applied
to improve the quality of teaching and learning. This study focused on machine
learning and natural language processing techniques (NaiveBayes, Maximum
Entropy, Long Short-Term Memory, Bi-Directional Long Short-Term Memory) on the
VietnameseStudents' Feedback Corpus collected from a university. The final
results were compared and evaluated to find the most effective model based on
different evaluation criteria. The experimental results show that the
Bi-Directional LongShort-Term Memory algorithm outperformed than three other
algorithms in terms of the F1-score measurement with 92.0% on the sentiment
classification task and 89.6% on the topic classification task. In addition, we
developed a sentiment analysis application analyzing student feedback. The
application will help the institution to recognize students' opinions about a
problem and identify shortcomings that still exist. With the use of this
application, the institution can propose an appropriate method to improve the
quality of training activities in the future.
",2019-11-17T12:32:50Z,http://arxiv.org/abs/1911.07223v1,"Phu X. V. Nguyen, Tham T. T. Hong, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen"
"Comparative Analysis of Contextual Relation Extraction based on Deep
  Learning Models","  Contextual Relation Extraction (CRE) is mainly used for constructing a
knowledge graph with a help of ontology. It performs various tasks such as
semantic search, query answering, and textual entailment. Relation extraction
identifies the entities from raw texts and the relations among them. An
efficient and accurate CRE system is essential for creating domain knowledge in
the biomedical industry. Existing Machine Learning and Natural Language
Processing (NLP) techniques are not suitable to predict complex relations from
sentences that consist of more than two relations and unspecified entities
efficiently. In this work, deep learning techniques have been used to identify
the appropriate semantic relation based on the context from multiple sentences.
Even though various machine learning models have been used for relation
extraction, they provide better results only for binary relations, i.e.,
relations occurred exactly between the two entities in a sentence. Machine
learning models are not suited for complex sentences that consist of the words
that have various meanings. To address these issues, hybrid deep learning
models have been used to extract the relations from complex sentence
effectively. This paper explores the analysis of various deep learning models
that are used for relation extraction.
",2023-09-13T09:05:09Z,http://arxiv.org/abs/2309.06814v1,"R. Priyadharshini, G. Jeyakodi, P. Shanthi Bala"
Recent Trends in Named Entity Recognition (NER),"  The availability of large amounts of computer-readable textual data and
hardware that can process the data has shifted the focus of knowledge projects
towards deep learning architecture. Natural Language Processing, particularly
the task of Named Entity Recognition is no exception. The bulk of the learning
methods that have produced state-of-the-art results have changed the deep
learning model, the training method used, the training data itself or the
encoding of the output of the NER system. In this paper, we review significant
learning methods that have been employed for NER in the recent past and how
they came about from the linear learning methods of the past. We also cover the
progress of related tasks that are upstream or downstream to NER, e.g.,
sequence tagging, entity linking, etc., wherever the processes in question have
also improved NER results.
",2021-01-25T14:18:24Z,http://arxiv.org/abs/2101.11420v1,Arya Roy
"Deep Collective Learning: Learning Optimal Inputs and Weights Jointly in
  Deep Neural Networks","  It is well observed that in deep learning and computer vision literature,
visual data are always represented in a manually designed coding scheme (eg.,
RGB images are represented as integers ranging from 0 to 255 for each channel)
when they are input to an end-to-end deep neural network (DNN) for any learning
task. We boldly question whether the manually designed inputs are good for DNN
training for different tasks and study whether the input to a DNN can be
optimally learned end-to-end together with learning the weights of the DNN. In
this paper, we propose the paradigm of {\em deep collective learning} which
aims to learn the weights of DNNs and the inputs to DNNs simultaneously for
given tasks. We note that collective learning has been implicitly but widely
used in natural language processing while it has almost never been studied in
computer vision. Consequently, we propose the lookup vision networks
(Lookup-VNets) as a solution to deep collective learning in computer vision.
This is achieved by associating each color in each channel with a vector in
lookup tables. As learning inputs in computer vision has almost never been
studied in the existing literature, we explore several aspects of this question
through varieties of experiments on image classification tasks. Experimental
results on four benchmark datasets, i.e., CIFAR-10, CIFAR-100, Tiny ImageNet,
and ImageNet (ILSVRC2012) have shown several surprising characteristics of
Lookup-VNets and have demonstrated the advantages and promise of Lookup-VNets
and deep collective learning.
",2020-09-17T00:33:04Z,http://arxiv.org/abs/2009.07988v1,"Xiang Deng, Zhongfei, Zhang"
"A Universal Prompting Strategy for Extracting Process Model Information
  from Natural Language Text using Large Language Models","  Over the past decade, extensive research efforts have been dedicated to the
extraction of information from textual process descriptions. Despite the
remarkable progress witnessed in natural language processing (NLP), information
extraction within the Business Process Management domain remains predominantly
reliant on rule-based systems and machine learning methodologies. Data scarcity
has so far prevented the successful application of deep learning techniques.
However, the rapid progress in generative large language models (LLMs) makes it
possible to solve many NLP tasks with very high quality without the need for
extensive data. Therefore, we systematically investigate the potential of LLMs
for extracting information from textual process descriptions, targeting the
detection of process elements such as activities and actors, and relations
between them. Using a heuristic algorithm, we demonstrate the suitability of
the extracted information for process model generation. Based on a novel
prompting strategy, we show that LLMs are able to outperform state-of-the-art
machine learning approaches with absolute performance improvements of up to 8\%
$F_1$ score across three different datasets. We evaluate our prompting strategy
on eight different LLMs, showing it is universally applicable, while also
analyzing the impact of certain prompt parts on extraction quality. The number
of example texts, the specificity of definitions, and the rigour of format
instructions are identified as key for improving the accuracy of extracted
information. Our code, prompts, and data are publicly available.
",2024-07-26T06:39:35Z,http://arxiv.org/abs/2407.18540v1,"Julian Neuberger, Lars Ackermann, Han van der Aa, Stefan Jablonski"
"One Deep Music Representation to Rule Them All? : A comparative analysis
  of different representation learning strategies","  Inspired by the success of deploying deep learning in the fields of Computer
Vision and Natural Language Processing, this learning paradigm has also found
its way into the field of Music Information Retrieval. In order to benefit from
deep learning in an effective, but also efficient manner, deep transfer
learning has become a common approach. In this approach, it is possible to
reuse the output of a pre-trained neural network as the basis for a new
learning task. The underlying hypothesis is that if the initial and new
learning tasks show commonalities and are applied to the same type of input
data (e.g. music audio), the generated deep representation of the data is also
informative for the new task. Since, however, most of the networks used to
generate deep representations are trained using a single initial learning
source, their representation is unlikely to be informative for all possible
future tasks. In this paper, we present the results of our investigation of
what are the most important factors to generate deep representations for the
data and learning tasks in the music domain. We conducted this investigation
via an extensive empirical study that involves multiple learning sources, as
well as multiple deep learning architectures with varying levels of information
sharing between sources, in order to learn music representations. We then
validate these representations considering multiple target datasets for
evaluation. The results of our experiments yield several insights on how to
approach the design of methods for learning widely deployable deep data
representations in the music domain.
",2018-02-12T14:08:54Z,http://arxiv.org/abs/1802.04051v4,"Jaehun Kim, Juli√°n Urbano, Cynthia C. S. Liem, Alan Hanjalic"
Matching Text with Deep Mutual Information Estimation,"  Text matching is a core natural language processing research problem. How to
retain sufficient information on both content and structure information is one
important challenge. In this paper, we present a neural approach for
general-purpose text matching with deep mutual information estimation
incorporated. Our approach, Text matching with Deep Info Max (TIM), is
integrated with a procedure of unsupervised learning of representations by
maximizing the mutual information between text matching neural network's input
and output. We use both global and local mutual information to learn text
representations. We evaluate our text matching approach on several tasks
including natural language inference, paraphrase identification, and answer
selection. Compared to the state-of-the-art approaches, the experiments show
that our method integrated with mutual information estimation learns better
text representation and achieves better experimental results of text matching
tasks without exploiting pretraining on external data.
",2020-03-09T15:25:37Z,http://arxiv.org/abs/2003.11521v1,"Xixi Zhou, Chengxi Li, Jiajun Bu, Chengwei Yao, Keyue Shi, Zhi Yu, Zhou Yu"
"Detecting ESG topics using domain-specific language models and data
  augmentation approaches","  Despite recent advances in deep learning-based language modelling, many
natural language processing (NLP) tasks in the financial domain remain
challenging due to the paucity of appropriately labelled data. Other issues
that can limit task performance are differences in word distribution between
the general corpora - typically used to pre-train language models - and
financial corpora, which often exhibit specialized language and symbology.
Here, we investigate two approaches that may help to mitigate these issues.
Firstly, we experiment with further language model pre-training using large
amounts of in-domain data from business and financial news. We then apply
augmentation approaches to increase the size of our dataset for model
fine-tuning. We report our findings on an Environmental, Social and Governance
(ESG) controversies dataset and demonstrate that both approaches are beneficial
to accuracy in classification tasks.
",2020-10-16T11:20:07Z,http://arxiv.org/abs/2010.08319v1,"Tim Nugent, Nicole Stelea, Jochen L. Leidner"
A Survey on Transfer Learning in Natural Language Processing,"  Deep learning models usually require a huge amount of data. However, these
large datasets are not always attainable. This is common in many challenging
NLP tasks. Consider Neural Machine Translation, for instance, where curating
such large datasets may not be possible specially for low resource languages.
Another limitation of deep learning models is the demand for huge computing
resources. These obstacles motivate research to question the possibility of
knowledge transfer using large trained models. The demand for transfer learning
is increasing as many large models are emerging. In this survey, we feature the
recent transfer learning advances in the field of NLP. We also provide a
taxonomy for categorizing different transfer learning approaches from the
literature.
",2020-05-31T21:52:31Z,http://arxiv.org/abs/2007.04239v1,"Zaid Alyafeai, Maged Saeed AlShaibani, Irfan Ahmad"
EnSyth: A Pruning Approach to Synthesis of Deep Learning Ensembles,"  Deep neural networks have achieved state-of-art performance in many domains
including computer vision, natural language processing and self-driving cars.
However, they are very computationally expensive and memory intensive which
raises significant challenges when it comes to deploy or train them on strict
latency applications or resource-limited environments. As a result, many
attempts have been introduced to accelerate and compress deep learning models,
however the majority were not able to maintain the same accuracy of the
baseline models. In this paper, we describe EnSyth, a deep learning ensemble
approach to enhance the predictability of compact neural network's models.
First, we generate a set of diverse compressed deep learning models using
different hyperparameters for a pruning method, after that we utilise ensemble
learning to synthesise the outputs of the compressed models to compose a new
pool of classifiers. Finally, we apply backward elimination on the generated
pool to explore the best performing combinations of models. On CIFAR-10,
CIFAR-5 data-sets with LeNet-5, EnSyth outperforms the predictability of the
baseline model.
",2019-07-22T12:44:46Z,http://arxiv.org/abs/1907.09286v1,"Besher Alhalabi, Mohamed Medhat Gaber, Shadi Basurra"
"MessageNet: Message Classification using Natural Language Processing and
  Meta-data","  In this paper we propose a new Deep Learning (DL) approach for message
classification. Our method is based on the state-of-the-art Natural Language
Processing (NLP) building blocks, combined with a novel technique for infusing
the meta-data input that is typically available in messages such as the sender
information, timestamps, attached image, audio, affiliations, and more. As we
demonstrate throughout the paper, going beyond the mere text by leveraging all
available channels in the message, could yield an improved representation and
higher classification accuracy. To achieve message representation, each type of
input is processed in a dedicated block in the neural network architecture that
is suitable for the data type. Such an implementation enables training all
blocks together simultaneously, and forming cross channels features in the
network. We show in the Experiments Section that in some cases, message's
meta-data holds an additional information that cannot be extracted just from
the text, and when using this information we achieve better performance.
Furthermore, we demonstrate that our multi-modality block approach outperforms
other approaches for injecting the meta data to the the text classifier.
",2023-01-04T20:11:00Z,http://arxiv.org/abs/2301.01808v1,"Adar Kahana, Oren Elisha"
"Deep Learning and Machine Learning, Advancing Big Data Analytics and
  Management: Handy Appetizer","  This book explores the role of Artificial Intelligence (AI), Machine Learning
(ML), and Deep Learning (DL) in driving the progress of big data analytics and
management. The book focuses on simplifying the complex mathematical concepts
behind deep learning, offering intuitive visualizations and practical case
studies to help readers understand how neural networks and technologies like
Convolutional Neural Networks (CNNs) work. It introduces several classic models
and technologies such as Transformers, GPT, ResNet, BERT, and YOLO,
highlighting their applications in fields like natural language processing,
image recognition, and autonomous driving. The book also emphasizes the
importance of pre-trained models and how they can enhance model performance and
accuracy, with instructions on how to apply these models in various real-world
scenarios. Additionally, it provides an overview of key big data management
technologies like SQL and NoSQL databases, as well as distributed computing
frameworks such as Apache Hadoop and Spark, explaining their importance in
managing and processing vast amounts of data. Ultimately, the book underscores
the value of mastering deep learning and big data management skills as critical
tools for the future workforce, making it an essential resource for both
beginners and experienced professionals.
",2024-09-25T17:31:45Z,http://arxiv.org/abs/2409.17120v1,"Benji Peng, Xuanhe Pan, Yizhu Wen, Ziqian Bi, Keyu Chen, Ming Li, Ming Liu, Qian Niu, Junyu Liu, Jinlang Wang, Sen Zhang, Jiawei Xu, Pohsun Feng"
"Leveraging pre-trained language models for conversational information
  seeking from text","  Recent advances in Natural Language Processing, and in particular on the
construction of very large pre-trained language representation models, is
opening up new perspectives on the construction of conversational information
seeking (CIS) systems. In this paper we investigate the usage of in-context
learning and pre-trained language representation models to address the problem
of information extraction from process description documents, in an incremental
question and answering oriented fashion. In particular we investigate the usage
of the native GPT-3 (Generative Pre-trained Transformer 3) model, together with
two in-context learning customizations that inject conceptual definitions and a
limited number of samples in a few shot-learning fashion. The results highlight
the potential of the approach and the usefulness of the in-context learning
customizations, which can substantially contribute to address the ""training
data challenge"" of deep learning based NLP techniques the BPM field. It also
highlight the challenge posed by control flow relations for which further
training needs to be devised.
",2022-03-31T09:00:46Z,http://arxiv.org/abs/2204.03542v1,"Patrizio Bellan, Mauro Dragoni, Chiara Ghidini"
Training Larger Networks for Deep Reinforcement Learning,"  The success of deep learning in the computer vision and natural language
processing communities can be attributed to training of very deep neural
networks with millions or billions of parameters which can then be trained with
massive amounts of data. However, similar trend has largely eluded training of
deep reinforcement learning (RL) algorithms where larger networks do not lead
to performance improvement. Previous work has shown that this is mostly due to
instability during training of deep RL agents when using larger networks. In
this paper, we make an attempt to understand and address training of larger
networks for deep RL. We first show that naively increasing network capacity
does not improve performance. Then, we propose a novel method that consists of
1) wider networks with DenseNet connection, 2) decoupling representation
learning from training of RL, 3) a distributed training method to mitigate
overfitting problems. Using this three-fold technique, we show that we can
train very large networks that result in significant performance gains. We
present several ablation studies to demonstrate the efficacy of the proposed
method and some intuitive understanding of the reasons for performance gain. We
show that our proposed method outperforms other baseline algorithms on several
challenging locomotion tasks.
",2021-02-16T02:16:54Z,http://arxiv.org/abs/2102.07920v1,"Kei Ota, Devesh K. Jha, Asako Kanezaki"
A Survey on Uncertainty Quantification Methods for Deep Learning,"  Deep neural networks (DNNs) have achieved tremendous success in making
accurate predictions for computer vision, natural language processing, as well
as science and engineering domains. However, it is also well-recognized that
DNNs sometimes make unexpected, incorrect, but overconfident predictions. This
can cause serious consequences in high-stake applications, such as autonomous
driving, medical diagnosis, and disaster response. Uncertainty quantification
(UQ) aims to estimate the confidence of DNN predictions beyond prediction
accuracy. In recent years, many UQ methods have been developed for DNNs. It is
of great practical value to systematically categorize these UQ methods and
compare their advantages and disadvantages. However, existing surveys mostly
focus on categorizing UQ methodologies from a neural network architecture
perspective or a Bayesian perspective and ignore the source of uncertainty that
each methodology can incorporate, making it difficult to select an appropriate
UQ method in practice. To fill the gap, this paper presents a systematic
taxonomy of UQ methods for DNNs based on the types of uncertainty sources (data
uncertainty versus model uncertainty). We summarize the advantages and
disadvantages of methods in each category. We show how our taxonomy of UQ
methodologies can potentially help guide the choice of UQ method in different
machine learning problems (e.g., active learning, robustness, and reinforcement
learning). We also identify current research gaps and propose several future
research directions.
",2023-02-26T22:30:08Z,http://arxiv.org/abs/2302.13425v5,"Wenchong He, Zhe Jiang, Tingsong Xiao, Zelin Xu, Yukun Li"
Hopular: Modern Hopfield Networks for Tabular Data,"  While Deep Learning excels in structured data as encountered in vision and
natural language processing, it failed to meet its expectations on tabular
data. For tabular data, Support Vector Machines (SVMs), Random Forests, and
Gradient Boosting are the best performing techniques with Gradient Boosting in
the lead. Recently, we saw a surge of Deep Learning methods that were tailored
to tabular data but still underperform compared to Gradient Boosting on
small-sized datasets. We suggest ""Hopular"", a novel Deep Learning architecture
for medium- and small-sized datasets, where each layer is equipped with
continuous modern Hopfield networks. The modern Hopfield networks use stored
data to identify feature-feature, feature-target, and sample-sample
dependencies. Hopular's novelty is that every layer can directly access the
original input as well as the whole training set via stored data in the
Hopfield networks. Therefore, Hopular can step-wise update its current model
and the resulting prediction at every layer like standard iterative learning
algorithms. In experiments on small-sized tabular datasets with less than 1,000
samples, Hopular surpasses Gradient Boosting, Random Forests, SVMs, and in
particular several Deep Learning methods. In experiments on medium-sized
tabular data with about 10,000 samples, Hopular outperforms XGBoost, CatBoost,
LightGBM and a state-of-the art Deep Learning method designed for tabular data.
Thus, Hopular is a strong alternative to these methods on tabular data.
",2022-06-01T17:57:44Z,http://arxiv.org/abs/2206.00664v1,"Bernhard Sch√§fl, Lukas Gruber, Angela Bitto-Nemling, Sepp Hochreiter"
A New Method for Cross-Lingual-based Semantic Role Labeling,"  Semantic role labeling is a crucial task in natural language processing,
enabling better comprehension of natural language. However, the lack of
annotated data in multiple languages has posed a challenge for researchers. To
address this, a deep learning algorithm based on model transfer has been
proposed. The algorithm utilizes a dataset consisting of the English portion of
CoNLL2009 and a corpus of semantic roles in Persian. To optimize the efficiency
of training, only ten percent of the educational data from each language is
used. The results of the proposed model demonstrate significant improvements
compared to Niksirt et al.'s model. In monolingual mode, the proposed model
achieved a 2.05 percent improvement on F1-score, while in cross-lingual mode,
the improvement was even more substantial, reaching 6.23 percent. Worth noting
is that the compared model only trained two of the four stages of semantic role
labeling and employed golden data for the remaining two stages. This suggests
that the actual superiority of the proposed model surpasses the reported
numbers by a significant margin. The development of cross-lingual methods for
semantic role labeling holds promise, particularly in addressing the scarcity
of annotated data for various languages. These advancements pave the way for
further research in understanding and processing natural language across
different linguistic contexts.
",2024-08-28T16:06:12Z,http://arxiv.org/abs/2408.15896v1,"Mohammad Ebrahimi, Behrouz Minaei Bidgoli, Nasim Khozouei"
"Emulating Spatio-Temporal Realizations of Three-Dimensional Isotropic
  Turbulence via Deep Sequence Learning Models","  We use a data-driven approach to model a three-dimensional turbulent flow
using cutting-edge Deep Learning techniques. The deep learning framework
incorporates physical constraints on the flow, such as preserving
incompressibility and global statistical invariants of velocity gradient
tensor. The accuracy of the model is assessed using statistical and
physics-based metrics. The data set comes from Direct Numerical Simulation of
an incompressible, statistically stationary, isotropic turbulent flow in a
cubic box. Since the size of the dataset is memory intensive, we first generate
a low-dimensional representation of the velocity data, and then pass it to a
sequence prediction network that learns the spatial and temporal correlations
of the underlying data. The dimensionality reduction is performed via
extraction using Vector-Quantized Autoencoder (VQ-AE), which learns the
discrete latent variables. For the sequence forecasting, the idea of
Transformer architecture from natural language processing is used, and its
performance compared against more standard Recurrent Networks (such as
Convolutional LSTM). These architectures are designed and trained to perform a
sequence to sequence multi-class classification task in which they take an
input sequence with a fixed length (k) and predict a sequence with a fixed
length (p), representing the future time instants of the flow. Our results for
the short-term predictions show that the accuracy of results for both models
deteriorates across predicted snapshots due to autoregressive nature of the
predictions. Based on our diagnostics tests, the trained Conv-Transformer model
outperforms the Conv-LSTM one and can accurately, both quantitatively and
qualitatively, retain the large scales and capture well the inertial scales of
flow but fails at recovering the small and intermittent fluid motions.
",2021-12-07T03:33:39Z,http://arxiv.org/abs/2112.03469v1,"Mohammadreza Momenifar, Enmao Diao, Vahid Tarokh, Andrew D. Bragg"
"Deep Learning Approaches for Improving Question Answering Systems in
  Hepatocellular Carcinoma Research","  In recent years, advancements in natural language processing (NLP) have been
fueled by deep learning techniques, particularly through the utilization of
powerful computing resources like GPUs and TPUs. Models such as BERT and GPT-3,
trained on vast amounts of data, have revolutionized language understanding and
generation. These pre-trained models serve as robust bases for various tasks
including semantic understanding, intelligent writing, and reasoning, paving
the way for a more generalized form of artificial intelligence. NLP, as a vital
application of AI, aims to bridge the gap between humans and computers through
natural language interaction. This paper delves into the current landscape and
future prospects of large-scale model-based NLP, focusing on the
question-answering systems within this domain. Practical cases and developments
in artificial intelligence-driven question-answering systems are analyzed to
foster further exploration and research in the realm of large-scale NLP.
",2024-02-25T09:32:17Z,http://arxiv.org/abs/2402.16038v1,"Shuning Huo, Yafei Xiang, Hanyi Yu, Mengran Zhu, Yulu Gong"
"EXPLORER: Exploration-guided Reasoning for Textual Reinforcement
  Learning","  Text-based games (TBGs) have emerged as an important collection of NLP tasks,
requiring reinforcement learning (RL) agents to combine natural language
understanding with reasoning. A key challenge for agents attempting to solve
such tasks is to generalize across multiple games and demonstrate good
performance on both seen and unseen objects. Purely deep-RL-based approaches
may perform well on seen objects; however, they fail to showcase the same
performance on unseen objects. Commonsense-infused deep-RL agents may work
better on unseen data; unfortunately, their policies are often not
interpretable or easily transferable. To tackle these issues, in this paper, we
present EXPLORER which is an exploration-guided reasoning agent for textual
reinforcement learning. EXPLORER is neurosymbolic in nature, as it relies on a
neural module for exploration and a symbolic module for exploitation. It can
also learn generalized symbolic policies and perform well over unseen data. Our
experiments show that EXPLORER outperforms the baseline agents on Text-World
cooking (TW-Cooking) and Text-World Commonsense (TWC) games.
",2024-03-15T21:22:37Z,http://arxiv.org/abs/2403.10692v1,"Kinjal Basu, Keerthiram Murugesan, Subhajit Chaudhury, Murray Campbell, Kartik Talamadupula, Tim Klinger"
Predicting Process Behaviour using Deep Learning,"  Predicting business process behaviour is an important aspect of business
process management. Motivated by research in natural language processing, this
paper describes an application of deep learning with recurrent neural networks
to the problem of predicting the next event in a business process. This is both
a novel method in process prediction, which has largely relied on explicit
process models, and also a novel application of deep learning methods. The
approach is evaluated on two real datasets and our results surpass the
state-of-the-art in prediction precision.
",2016-12-14T12:33:28Z,http://arxiv.org/abs/1612.04600v2,"Joerg Evermann, Jana-Rebecca Rehse, Peter Fettke"
"Sample-efficient Actor-Critic Reinforcement Learning with Supervised
  Data for Dialogue Management","  Deep reinforcement learning (RL) methods have significant potential for
dialogue policy optimisation. However, they suffer from a poor performance in
the early stages of learning. This is especially problematic for on-line
learning with real users. Two approaches are introduced to tackle this problem.
Firstly, to speed up the learning process, two sample-efficient neural networks
algorithms: trust region actor-critic with experience replay (TRACER) and
episodic natural actor-critic with experience replay (eNACER) are presented.
For TRACER, the trust region helps to control the learning step size and avoid
catastrophic model changes. For eNACER, the natural gradient identifies the
steepest ascent direction in policy space to speed up the convergence. Both
models employ off-policy learning with experience replay to improve
sample-efficiency. Secondly, to mitigate the cold start issue, a corpus of
demonstration data is utilised to pre-train the models prior to on-line
reinforcement learning. Combining these two approaches, we demonstrate a
practical approach to learn deep RL-based dialogue policies and demonstrate
their effectiveness in a task-oriented information seeking domain.
",2017-07-01T09:56:31Z,http://arxiv.org/abs/1707.00130v2,"Pei-Hao Su, Pawel Budzianowski, Stefan Ultes, Milica Gasic, Steve Young"
"What makes a language easy to deep-learn? Deep neural networks and
  humans similarly benefit from compositional structure","  Deep neural networks drive the success of natural language processing. A
fundamental property of language is its compositional structure, allowing
humans to systematically produce forms for new meanings. For humans, languages
with more compositional and transparent structures are typically easier to
learn than those with opaque and irregular structures. However, this
learnability advantage has not yet been shown for deep neural networks,
limiting their use as models for human language learning. Here, we directly
test how neural networks compare to humans in learning and generalizing
different languages that vary in their degree of compositional structure. We
evaluate the memorization and generalization capabilities of a large language
model and recurrent neural networks, and show that both deep neural networks
exhibit a learnability advantage for more structured linguistic input: neural
networks exposed to more compositional languages show more systematic
generalization, greater agreement between different agents, and greater
similarity to human learners.
",2023-02-23T18:57:34Z,http://arxiv.org/abs/2302.12239v4,"Lukas Galke, Yoav Ram, Limor Raviv"
Text segmentation with character-level text embeddings,"  Learning word representations has recently seen much success in computational
linguistics. However, assuming sequences of word tokens as input to linguistic
analysis is often unjustified. For many languages word segmentation is a
non-trivial task and naturally occurring text is sometimes a mixture of natural
language strings and other character data. We propose to learn text
representations directly from raw character sequences by training a Simple
recurrent Network to predict the next character in text. The network uses its
hidden layer to evolve abstract representations of the character sequences it
sees. To demonstrate the usefulness of the learned text embeddings, we use them
as features in a supervised character level text segmentation and labeling
task: recognizing spans of text containing programming language code. By using
the embeddings as features we are able to substantially improve over a baseline
which uses only surface character n-grams.
",2013-09-18T12:38:34Z,http://arxiv.org/abs/1309.4628v1,Grzegorz Chrupa≈Ça
"Continually Learn to Map Visual Concepts to Large Language Models in
  Resource-constrained Environments","  Learning continually from a stream of non-i.i.d. data is an open challenge in
deep learning, even more so when working in resource-constrained environments
such as embedded devices. Visual models that are continually updated through
supervised learning are often prone to overfitting, catastrophic forgetting,
and biased representations. On the other hand, large language models contain
knowledge about multiple concepts and their relations, which can foster a more
robust, informed and coherent learning process. This work proposes Continual
Visual Mapping (CVM), an approach that continually ground vision
representations to a knowledge space extracted from a fixed Language model.
Specifically, CVM continually trains a small and efficient visual model to map
its representations into a conceptual space established by a fixed Large
Language Model. Due to their smaller nature, CVM can be used when directly
adapting large visual pre-trained models is unfeasible due to computational or
data constraints. CVM overcome state-of-the-art continual learning methods on
five benchmarks and offers a promising avenue for addressing generalization
capabilities in continual learning, even in computationally constrained
devices.
",2024-07-11T08:28:40Z,http://arxiv.org/abs/2407.08279v1,"Clea Rebillard, Julio Hurtado, Andrii Krutsylo, Lucia Passaro, Vincenzo Lomonaco"
Operationalising Representation in Natural Language Processing,"  Despite its centrality in the philosophy of cognitive science, there has been
little prior philosophical work engaging with the notion of representation in
contemporary NLP practice. This paper attempts to fill that lacuna: drawing on
ideas from cognitive science, I introduce a framework for evaluating the
representational claims made about components of neural NLP models, proposing
three criteria with which to evaluate whether a component of a model represents
a property and operationalising these criteria using probing classifiers, a
popular analysis technique in NLP (and deep learning more broadly).
  The project of operationalising a philosophically-informed notion of
representation should be of interest to both philosophers of science and NLP
practitioners. It affords philosophers a novel testing-ground for claims about
the nature of representation, and helps NLPers organise the large literature on
probing experiments, suggesting novel avenues for empirical research.
",2023-06-14T01:34:16Z,http://arxiv.org/abs/2306.08193v2,Jacqueline Harding
"Fine-tuning Vision Transformers for the Prediction of State Variables in
  Ising Models","  Transformers are state-of-the-art deep learning models that are composed of
stacked attention and point-wise, fully connected layers designed for handling
sequential data. Transformers are not only ubiquitous throughout Natural
Language Processing (NLP), but, recently, they have inspired a new wave of
Computer Vision (CV) applications research. In this work, a Vision Transformer
(ViT) is applied to predict the state variables of 2-dimensional Ising model
simulations. Our experiments show that ViT outperform state-of-the-art
Convolutional Neural Networks (CNN) when using a small number of microstate
images from the Ising model corresponding to various boundary conditions and
temperatures. This work opens the possibility of applying ViT to other
simulations, and raises interesting research directions on how attention maps
can learn about the underlying physics governing different phenomena.
",2021-09-28T00:23:31Z,http://arxiv.org/abs/2109.13925v2,"Onur Kara, Arijit Sehanobish, Hector H Corzo"
"A Systematic Literature Review on the Use of Machine Learning in
  Software Engineering","  Software engineering (SE) is a dynamic field that involves multiple phases
all of which are necessary to develop sustainable software systems. Machine
learning (ML), a branch of artificial intelligence (AI), has drawn a lot of
attention in recent years thanks to its ability to analyze massive volumes of
data and extract useful patterns from data. Several studies have focused on
examining, categorising, and assessing the application of ML in SE processes.
We conducted a literature review on primary studies to address this gap. The
study was carried out following the objective and the research questions to
explore the current state of the art in applying machine learning techniques in
software engineering processes. The review identifies the key areas within
software engineering where ML has been applied, including software quality
assurance, software maintenance, software comprehension, and software
documentation. It also highlights the specific ML techniques that have been
leveraged in these domains, such as supervised learning, unsupervised learning,
and deep learning.
  Keywords: machine learning, deep learning, software engineering, natural
language processing, source code
",2024-06-19T23:04:27Z,http://arxiv.org/abs/2406.13877v1,"Nyaga Fred, I. O. Temkin"
Word Embedding based Edit Distance,"  Text similarity calculation is a fundamental problem in natural language
processing and related fields. In recent years, deep neural networks have been
developed to perform the task and high performances have been achieved. The
neural networks are usually trained with labeled data in supervised learning,
and creation of labeled data is usually very costly. In this short paper, we
address unsupervised learning for text similarity calculation. We propose a new
method called Word Embedding based Edit Distance (WED), which incorporates word
embedding into edit distance. Experiments on three benchmark datasets show WED
outperforms state-of-the-art unsupervised methods including edit distance,
TF-IDF based cosine, word embedding based cosine, Jaccard index, etc.
",2018-10-25T07:50:17Z,http://arxiv.org/abs/1810.10752v1,"Yilin Niu, Chao Qiao, Hang Li, Minlie Huang"
"Improving a neural network model by explanation-guided training for
  glioma classification based on MRI data","  In recent years, artificial intelligence (AI) systems have come to the
forefront. These systems, mostly based on Deep learning (DL), achieve excellent
results in areas such as image processing, natural language processing, or
speech recognition. Despite the statistically high accuracy of deep learning
models, their output is often a decision of ""black box"". Thus, Interpretability
methods have become a popular way to gain insight into the decision-making
process of deep learning models. Explanation of a deep learning model is
desirable in the medical domain since the experts have to justify their
judgments to the patient. In this work, we proposed a method for
explanation-guided training that uses a Layer-wise relevance propagation (LRP)
technique to force the model to focus only on the relevant part of the image.
We experimentally verified our method on a convolutional neural network (CNN)
model for low-grade and high-grade glioma classification problems. Our
experiments show promising results in a way to use interpretation techniques in
the model training process.
",2021-07-05T13:27:28Z,http://arxiv.org/abs/2107.02008v2,"Frantisek Sefcik, Wanda Benesova"
"Bridging Text and Molecule: A Survey on Multimodal Frameworks for
  Molecule","  Artificial intelligence has demonstrated immense potential in scientific
research. Within molecular science, it is revolutionizing the traditional
computer-aided paradigm, ushering in a new era of deep learning. With recent
progress in multimodal learning and natural language processing, an emerging
trend has targeted at building multimodal frameworks to jointly model molecules
with textual domain knowledge. In this paper, we present the first systematic
survey on multimodal frameworks for molecules research. Specifically,we begin
with the development of molecular deep learning and point out the necessity to
involve textual modality. Next, we focus on recent advances in text-molecule
alignment methods, categorizing current models into two groups based on their
architectures and listing relevant pre-training tasks. Furthermore, we delves
into the utilization of large language models and prompting techniques for
molecular tasks and present significant applications in drug discovery.
Finally, we discuss the limitations in this field and highlight several
promising directions for future research.
",2024-03-07T03:03:13Z,http://arxiv.org/abs/2403.13830v1,"Yi Xiao, Xiangxin Zhou, Qiang Liu, Liang Wang"
"Predicting ATP binding sites in protein sequences using Deep Learning
  and Natural Language Processing","  Predicting ATP-Protein Binding sites in genes is of great significance in the
field of Biology and Medicine. The majority of research in this field has been
conducted through time- and resource-intensive 'wet experiments' in
laboratories. Over the years, researchers have been investigating computational
methods computational methods to accomplish the same goals, utilising the
strength of advanced Deep Learning and NLP algorithms. In this paper, we
propose to develop methods to classify ATP-Protein binding sites. We conducted
various experiments mainly using PSSMs and several word embeddings as features.
We used 2D CNNs and LightGBM classifiers as our chief Deep Learning Algorithms.
The MP3Vec and BERT models have also been subjected to testing in our study.
The outcomes of our experiments demonstrated improvement over the
state-of-the-art benchmarks.
",2024-02-02T18:42:39Z,http://arxiv.org/abs/2402.01829v1,"Shreyas V, Swati Agarwal"
"Categorization in the Wild: Generalizing Cognitive Models to
  Naturalistic Data across Languages","  Categories such as animal or furniture are acquired at an early age and play
an important role in processing, organizing, and communicating world knowledge.
Categories exist across cultures: they allow to efficiently represent the
complexity of the world, and members of a community strongly agree on their
nature, revealing a shared mental representation. Models of category learning
and representation, however, are typically tested on data from small-scale
experiments involving small sets of concepts with artificially restricted
features; and experiments predominantly involve participants of selected
cultural and socio-economical groups (very often involving western native
speakers of English such as U.S. college students) . This work investigates
whether models of categorization generalize (a) to rich and noisy data
approximating the environment humans live in; and (b) across languages and
cultures. We present a Bayesian cognitive model designed to jointly learn
categories and their structured representation from natural language text which
allows us to (a) evaluate performance on a large scale, and (b) apply our model
to a diverse set of languages. We show that meaningful categories comprising
hundreds of concepts and richly structured featural representations emerge
across languages. Our work illustrates the potential of recent advances in
computational modeling and large scale naturalistic datasets for cognitive
science research.
",2019-02-23T19:21:08Z,http://arxiv.org/abs/1902.08830v1,"Lea Frermann, Mirella Lapata"
"MineObserver 2.0: A Deep Learning & In-Game Framework for Assessing
  Natural Language Descriptions of Minecraft Imagery","  MineObserver 2.0 is an AI framework that uses Computer Vision and Natural
Language Processing for assessing the accuracy of learner-generated
descriptions of Minecraft images that include some scientifically relevant
content. The system automatically assesses the accuracy of participant
observations, written in natural language, made during science learning
activities that take place in Minecraft. We demonstrate our system working in
real-time and describe a teacher support dashboard to showcase observations,
both of which advance our previous work. We present the results of a study
showing that MineObserver 2.0 improves over its predecessor both in perceived
accuracy of the system's generated descriptions as well as in usefulness of the
system's feedback. In future work we intend improve system-generated
descriptions, give teachers more control and upgrade the system to perform
continuous learning to more effectively and rapidly respond to novel
observations made by learners.
",2023-12-19T00:15:35Z,http://arxiv.org/abs/2312.11761v1,"Jay Mahajan, Samuel Hum, Jack Henhapl, Diya Yunus, Matthew Gadbury, Emi Brown, Jeff Ginger, H. Chad Lane"
"Look Ma, Only 400 Samples! Revisiting the Effectiveness of Automatic
  N-Gram Rule Generation for Spelling Normalization in Filipino","  With 84.75 million Filipinos online, the ability for models to process online
text is crucial for developing Filipino NLP applications. To this end, spelling
correction is a crucial preprocessing step for downstream processing. However,
the lack of data prevents the use of language models for this task. In this
paper, we propose an N-Gram + Damerau Levenshtein distance model with automatic
rule extraction. We train the model on 300 samples, and show that despite
limited training data, it achieves good performance and outperforms other deep
learning approaches in terms of accuracy and edit distance. Moreover, the model
(1) requires little compute power, (2) trains in little time, thus allowing for
retraining, and (3) is easily interpretable, allowing for direct
troubleshooting, highlighting the success of traditional approaches over more
complex deep learning models in settings where data is unavailable.
",2022-10-06T04:41:26Z,http://arxiv.org/abs/2210.02675v2,"Lorenzo Jaime Yu Flores, Dragomir Radev"
MMREC: LLM Based Multi-Modal Recommender System,"  The importance of recommender systems is growing rapidly due to the
exponential increase in the volume of content generated daily. This surge in
content presents unique challenges for designing effective recommender systems.
Key among these challenges is the need to effectively leverage the vast amounts
of natural language data and images that represent user preferences. This paper
presents a novel approach to enhancing recommender systems by leveraging Large
Language Models (LLMs) and deep learning techniques. The proposed framework
aims to improve the accuracy and relevance of recommendations by incorporating
multi-modal information processing and by the use of unified latent space
representation. The study explores the potential of LLMs to better understand
and utilize natural language data in recommendation contexts, addressing the
limitations of previous methods. The framework efficiently extracts and
integrates text and image information through LLMs, unifying diverse modalities
in a latent space to simplify the learning process for the ranking model.
Experimental results demonstrate the enhanced discriminative power of the model
when utilizing multi-modal information. This research contributes to the
evolving field of recommender systems by showcasing the potential of LLMs and
multi-modal data integration to create more personalized and contextually
relevant recommendations.
",2024-08-08T04:31:29Z,http://arxiv.org/abs/2408.04211v1,"Jiahao Tian, Jinman Zhao, Zhenkai Wang, Zhicheng Ding"
"Reverse Transfer Learning: Can Word Embeddings Trained for Different NLP
  Tasks Improve Neural Language Models?","  Natural language processing (NLP) tasks tend to suffer from a paucity of
suitably annotated training data, hence the recent success of transfer learning
across a wide variety of them. The typical recipe involves: (i) training a
deep, possibly bidirectional, neural network with an objective related to
language modeling, for which training data is plentiful; and (ii) using the
trained network to derive contextual representations that are far richer than
standard linear word embeddings such as word2vec, and thus result in important
gains. In this work, we wonder whether the opposite perspective is also true:
can contextual representations trained for different NLP tasks improve language
modeling itself? Since language models (LMs) are predominantly locally
optimized, other NLP tasks may help them make better predictions based on the
entire semantic fabric of a document. We test the performance of several types
of pre-trained embeddings in neural LMs, and we investigate whether it is
possible to make the LM more aware of global semantic information through
embeddings pre-trained with a domain classification model. Initial experiments
suggest that as long as the proper objective criterion is used during training,
pre-trained embeddings are likely to be beneficial for neural language
modeling.
",2019-09-09T20:01:51Z,http://arxiv.org/abs/1909.04130v1,"Lyan Verwimp, Jerome R. Bellegarda"
"ParticleGrid: Enabling Deep Learning using 3D Representation of
  Materials","  From AlexNet to Inception, autoencoders to diffusion models, the development
of novel and powerful deep learning models and learning algorithms has
proceeded at breakneck speeds. In part, we believe that rapid iteration of
model architecture and learning techniques by a large community of researchers
over a common representation of the underlying entities has resulted in
transferable deep learning knowledge. As a result, model scale, accuracy,
fidelity, and compute performance have dramatically increased in computer
vision and natural language processing. On the other hand, the lack of a common
representation for chemical structure has hampered similar progress. To enable
transferable deep learning, we identify the need for a robust 3-dimensional
representation of materials such as molecules and crystals. The goal is to
enable both materials property prediction and materials generation with 3D
structures. While computationally costly, such representations can model a
large set of chemical structures. We propose $\textit{ParticleGrid}$, a
SIMD-optimized library for 3D structures, that is designed for deep learning
applications and to seamlessly integrate with deep learning frameworks. Our
highly optimized grid generation allows for generating grids on the fly on the
CPU, reducing storage and GPU compute and memory requirements. We show the
efficacy of 3D grids generated via $\textit{ParticleGrid}$ and accurately
predict molecular energy properties using a 3D convolutional neural network.
Our model is able to get 0.006 mean square error and nearly match the values
calculated using computationally costly density functional theory at a fraction
of the time.
",2022-11-15T21:03:34Z,http://arxiv.org/abs/2211.08506v1,"Shehtab Zaman, Ethan Ferguson, Cecile Pereira, Denis Akhiyarov, Mauricio Araya-Polo, Kenneth Chiu"
"Deep Learning -- A first Meta-Survey of selected Reviews across
  Scientific Disciplines, their Commonalities, Challenges and Research Impact","  Deep learning belongs to the field of artificial intelligence, where machines
perform tasks that typically require some kind of human intelligence. Similar
to the basic structure of a brain, a deep learning algorithm consists of an
artificial neural network, which resembles the biological brain structure.
Mimicking the learning process of humans with their senses, deep learning
networks are fed with (sensory) data, like texts, images, videos or sounds.
These networks outperform the state-of-the-art methods in different tasks and,
because of this, the whole field saw an exponential growth during the last
years. This growth resulted in way over 10,000 publications per year in the
last years. For example, the search engine PubMed alone, which covers only a
sub-set of all publications in the medical field, provides already over 11,000
results in Q3 2020 for the search term 'deep learning', and around 90% of these
results are from the last three years. Consequently, a complete overview over
the field of deep learning is already impossible to obtain and, in the near
future, it will potentially become difficult to obtain an overview over a
subfield. However, there are several review articles about deep learning, which
are focused on specific scientific fields or applications, for example deep
learning advances in computer vision or in specific tasks like object
detection. With these surveys as a foundation, the aim of this contribution is
to provide a first high-level, categorized meta-survey of selected reviews on
deep learning across different scientific disciplines. The categories (computer
vision, language processing, medical informatics and additional works) have
been chosen according to the underlying data sources (image, language, medical,
mixed). In addition, we review the common architectures, methods, pros, cons,
evaluations, challenges and future directions for every sub-category.
",2020-11-16T13:14:18Z,http://arxiv.org/abs/2011.08184v2,"Jan Egger, Antonio Pepe, Christina Gsaxner, Yuan Jin, Jianning Li, Roman Kern"
"iReason: Multimodal Commonsense Reasoning using Videos and Natural
  Language with Interpretability","  Causality knowledge is vital to building robust AI systems. Deep learning
models often perform poorly on tasks that require causal reasoning, which is
often derived using some form of commonsense knowledge not immediately
available in the input but implicitly inferred by humans. Prior work has
unraveled spurious observational biases that models fall prey to in the absence
of causality. While language representation models preserve contextual
knowledge within learned embeddings, they do not factor in causal relationships
during training. By blending causal relationships with the input features to an
existing model that performs visual cognition tasks (such as scene
understanding, video captioning, video question-answering, etc.), better
performance can be achieved owing to the insight causal relationships bring
about. Recently, several models have been proposed that have tackled the task
of mining causal data from either the visual or textual modality. However,
there does not exist widespread research that mines causal relationships by
juxtaposing the visual and language modalities. While images offer a rich and
easy-to-process resource for us to mine causality knowledge from, videos are
denser and consist of naturally time-ordered events. Also, textual information
offers details that could be implicit in videos. We propose iReason, a
framework that infers visual-semantic commonsense knowledge using both videos
and natural language captions. Furthermore, iReason's architecture integrates a
causal rationalization module to aid the process of interpretability, error
analysis and bias detection. We demonstrate the effectiveness of iReason using
a two-pronged comparative analysis with language representation learning models
(BERT, GPT-2) as well as current state-of-the-art multimodal causality models.
",2021-06-25T02:56:34Z,http://arxiv.org/abs/2107.10300v1,"Aman Chadha, Vinija Jain"
"Towards Automated Data Sciences with Natural Language and SageCopilot:
  Practices and Lessons Learned","  While the field of NL2SQL has made significant advancements in translating
natural language instructions into executable SQL scripts for data querying and
processing, achieving full automation within the broader data science pipeline
- encompassing data querying, analysis, visualization, and reporting - remains
a complex challenge. This study introduces SageCopilot, an advanced,
industry-grade system system that automates the data science pipeline by
integrating Large Language Models (LLMs), Autonomous Agents (AutoAgents), and
Language User Interfaces (LUIs). Specifically, SageCopilot incorporates a
two-phase design: an online component refining users' inputs into executable
scripts through In-Context Learning (ICL) and running the scripts for results
reporting & visualization, and an offline preparing demonstrations requested by
ICL in the online phase. A list of trending strategies such as Chain-of-Thought
and prompt-tuning have been used to augment SageCopilot for enhanced
performance. Through rigorous testing and comparative analysis against
prompt-based solutions, SageCopilot has been empirically validated to achieve
superior end-to-end performance in generating or executing scripts and offering
results with visualization, backed by real-world datasets. Our in-depth
ablation studies highlight the individual contributions of various components
and strategies used by SageCopilot to the end-to-end correctness for data
sciences.
",2024-07-21T08:58:18Z,http://arxiv.org/abs/2407.21040v1,"Yuan Liao, Jiang Bian, Yuhui Yun, Shuo Wang, Yubo Zhang, Jiaming Chu, Tao Wang, Kewei Li, Yuchen Li, Xuhong Li, Shilei Ji, Haoyi Xiong"
"An implementation of the ""Guess who?"" game using CLIP","  CLIP (Contrastive Language-Image Pretraining) is an efficient method for
learning computer vision tasks from natural language supervision that has
powered a recent breakthrough in deep learning due to its zero-shot transfer
capabilities. By training from image-text pairs available on the internet, the
CLIP model transfers non-trivially to most tasks without the need for any data
set specific training. In this work, we use CLIP to implement the engine of the
popular game ""Guess who?"", so that the player interacts with the game using
natural language prompts and CLIP automatically decides whether an image in the
game board fulfills that prompt or not. We study the performance of this
approach by benchmarking on different ways of prompting the questions to CLIP,
and show the limitations of its zero-shot capabilites.
",2021-11-30T13:10:52Z,http://arxiv.org/abs/2112.00599v1,"Arnau Mart√≠ Sarri, Victor Rodriguez-Fernandez"
"A Deep Learning Architecture for De-identification of Patient Notes:
  Implementation and Evaluation","  De-identification is the process of removing 18 protected health information
(PHI) from clinical notes in order for the text to be considered not
individually identifiable. Recent advances in natural language processing (NLP)
has allowed for the use of deep learning techniques for the task of
de-identification. In this paper, we present a deep learning architecture that
builds on the latest NLP advances by incorporating deep contextualized word
embeddings and variational drop out Bi-LSTMs. We test this architecture on two
gold standard datasets and show that the architecture achieves state-of-the-art
performance on both data sets while also converging faster than other systems
without the use of dictionaries or other knowledge sources.
",2018-10-03T02:53:04Z,http://arxiv.org/abs/1810.01570v1,"Kaung Khin, Philipp Burckhardt, Rema Padman"
Human Cognition and Language Processing with Neural-Lexicon Hypothesis,"  Cognition and language seem closely related to the human cognitive process,
although they have not been studied and investigated in detail. Our brain is
too complex to fully comprehend the structures and connectivity, as well as its
functions, with the currently available technology such as
electro-encephalography, positron emission tomography, or functional magnetic
resonance imaging, and neurobiological data. Therefore, the exploration of
neurobiological processes, such as cognition, requires substantially more
related evidences, especially from in-vivo human experiments. Cognition and
language are of inter-disciplinary nature and additional methodological support
is needed from other disciplines, such as deep learning in the field of
artificial intelligence, for example. In this paper, we have attempted to
explain the neural mechanisms underlying ""cognition and language processing"" or
""cognition or thinking"" using a novel neural network model with several newly
emerging developments such as neuronal resonance, in-vivo human fiber
tractography or connectivity data, Engram and Hebbian hypothesis, human memory
formation in the high brain areas, deep learning, and more recently developed
neural memory concepts, the neural lexicon. The neural lexicon is developed via
language by repeated exposure to the neural system, similar to multilayer
signal processing in deep learning. We have derived a neural model to explain
how human ""cognition and language processing"" or ""cognition and thinking""
works, with a focus on language, a universal medium of the human society.
Although the proposed hypothesis is not fully based on experimental evidences,
a substantial portion of the observations in this study is directly and
indirectly supported by recent experimental findings and the theoretical bases
of deep learning research.
",2022-10-24T05:31:09Z,http://arxiv.org/abs/2210.12960v2,"Zang-Hee Cho, Sun-Ha Paek, Young-Bo Kim, Taigyoun Cho, Hyejin Jeong, Haigun Lee"
Chatbot System Architecture,"  The conversational agents is one of the most interested topics in computer
science field in the recent decade. Which can be composite from more than one
subject in this field, which you need to apply Natural Language Processing
Concepts and some Artificial Intelligence Techniques such as Deep Learning
methods to make decision about how should be the response. This paper is
dedicated to discuss the system architecture for the conversational agent and
explain each component in details.
",2022-01-17T11:07:58Z,http://arxiv.org/abs/2201.06348v1,"Moataz Mohammed, Mostafa M. Aref"
"Leveraging Large Language Models for Wireless Symbol Detection via
  In-Context Learning","  Deep neural networks (DNNs) have made significant strides in tackling
challenging tasks in wireless systems, especially when an accurate wireless
model is not available. However, when available data is limited, traditional
DNNs often yield subpar results due to underfitting. At the same time, large
language models (LLMs) exemplified by GPT-3, have remarkably showcased their
capabilities across a broad range of natural language processing tasks. But
whether and how LLMs can benefit challenging non-language tasks in wireless
systems is unexplored. In this work, we propose to leverage the in-context
learning ability (a.k.a. prompting) of LLMs to solve wireless tasks in the low
data regime without any training or fine-tuning, unlike DNNs which require
training. We further demonstrate that the performance of LLMs varies
significantly when employed with different prompt templates. To solve this
issue, we employ the latest LLM calibration methods. Our results reveal that
using LLMs via ICL methods generally outperforms traditional DNNs on the symbol
demodulation task and yields highly confident predictions when coupled with
calibration techniques.
",2024-08-28T17:19:20Z,http://arxiv.org/abs/2409.00124v2,"Momin Abbas, Koushik Kar, Tianyi Chen"
"A Hybrid Natural Language Generation System Integrating Rules and Deep
  Learning Algorithms","  This paper proposes an enhanced natural language generation system combining
the merits of both rule-based approaches and modern deep learning algorithms,
boosting its performance to the extent where the generated textual content is
capable of exhibiting agile human-writing styles and the content logic of which
is highly controllable. We also come up with a novel approach called HMCU to
measure the performance of the natural language processing comprehensively and
precisely.
",2020-06-15T00:50:41Z,http://arxiv.org/abs/2006.09213v2,"Wei Wei, Bei Zhou, Georgios Leontidis"
"Distillation of Weighted Automata from Recurrent Neural Networks using a
  Spectral Approach","  This paper is an attempt to bridge the gap between deep learning and
grammatical inference. Indeed, it provides an algorithm to extract a
(stochastic) formal language from any recurrent neural network trained for
language modelling. In detail, the algorithm uses the already trained network
as an oracle -- and thus does not require the access to the inner
representation of the black-box -- and applies a spectral approach to infer a
weighted automaton.
  As weighted automata compute linear functions, they are computationally more
efficient than neural networks and thus the nature of the approach is the one
of knowledge distillation. We detail experiments on 62 data sets (both
synthetic and from real-world applications) that allow an in-depth study of the
abilities of the proposed algorithm. The results show the WA we extract are
good approximations of the RNN, validating the approach. Moreover, we show how
the process provides interesting insights toward the behavior of RNN learned on
data, enlarging the scope of this work to the one of explainability of deep
learning models.
",2020-09-28T07:04:15Z,http://arxiv.org/abs/2009.13101v1,"Remi Eyraud, Stephane Ayache"
"Cross-lingual Adaption Model-Agnostic Meta-Learning for Natural Language
  Understanding","  Meta learning with auxiliary languages has demonstrated promising
improvements for cross-lingual natural language processing. However, previous
studies sample the meta-training and meta-testing data from the same language,
which limits the ability of the model for cross-lingual transfer. In this
paper, we propose XLA-MAML, which performs direct cross-lingual adaption in the
meta-learning stage. We conduct zero-shot and few-shot experiments on Natural
Language Inference and Question Answering. The experimental results demonstrate
the effectiveness of our method across different languages, tasks, and
pretrained models. We also give analysis on various cross-lingual specific
settings for meta-learning including sampling strategy and parallelism.
",2021-11-10T16:53:50Z,http://arxiv.org/abs/2111.05805v1,"Qianying Liu, Fei Cheng, Sadao Kurohashi"
"Harlequin: Color-driven Generation of Synthetic Data for Referring
  Expression Comprehension","  Referring Expression Comprehension (REC) aims to identify a particular object
in a scene by a natural language expression, and is an important topic in
visual language understanding. State-of-the-art methods for this task are based
on deep learning, which generally requires expensive and manually labeled
annotations. Some works tackle the problem with limited-supervision learning or
relying on Large Vision and Language Models. However, the development of
techniques to synthesize labeled data is overlooked. In this paper, we propose
a novel framework that generates artificial data for the REC task, taking into
account both textual and visual modalities. At first, our pipeline processes
existing data to create variations in the annotations. Then, it generates an
image using altered annotations as guidance. The result of this pipeline is a
new dataset, called Harlequin, made by more than 1M queries. This approach
eliminates manual data collection and annotation, enabling scalability and
facilitating arbitrary complexity. We pre-train three REC models on Harlequin,
then fine-tuned and evaluated on human-annotated datasets. Our experiments show
that the pre-training on artificial data is beneficial for performance.
",2024-11-22T09:08:36Z,http://arxiv.org/abs/2411.14807v1,"Luca Parolari, Elena Izzo, Lamberto Ballan"
Advanced Multimodal Deep Learning Architecture for Image-Text Matching,"  Image-text matching is a key multimodal task that aims to model the semantic
association between images and text as a matching relationship. With the advent
of the multimedia information age, image, and text data show explosive growth,
and how to accurately realize the efficient and accurate semantic
correspondence between them has become the core issue of common concern in
academia and industry. In this study, we delve into the limitations of current
multimodal deep learning models in processing image-text pairing tasks.
Therefore, we innovatively design an advanced multimodal deep learning
architecture, which combines the high-level abstract representation ability of
deep neural networks for visual information with the advantages of natural
language processing models for text semantic understanding. By introducing a
novel cross-modal attention mechanism and hierarchical feature fusion strategy,
the model achieves deep fusion and two-way interaction between image and text
feature space. In addition, we also optimize the training objectives and loss
functions to ensure that the model can better map the potential association
structure between images and text during the learning process. Experiments show
that compared with existing image-text matching models, the optimized new model
has significantly improved performance on a series of benchmark data sets. In
addition, the new model also shows excellent generalization and robustness on
large and diverse open scenario datasets and can maintain high matching
performance even in the face of previously unseen complex situations.
",2024-06-13T08:32:24Z,http://arxiv.org/abs/2406.15306v1,"Jinyin Wang, Haijing Zhang, Yihao Zhong, Yingbin Liang, Rongwei Ji, Yiru Cang"
"GUIDO: A Hybrid Approach to Guideline Discovery & Ordering from Natural
  Language Texts","  Extracting workflow nets from textual descriptions can be used to simplify
guidelines or formalize textual descriptions of formal processes like business
processes and algorithms. The task of manually extracting processes, however,
requires domain expertise and effort. While automatic process model extraction
is desirable, annotating texts with formalized process models is expensive.
Therefore, there are only a few machine-learning-based extraction approaches.
Rule-based approaches, in turn, require domain specificity to work well and can
rarely distinguish relevant and irrelevant information in textual descriptions.
In this paper, we present GUIDO, a hybrid approach to the process model
extraction task that first, classifies sentences regarding their relevance to
the process model, using a BERT-based sentence classifier, and second, extracts
a process model from the sentences classified as relevant, using dependency
parsing. The presented approach achieves significantly better results than a
pure rule-based approach. GUIDO achieves an average behavioral similarity score
of $0.93$. Still, in comparison to purely machine-learning-based approaches,
the annotation costs stay low.
",2023-07-19T13:01:03Z,http://arxiv.org/abs/2307.09959v1,"Nils Freyer, Dustin Thewes, Matthias Meinecke"
Modeling Protein Using Large-scale Pretrain Language Model,"  Protein is linked to almost every life process. Therefore, analyzing the
biological structure and property of protein sequences is critical to the
exploration of life, as well as disease detection and drug discovery.
Traditional protein analysis methods tend to be labor-intensive and
time-consuming. The emergence of deep learning models makes modeling data
patterns in large quantities of data possible. Interdisciplinary researchers
have begun to leverage deep learning methods to model large biological
datasets, e.g. using long short-term memory and convolutional neural network
for protein sequence classification. After millions of years of evolution,
evolutionary information is encoded in protein sequences. Inspired by the
similarity between natural language and protein sequences, we use large-scale
language models to model evolutionary-scale protein sequences, encoding protein
biology information in representation. Significant improvements are observed in
both token-level and sequence-level tasks, demonstrating that our large-scale
model can accurately capture evolution information from pretraining on
evolutionary-scale individual sequences. Our code and model are available at
https://github.com/THUDM/ProteinLM.
",2021-08-17T04:13:11Z,http://arxiv.org/abs/2108.07435v2,"Yijia Xiao, Jiezhong Qiu, Ziang Li, Chang-Yu Hsieh, Jie Tang"
Knowledge-based Deep Learning for Modeling Chaotic Systems,"  Deep Learning has received increased attention due to its unbeatable success
in many fields, such as computer vision, natural language processing,
recommendation systems, and most recently in simulating multiphysics problems
and predicting nonlinear dynamical systems. However, modeling and forecasting
the dynamics of chaotic systems remains an open research problem since training
deep learning models requires big data, which is not always available in many
cases. Such deep learners can be trained from additional information obtained
from simulated results and by enforcing the physical laws of the chaotic
systems. This paper considers extreme events and their dynamics and proposes
elegant models based on deep neural networks, called knowledge-based deep
learning (KDL). Our proposed KDL can learn the complex patterns governing
chaotic systems by jointly training on real and simulated data directly from
the dynamics and their differential equations. This knowledge is transferred to
model and forecast real-world chaotic events exhibiting extreme behavior. We
validate the efficiency of our model by assessing it on three real-world
benchmark datasets: El Nino sea surface temperature, San Juan Dengue viral
infection, and Bj{\o}rn{\o}ya daily precipitation, all governed by extreme
events' dynamics. Using prior knowledge of extreme events and physics-based
loss functions to lead the neural network learning, we ensure physically
consistent, generalizable, and accurate forecasting, even in a small data
regime.
",2022-09-09T11:46:25Z,http://arxiv.org/abs/2209.04259v1,"Zakaria Elabid, Tanujit Chakraborty, Abdenour Hadid"
"Deep Learning for Time Series Classification and Extrinsic Regression: A
  Current Survey","  Time Series Classification and Extrinsic Regression are important and
challenging machine learning tasks. Deep learning has revolutionized natural
language processing and computer vision and holds great promise in other fields
such as time series analysis where the relevant features must often be
abstracted from the raw data but are not known a priori. This paper surveys the
current state of the art in the fast-moving field of deep learning for time
series classification and extrinsic regression. We review different network
architectures and training methods used for these tasks and discuss the
challenges and opportunities when applying deep learning to time series data.
We also summarize two critical applications of time series classification and
extrinsic regression, human activity recognition and satellite earth
observation.
",2023-02-06T01:01:00Z,http://arxiv.org/abs/2302.02515v2,"Navid Mohammadi Foumani, Lynn Miller, Chang Wei Tan, Geoffrey I. Webb, Germain Forestier, Mahsa Salehi"
"Multi-task learning for natural language processing in the 2020s: where
  are we going?","  Multi-task learning (MTL) significantly pre-dates the deep learning era, and
it has seen a resurgence in the past few years as researchers have been
applying MTL to deep learning solutions for natural language tasks. While
steady MTL research has always been present, there is a growing interest driven
by the impressive successes published in the related fields of transfer
learning and pre-training, such as BERT, and the release of new challenge
problems, such as GLUE and the NLP Decathlon (decaNLP). These efforts place
more focus on how weights are shared across networks, evaluate the re-usability
of network components and identify use cases where MTL can significantly
outperform single-task solutions. This paper strives to provide a comprehensive
survey of the numerous recent MTL contributions to the field of natural
language processing and provide a forum to focus efforts on the hardest
unsolved problems in the next decade. While novel models that improve
performance on NLP benchmarks are continually produced, lasting MTL challenges
remain unsolved which could hold the key to better language understanding,
knowledge discovery and natural language interfaces.
",2020-07-22T13:44:57Z,http://arxiv.org/abs/2007.16008v1,"Joseph Worsham, Jugal Kalita"
Semi-supervised Interactive Intent Labeling,"  Building the Natural Language Understanding (NLU) modules of task-oriented
Spoken Dialogue Systems (SDS) involves a definition of intents and entities,
collection of task-relevant data, annotating the data with intents and
entities, and then repeating the same process over and over again for adding
any functionality/enhancement to the SDS. In this work, we showcase an Intent
Bulk Labeling system where SDS developers can interactively label and augment
training data from unlabeled utterance corpora using advanced clustering and
visual labeling methods. We extend the Deep Aligned Clustering work with a
better backbone BERT model, explore techniques to select the seed data for
labeling, and develop a data balancing method using an oversampling technique
that utilizes paraphrasing models. We also look at the effect of data
augmentation on the clustering process. Our results show that we can achieve
over 10% gain in clustering accuracy on some datasets using the combination of
the above techniques. Finally, we extract utterance embeddings from the
clustering model and plot the data to interactively bulk label the samples,
reducing the time and effort for data labeling of the whole dataset
significantly.
",2021-04-27T18:06:55Z,http://arxiv.org/abs/2104.13406v2,"Saurav Sahay, Eda Okur, Nagib Hakim, Lama Nachman"
EduBERT: Pretrained Deep Language Models for Learning Analytics,"  The use of large pretrained neural networks to create contextualized word
embeddings has drastically improved performance on several natural language
processing (NLP) tasks. These computationally expensive models have begun to be
applied to domain-specific NLP tasks such as re-hospitalization prediction from
clinical notes. This paper demonstrates that using large pretrained models
produces excellent results on common learning analytics tasks. Pre-training
deep language models using student forum data from a wide array of online
courses improves performance beyond the state of the art on three text
classification tasks. We also show that a smaller, distilled version of our
model produces the best results on two of the three tasks while limiting
computational cost. We make both models available to the research community at
large.
",2019-12-02T11:32:53Z,http://arxiv.org/abs/1912.00690v1,"Benjamin Clavi√©, Kobi Gal"
BabyBear: Cheap inference triage for expensive language models,"  Transformer language models provide superior accuracy over previous models
but they are computationally and environmentally expensive. Borrowing the
concept of model cascading from computer vision, we introduce BabyBear, a
framework for cascading models for natural language processing (NLP) tasks to
minimize cost. The core strategy is inference triage, exiting early when the
least expensive model in the cascade achieves a sufficiently high-confidence
prediction. We test BabyBear on several open source data sets related to
document classification and entity recognition. We find that for common NLP
tasks a high proportion of the inference load can be accomplished with cheap,
fast models that have learned by observing a deep learning model. This allows
us to reduce the compute cost of large-scale classification jobs by more than
50% while retaining overall accuracy. For named entity recognition, we save 33%
of the deep learning compute while maintaining an F1 score higher than 95% on
the CoNLL benchmark.
",2022-05-24T03:21:07Z,http://arxiv.org/abs/2205.11747v1,"Leila Khalili, Yao You, John Bohannon"
A Survey on Deep Learning for Theorem Proving,"  Theorem proving is a fundamental aspect of mathematics, spanning from
informal reasoning in natural language to rigorous derivations in formal
systems. In recent years, the advancement of deep learning, especially the
emergence of large language models, has sparked a notable surge of research
exploring these techniques to enhance the process of theorem proving. This
paper presents a comprehensive survey of deep learning for theorem proving by
offering (i) a thorough review of existing approaches across various tasks such
as autoformalization, premise selection, proofstep generation, and proof
search; (ii) an extensive summary of curated datasets and strategies for
synthetic data generation; (iii) a detailed analysis of evaluation metrics and
the performance of state-of-the-art methods; and (iv) a critical discussion on
the persistent challenges and the promising avenues for future exploration. Our
survey aims to serve as a foundational reference for deep learning approaches
in theorem proving, inspiring and catalyzing further research endeavors in this
rapidly growing field. A curated list of papers is available at
https://github.com/zhaoyu-li/DL4TP.
",2024-04-15T17:07:55Z,http://arxiv.org/abs/2404.09939v3,"Zhaoyu Li, Jialiang Sun, Logan Murphy, Qidong Su, Zenan Li, Xian Zhang, Kaiyu Yang, Xujie Si"
"Training point-based deep learning networks for forest segmentation with
  synthetic data","  Remote sensing through unmanned aerial systems (UAS) has been increasing in
forestry in recent years, along with using machine learning for data
processing. Deep learning architectures, extensively applied in natural
language and image processing, have recently been extended to the point cloud
domain. However, the availability of point cloud datasets for training and
testing remains limited. Creating forested environment point cloud datasets is
expensive, requires high-precision sensors, and is time-consuming as manual
point classification is required. Moreover, forest areas could be inaccessible
or dangerous for humans, further complicating data collection. Then, a question
arises whether it is possible to use synthetic data to train deep learning
networks without the need to rely on large volumes of real forest data. To
answer this question, we developed a realistic simulator that procedurally
generates synthetic forest scenes. Thanks to this, we have conducted a
comparative study of different state-of-the-art point-based deep learning
networks for forest segmentation. Using created datasets, we determined the
feasibility of using synthetic data to train deep learning networks to classify
point clouds from real forest datasets. Both the simulator and the datasets are
released as part of this work.
",2024-03-21T04:01:26Z,http://arxiv.org/abs/2403.14115v2,"Francisco Raverta Capua, Juan Schandin, Pablo De Crist√≥foris"
"Automatic coding of students' writing via Contrastive Representation
  Learning in the Wasserstein space","  Qualitative analysis of verbal data is of central importance in the learning
sciences. It is labor-intensive and time-consuming, however, which limits the
amount of data researchers can include in studies. This work is a step towards
building a statistical machine learning (ML) method for achieving an automated
support for qualitative analyses of students' writing, here specifically in
score laboratory reports in introductory biology for sophistication of
argumentation and reasoning. We start with a set of lab reports from an
undergraduate biology course, scored by a four-level scheme that considers the
complexity of argument structure, the scope of evidence, and the care and
nuance of conclusions. Using this set of labeled data, we show that a popular
natural language modeling processing pipeline, namely vector representation of
words, a.k.a word embeddings, followed by Long Short Term Memory (LSTM) model
for capturing language generation as a state-space model, is able to
quantitatively capture the scoring, with a high Quadratic Weighted Kappa (QWK)
prediction score, when trained in via a novel contrastive learning set-up. We
show that the ML algorithm approached the inter-rater reliability of human
analysis. Ultimately, we conclude, that machine learning (ML) for natural
language processing (NLP) holds promise for assisting learning sciences
researchers in conducting qualitative studies at much larger scales than is
currently possible.
",2020-11-26T16:52:48Z,http://arxiv.org/abs/2011.13384v2,"Ruijie Jiang, Julia Gouvea, David Hammer, Eric Miller, Shuchin Aeron"
Unsupervised Ranking Model for Entity Coreference Resolution,"  Coreference resolution is one of the first stages in deep language
understanding and its importance has been well recognized in the natural
language processing community. In this paper, we propose a generative,
unsupervised ranking model for entity coreference resolution by introducing
resolution mode variables. Our unsupervised system achieves 58.44% F1 score of
the CoNLL metric on the English data from the CoNLL-2012 shared task (Pradhan
et al., 2012), outperforming the Stanford deterministic system (Lee et al.,
2013) by 3.01%.
",2016-03-15T04:39:15Z,http://arxiv.org/abs/1603.04553v1,"Xuezhe Ma, Zhengzhong Liu, Eduard Hovy"
"Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe
  Noise","  The growing importance of massive datasets used for deep learning makes
robustness to label noise a critical property for classifiers to have. Sources
of label noise include automatic labeling, non-expert labeling, and label
corruption by data poisoning adversaries. Numerous previous works assume that
no source of labels can be trusted. We relax this assumption and assume that a
small subset of the training data is trusted. This enables substantial label
corruption robustness performance gains. In addition, particularly severe label
noise can be combated by using a set of trusted data with clean labels. We
utilize trusted data by proposing a loss correction technique that utilizes
trusted examples in a data-efficient manner to mitigate the effects of label
noise on deep neural network classifiers. Across vision and natural language
processing tasks, we experiment with various label noises at several strengths,
and show that our method significantly outperforms existing methods.
",2018-02-14T19:48:50Z,http://arxiv.org/abs/1802.05300v4,"Dan Hendrycks, Mantas Mazeika, Duncan Wilson, Kevin Gimpel"
"STA: Self-controlled Text Augmentation for Improving Text
  Classifications","  Despite recent advancements in Machine Learning, many tasks still involve
working in low-data regimes which can make solving natural language problems
difficult. Recently, a number of text augmentation techniques have emerged in
the field of Natural Language Processing (NLP) which can enrich the training
data with new examples, though they are not without their caveats. For
instance, simple rule-based heuristic methods are effective, but lack variation
in semantic content and syntactic structure with respect to the original text.
On the other hand, more complex deep learning approaches can cause extreme
shifts in the intrinsic meaning of the text and introduce unwanted noise into
the training data. To more reliably control the quality of the augmented
examples, we introduce a state-of-the-art approach for Self-Controlled Text
Augmentation (STA). Our approach tightly controls the generation process by
introducing a self-checking procedure to ensure that generated examples retain
the semantic content of the original text. Experimental results on multiple
benchmarking datasets demonstrate that STA substantially outperforms existing
state-of-the-art techniques, whilst qualitative analysis reveals that the
generated examples are both lexically diverse and semantically reliable.
",2023-02-24T17:54:12Z,http://arxiv.org/abs/2302.12784v1,"Congcong Wang, Gonzalo Fiz Pontiveros, Steven Derby, Tri Kurniawan Wijaya"
"An Uncertainty-aware Deep Learning Framework-based Robust Design
  Optimization of Metamaterial Units","  Mechanical metamaterials represent an innovative class of artificial
structures, distinguished by their extraordinary mechanical characteristics,
which are beyond the scope of traditional natural materials. The use of deep
generative models has become increasingly popular in the design of metamaterial
units. The effectiveness of using deep generative models lies in their capacity
to compress complex input data into a simplified, lower-dimensional latent
space, while also enabling the creation of novel optimal designs through
sampling within this space. However, the design process does not take into
account the effect of model uncertainty due to data sparsity or the effect of
input data uncertainty due to inherent randomness in the data. This might lead
to the generation of undesirable structures with high sensitivity to the
uncertainties in the system. To address this issue, a novel uncertainty-aware
deep learning framework-based robust design approach is proposed for the design
of metamaterial units with optimal target properties. The proposed approach
utilizes the probabilistic nature of the deep learning framework and quantifies
both aleatoric and epistemic uncertainties associated with surrogate-based
design optimization. We demonstrate that the proposed design approach is
capable of designing high-performance metamaterial units with high reliability.
To showcase the effectiveness of the proposed design approach, a
single-objective design optimization problem and a multi-objective design
optimization problem are presented. The optimal robust designs obtained are
validated by comparing them to the designs obtained from the topology
optimization method as well as the designs obtained from a deterministic deep
learning framework-based design optimization where none of the uncertainties in
the system are explicitly considered.
",2024-07-19T22:21:27Z,http://arxiv.org/abs/2407.20251v1,"Zihan Wang, Anindya Bhaduri, Hongyi Xu, Liping Wang"
"Multimodal machine learning for materials science: composition-structure
  bimodal learning for experimentally measured properties","  The widespread application of multimodal machine learning models like GPT-4
has revolutionized various research fields including computer vision and
natural language processing. However, its implementation in materials
informatics remains underexplored, despite the presence of materials data
across diverse modalities, such as composition and structure. The effectiveness
of machine learning models trained on large calculated datasets depends on the
accuracy of calculations, while experimental datasets often have limited data
availability and incomplete information. This paper introduces a novel approach
to multimodal machine learning in materials science via composition-structure
bimodal learning. The proposed COmposition-Structure Bimodal Network (COSNet)
is designed to enhance learning and predictions of experimentally measured
materials properties that have incomplete structure information. Bimodal
learning significantly reduces prediction errors across distinct materials
properties including Li conductivity in solid electrolyte, band gap, refractive
index, dielectric constant, energy, and magnetic moment, surpassing
composition-only learning methods. Furthermore, we identified that data
augmentation based on modal availability plays a pivotal role in the success of
bimodal learning.
",2023-08-04T02:04:52Z,http://arxiv.org/abs/2309.04478v1,"Sheng Gong, Shuo Wang, Taishan Zhu, Yang Shao-Horn, Jeffrey C. Grossman"
"GIT-Mol: A Multi-modal Large Language Model for Molecular Science with
  Graph, Image, and Text","  Large language models have made significant strides in natural language
processing, enabling innovative applications in molecular science by processing
textual representations of molecules. However, most existing language models
cannot capture the rich information with complex molecular structures or
images. In this paper, we introduce GIT-Mol, a multi-modal large language model
that integrates the Graph, Image, and Text information. To facilitate the
integration of multi-modal molecular data, we propose GIT-Former, a novel
architecture that is capable of aligning all modalities into a unified latent
space. We achieve a 5%-10% accuracy increase in properties prediction and a
20.2% boost in molecule generation validity compared to the baselines. With the
any-to-language molecular translation strategy, our model has the potential to
perform more downstream tasks, such as compound name recognition and chemical
reaction prediction.
",2023-08-14T03:12:29Z,http://arxiv.org/abs/2308.06911v3,"Pengfei Liu, Yiming Ren, Jun Tao, Zhixiang Ren"
"Active Learning for Sequence Tagging with Deep Pre-trained Models and
  Bayesian Uncertainty Estimates","  Annotating training data for sequence tagging of texts is usually very
time-consuming. Recent advances in transfer learning for natural language
processing in conjunction with active learning open the possibility to
significantly reduce the necessary annotation budget. We are the first to
thoroughly investigate this powerful combination for the sequence tagging task.
We conduct an extensive empirical study of various Bayesian uncertainty
estimation methods and Monte Carlo dropout options for deep pre-trained models
in the active learning framework and find the best combinations for different
types of models. Besides, we also demonstrate that to acquire instances during
active learning, a full-size Transformer can be substituted with a distilled
version, which yields better computational performance and reduces obstacles
for applying deep active learning in practice.
",2021-01-20T13:59:25Z,http://arxiv.org/abs/2101.08133v2,"Artem Shelmanov, Dmitri Puzyrev, Lyubov Kupriyanova, Denis Belyakov, Daniil Larionov, Nikita Khromov, Olga Kozlova, Ekaterina Artemova, Dmitry V. Dylov, Alexander Panchenko"
A Selective Overview of Deep Learning,"  Deep learning has arguably achieved tremendous success in recent years. In
simple words, deep learning uses the composition of many nonlinear functions to
model the complex dependency between input features and labels. While neural
networks have a long history, recent advances have greatly improved their
performance in computer vision, natural language processing, etc. From the
statistical and scientific perspective, it is natural to ask: What is deep
learning? What are the new characteristics of deep learning, compared with
classical methods? What are the theoretical foundations of deep learning? To
answer these questions, we introduce common neural network models (e.g.,
convolutional neural nets, recurrent neural nets, generative adversarial nets)
and training techniques (e.g., stochastic gradient descent, dropout, batch
normalization) from a statistical point of view. Along the way, we highlight
new characteristics of deep learning (including depth and over-parametrization)
and explain their practical and theoretical benefits. We also sample recent
results on theories of deep learning, many of which are only suggestive. While
a complete understanding of deep learning remains elusive, we hope that our
perspectives and discussions serve as a stimulus for new statistical research.
",2019-04-10T17:53:15Z,http://arxiv.org/abs/1904.05526v2,"Jianqing Fan, Cong Ma, Yiqiao Zhong"
Fine-grained Sentiment Classification using BERT,"  Sentiment classification is an important process in understanding people's
perception towards a product, service, or topic. Many natural language
processing models have been proposed to solve the sentiment classification
problem. However, most of them have focused on binary sentiment classification.
In this paper, we use a promising deep learning model called BERT to solve the
fine-grained sentiment classification task. Experiments show that our model
outperforms other popular models for this task without sophisticated
architecture. We also demonstrate the effectiveness of transfer learning in
natural language processing in the process.
",2019-10-04T09:20:48Z,http://arxiv.org/abs/1910.03474v1,"Manish Munikar, Sushil Shakya, Aakash Shrestha"
Deep Active Learning for Data Mining from Conflict Text Corpora,"  High-resolution event data on armed conflict and related processes have
revolutionized the study of political contention with datasets like UCDP GED,
ACLED etc. However, most of these datasets limit themselves to collecting
spatio-temporal (high-resolution) and intensity data. Information on dynamics,
such as targets, tactics, purposes etc. are rarely collected owing to the
extreme workload of collecting data. However, most datasets rely on a rich
corpus of textual data allowing further mining of further information connected
to each event. This paper proposes one such approach that is inexpensive and
high performance, leveraging active learning - an iterative process of
improving a machine learning model based on sequential (guided) human input.
Active learning is employed to then step-wise train (fine-tuning) of a large,
encoder-only language model adapted for extracting sub-classes of events
relating to conflict dynamics. The approach shows performance similar to human
(gold-standard) coding while reducing the amount of required human annotation
by as much as 99%.
",2024-02-02T17:16:23Z,http://arxiv.org/abs/2402.01577v1,Mihai Croicu
"Explainable machine learning multi-label classification of Spanish legal
  judgements","  Artificial Intelligence techniques such as Machine Learning (ML) have not
been exploited to their maximum potential in the legal domain. This has been
partially due to the insufficient explanations they provided about their
decisions. Automatic expert systems with explanatory capabilities can be
specially useful when legal practitioners search jurisprudence to gather
contextual knowledge for their cases. Therefore, we propose a hybrid system
that applies ML for multi-label classification of judgements (sentences) and
visual and natural language descriptions for explanation purposes, boosted by
Natural Language Processing techniques and deep legal reasoning to identify the
entities, such as the parties, involved. We are not aware of any prior work on
automatic multi-label classification of legal judgements also providing natural
language explanations to the end-users with comparable overall quality. Our
solution achieves over 85 % micro precision on a labelled data set annotated by
legal experts. This endorses its interest to relieve human experts from
monotonous labour-intensive legal classification tasks.
",2024-05-27T19:16:42Z,http://arxiv.org/abs/2405.17610v1,"Francisco de Arriba-P√©rez, Silvia Garc√≠a-M√©ndez, Francisco J. Gonz√°lez-Casta√±o, Jaime Gonz√°lez-Gonz√°lez"
"Sensitive Data Detection and Classification in Spanish Clinical Text:
  Experiments with BERT","  Massive digital data processing provides a wide range of opportunities and
benefits, but at the cost of endangering personal data privacy. Anonymisation
consists in removing or replacing sensitive information from data, enabling its
exploitation for different purposes while preserving the privacy of
individuals. Over the years, a lot of automatic anonymisation systems have been
proposed; however, depending on the type of data, the target language or the
availability of training documents, the task remains challenging still. The
emergence of novel deep-learning models during the last two years has brought
large improvements to the state of the art in the field of Natural Language
Processing. These advancements have been most noticeably led by BERT, a model
proposed by Google in 2018, and the shared language models pre-trained on
millions of documents. In this paper, we use a BERT-based sequence labelling
model to conduct a series of anonymisation experiments on several clinical
datasets in Spanish. We also compare BERT to other algorithms. The experiments
show that a simple BERT-based model with general-domain pre-training obtains
highly competitive results without any domain specific feature engineering.
",2020-03-06T09:46:51Z,http://arxiv.org/abs/2003.03106v2,"Aitor Garc√≠a-Pablos, Naiara Perez, Montse Cuadros"
"Deep Unsupervised Domain Adaptation: A Review of Recent Advances and
  Perspectives","  Deep learning has become the method of choice to tackle real-world problems
in different domains, partly because of its ability to learn from data and
achieve impressive performance on a wide range of applications. However, its
success usually relies on two assumptions: (i) vast troves of labeled datasets
are required for accurate model fitting, and (ii) training and testing data are
independent and identically distributed. Its performance on unseen target
domains, thus, is not guaranteed, especially when encountering
out-of-distribution data at the adaptation stage. The performance drop on data
in a target domain is a critical problem in deploying deep neural networks that
are successfully trained on data in a source domain. Unsupervised domain
adaptation (UDA) is proposed to counter this, by leveraging both labeled source
domain data and unlabeled target domain data to carry out various tasks in the
target domain. UDA has yielded promising results on natural image processing,
video analysis, natural language processing, time-series data analysis, medical
image analysis, etc. In this review, as a rapidly evolving topic, we provide a
systematic comparison of its methods and applications. In addition, the
connection of UDA with its closely related tasks, e.g., domain generalization
and out-of-distribution detection, has also been discussed. Furthermore,
deficiencies in current methods and possible promising directions are
highlighted.
",2022-08-15T20:05:07Z,http://arxiv.org/abs/2208.07422v1,"Xiaofeng Liu, Chaehwa Yoo, Fangxu Xing, Hyejin Oh, Georges El Fakhri, Je-Won Kang, Jonghye Woo"
"Kencorpus: A Kenyan Language Corpus of Swahili, Dholuo and Luhya for
  Natural Language Processing Tasks","  Indigenous African languages are categorized as under-served in Natural
Language Processing. They therefore experience poor digital inclusivity and
information access. The processing challenge with such languages has been how
to use machine learning and deep learning models without the requisite data.
The Kencorpus project intends to bridge this gap by collecting and storing text
and speech data that is good enough for data-driven solutions in applications
such as machine translation, question answering and transcription in
multilingual communities. The Kencorpus dataset is a text and speech corpus for
three languages predominantly spoken in Kenya: Swahili, Dholuo and Luhya. Data
collection was done by researchers from communities, schools, media, and
publishers. The Kencorpus' dataset has a collection of 5,594 items - 4,442
texts (5.6M words) and 1,152 speech files (177hrs). Based on this data, Part of
Speech tagging sets for Dholuo and Luhya (50,000 and 93,000 words respectively)
were developed. We developed 7,537 Question-Answer pairs for Swahili and
created a text translation set of 13,400 sentences from Dholuo and Luhya into
Swahili. The datasets are useful for downstream machine learning tasks such as
model training and translation. We also developed two proof of concept systems:
for Kiswahili speech-to-text and machine learning system for Question Answering
task, with results of 18.87% word error rate and 80% Exact Match (EM)
respectively. These initial results give great promise to the usability of
Kencorpus to the machine learning community. Kencorpus is one of few public
domain corpora for these three low resource languages and forms a basis of
learning and sharing experiences for similar works especially for low resource
languages.
",2022-08-25T13:27:14Z,http://arxiv.org/abs/2208.12081v2,"Barack Wanjawa, Lilian Wanzare, Florence Indede, Owen McOnyango, Edward Ombui, Lawrence Muchemi"
Language Semantic Graph Guided Data-Efficient Learning,"  Developing generalizable models that can effectively learn from limited data
and with minimal reliance on human supervision is a significant objective
within the machine learning community, particularly in the era of deep neural
networks. Therefore, to achieve data-efficient learning, researchers typically
explore approaches that can leverage more related or unlabeled data without
necessitating additional manual labeling efforts, such as Semi-Supervised
Learning (SSL), Transfer Learning (TL), and Data Augmentation (DA). SSL
leverages unlabeled data in the training process, while TL enables the transfer
of expertise from related data distributions. DA broadens the dataset by
synthesizing new data from existing examples. However, the significance of
additional knowledge contained within labels has been largely overlooked in
research. In this paper, we propose a novel perspective on data efficiency that
involves exploiting the semantic information contained in the labels of the
available data. Specifically, we introduce a Language Semantic Graph (LSG)
which is constructed from labels manifest as natural language descriptions.
Upon this graph, an auxiliary graph neural network is trained to extract
high-level semantic relations and then used to guide the training of the
primary model, enabling more adequate utilization of label knowledge. Across
image, video, and audio modalities, we utilize the LSG method in both TL and
SSL scenarios and illustrate its versatility in significantly enhancing
performance compared to other data-efficient learning approaches. Additionally,
our in-depth analysis shows that the LSG method also expedites the training
process.
",2023-11-15T08:54:57Z,http://arxiv.org/abs/2311.08782v1,"Wenxuan Ma, Shuang Li, Lincan Cai, Jingxuan Kang"
Neural Networks for Entity Matching: A Survey,"  Entity matching is the problem of identifying which records refer to the same
real-world entity. It has been actively researched for decades, and a variety
of different approaches have been developed. Even today, it remains a
challenging problem, and there is still generous room for improvement. In
recent years we have seen new methods based upon deep learning techniques for
natural language processing emerge.
  In this survey, we present how neural networks have been used for entity
matching. Specifically, we identify which steps of the entity matching process
existing work have targeted using neural networks, and provide an overview of
the different techniques used at each step. We also discuss contributions from
deep learning in entity matching compared to traditional methods, and propose a
taxonomy of deep neural networks for entity matching.
",2020-10-21T15:36:03Z,http://arxiv.org/abs/2010.11075v2,"Nils Barlaug, Jon Atle Gulla"
A Deep Learning System for Domain-specific Speech Recognition,"  As human-machine voice interfaces provide easy access to increasingly
intelligent machines, many state-of-the-art automatic speech recognition (ASR)
systems are proposed. However, commercial ASR systems usually have poor
performance on domain-specific speech especially under low-resource settings.
The author works with pre-trained DeepSpeech2 and Wav2Vec2 acoustic models to
develop benefit-specific ASR systems. The domain-specific data are collected
using proposed semi-supervised learning annotation with little human
intervention. The best performance comes from a fine-tuned Wav2Vec2-Large-LV60
acoustic model with an external KenLM, which surpasses the Google and AWS ASR
systems on benefit-specific speech. The viability of using error prone ASR
transcriptions as part of spoken language understanding (SLU) is also
investigated. Results of a benefit-specific natural language understanding
(NLU) task show that the domain-specific fine-tuned ASR system can outperform
the commercial ASR systems even when its transcriptions have higher word error
rate (WER), and the results between fine-tuned ASR and human transcriptions are
similar.
",2023-03-18T22:19:09Z,http://arxiv.org/abs/2303.10510v2,Yanan Jia
"DataAgent: Evaluating Large Language Models' Ability to Answer
  Zero-Shot, Natural Language Queries","  Conventional processes for analyzing datasets and extracting meaningful
information are often time-consuming and laborious. Previous work has
identified manual, repetitive coding and data collection as major obstacles
that hinder data scientists from undertaking more nuanced labor and high-level
projects. To combat this, we evaluated OpenAI's GPT-3.5 as a ""Language Data
Scientist"" (LDS) that can extrapolate key findings, including correlations and
basic information, from a given dataset. The model was tested on a diverse set
of benchmark datasets to evaluate its performance across multiple standards,
including data science code-generation based tasks involving libraries such as
NumPy, Pandas, Scikit-Learn, and TensorFlow, and was broadly successful in
correctly answering a given data science query related to the benchmark
dataset. The LDS used various novel prompt engineering techniques to
effectively answer a given question, including Chain-of-Thought reinforcement
and SayCan prompt engineering. Our findings demonstrate great potential for
leveraging Large Language Models for low-level, zero-shot data analysis.
",2024-03-29T22:59:34Z,http://arxiv.org/abs/2404.00188v1,"Manit Mishra, Abderrahman Braham, Charles Marsom, Bryan Chung, Gavin Griffin, Dakshesh Sidnerlikar, Chatanya Sarin, Arjun Rajaram"
"Enable Deep Learning on Mobile Devices: Methods, Systems, and
  Applications","  Deep neural networks (DNNs) have achieved unprecedented success in the field
of artificial intelligence (AI), including computer vision, natural language
processing and speech recognition. However, their superior performance comes at
the considerable cost of computational complexity, which greatly hinders their
applications in many resource-constrained devices, such as mobile phones and
Internet of Things (IoT) devices. Therefore, methods and techniques that are
able to lift the efficiency bottleneck while preserving the high accuracy of
DNNs are in great demand in order to enable numerous edge AI applications. This
paper provides an overview of efficient deep learning methods, systems and
applications. We start from introducing popular model compression methods,
including pruning, factorization, quantization as well as compact model design.
To reduce the large design cost of these manual solutions, we discuss the
AutoML framework for each of them, such as neural architecture search (NAS) and
automated pruning and quantization. We then cover efficient on-device training
to enable user customization based on the local data on mobile devices. Apart
from general acceleration techniques, we also showcase several task-specific
accelerations for point cloud, video and natural language processing by
exploiting their spatial sparsity and temporal/token redundancy. Finally, to
support all these algorithmic advancements, we introduce the efficient deep
learning system design from both software and hardware perspectives.
",2022-04-25T16:52:48Z,http://arxiv.org/abs/2204.11786v1,"Han Cai, Ji Lin, Yujun Lin, Zhijian Liu, Haotian Tang, Hanrui Wang, Ligeng Zhu, Song Han"
Multi-Task Learning in Natural Language Processing: An Overview,"  Deep learning approaches have achieved great success in the field of Natural
Language Processing (NLP). However, directly training deep neural models often
suffer from overfitting and data scarcity problems that are pervasive in NLP
tasks. In recent years, Multi-Task Learning (MTL), which can leverage useful
information of related tasks to achieve simultaneous performance improvement on
these tasks, has been used to handle these problems. In this paper, we give an
overview of the use of MTL in NLP tasks. We first review MTL architectures used
in NLP tasks and categorize them into four classes, including parallel
architecture, hierarchical architecture, modular architecture, and generative
adversarial architecture. Then we present optimization techniques on loss
construction, gradient regularization, data sampling, and task scheduling to
properly train a multi-task model. After presenting applications of MTL in a
variety of NLP tasks, we introduce some benchmark datasets. Finally, we make a
conclusion and discuss several possible research directions in this field.
",2021-09-19T14:51:51Z,http://arxiv.org/abs/2109.09138v2,"Shijie Chen, Yu Zhang, Qiang Yang"
"Potential, Challenges and Future Directions for Deep Learning in
  Prognostics and Health Management Applications","  Deep learning applications have been thriving over the last decade in many
different domains, including computer vision and natural language
understanding. The drivers for the vibrant development of deep learning have
been the availability of abundant data, breakthroughs of algorithms and the
advancements in hardware. Despite the fact that complex industrial assets have
been extensively monitored and large amounts of condition monitoring signals
have been collected, the application of deep learning approaches for detecting,
diagnosing and predicting faults of complex industrial assets has been limited.
The current paper provides a thorough evaluation of the current developments,
drivers, challenges, potential solutions and future research needs in the field
of deep learning applied to Prognostics and Health Management (PHM)
applications.
",2020-05-05T13:35:28Z,http://arxiv.org/abs/2005.02144v1,"Olga Fink, Qin Wang, Markus Svens√©n, Pierre Dersin, Wan-Jui Lee, Melanie Ducoffe"
"The Vulnerability of the Neural Networks Against Adversarial Examples in
  Deep Learning Algorithms","  With further development in the fields of computer vision, network security,
natural language processing and so on so forth, deep learning technology
gradually exposed certain security risks. The existing deep learning algorithms
cannot effectively describe the essential characteristics of data, making the
algorithm unable to give the correct result in the face of malicious input.
Based on current security threats faced by deep learning, this paper introduces
the problem of adversarial examples in deep learning, sorts out the existing
attack and defense methods of the black box and white box, and classifies them.
It briefly describes the application of some adversarial examples in different
scenarios in recent years, compares several defense technologies of adversarial
examples, and finally summarizes the problems in this research field and
prospects for its future development. This paper introduces the common white
box attack methods in detail, and further compares the similarities and
differences between the attack of the black and white box. Correspondingly, the
author also introduces the defense methods, and analyzes the performance of
these methods against the black and white box attack.
",2020-11-02T04:41:08Z,http://arxiv.org/abs/2011.05976v2,Rui Zhao
"Word class representations spontaneously emerge in a deep neural network
  trained on next word prediction","  How do humans learn language, and can the first language be learned at all?
These fundamental questions are still hotly debated. In contemporary
linguistics, there are two major schools of thought that give completely
opposite answers. According to Chomsky's theory of universal grammar, language
cannot be learned because children are not exposed to sufficient data in their
linguistic environment. In contrast, usage-based models of language assume a
profound relationship between language structure and language use. In
particular, contextual mental processing and mental representations are assumed
to have the cognitive capacity to capture the complexity of actual language use
at all levels. The prime example is syntax, i.e., the rules by which words are
assembled into larger units such as sentences. Typically, syntactic rules are
expressed as sequences of word classes. However, it remains unclear whether
word classes are innate, as implied by universal grammar, or whether they
emerge during language acquisition, as suggested by usage-based approaches.
Here, we address this issue from a machine learning and natural language
processing perspective. In particular, we trained an artificial deep neural
network on predicting the next word, provided sequences of consecutive words as
input. Subsequently, we analyzed the emerging activation patterns in the hidden
layers of the neural network. Strikingly, we find that the internal
representations of nine-word input sequences cluster according to the word
class of the tenth word to be predicted as output, even though the neural
network did not receive any explicit information about syntactic rules or word
classes during training. This surprising result suggests, that also in the
human brain, abstract representational categories such as word classes may
naturally emerge as a consequence of predictive coding and processing during
language acquisition.
",2023-02-15T11:02:50Z,http://arxiv.org/abs/2302.07588v1,"Kishore Surendra, Achim Schilling, Paul Stoewer, Andreas Maier, Patrick Krauss"
GPT-3 Models are Poor Few-Shot Learners in the Biomedical Domain,"  Deep neural language models have set new breakthroughs in many tasks of
Natural Language Processing (NLP). Recent work has shown that deep transformer
language models (pretrained on large amounts of texts) can achieve high levels
of task-specific few-shot performance comparable to state-of-the-art models.
However, the ability of these large language models in few-shot transfer
learning has not yet been explored in the biomedical domain. We investigated
the performance of two powerful transformer language models, i.e. GPT-3 and
BioBERT, in few-shot settings on various biomedical NLP tasks. The experimental
results showed that, to a great extent, both the models underperform a language
model fine-tuned on the full training data. Although GPT-3 had already achieved
near state-of-the-art results in few-shot knowledge transfer on open-domain NLP
tasks, it could not perform as effectively as BioBERT, which is orders of
magnitude smaller than GPT-3. Regarding that BioBERT was already pretrained on
large biomedical text corpora, our study suggests that language models may
largely benefit from in-domain pretraining in task-specific few-shot learning.
However, in-domain pretraining seems not to be sufficient; novel pretraining
and few-shot learning strategies are required in the biomedical NLP domain.
",2021-09-06T15:50:37Z,http://arxiv.org/abs/2109.02555v2,"Milad Moradi, Kathrin Blagec, Florian Haberl, Matthias Samwald"
Paraphrase Generation with Deep Reinforcement Learning,"  Automatic generation of paraphrases from a given sentence is an important yet
challenging task in natural language processing (NLP), and plays a key role in
a number of applications such as question answering, search, and dialogue. In
this paper, we present a deep reinforcement learning approach to paraphrase
generation. Specifically, we propose a new framework for the task, which
consists of a \textit{generator} and an \textit{evaluator}, both of which are
learned from data. The generator, built as a sequence-to-sequence learning
model, can produce paraphrases given a sentence. The evaluator, constructed as
a deep matching model, can judge whether two sentences are paraphrases of each
other. The generator is first trained by deep learning and then further
fine-tuned by reinforcement learning in which the reward is given by the
evaluator. For the learning of the evaluator, we propose two methods based on
supervised learning and inverse reinforcement learning respectively, depending
on the type of available training data. Empirical study shows that the learned
evaluator can guide the generator to produce more accurate paraphrases.
Experimental results demonstrate the proposed models (the generators)
outperform the state-of-the-art methods in paraphrase generation in both
automatic evaluation and human evaluation.
",2017-11-01T10:40:42Z,http://arxiv.org/abs/1711.00279v3,"Zichao Li, Xin Jiang, Lifeng Shang, Hang Li"
"Natural Language Processing in Electronic Health Records in Relation to
  Healthcare Decision-making: A Systematic Review","  Background: Natural Language Processing (NLP) is widely used to extract
clinical insights from Electronic Health Records (EHRs). However, the lack of
annotated data, automated tools, and other challenges hinder the full
utilisation of NLP for EHRs. Various Machine Learning (ML), Deep Learning (DL)
and NLP techniques are studied and compared to understand the limitations and
opportunities in this space comprehensively.
  Methodology: After screening 261 articles from 11 databases, we included 127
papers for full-text review covering seven categories of articles: 1) medical
note classification, 2) clinical entity recognition, 3) text summarisation, 4)
deep learning (DL) and transfer learning architecture, 5) information
extraction, 6) Medical language translation and 7) other NLP applications. This
study follows the Preferred Reporting Items for Systematic Reviews and
Meta-Analyses (PRISMA) guidelines.
  Result and Discussion: EHR was the most commonly used data type among the
selected articles, and the datasets were primarily unstructured. Various ML and
DL methods were used, with prediction or classification being the most common
application of ML or DL. The most common use cases were: the International
Classification of Diseases, Ninth Revision (ICD-9) classification, clinical
note analysis, and named entity recognition (NER) for clinical descriptions and
research on psychiatric disorders.
  Conclusion: We find that the adopted ML models were not adequately assessed.
In addition, the data imbalance problem is quite important, yet we must find
techniques to address this underlining problem. Future studies should address
key limitations in studies, primarily identifying Lupus Nephritis, Suicide
Attempts, perinatal self-harmed and ICD-9 classification.
",2023-06-22T12:10:41Z,http://arxiv.org/abs/2306.12834v1,"Elias Hossain, Rajib Rana, Niall Higgins, Jeffrey Soar, Prabal Datta Barua, Anthony R. Pisani, Ph. D, Kathryn Turner}"
V-CNN: When Convolutional Neural Network encounters Data Visualization,"  In recent years, deep learning poses a deep technical revolution in almost
every field and attracts great attentions from industry and academia.
Especially, the convolutional neural network (CNN), one representative model of
deep learning, achieves great successes in computer vision and natural language
processing. However, simply or blindly applying CNN to the other fields results
in lower training effects or makes it quite difficult to adjust the model
parameters. In this poster, we propose a general methodology named V-CNN by
introducing data visualizing for CNN. V-CNN introduces a data visualization
model prior to CNN modeling to make sure the data after processing is fit for
the features of images as well as CNN modeling. We apply V-CNN to the network
intrusion detection problem based on a famous practical dataset: AWID.
Simulation results confirm V-CNN significantly outperforms other studies and
the recall rate of each invasion category is more than 99.8%.
",2018-06-12T10:57:57Z,http://arxiv.org/abs/1807.02164v1,"Mao Yang, Bo Li, Guanxiong Feng, Zhongjiang Yan"
"Security Vulnerability Detection Using Deep Learning Natural Language
  Processing","  Detecting security vulnerabilities in software before they are exploited has
been a challenging problem for decades. Traditional code analysis methods have
been proposed, but are often ineffective and inefficient. In this work, we
model software vulnerability detection as a natural language processing (NLP)
problem with source code treated as texts, and address the automated software
venerability detection with recent advanced deep learning NLP models assisted
by transfer learning on written English. For training and testing, we have
preprocessed the NIST NVD/SARD databases and built a dataset of over 100,000
files in $C$ programming language with 123 types of vulnerabilities. The
extensive experiments generate the best performance of over 93\% accuracy in
detecting security vulnerabilities.
",2021-05-06T01:28:21Z,http://arxiv.org/abs/2105.02388v1,"Noah Ziems, Shaoen Wu"
"Multimodal Deep Neural Networks using Both Engineered and Learned
  Representations for Biodegradability Prediction","  Deep learning algorithms excel at extracting patterns from raw data, and with
large datasets, they have been very successful in computer vision and natural
language applications. However, in other domains, large datasets on which to
learn representations from may not exist. In this work, we develop a novel
multimodal CNN-MLP neural network architecture that utilizes both
domain-specific feature engineering as well as learned representations from raw
data. We illustrate the effectiveness of such network designs in the chemical
sciences, for predicting biodegradability. DeepBioD, a multimodal CNN-MLP
network is more accurate than either standalone network designs, and achieves
an error classification rate of 0.125 that is 27% lower than the current
state-of-the-art. Thus, our work indicates that combining traditional feature
engineering with representation learning can be effective, particularly in
situations where labeled data is limited.
",2018-08-13T20:36:08Z,http://arxiv.org/abs/1808.04456v2,"Garrett B. Goh, Khushmeen Sakloth, Charles Siegel, Abhinav Vishnu, Jim Pfaendtner"
"Processamento de linguagem natural em Portugu√™s e aprendizagem
  profunda para o dom√≠nio de √ìleo e G√°s","  Over the last few decades, institutions around the world have been challenged
to deal with the sheer volume of information captured in unstructured formats,
especially in textual documents. The so called Digital Transformation age,
characterized by important technological advances and the advent of disruptive
methods in Artificial Intelligence, offers opportunities to make better use of
this information. Recent techniques in Natural Language Processing (NLP) with
Deep Learning approaches allow to efficiently process a large volume of data in
order to obtain relevant information, to identify patterns, classify text,
among other applications. In this context, the highly technical vocabulary of
Oil and Gas (O&G) domain represents a challenge for these NLP algorithms, in
which terms can assume a very different meaning in relation to common sense
understanding. The search for suitable mathematical representations and
specific models requires a large amount of representative corpora in the O&G
domain. However, public access to this material is scarce in the scientific
literature, especially considering the Portuguese language. This paper presents
a literature review about the main techniques for deep learning NLP and their
major applications for O&G domain in Portuguese.
",2019-08-05T15:05:48Z,http://arxiv.org/abs/1908.01674v2,"Diogo Gomes, Alexandre Evsukoff"
"Librarian-in-the-Loop: A Natural Language Processing Paradigm for
  Detecting Informal Mentions of Research Data in Academic Literature","  Data citations provide a foundation for studying research data impact.
Collecting and managing data citations is a new frontier in archival science
and scholarly communication. However, the discovery and curation of research
data citations is labor intensive. Data citations that reference unique
identifiers (i.e. DOIs) are readily findable; however, informal mentions made
to research data are more challenging to infer. We propose a natural language
processing (NLP) paradigm to support the human task of identifying informal
mentions made to research datasets. The work of discovering informal data
mentions is currently performed by librarians and their staff in the
Inter-university Consortium for Political and Social Research (ICPSR), a large
social science data archive that maintains a large bibliography of data-related
literature. The NLP model is bootstrapped from data citations actively
collected by librarians at ICPSR. The model combines pattern matching with
multiple iterations of human annotations to learn additional rules for
detecting informal data mentions. These examples are then used to train an NLP
pipeline. The librarian-in-the-loop paradigm is centered in the data work
performed by ICPSR librarians, supporting broader efforts to build a more
comprehensive bibliography of data-related literature that reflects the
scholarly communities of research data users.
",2022-03-10T02:11:30Z,http://arxiv.org/abs/2203.05112v1,"Lizhou Fan, Sara Lafia, David Bleckley, Elizabeth Moss, Andrea Thomer, Libby Hemphill"
A Robust Deep Ensemble Classifier for Figurative Language Detection,"  Recognition and classification of Figurative Language (FL) is an open problem
of Sentiment Analysis in the broader field of Natural Language Processing (NLP)
due to the contradictory meaning contained in phrases with metaphorical
content. The problem itself contains three interrelated FL recognition tasks:
sarcasm, irony and metaphor which, in the present paper, are dealt with
advanced Deep Learning (DL) techniques. First, we introduce a data
prepossessing framework towards efficient data representation formats so that
to optimize the respective inputs to the DL models. In addition, special
features are extracted in order to characterize the syntactic, expressive,
emotional and temper content reflected in the respective social media text
references. These features aim to capture aspects of the social network user's
writing method. Finally, features are fed to a robust, Deep Ensemble Soft
Classifier (DESC) which is based on the combination of different DL techniques.
Using three different benchmark datasets (one of them containing various FL
forms) we conclude that the DESC model achieves a very good performance, worthy
of comparison with relevant methodologies and state-of-the-art technologies in
the challenging field of FL recognition.
",2021-07-09T11:26:37Z,http://arxiv.org/abs/2107.04372v1,"Rolandos Alexandros Potamias, Georgios Siolas, Andreas - Georgios Stafylopatis"
"Background-aware Multi-source Fusion Financial Trend Forecasting
  Mechanism","  Stock prices, as an economic indicator, reflect changes in economic
development and market conditions. Traditional stock price prediction models
often only consider time-series data and are limited by the mechanisms of the
models themselves. Some deep learning models have high computational costs,
depend on a large amount of high-quality data, and have poor interpretations,
making it difficult to intuitively understand the driving factors behind the
predictions. Some studies have used deep learning models to extract text
features and combine them with price data to make joint predictions, but there
are issues with dealing with information noise, accurate extraction of text
sentiment, and how to efficiently fuse text and numerical data. To address
these issues in this paper, we propose a background-aware multi-source fusion
financial trend forecasting mechanism. The system leverages a large language
model to extract key information from policy and stock review texts, utilizing
the MacBERT model to generate feature vectors. These vectors are then
integrated with stock price data to form comprehensive feature representations.
These integrated features are input into a neural network comprising various
deep learning architectures. By integrating multiple data sources, the system
offers a holistic view of market dynamics. It harnesses the comprehensive
analytical and interpretative capabilities of large language models, retaining
deep semantic and sentiment information from policy texts to provide richer
input features for stock trend prediction. Additionally, we compare the
accuracy of six models (LSTM, BiLSTM, MogrifierLSTM, GRU, ST-LSTM, SwinLSTM).
The results demonstrate that our system achieves generally better accuracy in
predicting stock movements, attributed to the incorporation of large language
model processing, policy information, and other influential features.
",2024-07-01T02:10:17Z,http://arxiv.org/abs/2407.00904v1,"Fengting Mo, Shanshan Yan, Yinhao Xiao"
"Crystal Transformer: Self-learning neural language model for Generative
  and Tinkering Design of Materials","  Self-supervised neural language models have recently achieved unprecedented
success, from natural language processing to learning the languages of
biological sequences and organic molecules. These models have demonstrated
superior performance in the generation, structure classification, and
functional predictions for proteins and molecules with learned representations.
However, most of the masking-based pre-trained language models are not designed
for generative design, and their black-box nature makes it difficult to
interpret their design logic. Here we propose BLMM Crystal Transformer, a
neural network based probabilistic generative model for generative and
tinkering design of inorganic materials. Our model is built on the blank
filling language model for text generation and has demonstrated unique
advantages in learning the ""materials grammars"" together with high-quality
generation, interpretability, and data efficiency. It can generate chemically
valid materials compositions with as high as 89.7\% charge neutrality and
84.8\% balanced electronegativity, which are more than 4 and 8 times higher
compared to a pseudo random sampling baseline. The probabilistic generation
process of BLMM allows it to recommend tinkering operations based on learned
materials chemistry and makes it useful for materials doping. Combined with the
TCSP crysal structure prediction algorithm, We have applied our model to
discover a set of new materials as validated using DFT calculations. Our work
thus brings the unsupervised transformer language models based generative
artificial intelligence to inorganic materials. A user-friendly web app has
been developed for computational materials doping and can be accessed freely at
\url{www.materialsatlas.org/blmtinker}.
",2022-04-25T20:20:26Z,http://arxiv.org/abs/2204.11953v1,"Lai Wei, Qinyang Li, Yuqi Song, Stanislav Stefanov, Edirisuriya M. D. Siriwardane, Fanglin Chen, Jianjun Hu"
"Diatom-inspired architected materials using language-based deep
  learning: Perception, transformation and manufacturing","  Learning from nature has been a quest of humanity for millennia. While this
has taken the form of humans assessing natural designs such as bones, butterfly
wings, or spider webs, we can now achieve generating designs using advanced
computational algorithms. In this paper we report novel biologically inspired
designs of diatom structures, enabled using transformer neural networks, using
natural language models to learn, process and transfer insights across
manifestations. We illustrate a series of novel diatom-based designs and also
report a manufactured specimen, created using additive manufacturing. The
method applied here could be expanded to focus on other biological design cues,
implement a systematic optimization to meet certain design targets, and include
a hybrid set of material design sets.
",2023-01-14T10:02:51Z,http://arxiv.org/abs/2301.05875v1,Markus J. Buehler
"A neural document language modeling framework for spoken document
  retrieval","  Recent developments in deep learning have led to a significant innovation in
various classic and practical subjects, including speech recognition, computer
vision, question answering, information retrieval and so on. In the context of
natural language processing (NLP), language representations have shown giant
successes in many downstream tasks, so the school of studies have become a
major stream of research recently. Because the immenseness of multimedia data
along with speech have spread around the world in our daily life, spoken
document retrieval (SDR) has become an important research subject in the past
decades. Targeting on enhancing the SDR performance, the paper concentrates on
proposing a neural retrieval framework, which assembles the merits of using
language modeling (LM) mechanism in SDR and leveraging the abstractive
information learned by the language representation models. Consequently, to our
knowledge, this is a pioneer study on supervised training of a neural LM-based
SDR framework, especially combined with the pretrained language representation
methods.
",2019-10-31T07:50:41Z,http://arxiv.org/abs/1910.14286v1,"Li-Phen Yen, Zhen-Yu Wu, Kuan-Yu Chen"
A Survey on Dialogue Systems: Recent Advances and New Frontiers,"  Dialogue systems have attracted more and more attention. Recent advances on
dialogue systems are overwhelmingly contributed by deep learning techniques,
which have been employed to enhance a wide range of big data applications such
as computer vision, natural language processing, and recommender systems. For
dialogue systems, deep learning can leverage a massive amount of data to learn
meaningful feature representations and response generation strategies, while
requiring a minimum amount of hand-crafting. In this article, we give an
overview to these recent advances on dialogue systems from various perspectives
and discuss some possible research directions. In particular, we generally
divide existing dialogue systems into task-oriented and non-task-oriented
models, then detail how deep learning techniques help them with representative
algorithms and finally discuss some appealing research directions that can
bring the dialogue system research into a new frontier.
",2017-11-06T05:20:54Z,http://arxiv.org/abs/1711.01731v3,"Hongshen Chen, Xiaorui Liu, Dawei Yin, Jiliang Tang"
Deep Anomaly Detection with Outlier Exposure,"  It is important to detect anomalous inputs when deploying machine learning
systems. The use of larger and more complex inputs in deep learning magnifies
the difficulty of distinguishing between anomalous and in-distribution
examples. At the same time, diverse image and text data are available in
enormous quantities. We propose leveraging these data to improve deep anomaly
detection by training anomaly detectors against an auxiliary dataset of
outliers, an approach we call Outlier Exposure (OE). This enables anomaly
detectors to generalize and detect unseen anomalies. In extensive experiments
on natural language processing and small- and large-scale vision tasks, we find
that Outlier Exposure significantly improves detection performance. We also
observe that cutting-edge generative models trained on CIFAR-10 may assign
higher likelihoods to SVHN images than to CIFAR-10 images; we use OE to
mitigate this issue. We also analyze the flexibility and robustness of Outlier
Exposure, and identify characteristics of the auxiliary dataset that improve
performance.
",2018-12-11T18:49:50Z,http://arxiv.org/abs/1812.04606v3,"Dan Hendrycks, Mantas Mazeika, Thomas Dietterich"
"Attention mechanisms and deep learning for machine vision: A survey of
  the state of the art","  With the advent of state of the art nature-inspired pure attention based
models i.e. transformers, and their success in natural language processing
(NLP), their extension to machine vision (MV) tasks was inevitable and much
felt. Subsequently, vision transformers (ViTs) were introduced which are giving
quite a challenge to the established deep learning based machine vision
techniques. However, pure attention based models/architectures like
transformers require huge data, large training times and large computational
resources. Some recent works suggest that combinations of these two varied
fields can prove to build systems which have the advantages of both these
fields. Accordingly, this state of the art survey paper is introduced which
hopefully will help readers get useful information about this interesting and
potential research area. A gentle introduction to attention mechanisms is
given, followed by a discussion of the popular attention based deep
architectures. Subsequently, the major categories of the intersection of
attention mechanisms and deep learning for machine vision (MV) based are
discussed. Afterwards, the major algorithms, issues and trends within the scope
of the paper are discussed.
",2021-06-03T10:23:32Z,http://arxiv.org/abs/2106.07550v1,"Abdul Mueed Hafiz, Shabir Ahmad Parah, Rouf Ul Alam Bhat"
Natural Language Adversarial Defense through Synonym Encoding,"  In the area of natural language processing, deep learning models are recently
known to be vulnerable to various types of adversarial perturbations, but
relatively few works are done on the defense side. Especially, there exists few
effective defense method against the successful synonym substitution based
attacks that preserve the syntactic structure and semantic information of the
original text while fooling the deep learning models. We contribute in this
direction and propose a novel adversarial defense method called Synonym
Encoding Method (SEM). Specifically, SEM inserts an encoder before the input
layer of the target model to map each cluster of synonyms to a unique encoding
and trains the model to eliminate possible adversarial perturbations without
modifying the network architecture or adding extra data. Extensive experiments
demonstrate that SEM can effectively defend the current synonym substitution
based attacks and block the transferability of adversarial examples. SEM is
also easy and efficient to scale to large models and big datasets.
",2019-09-15T03:35:18Z,http://arxiv.org/abs/1909.06723v4,"Xiaosen Wang, Hao Jin, Yichen Yang, Kun He"
Learning Unification-Based Natural Language Grammars,"  When parsing unrestricted language, wide-covering grammars often
undergenerate. Undergeneration can be tackled either by sentence correction, or
by grammar correction. This thesis concentrates upon automatic grammar
correction (or machine learning of grammar) as a solution to the problem of
undergeneration. Broadly speaking, grammar correction approaches can be
classified as being either {\it data-driven}, or {\it model-based}. Data-driven
learners use data-intensive methods to acquire grammar. They typically use
grammar formalisms unsuited to the needs of practical text processing and
cannot guarantee that the resulting grammar is adequate for subsequent semantic
interpretation. That is, data-driven learners acquire grammars that generate
strings that humans would judge to be grammatically ill-formed (they {\it
overgenerate}) and fail to assign linguistically plausible parses. Model-based
learners are knowledge-intensive and are reliant for success upon the
completeness of a {\it model of grammaticality}. But in practice, the model
will be incomplete. Given that in this thesis we deal with undergeneration by
learning, we hypothesise that the combined use of data-driven and model-based
learning would allow data-driven learning to compensate for model-based
learning's incompleteness, whilst model-based learning would compensate for
data-driven learning's unsoundness. We describe a system that we have used to
test the hypothesis empirically. The system combines data-driven and
model-based learning to acquire unification-based grammars that are more
suitable for practical text parsing. Using the Spoken English Corpus as data,
and by quantitatively measuring undergeneration, overgeneration and parse
plausibility, we show that this hypothesis is correct.
",1995-02-03T12:17:28Z,http://arxiv.org/abs/cmp-lg/9502002v1,Miles Osborne
Privacy in Deep Learning: A Survey,"  The ever-growing advances of deep learning in many areas including vision,
recommendation systems, natural language processing, etc., have led to the
adoption of Deep Neural Networks (DNNs) in production systems. The availability
of large datasets and high computational power are the main contributors to
these advances. The datasets are usually crowdsourced and may contain sensitive
information. This poses serious privacy concerns as this data can be misused or
leaked through various vulnerabilities. Even if the cloud provider and the
communication link is trusted, there are still threats of inference attacks
where an attacker could speculate properties of the data used for training, or
find the underlying model architecture and parameters. In this survey, we
review the privacy concerns brought by deep learning, and the mitigating
techniques introduced to tackle these issues. We also show that there is a gap
in the literature regarding test-time inference privacy, and propose possible
future research directions.
",2020-04-25T23:47:25Z,http://arxiv.org/abs/2004.12254v5,"Fatemehsadat Mireshghallah, Mohammadkazem Taram, Praneeth Vepakomma, Abhishek Singh, Ramesh Raskar, Hadi Esmaeilzadeh"
"Surrogate Modeling of Trajectory Map-matching in Urban Road Networks
  using Transformer Sequence-to-Sequence Model","  Large-scale geolocation telematics data acquired from connected vehicles has
the potential to significantly enhance mobility infrastructures and operational
systems within smart cities. To effectively utilize this data, it is essential
to accurately match the geolocation data to the road segments. However, this
matching is often not trivial due to the low sampling rate and errors
exacerbated by multipath effects in urban environments. Traditionally,
statistical modeling techniques such as Hidden-Markov models incorporating
domain knowledge into the matching process have been extensively used for
map-matching tasks. However, rule-based map-matching tasks are noise-sensitive
and inefficient in processing large-scale trajectory data. Deep learning
techniques directly learn the relationship between observed data and road
networks from the data, often without the need for hand-crafted rules or domain
knowledge. This renders them an efficient approach for map-matching large-scale
datasets and more robust to the noise. This paper introduces a deep-learning
model, specifically the transformer-based encoder-decoder model, to perform as
a surrogate for offline map-matching algorithms. The encoder-decoder
architecture initially encodes the series of noisy GPS points into a
representation that automatically captures hidden contextual structures and
spatial correlations between GPS points. Subsequently, the decoder associates
data points with the road network features and thus transforms these
representations into a sequence of road segments. The model is trained and
evaluated using GPS traces collected in Manhattan, New York. Achieving an
accuracy of 75%, transformer-based encoder-decoder models extensively employed
in natural language processing presented a promising performance for
translating noisy GPS data to the navigated routes in urban road networks.
",2024-04-18T18:39:23Z,http://arxiv.org/abs/2404.12460v3,"Sevin Mohammadi, Andrew W. Smyth"
One-shot and few-shot learning of word embeddings,"  Standard deep learning systems require thousands or millions of examples to
learn a concept, and cannot integrate new concepts easily. By contrast, humans
have an incredible ability to do one-shot or few-shot learning. For instance,
from just hearing a word used in a sentence, humans can infer a great deal
about it, by leveraging what the syntax and semantics of the surrounding words
tells us. Here, we draw inspiration from this to highlight a simple technique
by which deep recurrent networks can similarly exploit their prior knowledge to
learn a useful representation for a new word from little data. This could make
natural language processing systems much more flexible, by allowing them to
learn continually from the new words they encounter.
",2017-10-27T18:05:22Z,http://arxiv.org/abs/1710.10280v2,"Andrew K. Lampinen, James L. McClelland"
"A Review of Different Word Embeddings for Sentiment Classification using
  Deep Learning","  The web is loaded with textual content, and Natural Language Processing is a
standout amongst the most vital fields in Machine Learning. But when data is
huge simple Machine Learning algorithms are not able to handle it and that is
when Deep Learning comes into play which based on Neural Networks. However
since neural networks cannot process raw text, we have to change over them
through some diverse strategies of word embedding. This paper demonstrates
those distinctive word embedding strategies implemented on an Amazon Review
Dataset, which has two sentiments to be classified: Happy and Unhappy based on
numerous customer reviews. Moreover we demonstrate the distinction in accuracy
with a discourse about which word embedding to apply when.
",2018-07-05T07:17:21Z,http://arxiv.org/abs/1807.02471v1,Debadri Dutta
From LIMA to DeepLIMA: following a new path of interoperability,"  In this article, we describe the architecture of the LIMA (Libre Multilingual
Analyzer) framework and its recent evolution with the addition of new text
analysis modules based on deep neural networks. We extended the functionality
of LIMA in terms of the number of supported languages while preserving existing
configurable architecture and the availability of previously developed
rule-based and statistical analysis components. Models were trained for more
than 60 languages on the Universal Dependencies 2.5 corpora, WikiNer corpora,
and CoNLL-03 dataset. Universal Dependencies allowed us to increase the number
of supported languages and to generate models that could be integrated into
other platforms. This integration of ubiquitous Deep Learning Natural Language
Processing models and the use of standard annotated collections using Universal
Dependencies can be viewed as a new path of interoperability, through the
normalization of models and data, that are complementary to a more standard
technical interoperability, implemented in LIMA through services available in
Docker containers on Docker Hub.
",2024-09-10T14:26:12Z,http://arxiv.org/abs/2409.06550v1,"Victor Bocharov, Romaric Besan√ßon, Ga√´l de Chalendar, Olivier Ferret, Nasredine Semmar"
"Unlocking Futures: A Natural Language Driven Career Prediction System
  for Computer Science and Software Engineering Students","  A career is a crucial aspect for any person to fulfill their desires through
hard work. During their studies, students cannot find the best career
suggestions unless they receive meaningful guidance tailored to their skills.
Therefore, we developed an AI-assisted model for early prediction to provide
better career suggestions. Although the task is difficult, proper guidance can
make it easier. Effective career guidance requires understanding a student's
academic skills, interests, and skill-related activities. In this research, we
collected essential information from Computer Science (CS) and Software
Engineering (SWE) students to train a machine learning (ML) model that predicts
career paths based on students' career-related information. To adequately train
the models, we applied Natural Language Processing (NLP) techniques and
completed dataset pre-processing. For comparative analysis, we utilized
multiple classification ML algorithms and deep learning (DL) algorithms. This
study contributes valuable insights to educational advising by providing
specific career suggestions based on the unique features of CS and SWE
students. Additionally, the research helps individual CS and SWE students find
suitable jobs that match their skills, interests, and skill-related activities.
",2024-05-28T12:56:57Z,http://arxiv.org/abs/2405.18139v1,"Sakir Hossain Faruque, Sharun Akter Khushbu, Sharmin Akter"
Visualizing and Understanding Deep Neural Networks in CTR Prediction,"  Although deep learning techniques have been successfully applied to many
tasks, interpreting deep neural network models is still a big challenge to us.
Recently, many works have been done on visualizing and analyzing the mechanism
of deep neural networks in the areas of image processing and natural language
processing. In this paper, we present our approaches to visualize and
understand deep neural networks for a very important commercial task--CTR
(Click-through rate) prediction. We conduct experiments on the productive data
from our online advertising system with daily varying distribution. To
understand the mechanism and the performance of the model, we inspect the
model's inner status at neuron level. Also, a probe approach is implemented to
measure the layer-wise performance of the model. Moreover, to measure the
influence from the input features, we calculate saliency scores based on the
back-propagated gradients. Practical applications are also discussed, for
example, in understanding, monitoring, diagnosing and refining models and
algorithms.
",2018-06-22T08:03:35Z,http://arxiv.org/abs/1806.08541v1,"Lin Guo, Hui Ye, Wenbo Su, Henhuan Liu, Kai Sun, Hang Xiang"
"Incorporating Dictionaries into Deep Neural Networks for the Chinese
  Clinical Named Entity Recognition","  Clinical Named Entity Recognition (CNER) aims to identify and classify
clinical terms such as diseases, symptoms, treatments, exams, and body parts in
electronic health records, which is a fundamental and crucial task for clinical
and translational research. In recent years, deep neural networks have achieved
significant success in named entity recognition and many other Natural Language
Processing (NLP) tasks. Most of these algorithms are trained end to end, and
can automatically learn features from large scale labeled datasets. However,
these data-driven methods typically lack the capability of processing rare or
unseen entities. Previous statistical methods and feature engineering practice
have demonstrated that human knowledge can provide valuable information for
handling rare and unseen cases. In this paper, we address the problem by
incorporating dictionaries into deep neural networks for the Chinese CNER task.
Two different architectures that extend the Bi-directional Long Short-Term
Memory (Bi-LSTM) neural network and five different feature representation
schemes are proposed to handle the task. Computational results on the CCKS-2017
Task 2 benchmark dataset show that the proposed method achieves the highly
competitive performance compared with the state-of-the-art deep learning
methods.
",2018-04-13T16:36:44Z,http://arxiv.org/abs/1804.05017v1,"Qi Wang, Yuhang Xia, Yangming Zhou, Tong Ruan, Daqi Gao, Ping He"
"Describing Semantic Representations of Brain Activity Evoked by Visual
  Stimuli","  Quantitative modeling of human brain activity based on language
representations has been actively studied in systems neuroscience. However,
previous studies examined word-level representation, and little is known about
whether we could recover structured sentences from brain activity. This study
attempts to generate natural language descriptions of semantic contents from
human brain activity evoked by visual stimuli. To effectively use a small
amount of available brain activity data, our proposed method employs a
pre-trained image-captioning network model using a deep learning framework. To
apply brain activity to the image-captioning network, we train regression
models that learn the relationship between brain activity and deep-layer image
features. The results demonstrate that the proposed model can decode brain
activity and generate descriptions using natural language sentences. We also
conducted several experiments with data from different subsets of brain regions
known to process visual stimuli. The results suggest that semantic information
for sentence generations is widespread across the entire cortex.
",2018-01-19T05:12:59Z,http://arxiv.org/abs/1802.02210v1,"Eri Matsuo, Ichiro Kobayashi, Shinji Nishimoto, Satoshi Nishida, Hideki Asoh"
Transferable Models for Bioacoustics with Human Language Supervision,"  Passive acoustic monitoring offers a scalable, non-invasive method for
tracking global biodiversity and anthropogenic impacts on species. Although
deep learning has become a vital tool for processing this data, current models
are inflexible, typically cover only a handful of species, and are limited by
data scarcity. In this work, we propose BioLingual, a new model for
bioacoustics based on contrastive language-audio pretraining. We first
aggregate bioacoustic archives into a language-audio dataset, called
AnimalSpeak, with over a million audio-caption pairs holding information on
species, vocalization context, and animal behavior. After training on this
dataset to connect language and audio representations, our model can identify
over a thousand species' calls across taxa, complete bioacoustic tasks
zero-shot, and retrieve animal vocalization recordings from natural text
queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks
in the Benchmark of Animal Sounds. Given its broad taxa coverage and ability to
be flexibly queried in human language, we believe this model opens new
paradigms in ecological monitoring and research, including free-text search on
the world's acoustic monitoring archives. We open-source our models, dataset,
and code.
",2023-08-09T14:22:18Z,http://arxiv.org/abs/2308.04978v1,"David Robinson, Adelaide Robinson, Lily Akrapongpisak"
"Prior Knowledge Driven Label Embedding for Slot Filling in Natural
  Language Understanding","  Traditional slot filling in natural language understanding (NLU) predicts a
one-hot vector for each word. This form of label representation lacks semantic
correlation modelling, which leads to severe data sparsity problem, especially
when adapting an NLU model to a new domain. To address this issue, a novel
label embedding based slot filling framework is proposed in this paper. Here,
distributed label embedding is constructed for each slot using prior knowledge.
Three encoding methods are investigated to incorporate different kinds of prior
knowledge about slots: atomic concepts, slot descriptions, and slot exemplars.
The proposed label embeddings tend to share text patterns and reuses data with
different slot labels. This makes it useful for adaptive NLU with limited data.
Also, since label embedding is independent of NLU model, it is compatible with
almost all deep learning based slot filling models. The proposed approaches are
evaluated on three datasets. Experiments on single domain and domain adaptation
tasks show that label embedding achieves significant performance improvement
over traditional one-hot label representation as well as advanced zero-shot
approaches.
",2020-03-22T07:27:07Z,http://arxiv.org/abs/2003.09831v1,"Su Zhu, Zijian Zhao, Rao Ma, Kai Yu"
"Enhancing Deep Knowledge Tracing via Diffusion Models for Personalized
  Adaptive Learning","  In contrast to pedagogies like evidence-based teaching, personalized adaptive
learning (PAL) distinguishes itself by closely monitoring the progress of
individual students and tailoring the learning path to their unique knowledge
and requirements. A crucial technique for effective PAL implementation is
knowledge tracing, which models students' evolving knowledge to predict their
future performance. Based on these predictions, personalized recommendations
for resources and learning paths can be made to meet individual needs. Recent
advancements in deep learning have successfully enhanced knowledge tracking
through Deep Knowledge Tracing (DKT). This paper introduces generative AI
models to further enhance DKT. Generative AI models, rooted in deep learning,
are trained to generate synthetic data, addressing data scarcity challenges in
various applications across fields such as natural language processing (NLP)
and computer vision (CV). This study aims to tackle data shortage issues in
student learning records to enhance DKT performance for PAL. Specifically, it
employs TabDDPM, a diffusion model, to generate synthetic educational records
to augment training data for enhancing DKT. The proposed method's effectiveness
is validated through extensive experiments on ASSISTments datasets. The
experimental results demonstrate that the AI-generated data by TabDDPM
significantly improves DKT performance, particularly in scenarios with small
data for training and large data for testing.
",2024-04-25T00:23:20Z,http://arxiv.org/abs/2405.05134v1,"Ming Kuo, Shouvon Sarker, Lijun Qian, Yujian Fu, Xiangfang Li, Xishuang Dong"
"Using Focal Loss to Fight Shallow Heuristics: An Empirical Analysis of
  Modulated Cross-Entropy in Natural Language Inference","  There is no such thing as a perfect dataset. In some datasets, deep neural
networks discover underlying heuristics that allow them to take shortcuts in
the learning process, resulting in poor generalization capability. Instead of
using standard cross-entropy, we explore whether a modulated version of
cross-entropy called focal loss can constrain the model so as not to use
heuristics and improve generalization performance. Our experiments in natural
language inference show that focal loss has a regularizing impact on the
learning process, increasing accuracy on out-of-distribution data, but slightly
decreasing performance on in-distribution data. Despite the improved
out-of-distribution performance, we demonstrate the shortcomings of focal loss
and its inferiority in comparison to the performance of methods such as
unbiased focal loss and self-debiasing ensembles.
",2022-11-23T22:19:00Z,http://arxiv.org/abs/2211.13331v1,"Frano Rajiƒç, Ivan Stresec, Axel Marmet, Tim Po≈°tuvan"
"DeepEmotex: Classifying Emotion in Text Messages using Deep Transfer
  Learning","  Transfer learning has been widely used in natural language processing through
deep pretrained language models, such as Bidirectional Encoder Representations
from Transformers and Universal Sentence Encoder. Despite the great success,
language models get overfitted when applied to small datasets and are prone to
forgetting when fine-tuned with a classifier. To remedy this problem of
forgetting in transferring deep pretrained language models from one domain to
another domain, existing efforts explore fine-tuning methods to forget less. We
propose DeepEmotex an effective sequential transfer learning method to detect
emotion in text. To avoid forgetting problem, the fine-tuning step is
instrumented by a large amount of emotion-labeled data collected from Twitter.
We conduct an experimental study using both curated Twitter data sets and
benchmark data sets. DeepEmotex models achieve over 91% accuracy for
multi-class emotion classification on test dataset. We evaluate the performance
of the fine-tuned DeepEmotex models in classifying emotion in EmoInt and
Stimulus benchmark datasets. The models correctly classify emotion in 73% of
the instances in the benchmark datasets. The proposed DeepEmotex-BERT model
outperforms Bi-LSTM result on the benchmark datasets by 23%. We also study the
effect of the size of the fine-tuning dataset on the accuracy of our models.
Our evaluation results show that fine-tuning with a large set of
emotion-labeled data improves both the robustness and effectiveness of the
resulting target task model.
",2022-06-12T03:23:40Z,http://arxiv.org/abs/2206.06775v1,"Maryam Hasan, Elke Rundensteiner, Emmanuel Agu"
"Content-driven, unsupervised clustering of news articles through
  multiscale graph partitioning","  The explosion in the amount of news and journalistic content being generated
across the globe, coupled with extended and instantaneous access to information
through online media, makes it difficult and time-consuming to monitor news
developments and opinion formation in real time. There is an increasing need
for tools that can pre-process, analyse and classify raw text to extract
interpretable content; specifically, identifying topics and content-driven
groupings of articles. We present here such a methodology that brings together
powerful vector embeddings from Natural Language Processing with tools from
Graph Theory that exploit diffusive dynamics on graphs to reveal natural
partitions across scales. Our framework uses a recent deep neural network text
analysis methodology (Doc2vec) to represent text in vector form and then
applies a multi-scale community detection method (Markov Stability) to
partition a similarity graph of document vectors. The method allows us to
obtain clusters of documents with similar content, at different levels of
resolution, in an unsupervised manner. We showcase our approach with the
analysis of a corpus of 9,000 news articles published by Vox Media over one
year. Our results show consistent groupings of documents according to content
without a priori assumptions about the number or type of clusters to be found.
The multilevel clustering reveals a quasi-hierarchy of topics and subtopics
with increased intelligibility and improved topic coherence as compared to
external taxonomy services and standard topic detection methods.
",2018-08-03T12:57:15Z,http://arxiv.org/abs/1808.01175v1,"M. Tarik Altuncu, Sophia N. Yaliraki, Mauricio Barahona"
Detecting Bias in Transfer Learning Approaches for Text Classification,"  Classification is an essential and fundamental task in machine learning,
playing a cardinal role in the field of natural language processing (NLP) and
computer vision (CV). In a supervised learning setting, labels are always
needed for the classification task. Especially for deep neural models, a large
amount of high-quality labeled data are required for training. However, when a
new domain comes out, it is usually hard or expensive to acquire the labels.
Transfer learning could be an option to transfer the knowledge from a source
domain to a target domain. A challenge is that these two domains can be
different, either on the feature distribution, or the class distribution for
the nature of the samples. In this work, we evaluate some existing transfer
learning approaches on detecting the bias of imbalanced classes including
traditional and deep models. Besides, we propose an approach to bridge the gap
of the domain class imbalance issue.
",2021-02-03T15:48:21Z,http://arxiv.org/abs/2102.02114v1,Irene Li
"Combination of Domain Knowledge and Deep Learning for Sentiment Analysis
  of Short and Informal Messages on Social Media","  Sentiment analysis has been emerging recently as one of the major natural
language processing (NLP) tasks in many applications. Especially, as social
media channels (e.g. social networks or forums) have become significant sources
for brands to observe user opinions about their products, this task is thus
increasingly crucial. However, when applied with real data obtained from social
media, we notice that there is a high volume of short and informal messages
posted by users on those channels. This kind of data makes the existing works
suffer from many difficulties to handle, especially ones using deep learning
approaches. In this paper, we propose an approach to handle this problem. This
work is extended from our previous work, in which we proposed to combine the
typical deep learning technique of Convolutional Neural Networks with domain
knowledge. The combination is used for acquiring additional training data
augmentation and a more reasonable loss function. In this work, we further
improve our architecture by various substantial enhancements, including
negation-based data augmentation, transfer learning for word embeddings, the
combination of word-level embeddings and character-level embeddings, and using
multitask learning technique for attaching domain knowledge rules in the
learning process. Those enhancements, specifically aiming to handle short and
informal messages, help us to enjoy significant improvement in performance once
experimenting on real datasets.
",2019-02-16T06:03:57Z,http://arxiv.org/abs/1902.06050v2,"Khuong Vo, Tri Nguyen, Dang Pham, Mao Nguyen, Minh Truong, Trung Mai, Tho Quan"
UQ for Credit Risk Management: A deep evidence regression approach,"  Machine Learning has invariantly found its way into various Credit Risk
applications. Due to the intrinsic nature of Credit Risk, quantifying the
uncertainty of the predicted risk metrics is essential, and applying
uncertainty-aware deep learning models to credit risk settings can be very
helpful. In this work, we have explored the application of a scalable UQ-aware
deep learning technique, Deep Evidence Regression and applied it to predicting
Loss Given Default. We contribute to the literature by extending the Deep
Evidence Regression methodology to learning target variables generated by a
Weibull process and provide the relevant learning framework. We demonstrate the
application of our approach to both simulated and real-world data.
",2023-05-08T18:03:01Z,http://arxiv.org/abs/2305.04967v2,Ashish Dhiman
"Language Models are Drummers: Drum Composition with Natural Language
  Pre-Training","  Automatic music generation with artificial intelligence typically requires a
large amount of data which is hard to obtain for many less common genres and
musical instruments. To tackle this issue, we present ongoing work and
preliminary findings on the possibility for deep models to transfer knowledge
from language to music, by finetuning large language models pre-trained on a
massive text corpus on only hundreds of MIDI files of drum performances. We
show that by doing so, one of the largest, state-of-the-art models (GPT3) is
capable of generating reasonable drum grooves, while models that are not
pre-trained (Transformer) shows no such ability beyond naive repetition.
Evaluating generated music is a challenging task, more so is evaluating drum
grooves with little precedence in literature. Hence, we propose a tailored
structural evaluation method and analyze drum grooves produced by GPT3 compared
to those played by human professionals, exposing the strengths and weaknesses
of such generation by language-to-music transfer. Our findings suggest that
language-to-music transfer learning with large language models is viable and
promising.
",2023-01-03T15:47:53Z,http://arxiv.org/abs/2301.01162v1,"Li Zhang, Chris Callison-Burch"
Continual learning on 3D point clouds with random compressed rehearsal,"  Contemporary deep neural networks offer state-of-the-art results when applied
to visual reasoning, e.g., in the context of 3D point cloud data. Point clouds
are important datatype for precise modeling of three-dimensional environments,
but effective processing of this type of data proves to be challenging. In the
world of large, heavily-parameterized network architectures and
continuously-streamed data, there is an increasing need for machine learning
models that can be trained on additional data. Unfortunately, currently
available models cannot fully leverage training on additional data without
losing their past knowledge. Combating this phenomenon, called catastrophic
forgetting, is one of the main objectives of continual learning. Continual
learning for deep neural networks has been an active field of research,
primarily in 2D computer vision, natural language processing, reinforcement
learning, and robotics. However, in 3D computer vision, there are hardly any
continual learning solutions specifically designed to take advantage of point
cloud structure. This work proposes a novel neural network architecture capable
of continual learning on 3D point cloud data. We utilize point cloud structure
properties for preserving a heavily compressed set of past data. By using
rehearsal and reconstruction as regularization methods of the learning process,
our approach achieves a significant decrease of catastrophic forgetting
compared to the existing solutions on several most popular point cloud datasets
considering two continual learning settings: when a task is known beforehand,
and in the challenging scenario of when task information is unknown to the
model.
",2022-05-16T22:59:52Z,http://arxiv.org/abs/2205.08013v2,"Maciej Zamorski, Micha≈Ç Stypu≈Çkowski, Konrad Karanowski, Tomasz Trzci≈Ñski, Maciej Ziƒôba"
Deep Learning in Science,"  Much of the recent success of Artificial Intelligence (AI) has been spurred
on by impressive achievements within a broader family of machine learning
methods, commonly referred to as Deep Learning (DL). This paper provides
insights on the diffusion and impact of DL in science. Through a Natural
Language Processing (NLP) approach on the arXiv.org publication corpus, we
delineate the emerging DL technology and identify a list of relevant search
terms. These search terms allow us to retrieve DL-related publications from Web
of Science across all sciences. Based on that sample, we document the DL
diffusion process in the scientific system. We find i) an exponential growth in
the adoption of DL as a research tool across all sciences and all over the
world, ii) regional differentiation in DL application domains, and iii) a
transition from interdisciplinary DL applications to disciplinary research
within application domains. In a second step, we investigate how the adoption
of DL methods affects scientific development. Therefore, we empirically assess
how DL adoption relates to re-combinatorial novelty and scientific impact in
the health sciences. We find that DL adoption is negatively correlated with
re-combinatorial novelty, but positively correlated with expectation as well as
variance of citation performance. Our findings suggest that DL does not (yet?)
work as an autopilot to navigate complex knowledge landscapes and overthrow
their structure. However, the 'DL principle' qualifies for its versatility as
the nucleus of a general scientific method that advances science in a
measurable way.
",2020-09-03T10:41:29Z,http://arxiv.org/abs/2009.01575v2,"Stefano Bianchini, Moritz M√ºller, Pierre Pelletier"
A Unified Review of Deep Learning for Automated Medical Coding,"  Automated medical coding, an essential task for healthcare operation and
delivery, makes unstructured data manageable by predicting medical codes from
clinical documents. Recent advances in deep learning and natural language
processing have been widely applied to this task. However, deep learning-based
medical coding lacks a unified view of the design of neural network
architectures. This review proposes a unified framework to provide a general
understanding of the building blocks of medical coding models and summarizes
recent advanced models under the proposed framework. Our unified framework
decomposes medical coding into four main components, i.e., encoder modules for
text feature extraction, mechanisms for building deep encoder architectures,
decoder modules for transforming hidden representations into medical codes, and
the usage of auxiliary information. Finally, we introduce the benchmarks and
real-world usage and discuss key research challenges and future directions.
",2022-01-08T09:37:23Z,http://arxiv.org/abs/2201.02797v5,"Shaoxiong Ji, Wei Sun, Xiaobo Li, Hang Dong, Ara Taalas, Yijia Zhang, Honghan Wu, Esa Pitk√§nen, Pekka Marttinen"
"Speech representation learning: Learning bidirectional encoders with
  single-view, multi-view, and multi-task methods","  This thesis focuses on representation learning for sequence data over time or
space, aiming to improve downstream sequence prediction tasks by using the
learned representations. Supervised learning has been the most dominant
approach for training deep neural networks for learning good sequential
representations. However, one limiting factor to scale supervised learning is
the lack of enough annotated data. Motivated by this challenge, it is natural
to explore representation learning methods that can utilize large amounts of
unlabeled and weakly labeled data, as well as an additional data modality. I
describe my broad study of representation learning for speech data. Unlike most
other works that focus on a single learning setting, this thesis studies
multiple settings: supervised learning with auxiliary losses, unsupervised
learning, semi-supervised learning, and multi-view learning. Besides different
learning problems, I also explore multiple approaches for representation
learning. Though I focus on speech data, the methods described in this thesis
can also be applied to other domains. Overall, the field of representation
learning is developing rapidly. State-of-the-art results on speech related
tasks are typically based on Transformers pre-trained with large-scale
self-supervised learning, which aims to learn generic representations that can
benefit multiple downstream tasks. Since 2020, large-scale pre-training has
been the de facto choice to achieve good performance. This delayed thesis does
not attempt to summarize and compare with the latest results on speech
representation learning; instead, it presents a unique study on speech
representation learning before the Transformer era, that covers multiple
learning settings. Some of the findings in this thesis can still be useful
today.
",2023-07-25T20:38:55Z,http://arxiv.org/abs/2308.00129v1,Qingming Tang
Topics to Avoid: Demoting Latent Confounds in Text Classification,"  Despite impressive performance on many text classification tasks, deep neural
networks tend to learn frequent superficial patterns that are specific to the
training data and do not always generalize well. In this work, we observe this
limitation with respect to the task of native language identification. We find
that standard text classifiers which perform well on the test set end up
learning topical features which are confounds of the prediction task (e.g., if
the input text mentions Sweden, the classifier predicts that the author's
native language is Swedish). We propose a method that represents the latent
topical confounds and a model which ""unlearns"" confounding features by
predicting both the label of the input text and the confound; but we train the
two predictors adversarially in an alternating fashion to learn a text
representation that predicts the correct label but is less prone to using
information about the confound. We show that this model generalizes better and
learns features that are indicative of the writing style rather than the
content.
",2019-09-01T19:18:44Z,http://arxiv.org/abs/1909.00453v2,"Sachin Kumar, Shuly Wintner, Noah A. Smith, Yulia Tsvetkov"
"A Natural Language Processing and Deep Learning based Model for
  Automated Vehicle Diagnostics using Free-Text Customer Service Reports","  Initial fault detection and diagnostics are imperative measures to improve
the efficiency, safety, and stability of vehicle operation. In recent years,
numerous studies have investigated data-driven approaches to improve the
vehicle diagnostics process using available vehicle data. Moreover, data-driven
methods are employed to enhance customer-service agent interactions. In this
study, we demonstrate a machine learning pipeline to improve automated vehicle
diagnostics. First, Natural Language Processing (NLP) is used to automate the
extraction of crucial information from free-text failure reports (generated
during customers' calls to the service department). Then, deep learning
algorithms are employed to validate service requests and filter vague or
misleading claims. Ultimately, different classification algorithms are
implemented to classify service requests so that valid service requests can be
directed to the relevant service department. The proposed model- Bidirectional
Long Short Term Memory (BiLSTM) along with Convolution Neural Network (CNN)-
shows more than 18\% accuracy improvement in validating service requests
compared to technicians' capabilities. In addition, using domain-based NLP
techniques at preprocessing and feature extraction stages along with CNN-BiLSTM
based request validation enhanced the accuracy ($>25\%$), sensitivity
($>39\%$), specificity ($>11\%$), and precision ($>11\%$) of Gradient Tree
Boosting (GTB) service classification model. The Receiver Operating
Characteristic Area Under the Curve (ROC-AUC) reached 0.82.
",2021-11-29T21:41:34Z,http://arxiv.org/abs/2111.14977v1,"Ali Khodadadi, Soroush Ghandiparsi, Chen-Nee Chuah"
"Unnatural Language Processing: Bridging the Gap Between Synthetic and
  Natural Language Data","  Large, human-annotated datasets are central to the development of natural
language processing models. Collecting these datasets can be the most
challenging part of the development process. We address this problem by
introducing a general purpose technique for ``simulation-to-real'' transfer in
language understanding problems with a delimited set of target behaviors,
making it possible to develop models that can interpret natural utterances
without natural training data. We begin with a synthetic data generation
procedure, and train a model that can accurately interpret utterances produced
by the data generator. To generalize to natural utterances, we automatically
find projections of natural language utterances onto the support of the
synthetic language, using learned sentence embeddings to define a distance
metric. With only synthetic training data, our approach matches or outperforms
state-of-the-art models trained on natural language data in several domains.
These results suggest that simulation-to-real transfer is a practical framework
for developing NLP applications, and that improved models for transfer might
provide wide-ranging improvements in downstream tasks.
",2020-04-28T16:41:00Z,http://arxiv.org/abs/2004.13645v1,"Alana Marzoev, Samuel Madden, M. Frans Kaashoek, Michael Cafarella, Jacob Andreas"
Deep Clustering with Measure Propagation,"  Deep models have improved state-of-the-art for both supervised and
unsupervised learning. For example, deep embedded clustering (DEC) has greatly
improved the unsupervised clustering performance, by using stacked autoencoders
for representation learning. However, one weakness of deep modeling is that the
local neighborhood structure in the original space is not necessarily preserved
in the latent space. To preserve local geometry, various methods have been
proposed in the supervised and semi-supervised learning literature (e.g.,
spectral clustering and label propagation) using graph Laplacian
regularization. In this paper, we combine the strength of deep representation
learning with measure propagation (MP), a KL-divergence based graph
regularization method originally used in the semi-supervised scenario. The main
assumption of MP is that if two data points are close in the original space,
they are likely to belong to the same class, measured by KL-divergence of class
membership distribution. By taking the same assumption in the unsupervised
learning scenario, we propose our Deep Embedded Clustering Aided by Measure
Propagation (DECAMP) model. We evaluate DECAMP on short text clustering tasks.
On three public datasets, DECAMP performs competitively with other
state-of-the-art baselines, including baselines using additional data to
generate word embeddings used in the clustering process. As an example, on the
Stackoverflow dataset, DECAMP achieved a clustering accuracy of 79%, which is
about 5% higher than all existing baselines. These empirical results suggest
that DECAMP is a very effective method for unsupervised learning.
",2021-04-18T22:02:43Z,http://arxiv.org/abs/2104.08967v3,"Minhua Chen, Badrinath Jayakumar, Padmasundari Gopalakrishnan, Qiming Huang, Michael Johnston, Patrick Haffner"
"Natural Language Processing with Deep Learning for Medical Adverse Event
  Detection from Free-Text Medical Narratives: A Case Study of Detecting Total
  Hip Replacement Dislocation","  Accurate and timely detection of medical adverse events (AEs) from free-text
medical narratives is challenging. Natural language processing (NLP) with deep
learning has already shown great potential for analyzing free-text data, but
its application for medical AE detection has been limited. In this study we
proposed deep learning based NLP (DL-NLP) models for efficient and accurate hip
dislocation AE detection following total hip replacement from standard
(radiology notes) and non-standard (follow-up telephone notes) free-text
medical narratives. We benchmarked these proposed models with a wide variety of
traditional machine learning based NLP (ML-NLP) models, and also assessed the
accuracy of International Classification of Diseases (ICD) and Current
Procedural Terminology (CPT) codes in capturing these hip dislocation AEs in a
multi-center orthopaedic registry. All DL-NLP models out-performed all of the
ML-NLP models, with a convolutional neural network (CNN) model achieving the
best overall performance (Kappa = 0.97 for radiology notes, and Kappa = 1.00
for follow-up telephone notes). On the other hand, the ICD/CPT codes of the
patients who sustained a hip dislocation AE were only 75.24% accurate, showing
the potential of the proposed model to be used in largescale orthopaedic
registries for accurate and efficient hip dislocation AE detection to improve
the quality of care and patient outcome.
",2020-04-17T16:25:36Z,http://arxiv.org/abs/2004.08333v2,"Alireza Borjali, Martin Magneli, David Shin, Henrik Malchau, Orhun K. Muratoglu, Kartik M. Varadarajan"
"APALU: A Trainable, Adaptive Activation Function for Deep Learning
  Networks","  Activation function is a pivotal component of deep learning, facilitating the
extraction of intricate data patterns. While classical activation functions
like ReLU and its variants are extensively utilized, their static nature and
simplicity, despite being advantageous, often limit their effectiveness in
specialized tasks. The trainable activation functions also struggle sometimes
to adapt to the unique characteristics of the data. Addressing these
limitations, we introduce a novel trainable activation function, adaptive
piecewise approximated activation linear unit (APALU), to enhance the learning
performance of deep learning across a broad range of tasks. It presents a
unique set of features that enable it to maintain stability and efficiency in
the learning process while adapting to complex data representations.
Experiments reveal significant improvements over widely used activation
functions for different tasks. In image classification, APALU increases
MobileNet and GoogleNet accuracy by 0.37% and 0.04%, respectively, on the
CIFAR10 dataset. In anomaly detection, it improves the average area under the
curve of One-CLASS Deep SVDD by 0.8% on the MNIST dataset, 1.81% and 1.11%
improvements with DifferNet, and knowledge distillation, respectively, on the
MVTech dataset. Notably, APALU achieves 100% accuracy on a sign language
recognition task with a limited dataset. For regression tasks, APALU enhances
the performance of deep neural networks and recurrent neural networks on
different datasets. These improvements highlight the robustness and
adaptability of APALU across diverse deep-learning applications.
",2024-02-13T06:18:42Z,http://arxiv.org/abs/2402.08244v1,"Barathi Subramanian, Rathinaraja Jeyaraj, Rakhmonov Akhrorjon Akhmadjon Ugli, Jeonghong Kim"
"Model Performance Prediction for Hyperparameter Optimization of Deep
  Learning Models Using High Performance Computing and Quantum Annealing","  Hyperparameter Optimization (HPO) of Deep Learning-based models tends to be a
compute resource intensive process as it usually requires to train the target
model with many different hyperparameter configurations. We show that
integrating model performance prediction with early stopping methods holds
great potential to speed up the HPO process of deep learning models. Moreover,
we propose a novel algorithm called Swift-Hyperband that can use either
classical or quantum support vector regression for performance prediction and
benefit from distributed High Performance Computing environments. This
algorithm is tested not only for the Machine-Learned Particle Flow model used
in High Energy Physics, but also for a wider range of target models from
domains such as computer vision and natural language processing.
Swift-Hyperband is shown to find comparable (or better) hyperparameters as well
as using less computational resources in all test cases.
",2023-11-29T10:32:40Z,http://arxiv.org/abs/2311.17508v1,"Juan Pablo Garc√≠a Amboage, Eric Wulff, Maria Girone, Tom√°s F. Pena"
"Reconstructing Materials Tetrahedron: Challenges in Materials
  Information Extraction","  The discovery of new materials has a documented history of propelling human
progress for centuries and more. The behaviour of a material is a function of
its composition, structure, and properties, which further depend on its
processing and testing conditions. Recent developments in deep learning and
natural language processing have enabled information extraction at scale from
published literature such as peer-reviewed publications, books, and patents.
However, this information is spread in multiple formats, such as tables, text,
and images, and with little or no uniformity in reporting style giving rise to
several machine learning challenges. Here, we discuss, quantify, and document
these challenges in automated information extraction (IE) from materials
science literature towards the creation of a large materials science knowledge
base. Specifically, we focus on IE from text and tables and outline several
challenges with examples. We hope the present work inspires researchers to
address the challenges in a coherent fashion, providing a fillip to IE towards
developing a materials knowledge base.
",2023-10-12T14:57:24Z,http://arxiv.org/abs/2310.08383v3,"Kausik Hira, Mohd Zaki, Dhruvil Sheth, Mausam, N M Anoop Krishnan"
"Advancements in eHealth Data Analytics through Natural Language
  Processing and Deep Learning","  The healthcare environment is commonly referred to as ""information-rich"" but
also ""knowledge poor"". Healthcare systems collect huge amounts of data from
various sources: lab reports, medical letters, logs of medical tools or
programs, medical prescriptions, etc. These massive sets of data can provide
great knowledge and information that can improve the medical services, and
overall the healthcare domain, such as disease prediction by analyzing the
patient's symptoms or disease prevention, by facilitating the discovery of
behavioral factors for diseases. Unfortunately, only a relatively small volume
of the textual eHealth data is processed and interpreted, an important factor
being the difficulty in efficiently performing Big Data operations. In the
medical field, detecting domain-specific multi-word terms is a crucial task as
they can define an entire concept with a few words. A term can be defined as a
linguistic structure or a concept, and it is composed of one or more words with
a specific meaning to a domain. All the terms of a domain create its
terminology. This chapter offers a critical study of the current, most
performant solutions for analyzing unstructured (image and textual) eHealth
data. This study also provides a comparison of the current Natural Language
Processing and Deep Learning techniques in the eHealth context. Finally, we
examine and discuss some of the current issues, and we define a set of research
directions in this area.
",2024-01-19T17:51:11Z,http://arxiv.org/abs/2401.10850v1,"Elena-Simona Apostol, Ciprian-Octavian TruicƒÉ"
"ECGBERT: Understanding Hidden Language of ECGs with Self-Supervised
  Representation Learning","  In the medical field, current ECG signal analysis approaches rely on
supervised deep neural networks trained for specific tasks that require
substantial amounts of labeled data. However, our paper introduces ECGBERT, a
self-supervised representation learning approach that unlocks the underlying
language of ECGs. By unsupervised pre-training of the model, we mitigate
challenges posed by the lack of well-labeled and curated medical data. ECGBERT,
inspired by advances in the area of natural language processing and large
language models, can be fine-tuned with minimal additional layers for various
ECG-based problems. Through four tasks, including Atrial Fibrillation
arrhythmia detection, heartbeat classification, sleep apnea detection, and user
authentication, we demonstrate ECGBERT's potential to achieve state-of-the-art
results on a wide variety of tasks.
",2023-06-10T04:23:08Z,http://arxiv.org/abs/2306.06340v1,"Seokmin Choi, Sajad Mousavi, Phillip Si, Haben G. Yhdego, Fatemeh Khadem, Fatemeh Afghah"
"Deep Speech Based End-to-End Automated Speech Recognition (ASR) for
  Indian-English Accents","  Automated Speech Recognition (ASR) is an interdisciplinary application of
computer science and linguistics that enable us to derive the transcription
from the uttered speech waveform. It finds several applications in Military
like High-performance fighter aircraft, helicopters, air-traffic controller.
Other than military speech recognition is used in healthcare, persons with
disabilities and many more. ASR has been an active research area. Several
models and algorithms for speech to text (STT) have been proposed. One of the
most recent is Mozilla Deep Speech, it is based on the Deep Speech research
paper by Baidu. Deep Speech is a state-of-art speech recognition system is
developed using end-to-end deep learning, it is trained using well-optimized
Recurrent Neural Network (RNN) training system utilizing multiple Graphical
Processing Units (GPUs). This training is mostly done using American-English
accent datasets, which results in poor generalizability to other English
accents. India is a land of vast diversity. This can even be seen in the
speech, there are several English accents which vary from state to state. In
this work, we have used transfer learning approach using most recent Deep
Speech model i.e., deepspeech-0.9.3 to develop an end-to-end speech recognition
system for Indian-English accents. This work utilizes fine-tuning and data
argumentation to further optimize and improve the Deep Speech ASR system. Indic
TTS data of Indian-English accents is used for transfer learning and
fine-tuning the pre-trained Deep Speech model. A general comparison is made
among the untrained model, our trained model and other available speech
recognition services for Indian-English Accents.
",2022-04-03T03:11:21Z,http://arxiv.org/abs/2204.00977v1,"Priyank Dubey, Bilal Shah"
Neural Unsupervised Domain Adaptation in NLP---A Survey,"  Deep neural networks excel at learning from labeled data and achieve
state-of-the-art resultson a wide array of Natural Language Processing tasks.
In contrast, learning from unlabeled data, especially under domain shift,
remains a challenge. Motivated by the latest advances, in this survey we review
neural unsupervised domain adaptation techniques which do not require labeled
target domain data. This is a more challenging yet a more widely applicable
setup. We outline methods, from early traditional non-neural methods to
pre-trained model transfer. We also revisit the notion of domain, and we
uncover a bias in the type of Natural Language Processing tasks which received
most attention. Lastly, we outline future directions, particularly the broader
need for out-of-distribution generalization of future NLP.
",2020-05-31T22:34:14Z,http://arxiv.org/abs/2006.00632v2,"Alan Ramponi, Barbara Plank"
"Artificial intelligence-aided protein engineering: from topological data
  analysis to deep protein language models","  Protein engineering is an emerging field in biotechnology that has the
potential to revolutionize various areas, such as antibody design, drug
discovery, food security, ecology, and more. However, the mutational space
involved is too vast to be handled through experimental means alone. Leveraging
accumulative protein databases, machine learning (ML) models, particularly
those based on natural language processing (NLP), have considerably expedited
protein engineering. Moreover, advances in topological data analysis (TDA) and
artificial intelligence-based protein structure prediction, such as AlphaFold2,
have made more powerful structure-based ML-assisted protein engineering
strategies possible. This review aims to offer a comprehensive, systematic, and
indispensable set of methodological components, including TDA and NLP, for
protein engineering and to facilitate their future development.
",2023-07-27T02:14:09Z,http://arxiv.org/abs/2307.14587v1,"Yuchi Qiu, Guo-Wei Wei"
Do Neural Nets Learn Statistical Laws behind Natural Language?,"  The performance of deep learning in natural language processing has been
spectacular, but the reasons for this success remain unclear because of the
inherent complexity of deep learning. This paper provides empirical evidence of
its effectiveness and of a limitation of neural networks for language
engineering. Precisely, we demonstrate that a neural language model based on
long short-term memory (LSTM) effectively reproduces Zipf's law and Heaps' law,
two representative statistical properties underlying natural language. We
discuss the quality of reproducibility and the emergence of Zipf's law and
Heaps' law as training progresses. We also point out that the neural language
model has a limitation in reproducing long-range correlation, another
statistical property of natural language. This understanding could provide a
direction for improving the architectures of neural networks.
",2017-07-16T09:08:42Z,http://arxiv.org/abs/1707.04848v2,"Shuntaro Takahashi, Kumiko Tanaka-Ishii"
Knowledge Graphs Querying,"  Knowledge graphs (KGs) such as DBpedia, Freebase, YAGO, Wikidata, and NELL
were constructed to store large-scale, real-world facts as (subject, predicate,
object) triples -- that can also be modeled as a graph, where a node (a subject
or an object) represents an entity with attributes, and a directed edge (a
predicate) is a relationship between two entities. Querying KGs is critical in
web search, question answering (QA), semantic search, personal assistants, fact
checking, and recommendation. While significant progress has been made on KG
construction and curation, thanks to deep learning recently we have seen a
surge of research on KG querying and QA. The objectives of our survey are
two-fold. First, research on KG querying has been conducted by several
communities, such as databases, data mining, semantic web, machine learning,
information retrieval, and natural language processing (NLP), with different
focus and terminologies; and also in diverse topics ranging from graph
databases, query languages, join algorithms, graph patterns matching, to more
sophisticated KG embedding and natural language questions (NLQs). We aim at
uniting different interdisciplinary topics and concepts that have been
developed for KG querying. Second, many recent advances on KG and query
embedding, multimodal KG, and KG-QA come from deep learning, IR, NLP, and
computer vision domains. We identify important challenges of KG querying that
received less attention by graph databases, and by the DB community in general,
e.g., incomplete KG, semantic matching, multimodal data, and NLQs. We conclude
by discussing interesting opportunities for the data management community, for
instance, KG as a unified data model and vector-based query processing.
",2023-05-23T19:32:42Z,http://arxiv.org/abs/2305.14485v1,Arijit Khan
Tree Edit Distance Learning via Adaptive Symbol Embeddings,"  Metric learning has the aim to improve classification accuracy by learning a
distance measure which brings data points from the same class closer together
and pushes data points from different classes further apart. Recent research
has demonstrated that metric learning approaches can also be applied to trees,
such as molecular structures, abstract syntax trees of computer programs, or
syntax trees of natural language, by learning the cost function of an edit
distance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.
However, learning such costs directly may yield an edit distance which violates
metric axioms, is challenging to interpret, and may not generalize well. In
this contribution, we propose a novel metric learning approach for trees which
we call embedding edit distance learning (BEDL) and which learns an edit
distance indirectly by embedding the tree nodes as vectors, such that the
Euclidean distance between those vectors supports class discrimination. We
learn such embeddings by reducing the distance to prototypical trees from the
same class and increasing the distance to prototypical trees from different
classes. In our experiments, we show that BEDL improves upon the
state-of-the-art in metric learning for trees on six benchmark data sets,
ranging from computer science over biomedical data to a natural-language
processing data set containing over 300,000 nodes.
",2018-06-13T13:08:16Z,http://arxiv.org/abs/1806.05009v3,"Benjamin Paa√üen, Claudio Gallicchio, Alessio Micheli, Barbara Hammer"
"The Evolution of Distributed Systems for Graph Neural Networks and their
  Origin in Graph Processing and Deep Learning: A Survey","  Graph Neural Networks (GNNs) are an emerging research field. This specialized
Deep Neural Network (DNN) architecture is capable of processing graph
structured data and bridges the gap between graph processing and Deep Learning
(DL). As graphs are everywhere, GNNs can be applied to various domains
including recommendation systems, computer vision, natural language processing,
biology and chemistry. With the rapid growing size of real world graphs, the
need for efficient and scalable GNN training solutions has come. Consequently,
many works proposing GNN systems have emerged throughout the past few years.
However, there is an acute lack of overview, categorization and comparison of
such systems. We aim to fill this gap by summarizing and categorizing important
methods and techniques for large-scale GNN solutions. In addition, we establish
connections between GNN systems, graph processing systems and DL systems.
",2023-05-23T09:22:33Z,http://arxiv.org/abs/2305.13854v1,"Jana Vatter, Ruben Mayer, Hans-Arno Jacobsen"
"The Role of CNL and AMR in Scalable Abstractive Summarization for
  Multilingual Media Monitoring","  In the era of Big Data and Deep Learning, there is a common view that machine
learning approaches are the only way to cope with the robust and scalable
information extraction and summarization. It has been recently proposed that
the CNL approach could be scaled up, building on the concept of embedded CNL
and, thus, allowing for CNL-based information extraction from e.g. normative or
medical texts that are rather controlled by nature but still infringe the
boundaries of CNL. Although it is arguable if CNL can be exploited to approach
the robust wide-coverage semantic parsing for use cases like media monitoring,
its potential becomes much more obvious in the opposite direction: generation
of story highlights from the summarized AMR graphs, which is in the focus of
this position paper.
",2016-06-20T07:15:55Z,http://arxiv.org/abs/1606.05994v1,"Normunds Gruzitis, Guntis Barzdins"
"Beyond the Status Quo: A Contemporary Survey of Advances and Challenges
  in Audio Captioning","  Automated audio captioning (AAC), a task that mimics human perception as well
as innovatively links audio processing and natural language processing, has
overseen much progress over the last few years. AAC requires recognizing
contents such as the environment, sound events and the temporal relationships
between sound events and describing these elements with a fluent sentence.
Currently, an encoder-decoder-based deep learning framework is the standard
approach to tackle this problem. Plenty of works have proposed novel network
architectures and training schemes, including extra guidance, reinforcement
learning, audio-text self-supervised learning and diverse or controllable
captioning. Effective data augmentation techniques, especially based on large
language models are explored. Benchmark datasets and AAC-oriented evaluation
metrics also accelerate the improvement of this field. This paper situates
itself as a comprehensive survey covering the comparison between AAC and its
related tasks, the existing deep learning techniques, datasets, and the
evaluation metrics in AAC, with insights provided to guide potential future
research directions.
",2022-05-11T09:09:15Z,http://arxiv.org/abs/2205.05357v2,"Xuenan Xu, Zeyu Xie, Mengyue Wu, Kai Yu"
"Extracting Chemical-Protein Interactions via Calibrated Deep Neural
  Network and Self-training","  The extraction of interactions between chemicals and proteins from several
biomedical articles is important in many fields of biomedical research such as
drug development and prediction of drug side effects. Several natural language
processing methods, including deep neural network (DNN) models, have been
applied to address this problem. However, these methods were trained with
hard-labeled data, which tend to become over-confident, leading to degradation
of the model reliability. To estimate the data uncertainty and improve the
reliability, ""calibration"" techniques have been applied to deep learning
models. In this study, to extract chemical--protein interactions, we propose a
DNN-based approach incorporating uncertainty information and calibration
techniques. Our model first encodes the input sequence using a pre-trained
language-understanding model, following which it is trained using two
calibration methods: mixup training and addition of a confidence penalty loss.
Finally, the model is re-trained with augmented data that are extracted using
the estimated uncertainties. Our approach has achieved state-of-the-art
performance with regard to the Biocreative VI ChemProt task, while preserving
higher calibration abilities than those of previous approaches. Furthermore,
our approach also presents the possibilities of using uncertainty estimation
for performance improvement.
",2020-11-04T10:14:31Z,http://arxiv.org/abs/2011.02207v1,"Dongha Choi, Hyunju Lee"
"Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit","  Code intelligence leverages machine learning techniques to extract knowledge
from extensive code corpora, with the aim of developing intelligent tools to
improve the quality and productivity of computer programming. Currently, there
is already a thriving research community focusing on code intelligence, with
efforts ranging from software engineering, machine learning, data mining,
natural language processing, and programming languages. In this paper, we
conduct a comprehensive literature review on deep learning for code
intelligence, from the aspects of code representation learning, deep learning
techniques, and application tasks. We also benchmark several state-of-the-art
neural models for code intelligence, and provide an open-source toolkit
tailored for the rapid prototyping of deep-learning-based code intelligence
models. In particular, we inspect the existing code intelligence models under
the basis of code representation learning, and provide a comprehensive overview
to enhance comprehension of the present state of code intelligence.
Furthermore, we publicly release the source code and data resources to provide
the community with a ready-to-use benchmark, which can facilitate the
evaluation and comparison of existing and future code intelligence models
(https://xcodemind.github.io). At last, we also point out several challenging
and promising directions for future research.
",2023-12-30T17:48:37Z,http://arxiv.org/abs/2401.00288v1,"Yao Wan, Yang He, Zhangqian Bi, Jianguo Zhang, Hongyu Zhang, Yulei Sui, Guandong Xu, Hai Jin, Philip S. Yu"
Distilling Task-Specific Knowledge from BERT into Simple Neural Networks,"  In the natural language processing literature, neural networks are becoming
increasingly deeper and complex. The recent poster child of this trend is the
deep language representation model, which includes BERT, ELMo, and GPT. These
developments have led to the conviction that previous-generation, shallower
neural networks for language understanding are obsolete. In this paper,
however, we demonstrate that rudimentary, lightweight neural networks can still
be made competitive without architecture changes, external training data, or
additional input features. We propose to distill knowledge from BERT, a
state-of-the-art language representation model, into a single-layer BiLSTM, as
well as its siamese counterpart for sentence-pair tasks. Across multiple
datasets in paraphrasing, natural language inference, and sentiment
classification, we achieve comparable results with ELMo, while using roughly
100 times fewer parameters and 15 times less inference time.
",2019-03-28T17:23:50Z,http://arxiv.org/abs/1903.12136v1,"Raphael Tang, Yao Lu, Linqing Liu, Lili Mou, Olga Vechtomova, Jimmy Lin"
Financial data analysis application via multi-strategy text processing,"  Maintaining financial system stability is critical to economic development,
and early identification of risks and opportunities is essential. The financial
industry contains a wide variety of data, such as financial statements,
customer information, stock trading data, news, etc. Massive heterogeneous data
calls for intelligent algorithms for machines to process and understand. This
paper mainly focuses on the stock trading data and news about China A-share
companies. We present a financial data analysis application, Financial Quotient
Porter, designed to combine textual and numerical data by using a
multi-strategy data mining approach. Additionally, we present our efforts and
plans in deep learning financial text processing application scenarios using
natural language processing (NLP) and knowledge graph (KG) technologies. Based
on KG technology, risks and opportunities can be identified from heterogeneous
data. NLP technology can be used to extract entities, relations, and events
from unstructured text, and analyze market sentiment. Experimental results show
market sentiments towards a company and an industry, as well as news-level
associations between companies.
",2022-04-25T01:56:36Z,http://arxiv.org/abs/2204.11394v1,Hongyin Zhu
A Law of Data Separation in Deep Learning,"  While deep learning has enabled significant advances in many areas of
science, its black-box nature hinders architecture design for future artificial
intelligence applications and interpretation for high-stakes decision makings.
We addressed this issue by studying the fundamental question of how deep neural
networks process data in the intermediate layers. Our finding is a simple and
quantitative law that governs how deep neural networks separate data according
to class membership throughout all layers for classification. This law shows
that each layer improves data separation at a constant geometric rate, and its
emergence is observed in a collection of network architectures and datasets
during training. This law offers practical guidelines for designing
architectures, improving model robustness and out-of-sample performance, as
well as interpreting the predictions.
",2022-10-31T02:25:38Z,http://arxiv.org/abs/2210.17020v2,"Hangfeng He, Weijie J. Su"
Building Advanced Dialogue Managers for Goal-Oriented Dialogue Systems,"  Goal-Oriented (GO) Dialogue Systems, colloquially known as goal oriented
chatbots, help users achieve a predefined goal (e.g. book a movie ticket)
within a closed domain. A first step is to understand the user's goal by using
natural language understanding techniques. Once the goal is known, the bot must
manage a dialogue to achieve that goal, which is conducted with respect to a
learnt policy. The success of the dialogue system depends on the quality of the
policy, which is in turn reliant on the availability of high-quality training
data for the policy learning method, for instance Deep Reinforcement Learning.
  Due to the domain specificity, the amount of available data is typically too
low to allow the training of good dialogue policies. In this master thesis we
introduce a transfer learning method to mitigate the effects of the low
in-domain data availability. Our transfer learning based approach improves the
bot's success rate by $20\%$ in relative terms for distant domains and we more
than double it for close domains, compared to the model without transfer
learning. Moreover, the transfer learning chatbots learn the policy up to 5 to
10 times faster. Finally, as the transfer learning approach is complementary to
additional processing such as warm-starting, we show that their joint
application gives the best outcomes.
",2018-06-03T12:36:06Z,http://arxiv.org/abs/1806.00780v1,Vladimir Ilievski
"Mapping Complex Technologies via Science-Technology Linkages; The Case
  of Neuroscience -- A transformer based keyword extraction approach","  In this paper, we present an efficient deep learning based approach to
extract technology-related topics and keywords within scientific literature,
and identify corresponding technologies within patent applications.
Specifically, we utilize transformer based language models, tailored for use
with scientific text, to detect coherent topics over time and describe these by
relevant keywords that are automatically extracted from a large text corpus. We
identify these keywords using Named Entity Recognition, distinguishing between
those describing methods, applications and other scientific terminology. We
create a large amount of search queries based on combinations of method- and
application-keywords, which we use to conduct semantic search and identify
related patents. By doing so, we aim at contributing to the growing body of
research on text-based technology mapping and forecasting that leverages latest
advances in natural language processing and deep learning. We are able to map
technologies identified in scientific literature to patent applications,
thereby providing an empirical foundation for the study of science-technology
linkages. We illustrate the workflow as well as results obtained by mapping
publications within the field of neuroscience to related patent applications.
",2022-05-19T09:32:09Z,http://arxiv.org/abs/2205.10153v1,"Daniel Hain, Roman Jurowetzki, Mariagrazia Squicciarini"
"Knowledge Distillation in Automated Annotation: Supervised Text
  Classification with LLM-Generated Training Labels","  Computational social science (CSS) practitioners often rely on human-labeled
data to fine-tune supervised text classifiers. We assess the potential for
researchers to augment or replace human-generated training data with surrogate
training labels from generative large language models (LLMs). We introduce a
recommended workflow and test this LLM application by replicating 14
classification tasks and measuring performance. We employ a novel corpus of
English-language text classification data sets from recent CSS articles in
high-impact journals. Because these data sets are stored in password-protected
archives, our analyses are less prone to issues of contamination. For each
task, we compare supervised classifiers fine-tuned using GPT-4 labels against
classifiers fine-tuned with human annotations and against labels from GPT-4 and
Mistral-7B with few-shot in-context learning. Our findings indicate that
supervised classification models fine-tuned on LLM-generated labels perform
comparably to models fine-tuned with labels from human annotators. Fine-tuning
models using LLM-generated labels can be a fast, efficient and cost-effective
method of building supervised text classifiers.
",2024-06-25T15:20:25Z,http://arxiv.org/abs/2406.17633v1,"Nicholas Pangakis, Samuel Wolken"
"Resource Allocation and Workload Scheduling for Large-Scale Distributed
  Deep Learning: A Survey","  With rapidly increasing distributed deep learning workloads in large-scale
data centers, efficient distributed deep learning framework strategies for
resource allocation and workload scheduling have become the key to
high-performance deep learning. The large-scale environment with large volumes
of datasets, models, and computational and communication resources raises
various unique challenges for resource allocation and workload scheduling in
distributed deep learning, such as scheduling complexity, resource and workload
heterogeneity, and fault tolerance. To uncover these challenges and
corresponding solutions, this survey reviews the literature, mainly from 2019
to 2024, on efficient resource allocation and workload scheduling strategies
for large-scale distributed DL. We explore these strategies by focusing on
various resource types, scheduling granularity levels, and performance goals
during distributed training and inference processes. We highlight critical
challenges for each topic and discuss key insights of existing technologies. To
illustrate practical large-scale resource allocation and workload scheduling in
real distributed deep learning scenarios, we use a case study of training large
language models. This survey aims to encourage computer science, artificial
intelligence, and communications researchers to understand recent advances and
explore future research directions for efficient framework strategies for
large-scale distributed deep learning.
",2024-06-12T11:51:44Z,http://arxiv.org/abs/2406.08115v1,"Feng Liang, Zhen Zhang, Haifeng Lu, Chengming Li, Victor C. M. Leung, Yanyi Guo, Xiping Hu"
"Med7: a transferable clinical natural language processing model for
  electronic health records","  The field of clinical natural language processing has been advanced
significantly since the introduction of deep learning models. The
self-supervised representation learning and the transfer learning paradigm
became the methods of choice in many natural language processing application,
in particular in the settings with the dearth of high quality manually
annotated data. Electronic health record systems are ubiquitous and the
majority of patients' data are now being collected electronically and in
particular in the form of free text. Identification of medical concepts and
information extraction is a challenging task, yet important ingredient for
parsing unstructured data into structured and tabulated format for downstream
analytical tasks. In this work we introduced a named-entity recognition model
for clinical natural language processing. The model is trained to recognise
seven categories: drug names, route, frequency, dosage, strength, form,
duration. The model was first self-supervisedly pre-trained by predicting the
next word, using a collection of 2 million free-text patients' records from
MIMIC-III corpora and then fine-tuned on the named-entity recognition task. The
model achieved a lenient (strict) micro-averaged F1 score of 0.957 (0.893)
across all seven categories. Additionally, we evaluated the transferability of
the developed model using the data from the Intensive Care Unit in the US to
secondary care mental health records (CRIS) in the UK. A direct application of
the trained NER model to CRIS data resulted in reduced performance of F1=0.762,
however after fine-tuning on a small sample from CRIS, the model achieved a
reasonable performance of F1=0.944. This demonstrated that despite a close
similarity between the data sets and the NER tasks, it is essential to
fine-tune on the target domain data in order to achieve more accurate results.
",2020-03-03T00:55:43Z,http://arxiv.org/abs/2003.01271v2,"Andrey Kormilitzin, Nemanja Vaci, Qiang Liu, Alejo Nevado-Holgado"
"Robust Task-Oriented Dialogue Generation with Contrastive Pre-training
  and Adversarial Filtering","  Data artifacts incentivize machine learning models to learn non-transferable
generalizations by taking advantage of shortcuts in the data, and there is
growing evidence that data artifacts play a role for the strong results that
deep learning models achieve in recent natural language processing benchmarks.
In this paper, we focus on task-oriented dialogue and investigate whether
popular datasets such as MultiWOZ contain such data artifacts. We found that by
only keeping frequent phrases in the training examples, state-of-the-art models
perform similarly compared to the variant trained with full data, suggesting
they exploit these spurious correlations to solve the task. Motivated by this,
we propose a contrastive learning based framework to encourage the model to
ignore these cues and focus on learning generalisable patterns. We also
experiment with adversarial filtering to remove ""easy"" training instances so
that the model would focus on learning from the ""harder"" instances. We conduct
a number of generalization experiments -- e.g., cross-domain/dataset and
adversarial tests -- to assess the robustness of our approach and found that it
works exceptionally well.
",2022-05-20T03:13:02Z,http://arxiv.org/abs/2205.10363v1,"Shiquan Yang, Xinting Huang, Jey Han Lau, Sarah Erfani"
"Using Error Decay Prediction to Overcome Practical Issues of Deep Active
  Learning for Named Entity Recognition","  Existing deep active learning algorithms achieve impressive sampling
efficiency on natural language processing tasks. However, they exhibit several
weaknesses in practice, including (a) inability to use uncertainty sampling
with black-box models, (b) lack of robustness to labeling noise, and (c) lack
of transparency. In response, we propose a transparent batch active sampling
framework by estimating the error decay curves of multiple feature-defined
subsets of the data. Experiments on four named entity recognition (NER) tasks
demonstrate that the proposed methods significantly outperform
diversification-based methods for black-box NER taggers, and can make the
sampling process more robust to labeling noise when combined with
uncertainty-based methods. Furthermore, the analysis of experimental results
sheds light on the weaknesses of different active sampling strategies, and when
traditional uncertainty-based or diversification-based methods can be expected
to work well.
",2019-11-17T20:41:32Z,http://arxiv.org/abs/1911.07335v2,"Haw-Shiuan Chang, Shankar Vembu, Sunil Mohan, Rheeya Uppaal, Andrew McCallum"
Deep Active Learning with Noise Stability,"  Uncertainty estimation for unlabeled data is crucial to active learning. With
a deep neural network employed as the backbone model, the data selection
process is highly challenging due to the potential over-confidence of the model
inference. Existing methods resort to special learning fashions (e.g.
adversarial) or auxiliary models to address this challenge. This tends to
result in complex and inefficient pipelines, which would render the methods
impractical. In this work, we propose a novel algorithm that leverages noise
stability to estimate data uncertainty. The key idea is to measure the output
derivation from the original observation when the model parameters are randomly
perturbed by noise. We provide theoretical analyses by leveraging the small
Gaussian noise theory and demonstrate that our method favors a subset with
large and diverse gradients. Our method is generally applicable in various
tasks, including computer vision, natural language processing, and structural
data analysis. It achieves competitive performance compared against
state-of-the-art active learning baselines.
",2022-05-26T13:21:01Z,http://arxiv.org/abs/2205.13340v2,"Xingjian Li, Pengkun Yang, Yangcheng Gu, Xueying Zhan, Tianyang Wang, Min Xu, Chengzhong Xu"
"A Deep Learning Model with Hierarchical LSTMs and Supervised Attention
  for Anti-Phishing","  Anti-phishing aims to detect phishing content/documents in a pool of textual
data. This is an important problem in cybersecurity that can help to guard
users from fraudulent information. Natural language processing (NLP) offers a
natural solution for this problem as it is capable of analyzing the textual
content to perform intelligent recognition. In this work, we investigate
state-of-the-art techniques for text categorization in NLP to address the
problem of anti-phishing for emails (i.e, predicting if an email is phishing or
not). These techniques are based on deep learning models that have attracted
much attention from the community recently. In particular, we present a
framework with hierarchical long short-term memory networks (H-LSTMs) and
attention mechanisms to model the emails simultaneously at the word and the
sentence level. Our expectation is to produce an effective model for
anti-phishing and demonstrate the effectiveness of deep learning for problems
in cybersecurity.
",2018-05-03T21:53:09Z,http://arxiv.org/abs/1805.01554v1,"Minh Nguyen, Toan Nguyen, Thien Huu Nguyen"
Deep Spatial Learning with Molecular Vibration,"  Machine learning over-fitting caused by data scarcity greatly limits the
application of machine learning for molecules. Due to manufacturing processes
difference, big data is not always rendered available through computational
chemistry methods for some tasks, causing data scarcity problem for machine
learning algorithms. Here we propose to extract the natural features of
molecular structures and rationally distort them to augment the data
availability. This method allows a machine learning project to leverage the
powerful fit of physics-informed augmentation for providing significant boost
to predictive accuracy. Successfully verified by the prediction of rejection
rate and flux of thin film polyamide nanofiltration membranes, with the
relative error dropping from 16.34% to 6.71% and the coefficient of
determination rising from 0.16 to 0.75, the proposed deep spatial learning with
molecular vibration is widely instructive for molecular science. Experimental
comparison unequivocally demonstrates its superiority over common learning
algorithms.
",2020-11-14T02:46:43Z,http://arxiv.org/abs/2011.07200v1,"Ziyang Zhang, Yingtao Luo"
Self-Knowledge Distillation in Natural Language Processing,"  Since deep learning became a key player in natural language processing (NLP),
many deep learning models have been showing remarkable performances in a
variety of NLP tasks, and in some cases, they are even outperforming humans.
Such high performance can be explained by efficient knowledge representation of
deep learning models. While many methods have been proposed to learn more
efficient representation, knowledge distillation from pretrained deep networks
suggest that we can use more information from the soft target probability to
train other neural networks. In this paper, we propose a new knowledge
distillation method self-knowledge distillation, based on the soft target
probabilities of the training model itself, where multimode information is
distilled from the word embedding space right below the softmax layer. Due to
the time complexity, our method approximates the soft target probabilities. In
experiments, we applied the proposed method to two different and fundamental
NLP tasks: language model and neural machine translation. The experiment
results show that our proposed method improves performance on the tasks.
",2019-08-02T15:17:27Z,http://arxiv.org/abs/1908.01851v1,"Sangchul Hahn, Heeyoul Choi"
"Positional Attention-based Frame Identification with BERT: A Deep
  Learning Approach to Target Disambiguation and Semantic Frame Selection","  Semantic parsing is the task of transforming sentences from natural language
into formal representations of predicate-argument structures. Under this
research area, frame-semantic parsing has attracted much interest. This parsing
approach leverages the lexical information defined in FrameNet to associate
marked predicates or targets with semantic frames, thereby assigning semantic
roles to sentence components based on pre-specified frame elements in FrameNet.
In this paper, a deep neural network architecture known as Positional
Attention-based Frame Identification with BERT (PAFIBERT) is presented as a
solution to the frame identification subtask in frame-semantic parsing.
Although the importance of this subtask is well-established, prior research has
yet to find a robust solution that works satisfactorily for both in-domain and
out-of-domain data. This study thus set out to improve frame identification in
light of recent advancements of language modeling and transfer learning in
natural language processing. The proposed method is partially empowered by
BERT, a pre-trained language model that excels at capturing contextual
information in texts. By combining the language representation power of BERT
with a position-based attention mechanism, PAFIBERT is able to attend to
target-specific contexts in sentences for disambiguating targets and
associating them with the most suitable semantic frames. Under various
experimental settings, PAFIBERT outperformed existing solutions by a
significant margin, achieving new state-of-the-art results for both in-domain
and out-of-domain benchmark test sets.
",2019-10-31T15:51:04Z,http://arxiv.org/abs/1910.14549v1,"Sang-Sang Tan, Jin-Cheon Na"
Tackling Morphological Analogies Using Deep Learning -- Extended Version,"  Analogical proportions are statements of the form ""A is to B as C is to D"".
They constitute an inference tool that provides a logical framework to address
learning, transfer, and explainability concerns and that finds useful
applications in artificial intelligence and natural language processing. In
this paper, we address two problems, namely, analogy detection and resolution
in morphology. Multiple symbolic approaches tackle the problem of analogies in
morphology and achieve competitive performance. We show that it is possible to
use a data-driven strategy to outperform those models. We propose an approach
using deep learning to detect and solve morphological analogies. It encodes
structural properties of analogical proportions and relies on a specifically
designed embedding model capturing morphological characteristics of words. We
demonstrate our model's competitive performance on analogy detection and
resolution over multiple languages. We provide an empirical study to analyze
the impact of balancing training data and evaluate the robustness of our
approach to input perturbation.
",2021-11-09T13:45:23Z,http://arxiv.org/abs/2111.05147v1,"Safa Alsaidi, Amandine Decker, Esteban Marquer, Pierre-Alexandre Murena, Miguel Couceiro"
LSICC: A Large Scale Informal Chinese Corpus,"  Deep learning based natural language processing model is proven powerful, but
need large-scale dataset. Due to the significant gap between the real-world
tasks and existing Chinese corpus, in this paper, we introduce a large-scale
corpus of informal Chinese. This corpus contains around 37 million book reviews
and 50 thousand netizen's comments to the news. We explore the informal words
frequencies of the corpus and show the difference between our corpus and the
existing ones. The corpus can be further used to train deep learning based
natural language processing tasks such as Chinese word segmentation, sentiment
analysis.
",2018-11-26T03:58:09Z,http://arxiv.org/abs/1811.10167v1,"Jianyu Zhao, Zhuoran Ji"
"Res-CNN-BiLSTM Network for overcoming Mental Health Disturbances caused
  due to Cyberbullying through Social Media","  Mental Health Disturbance has many reasons and cyberbullying is one of the
major causes that does exploitation using social media as an instrument. The
cyberbullying is done on the basis of Religion, Ethnicity, Age and Gender which
is a sensitive psychological issue. This can be addressed using Natural
Language Processing with Deep Learning, since social media is the medium and it
generates massive form of data in textual form. Such data can be leveraged to
find the semantics and derive what type of cyberbullying is done and who are
the people involved for early measures. Since deriving semantics is essential
we proposed a Hybrid Deep Learning Model named 1-Dimensional
CNN-Bidirectional-LSTMs with Residuals shortly known as Res-CNN-BiLSTM. In this
paper we have proposed the architecture and compared its performance with
different approaches of Embedding Deep Learning Algorithms.
",2022-04-20T18:40:39Z,http://arxiv.org/abs/2204.09738v1,"Raunak Joshi, Abhishek Gupta, Nandan Kanvinde"
A Hybrid Deep Learning Model for Arabic Text Recognition,"  Arabic text recognition is a challenging task because of the cursive nature
of Arabic writing system, its joint writing scheme, the large number of
ligatures and many other challenges. Deep Learning DL models achieved
significant progress in numerous domains including computer vision and sequence
modelling. This paper presents a model that can recognize Arabic text that was
printed using multiple font types including fonts that mimic Arabic handwritten
scripts. The proposed model employs a hybrid DL network that can recognize
Arabic printed text without the need for character segmentation. The model was
tested on a custom dataset comprised of over two million word samples that were
generated using 18 different Arabic font types. The objective of the testing
process was to assess the model capability in recognizing a diverse set of
Arabic fonts representing a varied cursive styles. The model achieved good
results in recognizing characters and words and it also achieved promising
results in recognizing characters when it was tested on unseen data. The
prepared model, the custom datasets and the toolkit for generating similar
datasets are made publicly available, these tools can be used to prepare models
for recognizing other font types as well as to further extend and enhance the
performance of the proposed model.
",2020-09-04T02:49:17Z,http://arxiv.org/abs/2009.01987v1,"Mohammad Fasha, Bassam Hammo, Nadim Obeid, Jabir Widian"
"Architectures of Topological Deep Learning: A Survey of Message-Passing
  Topological Neural Networks","  The natural world is full of complex systems characterized by intricate
relations between their components: from social interactions between
individuals in a social network to electrostatic interactions between atoms in
a protein. Topological Deep Learning (TDL) provides a comprehensive framework
to process and extract knowledge from data associated with these systems, such
as predicting the social community to which an individual belongs or predicting
whether a protein can be a reasonable target for drug development. TDL has
demonstrated theoretical and practical advantages that hold the promise of
breaking ground in the applied sciences and beyond. However, the rapid growth
of the TDL literature for relational systems has also led to a lack of
unification in notation and language across message-passing Topological Neural
Network (TNN) architectures. This presents a real obstacle for building upon
existing works and for deploying message-passing TNNs to new real-world
problems. To address this issue, we provide an accessible introduction to TDL
for relational systems, and compare the recently published message-passing TNNs
using a unified mathematical and graphical notation. Through an intuitive and
critical review of the emerging field of TDL, we extract valuable insights into
current challenges and exciting opportunities for future development.
",2023-04-20T01:02:13Z,http://arxiv.org/abs/2304.10031v3,"Mathilde Papillon, Sophia Sanborn, Mustafa Hajij, Nina Miolane"
Data-driven geophysics: from dictionary learning to deep learning,"  Understanding the principles of geophysical phenomena is an essential and
challenging task. ""Model-driven"" approaches have supported the development of
geophysics for a long time; however, such methods suffer from the curse of
dimensionality and may inaccurately model the subsurface. ""Data-driven""
techniques may overcome these issues with increasingly available geophysical
data. In this article, we review the basic concepts of and recent advances in
data-driven approaches from dictionary learning to deep learning in a variety
of geophysical scenarios. Explorational geophysics including data processing,
inversion and interpretation will be mainly focused. Artificial intelligence
applications on geoscience involving deep Earth, earthquake, water resource,
atmospheric science, satellite remoe sensing and space sciences are also
reviewed. We present a coding tutorial and a summary of tips for beginners and
interested geophysical readers to rapidly explore deep learning. Some promising
directions are provided for future research involving deep learning in
geophysics, such as unsupervised learning, transfer learning, multimodal deep
learning, federated learning, uncertainty estimation, and activate learning.
",2020-07-13T04:39:49Z,http://arxiv.org/abs/2007.06183v2,"Siwei Yu, Jianwei Ma"
"On Linearizing Structured Data in Encoder-Decoder Language Models:
  Insights from Text-to-SQL","  Structured data, prevalent in tables, databases, and knowledge graphs, poses
a significant challenge in its representation. With the advent of large
language models (LLMs), there has been a shift towards linearization-based
methods, which process structured data as sequential token streams, diverging
from approaches that explicitly model structure, often as a graph. Crucially,
there remains a gap in our understanding of how these linearization-based
methods handle structured data, which is inherently non-linear. This work
investigates the linear handling of structured data in encoder-decoder language
models, specifically T5. Our findings reveal the model's ability to mimic
human-designed processes such as schema linking and syntax prediction,
indicating a deep, meaningful learning of structure beyond simple token
sequencing. We also uncover insights into the model's internal mechanisms,
including the ego-centric nature of structure node encodings and the potential
for model compression due to modality fusion redundancy. Overall, this work
sheds light on the inner workings of linearization-based methods and could
potentially provide guidance for future research.
",2024-04-03T01:16:20Z,http://arxiv.org/abs/2404.02389v1,"Yutong Shao, Ndapa Nakashole"
"Deep Learning and NLP in Cryptocurrency Forecasting: Integrating
  Financial, Blockchain, and Social Media Data","  We introduce novel approaches to cryptocurrency price forecasting, leveraging
Machine Learning (ML) and Natural Language Processing (NLP) techniques, with a
focus on Bitcoin and Ethereum. By analysing news and social media content,
primarily from Twitter and Reddit, we assess the impact of public sentiment on
cryptocurrency markets. A distinctive feature of our methodology is the
application of the BART MNLI zero-shot classification model to detect bullish
and bearish trends, significantly advancing beyond traditional sentiment
analysis. Additionally, we systematically compare a range of pre-trained and
fine-tuned deep learning NLP models against conventional dictionary-based
sentiment analysis methods. Another key contribution of our work is the
adoption of local extrema alongside daily price movements as predictive
targets, reducing trading frequency and portfolio volatility. Our findings
demonstrate that integrating textual data into cryptocurrency price forecasting
not only improves forecasting accuracy but also consistently enhances the
profitability and Sharpe ratio across various validation scenarios,
particularly when applying deep learning NLP techniques. The entire codebase of
our experiments is made available via an online repository:
https://anonymous.4open.science/r/crypto-forecasting-public
",2023-11-23T16:14:44Z,http://arxiv.org/abs/2311.14759v2,"Vincent Gurgul, Stefan Lessmann, Wolfgang Karl H√§rdle"
"Natural Language Interfaces for Tabular Data Querying and Visualization:
  A Survey","  The emergence of natural language processing has revolutionized the way users
interact with tabular data, enabling a shift from traditional query languages
and manual plotting to more intuitive, language-based interfaces. The rise of
large language models (LLMs) such as ChatGPT and its successors has further
advanced this field, opening new avenues for natural language processing
techniques. This survey presents a comprehensive overview of natural language
interfaces for tabular data querying and visualization, which allow users to
interact with data using natural language queries. We introduce the fundamental
concepts and techniques underlying these interfaces with a particular emphasis
on semantic parsing, the key technology facilitating the translation from
natural language to SQL queries or data visualization commands. We then delve
into the recent advancements in Text-to-SQL and Text-to-Vis problems from the
perspectives of datasets, methodologies, metrics, and system designs. This
includes a deep dive into the influence of LLMs, highlighting their strengths,
limitations, and potential for future improvements. Through this survey, we aim
to provide a roadmap for researchers and practitioners interested in developing
and applying natural language interfaces for data interaction in the era of
large language models.
",2023-10-27T05:01:20Z,http://arxiv.org/abs/2310.17894v3,"Weixu Zhang, Yifei Wang, Yuanfeng Song, Victor Junqiu Wei, Yuxing Tian, Yiyan Qi, Jonathan H. Chan, Raymond Chi-Wing Wong, Haiqin Yang"
A Survey on Backdoor Attack and Defense in Natural Language Processing,"  Deep learning is becoming increasingly popular in real-life applications,
especially in natural language processing (NLP). Users often choose training
outsourcing or adopt third-party data and models due to data and computation
resources being limited. In such a situation, training data and models are
exposed to the public. As a result, attackers can manipulate the training
process to inject some triggers into the model, which is called backdoor
attack. Backdoor attack is quite stealthy and difficult to be detected because
it has little inferior influence on the model's performance for the clean
samples. To get a precise grasp and understanding of this problem, in this
paper, we conduct a comprehensive review of backdoor attacks and defenses in
the field of NLP. Besides, we summarize benchmark datasets and point out the
open issues to design credible systems to defend against backdoor attacks.
",2022-11-22T02:35:12Z,http://arxiv.org/abs/2211.11958v1,"Xuan Sheng, Zhaoyang Han, Piji Li, Xiangmao Chang"
Fidelity-Weighted Learning,"  Training deep neural networks requires many training samples, but in practice
training labels are expensive to obtain and may be of varying quality, as some
may be from trusted expert labelers while others might be from heuristics or
other sources of weak supervision such as crowd-sourcing. This creates a
fundamental quality versus-quantity trade-off in the learning process. Do we
learn from the small amount of high-quality data or the potentially large
amount of weakly-labeled data? We argue that if the learner could somehow know
and take the label-quality into account when learning the data representation,
we could get the best of both worlds. To this end, we propose
""fidelity-weighted learning"" (FWL), a semi-supervised student-teacher approach
for training deep neural networks using weakly-labeled data. FWL modulates the
parameter updates to a student network (trained on the task we care about) on a
per-sample basis according to the posterior confidence of its label-quality
estimated by a teacher (who has access to the high-quality labels). Both
student and teacher are learned from the data. We evaluate FWL on two tasks in
information retrieval and natural language processing where we outperform
state-of-the-art alternative semi-supervised methods, indicating that our
approach makes better use of strong and weak labels, and leads to better
task-dependent data representations.
",2017-11-08T02:05:11Z,http://arxiv.org/abs/1711.02799v2,"Mostafa Dehghani, Arash Mehrjou, Stephan Gouws, Jaap Kamps, Bernhard Sch√∂lkopf"
"Tree Edit Distance Learning via Adaptive Symbol Embeddings:
  Supplementary Materials and Results","  Metric learning has the aim to improve classification accuracy by learning a
distance measure which brings data points from the same class closer together
and pushes data points from different classes further apart. Recent research
has demonstrated that metric learning approaches can also be applied to trees,
such as molecular structures, abstract syntax trees of computer programs, or
syntax trees of natural language, by learning the cost function of an edit
distance, i.e. the costs of replacing, deleting, or inserting nodes in a tree.
However, learning such costs directly may yield an edit distance which violates
metric axioms, is challenging to interpret, and may not generalize well. In
this contribution, we propose a novel metric learning approach for trees which
learns an edit distance indirectly by embedding the tree nodes as vectors, such
that the Euclidean distance between those vectors supports class
discrimination. We learn such embeddings by reducing the distance to
prototypical trees from the same class and increasing the distance to
prototypical trees from different classes. In our experiments, we show that our
proposed metric learning approach improves upon the state-of-the-art in metric
learning for trees on six benchmark data sets, ranging from computer science
over biomedical data to a natural-language processing data set containing over
300,000 nodes.
",2018-05-18T10:09:41Z,http://arxiv.org/abs/1805.07123v1,Benjamin Paa√üen
Value Prediction for Spatiotemporal Gait Data Using Deep Learning,"  Human gait has been commonly used for the diagnosis and evaluation of medical
conditions and for monitoring the progress during treatment and rehabilitation.
The use of wearable sensors that capture pressure or motion has yielded
techniques that analyze the gait data to aid recovery, identify activity
performed, or identify individuals. Deep learning, usually employing
classification, has been successfully utilized in a variety of applications
such as computer vision, biomedical imaging analysis, and natural language
processing. We expand the application of deep learning to value prediction of
time-series of spatiotemporal gait data. Moreover, we explore several deep
learning architectures (Recurrent Neural Networks (RNN) and RNN combined with
Convolutional Neural Networks (CNN)) to make short- and long-distance
predictions using two different experimental setups. Our results show that
short-distance prediction has an RMSE as low as 0.060675, and long-distance
prediction RMSE as low as 0.106365. Additionally, the results show that the
proposed deep learning models are capable of predicting the entire trial when
trained and validated using the trials from the same participant. The proposed,
customized models, used with value prediction open possibilities for additional
applications, such as fall prediction, in-home progress monitoring, aiding of
exoskeleton movement, and authentication.
",2024-02-29T18:30:13Z,http://arxiv.org/abs/2403.07926v1,"Ryan Cavanagh, Jelena Trajkovic, Wenlu Zhang, I-Hung Khoo, Vennila Krishnan"
"Unmasking Transformers: A Theoretical Approach to Data Recovery via
  Attention Weights","  In the realm of deep learning, transformers have emerged as a dominant
architecture, particularly in natural language processing tasks. However, with
their widespread adoption, concerns regarding the security and privacy of the
data processed by these models have arisen. In this paper, we address a pivotal
question: Can the data fed into transformers be recovered using their attention
weights and outputs? We introduce a theoretical framework to tackle this
problem. Specifically, we present an algorithm that aims to recover the input
data $X \in \mathbb{R}^{d \times n}$ from given attention weights $W = QK^\top
\in \mathbb{R}^{d \times d}$ and output $B \in \mathbb{R}^{n \times n}$ by
minimizing the loss function $L(X)$. This loss function captures the
discrepancy between the expected output and the actual output of the
transformer. Our findings have significant implications for the Localized
Layer-wise Mechanism (LLM), suggesting potential vulnerabilities in the model's
design from a security and privacy perspective. This work underscores the
importance of understanding and safeguarding the internal workings of
transformers to ensure the confidentiality of processed data.
",2023-10-19T04:41:01Z,http://arxiv.org/abs/2310.12462v1,"Yichuan Deng, Zhao Song, Shenghao Xie, Chiwun Yang"
Social Analysis of Young Basque Speaking Communities in Twitter,"  In this paper we take into account both social and linguistic aspects to
perform demographic analysis by processing a large amount of tweets in Basque
language. The study of demographic characteristics and social relationships are
approached by applying machine learning and modern deep-learning Natural
Language Processing (NLP) techniques, combining social sciences with automatic
text processing. More specifically, our main objective is to combine
demographic inference and social analysis in order to detect young Basque
Twitter users and to identify the communities that arise from their
relationships or shared content. This social and demographic analysis will be
entirely based on the~automatically collected tweets using NLP to convert
unstructured textual information into interpretable knowledge.
",2021-09-08T08:19:08Z,http://arxiv.org/abs/2109.03487v1,"J. Fernandez de Landa, R. Agerri"
ZeroBERTo: Leveraging Zero-Shot Text Classification by Topic Modeling,"  Traditional text classification approaches often require a good amount of
labeled data, which is difficult to obtain, especially in restricted domains or
less widespread languages. This lack of labeled data has led to the rise of
low-resource methods, that assume low data availability in natural language
processing. Among them, zero-shot learning stands out, which consists of
learning a classifier without any previously labeled data. The best results
reported with this approach use language models such as Transformers, but fall
into two problems: high execution time and inability to handle long texts as
input. This paper proposes a new model, ZeroBERTo, which leverages an
unsupervised clustering step to obtain a compressed data representation before
the classification task. We show that ZeroBERTo has better performance for long
inputs and shorter execution time, outperforming XLM-R by about 12% in the F1
score in the FolhaUOL dataset. Keywords: Low-Resource NLP, Unlabeled data,
Zero-Shot Learning, Topic Modeling, Transformers.
",2022-01-04T20:08:17Z,http://arxiv.org/abs/2201.01337v3,"Alexandre Alcoforado, Thomas Palmeira Ferraz, Rodrigo Gerber, Enzo Bustos, Andr√© Seidel Oliveira, Bruno Miguel Veloso, Fabio Levy Siqueira, Anna Helena Reali Costa"
Emotion Based Hate Speech Detection using Multimodal Learning,"  In recent years, monitoring hate speech and offensive language on social
media platforms has become paramount due to its widespread usage among all age
groups, races, and ethnicities. Consequently, there have been substantial
research efforts towards automated detection of such content using Natural
Language Processing (NLP). While successfully filtering textual data, no
research has focused on detecting hateful content in multimedia data. With
increased ease of data storage and the exponential growth of social media
platforms, multimedia content proliferates the internet as much as text data.
Nevertheless, it escapes the automatic filtering systems. Hate speech and
offensiveness can be detected in multimedia primarily via three modalities,
i.e., visual, acoustic, and verbal. Our preliminary study concluded that the
most essential features in classifying hate speech would be the speaker's
emotional state and its influence on the spoken words, therefore limiting our
current research to these modalities. This paper proposes the first multimodal
deep learning framework to combine the auditory features representing emotion
and the semantic features to detect hateful content. Our results demonstrate
that incorporating emotional attributes leads to significant improvement over
text-based models in detecting hateful multimedia content. This paper also
presents a new Hate Speech Detection Video Dataset (HSDVD) collected for the
purpose of multimodal learning as no such dataset exists today.
",2022-02-13T05:39:47Z,http://arxiv.org/abs/2202.06218v1,"Aneri Rana, Sonali Jha"
A Survey on Green Deep Learning,"  In recent years, larger and deeper models are springing up and continuously
pushing state-of-the-art (SOTA) results across various fields like natural
language processing (NLP) and computer vision (CV). However, despite promising
results, it needs to be noted that the computations required by SOTA models
have been increased at an exponential rate. Massive computations not only have
a surprisingly large carbon footprint but also have negative effects on
research inclusiveness and deployment on real-world applications.
  Green deep learning is an increasingly hot research field that appeals to
researchers to pay attention to energy usage and carbon emission during model
training and inference. The target is to yield novel results with lightweight
and efficient technologies. Many technologies can be used to achieve this goal,
like model compression and knowledge distillation. This paper focuses on
presenting a systematic review of the development of Green deep learning
technologies. We classify these approaches into four categories: (1) compact
networks, (2) energy-efficient training strategies, (3) energy-efficient
inference approaches, and (4) efficient data usage. For each category, we
discuss the progress that has been achieved and the unresolved challenges.
",2021-11-08T16:55:03Z,http://arxiv.org/abs/2111.05193v2,"Jingjing Xu, Wangchunshu Zhou, Zhiyi Fu, Hao Zhou, Lei Li"
"Textual Data Mining for Financial Fraud Detection: A Deep Learning
  Approach","  In this report, I present a deep learning approach to conduct a natural
language processing (hereafter NLP) binary classification task for analyzing
financial-fraud texts. First, I searched for regulatory announcements and
enforcement bulletins from HKEX news to define fraudulent companies and to
extract their MD&A reports before I organized the sentences from the reports
with labels and reporting time. My methodology involved different kinds of
neural network models, including Multilayer Perceptrons with Embedding layers,
vanilla Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM), and
Gated Recurrent Unit (GRU) for the text classification task. By utilizing this
diverse set of models, I aim to perform a comprehensive comparison of their
accuracy in detecting financial fraud. My results bring significant
implications for financial fraud detection as this work contributes to the
growing body of research at the intersection of deep learning, NLP, and
finance, providing valuable insights for industry practitioners, regulators,
and researchers in the pursuit of more robust and effective fraud detection
methodologies.
",2023-08-05T15:33:10Z,http://arxiv.org/abs/2308.03800v1,Qiuru Li
Using Sequences of Life-events to Predict Human Lives,"  Over the past decade, machine learning has revolutionized computers' ability
to analyze text through flexible computational models. Due to their structural
similarity to written language, transformer-based architectures have also shown
promise as tools to make sense of a range of multi-variate sequences from
protein-structures, music, electronic health records to weather-forecasts. We
can also represent human lives in a way that shares this structural similarity
to language. From one perspective, lives are simply sequences of events: People
are born, visit the pediatrician, start school, move to a new location, get
married, and so on. Here, we exploit this similarity to adapt innovations from
natural language processing to examine the evolution and predictability of
human lives based on detailed event sequences. We do this by drawing on
arguably the most comprehensive registry data in existence, available for an
entire nation of more than six million individuals across decades. Our data
include information about life-events related to health, education, occupation,
income, address, and working hours, recorded with day-to-day resolution. We
create embeddings of life-events in a single vector space showing that this
embedding space is robust and highly structured. Our models allow us to predict
diverse outcomes ranging from early mortality to personality nuances,
outperforming state-of-the-art models by a wide margin. Using methods for
interpreting deep learning models, we probe the algorithm to understand the
factors that enable our predictions. Our framework allows researchers to
identify new potential mechanisms that impact life outcomes and associated
possibilities for personalized interventions.
",2023-06-05T16:19:48Z,http://arxiv.org/abs/2306.03009v1,"Germans Savcisens, Tina Eliassi-Rad, Lars Kai Hansen, Laust Mortensen, Lau Lilleholt, Anna Rogers, Ingo Zettler, Sune Lehmann"
PassTSL: Modeling Human-Created Passwords through Two-Stage Learning,"  Textual passwords are still the most widely used user authentication
mechanism. Due to the close connections between textual passwords and natural
languages, advanced technologies in natural language processing (NLP) and
machine learning (ML) could be used to model passwords for different purposes
such as studying human password-creation behaviors and developing more advanced
password cracking methods for informing better defence mechanisms. In this
paper, we propose PassTSL (modeling human-created Passwords through Two-Stage
Learning), inspired by the popular pretraining-finetuning framework in NLP and
deep learning (DL). We report how different pretraining settings affected
PassTSL and proved its effectiveness by applying it to six large leaked
password databases. Experimental results showed that it outperforms five
state-of-the-art (SOTA) password cracking methods on password guessing by a
significant margin ranging from 4.11% to 64.69% at the maximum point. Based on
PassTSL, we also implemented a password strength meter (PSM), and our
experiments showed that it was able to estimate password strength more
accurately, causing fewer unsafe errors (overestimating the password strength)
than two other SOTA PSMs when they produce the same rate of safe errors
(underestimating the password strength): a neural-network based method and
zxcvbn. Furthermore, we explored multiple finetuning settings, and our
evaluations showed that, even a small amount of additional training data, e.g.,
only 0.1% of the pretrained data, can lead to over 3% improvement in password
guessing on average. We also proposed a heuristic approach to selecting
finetuning passwords based on JS (Jensen-Shannon) divergence and experimental
results validated its usefulness. In summary, our contributions demonstrate the
potential and feasibility of applying advanced NLP and ML methods to password
modeling and cracking.
",2024-07-19T09:23:30Z,http://arxiv.org/abs/2407.14145v1,"Yangde Wang, Haozhang Li, Weidong Qiu, Shujun Li, Peng Tang"
"Tinto: Multisensor Benchmark for 3D Hyperspectral Point Cloud
  Segmentation in the Geosciences","  The increasing use of deep learning techniques has reduced interpretation
time and, ideally, reduced interpreter bias by automatically deriving
geological maps from digital outcrop models. However, accurate validation of
these automated mapping approaches is a significant challenge due to the
subjective nature of geological mapping and the difficulty in collecting
quantitative validation data. Additionally, many state-of-the-art deep learning
methods are limited to 2D image data, which is insufficient for 3D digital
outcrops, such as hyperclouds. To address these challenges, we present Tinto, a
multi-sensor benchmark digital outcrop dataset designed to facilitate the
development and validation of deep learning approaches for geological mapping,
especially for non-structured 3D data like point clouds. Tinto comprises two
complementary sets: 1) a real digital outcrop model from Corta Atalaya (Spain),
with spectral attributes and ground-truth data, and 2) a synthetic twin that
uses latent features in the original datasets to reconstruct realistic spectral
data (including sensor noise and processing artifacts) from the ground-truth.
The point cloud is dense and contains 3,242,964 labeled points. We used these
datasets to explore the abilities of different deep learning approaches for
automated geological mapping. By making Tinto publicly available, we hope to
foster the development and adaptation of new deep learning tools for 3D
applications in Earth sciences. The dataset can be accessed through this link:
https://doi.org/10.14278/rodare.2256.
",2023-05-17T03:24:08Z,http://arxiv.org/abs/2305.09928v2,"Ahmed J. Afifi, Samuel T. Thiele, Aldino Rizaldy, Sandra Lorenz, Pedram Ghamisi, Raimon Tolosana-Delgado, Moritz Kirsch, Richard Gloaguen, Michael Heizmann"
"Machine and Deep Learning Methods with Manual and Automatic Labelling
  for News Classification in Bangla Language","  Research in Natural Language Processing (NLP) has increasingly become
important due to applications such as text classification, text mining,
sentiment analysis, POS tagging, named entity recognition, textual entailment,
and many others. This paper introduces several machine and deep learning
methods with manual and automatic labelling for news classification in the
Bangla language. We implemented several machine (ML) and deep learning (DL)
algorithms. The ML algorithms are Logistic Regression (LR), Stochastic Gradient
Descent (SGD), Support Vector Machine (SVM), Random Forest (RF), and K-Nearest
Neighbour (KNN), used with Bag of Words (BoW), Term Frequency-Inverse Document
Frequency (TF-IDF), and Doc2Vec embedding models. The DL algorithms are Long
Short-Term Memory (LSTM), Bidirectional LSTM (BiLSTM), Gated Recurrent Unit
(GRU), and Convolutional Neural Network (CNN), used with Word2vec, Glove, and
FastText word embedding models. We develop automatic labelling methods using
Latent Dirichlet Allocation (LDA) and investigate the performance of
single-label and multi-label article classification methods. To investigate
performance, we developed from scratch Potrika, the largest and the most
extensive dataset for news classification in the Bangla language, comprising
185.51 million words and 12.57 million sentences contained in 664,880 news
articles in eight distinct categories, curated from six popular online news
portals in Bangladesh for the period 2014-2020. GRU and Fasttext with 91.83%
achieve the highest accuracy for manually-labelled data. For the automatic
labelling case, KNN and Doc2Vec at 57.72% and 75% achieve the highest accuracy
for single-label and multi-label data, respectively. The methods developed in
this paper are expected to advance research in Bangla and other languages.
",2022-10-19T21:53:49Z,http://arxiv.org/abs/2210.10903v1,"Istiak Ahmad, Fahad AlQurashi, Rashid Mehmood"
"An open access NLP dataset for Arabic dialects : Data collection,
  labeling, and model construction","  Natural Language Processing (NLP) is today a very active field of research
and innovation. Many applications need however big sets of data for supervised
learning, suitably labelled for the training purpose. This includes
applications for the Arabic language and its national dialects. However, such
open access labeled data sets in Arabic and its dialects are lacking in the
Data Science ecosystem and this lack can be a burden to innovation and research
in this field. In this work, we present an open data set of social data content
in several Arabic dialects. This data was collected from the Twitter social
network and consists on +50K twits in five (5) national dialects. Furthermore,
this data was labeled for several applications, namely dialect detection, topic
detection and sentiment analysis. We publish this data as an open access data
to encourage innovation and encourage other works in the field of NLP for
Arabic dialects and social media. A selection of models were built using this
data set and are presented in this paper along with their performances.
",2021-02-07T01:39:52Z,http://arxiv.org/abs/2102.11000v1,"ElMehdi Boujou, Hamza Chataoui, Abdellah El Mekki, Saad Benjelloun, Ikram Chairi, Ismail Berrada"
"Integrating Chemical Language and Molecular Graph in Multimodal Fused
  Deep Learning for Drug Property Prediction","  Accurately predicting molecular properties is a challenging but essential
task in drug discovery. Recently, many mono-modal deep learning methods have
been successfully applied to molecular property prediction. However, the
inherent limitation of mono-modal learning arises from relying solely on one
modality of molecular representation, which restricts a comprehensive
understanding of drug molecules and hampers their resilience against data
noise. To overcome the limitations, we construct multimodal deep learning
models to cover different molecular representations. We convert drug molecules
into three molecular representations, SMILES-encoded vectors, ECFP
fingerprints, and molecular graphs. To process the modal information,
Transformer-Encoder, bi-directional gated recurrent units (BiGRU), and graph
convolutional network (GCN) are utilized for feature learning respectively,
which can enhance the model capability to acquire complementary and naturally
occurring bioinformatics information. We evaluated our triple-modal model on
six molecule datasets. Different from bi-modal learning models, we adopt five
fusion methods to capture the specific features and leverage the contribution
of each modal information better. Compared with mono-modal models, our
multimodal fused deep learning (MMFDL) models outperform single models in
accuracy, reliability, and resistance capability against noise. Moreover, we
demonstrate its generalization ability in the prediction of binding constants
for protein-ligand complex molecules in the refined set of PDBbind. The
advantage of the multimodal model lies in its ability to process diverse
sources of data using proper models and suitable fusion methods, which would
enhance the noise resistance of the model while obtaining data diversity.
",2023-12-29T07:19:42Z,http://arxiv.org/abs/2312.17495v2,"Xiaohua Lu, Liangxu Xie, Lei Xu, Rongzhi Mao, Shan Chang, Xiaojun Xu"
"Survey on Automated Short Answer Grading with Deep Learning: from Word
  Embeddings to Transformers","  Automated short answer grading (ASAG) has gained attention in education as a
means to scale educational tasks to the growing number of students. Recent
progress in Natural Language Processing and Machine Learning has largely
influenced the field of ASAG, of which we survey the recent research
advancements. We complement previous surveys by providing a comprehensive
analysis of recently published methods that deploy deep learning approaches. In
particular, we focus our analysis on the transition from hand engineered
features to representation learning approaches, which learn representative
features for the task at hand automatically from large corpora of data. We
structure our analysis of deep learning methods along three categories: word
embeddings, sequential models, and attention-based methods. Deep learning
impacted ASAG differently than other fields of NLP, as we noticed that the
learned representations alone do not contribute to achieve the best results,
but they rather show to work in a complementary way with hand-engineered
features. The best performance are indeed achieved by methods that combine the
carefully hand-engineered features with the power of the semantic descriptions
provided by the latest models, like transformers architectures. We identify
challenges and provide an outlook on research direction that can be addressed
in the future
",2022-03-11T13:47:08Z,http://arxiv.org/abs/2204.03503v1,"Stefan Haller, Adina Aldea, Christin Seifert, Nicola Strisciuglio"
Machine Translation : From Statistical to modern Deep-learning practices,"  Machine translation (MT) is an area of study in Natural Language processing
which deals with the automatic translation of human language, from one language
to another by the computer. Having a rich research history spanning nearly
three decades, Machine translation is one of the most sought after area of
research in the linguistics and computational community. In this paper, we
investigate the models based on deep learning that have achieved substantial
progress in recent years and becoming the prominent method in MT. We shall
discuss the two main deep-learning based Machine Translation methods, one at
component or domain level which leverages deep learning models to enhance the
efficacy of Statistical Machine Translation (SMT) and end-to-end deep learning
models in MT which uses neural networks to find correspondence between the
source and target languages using the encoder-decoder architecture. We conclude
this paper by providing a time line of the major research problems solved by
the researchers and also provide a comprehensive overview of present areas of
research in Neural Machine Translation.
",2018-12-11T07:04:44Z,http://arxiv.org/abs/1812.04238v1,"Siddhant Srivastava, Anupam Shukla, Ritu Tiwari"
IndicSTR12: A Dataset for Indic Scene Text Recognition,"  The importance of Scene Text Recognition (STR) in today's increasingly
digital world cannot be overstated. Given the significance of STR, data
intensive deep learning approaches that auto-learn feature mappings have
primarily driven the development of STR solutions. Several benchmark datasets
and substantial work on deep learning models are available for Latin languages
to meet this need. On more complex, syntactically and semantically, Indian
languages spoken and read by 1.3 billion people, there is less work and
datasets available. This paper aims to address the Indian space's lack of a
comprehensive dataset by proposing the largest and most comprehensive real
dataset - IndicSTR12 - and benchmarking STR performance on 12 major Indian
languages. A few works have addressed the same issue, but to the best of our
knowledge, they focused on a small number of Indian languages. The size and
complexity of the proposed dataset are comparable to those of existing Latin
contemporaries, while its multilingualism will catalyse the development of
robust text detection and recognition models. It was created specifically for a
group of related languages with different scripts. The dataset contains over
27000 word-images gathered from various natural scenes, with over 1000
word-images for each language. Unlike previous datasets, the images cover a
broader range of realistic conditions, including blur, illumination changes,
occlusion, non-iconic texts, low resolution, perspective text etc. Along with
the new dataset, we provide a high-performing baseline on three models -
PARSeq, CRNN, and STARNet.
",2024-03-12T18:14:48Z,http://arxiv.org/abs/2403.08007v1,"Harsh Lunia, Ajoy Mondal, C V Jawahar"
"Data-driven models and computational tools for neurolinguistics: a
  language technology perspective","  In this paper, our focus is the connection and influence of language
technologies on the research in neurolinguistics. We present a review of brain
imaging-based neurolinguistic studies with a focus on the natural language
representations, such as word embeddings and pre-trained language models.
Mutual enrichment of neurolinguistics and language technologies leads to
development of brain-aware natural language representations. The importance of
this research area is emphasized by medical applications.
",2020-03-23T20:41:51Z,http://arxiv.org/abs/2003.10540v1,"Ekaterina Artemova, Amir Bakarov, Aleksey Artemov, Evgeny Burnaev, Maxim Sharaev"
Deep Learning Model for Finding New Superconductors,"  Exploration of new superconductors still relies on the experience and
intuition of experts and is largely a process of experimental trial and error.
In one study, only 3% of the candidate materials showed superconductivity.
Here, we report the first deep learning model for finding new superconductors.
We introduced the method named ""reading periodic table"" which represented the
periodic table in a way that allows deep learning to learn to read the periodic
table and to learn the law of elements for the purpose of discovering novel
superconductors that are outside the training data. It is recognized that it is
difficult for deep learning to predict something outside the training data.
Although we used only the chemical composition of materials as information, we
obtained an $R^{2}$ value of 0.92 for predicting $T_\text{c}$ for materials in
a database of superconductors. We also introduced the method named ""garbage-in""
to create synthetic data of non-superconductors that do not exist.
Non-superconductors are not reported, but the data must be required for deep
learning to distinguish between superconductors and non-superconductors. We
obtained three remarkable results. The deep learning can predict
superconductivity for a material with a precision of 62%, which shows the
usefulness of the model; it found the recently discovered superconductor CaBi2
and another one Hf0.5Nb0.2V2Zr0.3, neither of which is in the superconductor
database; and it found Fe-based high-temperature superconductors (discovered in
2008) from the training data before 2008. These results open the way for the
discovery of new high-temperature superconductor families. The candidate
materials list, data, and method are openly available from the link
https://github.com/tomo835g/Deep-Learning-to-find-Superconductors.
",2018-12-03T05:30:34Z,http://arxiv.org/abs/1812.01995v4,"Tomohiko Konno, Hodaka Kurokawa, Fuyuki Nabeshima, Yuki Sakishita, Ryo Ogawa, Iwao Hosako, Atsutaka Maeda"
"Synergizing Unsupervised and Supervised Learning: A Hybrid Approach for
  Accurate Natural Language Task Modeling","  While supervised learning models have shown remarkable performance in various
natural language processing (NLP) tasks, their success heavily relies on the
availability of large-scale labeled datasets, which can be costly and
time-consuming to obtain. Conversely, unsupervised learning techniques can
leverage abundant unlabeled text data to learn rich representations, but they
do not directly optimize for specific NLP tasks. This paper presents a novel
hybrid approach that synergizes unsupervised and supervised learning to improve
the accuracy of NLP task modeling. While supervised models excel at specific
tasks, they rely on large labeled datasets. Unsupervised techniques can learn
rich representations from abundant unlabeled text but don't directly optimize
for tasks. Our methodology integrates an unsupervised module that learns
representations from unlabeled corpora (e.g., language models, word embeddings)
and a supervised module that leverages these representations to enhance
task-specific models. We evaluate our approach on text classification and named
entity recognition (NER), demonstrating consistent performance gains over
supervised baselines. For text classification, contextual word embeddings from
a language model pretrain a recurrent or transformer-based classifier. For NER,
word embeddings initialize a BiLSTM sequence labeler. By synergizing
techniques, our hybrid approach achieves SOTA results on benchmark datasets,
paving the way for more data-efficient and robust NLP systems.
",2024-06-03T08:31:35Z,http://arxiv.org/abs/2406.01096v1,"Wrick Talukdar, Anjanava Biswas"
"Talk2Data: A Natural Language Interface for Exploratory Visual Analysis
  via Question Decomposition","  Through a natural language interface (NLI) for exploratory visual analysis,
users can directly ""ask"" analytical questions about the given tabular data.
This process greatly improves user experience and lowers the technical barriers
of data analysis. Existing techniques focus on generating a visualization from
a concrete question. However, complex questions, requiring multiple data
queries and visualizations to answer, are frequently asked in data exploration
and analysis, which cannot be easily solved with the existing techniques. To
address this issue, in this paper, we introduce Talk2Data, a natural language
interface for exploratory visual analysis that supports answering complex
questions. It leverages an advanced deep-learning model to resolve complex
questions into a series of simple questions that could gradually elaborate on
the users' requirements. To present answers, we design a set of annotated and
captioned visualizations to represent the answers in a form that supports
interpretation and narration. We conducted an ablation study and a controlled
user study to evaluate Talk2Data's effectiveness and usefulness.
",2021-07-30T03:41:39Z,http://arxiv.org/abs/2107.14420v3,"Yi Guo, Danqing Shi, Mingjuan Guo, Yanqiu Wu, Qing Chen, Nan Cao"
Deep Learning for Text Style Transfer: A Survey,"  Text style transfer is an important task in natural language generation,
which aims to control certain attributes in the generated text, such as
politeness, emotion, humor, and many others. It has a long history in the field
of natural language processing, and recently has re-gained significant
attention thanks to the promising performance brought by deep neural models. In
this paper, we present a systematic survey of the research on neural text style
transfer, spanning over 100 representative articles since the first neural text
style transfer work in 2017. We discuss the task formulation, existing datasets
and subtasks, evaluation, as well as the rich methodologies in the presence of
parallel and non-parallel data. We also provide discussions on a variety of
important topics regarding the future development of this task. Our curated
paper list is at https://github.com/zhijing-jin/Text_Style_Transfer_Survey
",2020-11-01T04:04:43Z,http://arxiv.org/abs/2011.00416v5,"Di Jin, Zhijing Jin, Zhiting Hu, Olga Vechtomova, Rada Mihalcea"
Natural Language-Guided Programming,"  In today's software world with its cornucopia of reusable software libraries,
when a programmer is faced with a programming task that they suspect can be
completed through the use of a library, they often look for code examples using
a search engine and then manually adapt found examples to their specific
context of use. We put forward a vision based on a new breed of developer tools
that have the potential to largely automate this process. The key idea is to
adapt code autocompletion tools such that they take into account not only the
developer's already-written code but also the intent of the task the developer
is trying to achieve next, formulated in plain natural language. We call this
practice of enriching the code with natural language intent to facilitate its
completion natural language-guided programming.
  To show that this idea is feasible we design, implement and benchmark a tool
that solves this problem in the context of a specific domain (data science) and
a specific programming language (Python). Central to the tool is the use of
language models trained on a large corpus of documented code. Our initial
experiments confirm the feasibility of the idea but also make it clear that we
have only scratched the surface of what may become possible in the future. We
end the paper with a comprehensive research agenda to stimulate additional
research in the budding area of natural language-guided programming.
",2021-08-11T13:06:33Z,http://arxiv.org/abs/2108.05198v2,"Geert Heyman, Rafael Huysegems, Pascal Justen, Tom Van Cutsem"
"A Large Language Model and Denoising Diffusion Framework for Targeted
  Design of Microstructures with Commands in Natural Language","  Microstructure plays a critical role in determining the macroscopic
properties of materials, with applications spanning alloy design, MEMS devices,
and tissue engineering, among many others. Computational frameworks have been
developed to capture the complex relationship between microstructure and
material behavior. However, despite these advancements, the steep learning
curve associated with domain-specific knowledge and complex algorithms
restricts the broader application of these tools. To lower this barrier, we
propose a framework that integrates Natural Language Processing (NLP), Large
Language Models (LLMs), and Denoising Diffusion Probabilistic Models (DDPMs) to
enable microstructure design using intuitive natural language commands. Our
framework employs contextual data augmentation, driven by a pretrained LLM, to
generate and expand a diverse dataset of microstructure descriptors. A
retrained NER model extracts relevant microstructure descriptors from
user-provided natural language inputs, which are then used by the DDPM to
generate microstructures with targeted mechanical properties and topological
features. The NLP and DDPM components of the framework are modular, allowing
for separate training and validation, which ensures flexibility in adapting the
framework to different datasets and use cases. A surrogate model system is
employed to rank and filter generated samples based on their alignment with
target properties. Demonstrated on a database of nonlinear hyperelastic
microstructures, this framework serves as a prototype for accessible inverse
design of microstructures, starting from intuitive natural language commands.
",2024-09-22T14:45:22Z,http://arxiv.org/abs/2409.14473v1,"Nikita Kartashov, Nikolaos N. Vlassis"
Online Knowledge Integration for 3D Semantic Mapping: A Survey,"  Semantic mapping is a key component of robots operating in and interacting
with objects in structured environments. Traditionally, geometric and knowledge
representations within a semantic map have only been loosely integrated.
However, recent advances in deep learning now allow full integration of prior
knowledge, represented as knowledge graphs or language concepts, into sensor
data processing and semantic mapping pipelines. Semantic scene graphs and
language models enable modern semantic mapping approaches to incorporate
graph-based prior knowledge or to leverage the rich information in human
language both during and after the mapping process. This has sparked
substantial advances in semantic mapping, leading to previously impossible
novel applications. This survey reviews these recent developments
comprehensively, with a focus on online integration of knowledge into semantic
mapping. We specifically focus on methods using semantic scene graphs for
integrating symbolic prior knowledge and language models for respective capture
of implicit common-sense knowledge and natural language concepts
",2024-11-27T08:53:16Z,http://arxiv.org/abs/2411.18147v1,"Felix Igelbrink, Marian Renz, Martin G√ºnther, Piper Powell, Lennart Niecksch, Oscar Lima, Martin Atzmueller, Joachim Hertzberg"
A Morphology-aware Network for Morphological Disambiguation,"  Agglutinative languages such as Turkish, Finnish and Hungarian require
morphological disambiguation before further processing due to the complex
morphology of words. A morphological disambiguator is used to select the
correct morphological analysis of a word. Morphological disambiguation is
important because it generally is one of the first steps of natural language
processing and its performance affects subsequent analyses. In this paper, we
propose a system that uses deep learning techniques for morphological
disambiguation. Many of the state-of-the-art results in computer vision, speech
recognition and natural language processing have been obtained through deep
learning models. However, applying deep learning techniques to morphologically
rich languages is not well studied. In this work, while we focus on Turkish
morphological disambiguation we also present results for French and German in
order to show that the proposed architecture achieves high accuracy with no
language-specific feature engineering or additional resource. In the
experiments, we achieve 84.12, 88.35 and 93.78 morphological disambiguation
accuracy among the ambiguous words for Turkish, German and French respectively.
",2017-02-13T07:08:28Z,http://arxiv.org/abs/1702.03654v1,"Eray Yildiz, Caglar Tirkaz, H. Bahadir Sahin, Mustafa Tolga Eren, Ozan Sonmez"
SKOPE: A connectionist/symbolic architecture of spoken Korean processing,"  Spoken language processing requires speech and natural language integration.
Moreover, spoken Korean calls for unique processing methodology due to its
linguistic characteristics. This paper presents SKOPE, a connectionist/symbolic
spoken Korean processing engine, which emphasizes that: 1) connectionist and
symbolic techniques must be selectively applied according to their relative
strength and weakness, and 2) the linguistic characteristics of Korean must be
fully considered for phoneme recognition, speech and language integration, and
morphological/syntactic processing. The design and implementation of SKOPE
demonstrates how connectionist/symbolic hybrid architectures can be constructed
for spoken agglutinative language processing. Also SKOPE presents many novel
ideas for speech and language processing. The phoneme recognition,
morphological analysis, and syntactic analysis experiments show that SKOPE is a
viable approach for the spoken Korean processing.
",1995-04-07T14:39:09Z,http://arxiv.org/abs/cmp-lg/9504008v2,"Geunbae Lee, Jong-Hyeok Lee"
"Accelerating materials discovery for polymer solar cells: Data-driven
  insights enabled by natural language processing","  We present a simulation of various active learning strategies for the
discovery of polymer solar cell donor/acceptor pairs using data extracted from
the literature spanning $\sim$20 years by a natural language processing
pipeline. While data-driven methods have been well established to discover
novel materials faster than Edisonian trial-and-error approaches, their
benefits have not been quantified for material discovery problems that can take
decades. Our approach demonstrates a potential reduction in discovery time by
approximately 75 %, equivalent to a 15 year acceleration in material
innovation. Our pipeline enables us to extract data from greater than 3300
papers which is $\sim$5 times larger and therefore more diverse than similar
data sets reported by others. We also trained machine learning models to
predict the power conversion efficiency and used our model to identify
promising donor-acceptor combinations that are as yet unreported. We thus
demonstrate a pipeline that goes from published literature to extracted
material property data which in turn is used to obtain data-driven insights.
Our insights include active learning strategies that can be used to train
strong predictive models of material properties or be robust to the initial
material system used. This work provides a valuable framework for data-driven
research in materials science.
",2024-02-29T18:54:46Z,http://arxiv.org/abs/2402.19462v2,"Pranav Shetty, Aishat Adeboye, Sonakshi Gupta, Chao Zhang, Rampi Ramprasad"
Homological Convolutional Neural Networks,"  Deep learning methods have demonstrated outstanding performances on
classification and regression tasks on homogeneous data types (e.g., image,
audio, and text data). However, tabular data still pose a challenge, with
classic machine learning approaches being often computationally cheaper and
equally effective than increasingly complex deep learning architectures. The
challenge arises from the fact that, in tabular data, the correlation among
features is weaker than the one from spatial or semantic relationships in
images or natural language, and the dependency structures need to be modeled
without any prior information. In this work, we propose a novel deep learning
architecture that exploits the data structural organization through
topologically constrained network representations to gain relational
information from sparse tabular inputs. The resulting model leverages the power
of convolution and is centered on a limited number of concepts from network
topology to guarantee: (i) a data-centric and deterministic building pipeline;
(ii) a high level of interpretability over the inference process; and (iii) an
adequate room for scalability. We test our model on 18 benchmark datasets
against 5 classic machine learning and 3 deep learning models, demonstrating
that our approach reaches state-of-the-art performances on these challenging
datasets. The code to reproduce all our experiments is provided at
https://github.com/FinancialComputingUCL/HomologicalCNN.
",2023-08-26T08:48:51Z,http://arxiv.org/abs/2308.13816v2,"Antonio Briola, Yuanrong Wang, Silvia Bartolucci, Tomaso Aste"
"Improving Natural-Language-based Audio Retrieval with Transfer Learning
  and Audio & Text Augmentations","  The absence of large labeled datasets remains a significant challenge in many
application areas of deep learning. Researchers and practitioners typically
resort to transfer learning and data augmentation to alleviate this issue. We
study these strategies in the context of audio retrieval with natural language
queries (Task 6b of the DCASE 2022 Challenge). Our proposed system uses
pre-trained embedding models to project recordings and textual descriptions
into a shared audio-caption space in which related examples from different
modalities are close. We employ various data augmentation techniques on audio
and text inputs and systematically tune their corresponding hyperparameters
with sequential model-based optimization. Our results show that the used
augmentations strategies reduce overfitting and improve retrieval performance.
",2022-08-24T11:54:42Z,http://arxiv.org/abs/2208.11460v3,"Paul Primus, Gerhard Widmer"
"Leveraging Sparse and Dense Feature Combinations for Sentiment
  Classification","  Neural networks are one of the most popular approaches for many natural
language processing tasks such as sentiment analysis. They often outperform
traditional machine learning models and achieve the state-of-art results on
most tasks. However, many existing deep learning models are complex, difficult
to train and provide a limited improvement over simpler methods. We propose a
simple, robust and powerful model for sentiment classification. This model
outperforms many deep learning models and achieves comparable results to other
deep learning models with complex architectures on sentiment analysis datasets.
We publish the code online.
",2017-08-13T17:38:17Z,http://arxiv.org/abs/1708.03940v1,"Tao Yu, Christopher Hidey, Owen Rambow, Kathleen McKeown"
Active Learning amidst Logical Knowledge,"  Structured prediction is ubiquitous in applications of machine learning such
as knowledge extraction and natural language processing. Structure often can be
formulated in terms of logical constraints. We consider the question of how to
perform efficient active learning in the presence of logical constraints among
variables inferred by different classifiers. We propose several methods and
provide theoretical results that demonstrate the inappropriateness of employing
uncertainty guided sampling, a commonly used active learning method.
Furthermore, experiments on ten different datasets demonstrate that the methods
significantly outperform alternatives in practice. The results are of practical
significance in situations where labeled data is scarce.
",2017-09-26T06:13:49Z,http://arxiv.org/abs/1709.08850v1,"Emmanouil Antonios Platanios, Ashish Kapoor, Eric Horvitz"
Using Machine Learning Based Models for Personality Recognition,"  Personality can be defined as the combination of behavior, emotion,
motivation, and thoughts that aim at describing various aspects of human
behavior based on a few stable and measurable characteristics. Considering the
fact that our personality has a remarkable influence in our daily life,
automatic recognition of a person's personality attributes can provide many
essential practical applications in various aspects of cognitive science. deep
learning based method for the task of personality recognition from text is
proposed in this paper. Among various deep neural networks, Convolutional
Neural Networks (CNN) have demonstrated profound efficiency in natural language
processing and especially personality detection. Owing to the fact that various
filter sizes in CNN may influence its performance, we decided to combine CNN
with AdaBoost, a classical ensemble algorithm, to consider the possibility of
using the contribution of various filter lengths and gasp their potential in
the final classification via combining various classifiers with respective
filter size using AdaBoost. Our proposed method was validated on the Essay
dataset by conducting a series of experiments and the empirical results
demonstrated the superiority of our proposed method compared to both machine
learning and deep learning methods for the task of personality recognition.
",2022-01-17T07:20:51Z,http://arxiv.org/abs/2201.06248v1,"Fatemeh Mohades Deilami, Hossein Sadr, Mojdeh Nazari"
"Machine Learning: Algorithms, Models, and Applications","  Recent times are witnessing rapid development in machine learning algorithm
systems, especially in reinforcement learning, natural language processing,
computer and robot vision, image processing, speech, and emotional processing
and understanding. In tune with the increasing importance and relevance of
machine learning models, algorithms, and their applications, and with the
emergence of more innovative uses cases of deep learning and artificial
intelligence, the current volume presents a few innovative research works and
their applications in real world, such as stock trading, medical and healthcare
systems, and software automation. The chapters in the book illustrate how
machine learning and deep learning algorithms and models are designed,
optimized, and deployed. The volume will be useful for advanced graduate and
doctoral students, researchers, faculty members of universities, practicing
data scientists and data engineers, professionals, and consultants working on
the broad areas of machine learning, deep learning, and artificial
intelligence.
",2022-01-06T07:14:02Z,http://arxiv.org/abs/2201.01943v1,"Jaydip Sen, Sidra Mehtab, Rajdeep Sen, Abhishek Dutta, Pooja Kherwa, Saheel Ahmed, Pranay Berry, Sahil Khurana, Sonali Singh, David W. W Cadotte, David W. Anderson, Kalum J. Ost, Racheal S. Akinbo, Oladunni A. Daramola, Bongs Lainjo"
"Research on Optimization of Natural Language Processing Model Based on
  Multimodal Deep Learning","  This project intends to study the image representation based on attention
mechanism and multimodal data. By adding multiple pattern layers to the
attribute model, the semantic and hidden layers of image content are
integrated. The word vector is quantified by the Word2Vec method and then
evaluated by a word embedding convolutional neural network. The published
experimental results of the two groups were tested. The experimental results
show that this method can convert discrete features into continuous characters,
thus reducing the complexity of feature preprocessing. Word2Vec and natural
language processing technology are integrated to achieve the goal of direct
evaluation of missing image features. The robustness of the image feature
evaluation model is improved by using the excellent feature analysis
characteristics of a convolutional neural network. This project intends to
improve the existing image feature identification methods and eliminate the
subjective influence in the evaluation process. The findings from the
simulation indicate that the novel approach has developed is viable,
effectively augmenting the features within the produced representations.
",2024-06-13T06:03:59Z,http://arxiv.org/abs/2406.08838v1,"Dan Sun, Yaxin Liang, Yining Yang, Yuhan Ma, Qishi Zhan, Erdi Gao"
"FineText: Text Classification via Attention-based Language Model
  Fine-tuning","  Training deep neural networks from scratch on natural language processing
(NLP) tasks requires significant amount of manually labeled text corpus and
substantial time to converge, which usually cannot be satisfied by the
customers. In this paper, we aim to develop an effective transfer learning
algorithm by fine-tuning a pre-trained language model. The goal is to provide
expressive and convenient-to-use feature extractors for downstream NLP tasks,
and achieve improvement in terms of accuracy, data efficiency, and
generalization to new domains. Therefore, we propose an attention-based
fine-tuning algorithm that automatically selects relevant contextualized
features from the pre-trained language model and uses those features on
downstream text classification tasks. We test our methods on six widely-used
benchmarking datasets, and achieve new state-of-the-art performance on all of
them. Moreover, we then introduce an alternative multi-task learning approach,
which is an end-to-end algorithm given the pre-trained model. By doing
multi-task learning, one can largely reduce the total training time by trading
off some classification accuracy.
",2019-10-25T23:13:15Z,http://arxiv.org/abs/1910.11959v1,"Yunzhe Tao, Saurabh Gupta, Satyapriya Krishna, Xiong Zhou, Orchid Majumder, Vineet Khare"
"On the Use of BERT for Automated Essay Scoring: Joint Learning of
  Multi-Scale Essay Representation","  In recent years, pre-trained models have become dominant in most natural
language processing (NLP) tasks. However, in the area of Automated Essay
Scoring (AES), pre-trained models such as BERT have not been properly used to
outperform other deep learning models such as LSTM. In this paper, we introduce
a novel multi-scale essay representation for BERT that can be jointly learned.
We also employ multiple losses and transfer learning from out-of-domain essays
to further improve the performance. Experiment results show that our approach
derives much benefit from joint learning of multi-scale essay representation
and obtains almost the state-of-the-art result among all deep learning models
in the ASAP task. Our multi-scale essay representation also generalizes well to
CommonLit Readability Prize data set, which suggests that the novel text
representation proposed in this paper may be a new and effective choice for
long-text tasks.
",2022-05-08T10:36:54Z,http://arxiv.org/abs/2205.03835v2,"Yongjie Wang, Chuan Wang, Ruobing Li, Hui Lin"
Evolutionary Algorithm for Sinhala to English Translation,"  Machine Translation (MT) is an area in natural language processing, which
focus on translating from one language to another. Many approaches ranging from
statistical methods to deep learning approaches are used in order to achieve
MT. However, these methods either require a large number of data or a clear
understanding about the language. Sinhala language has less digital text which
could be used to train a deep neural network. Furthermore, Sinhala has complex
rules therefore, it is harder to create statistical rules in order to apply
statistical methods in MT. This research focuses on Sinhala to English
translation using an Evolutionary Algorithm (EA). EA is used to identifying the
correct meaning of Sinhala text and to translate it to English. The Sinhala
text is passed to identify the meaning in order to get the correct meaning of
the sentence. With the use of the EA the translation is carried out. The
translated text is passed on to grammatically correct the sentence. This has
shown to achieve accurate results.
",2019-07-06T22:51:28Z,http://arxiv.org/abs/1907.03202v1,"J. K. Joseph, W. M. T. Chathurika, A. Nugaliyadde, Y. Mallawarachchi"
"Semantics of the Black-Box: Can knowledge graphs help make deep learning
  systems more interpretable and explainable?","  The recent series of innovations in deep learning (DL) have shown enormous
potential to impact individuals and society, both positively and negatively.
The DL models utilizing massive computing power and enormous datasets have
significantly outperformed prior historical benchmarks on increasingly
difficult, well-defined research tasks across technology domains such as
computer vision, natural language processing, signal processing, and
human-computer interactions. However, the Black-Box nature of DL models and
their over-reliance on massive amounts of data condensed into labels and dense
representations poses challenges for interpretability and explainability of the
system. Furthermore, DLs have not yet been proven in their ability to
effectively utilize relevant domain knowledge and experience critical to human
understanding. This aspect is missing in early data-focused approaches and
necessitated knowledge-infused learning and other strategies to incorporate
computational knowledge. This article demonstrates how knowledge, provided as a
knowledge graph, is incorporated into DL methods using knowledge-infused
learning, which is one of the strategies. We then discuss how this makes a
fundamental difference in the interpretability and explainability of current
approaches, and illustrate it with examples from natural language processing
for healthcare and education applications.
",2020-10-16T22:55:23Z,http://arxiv.org/abs/2010.08660v4,"Manas Gaur, Keyur Faldu, Amit Sheth"
Curriculum Learning in Deep Neural Networks for Financial Forecasting,"  For any financial organization, computing accurate quarterly forecasts for
various products is one of the most critical operations. As the granularity at
which forecasts are needed increases, traditional statistical time series
models may not scale well. We apply deep neural networks in the forecasting
domain by experimenting with techniques from Natural Language Processing
(Encoder-Decoder LSTMs) and Computer Vision (Dilated CNNs), as well as
incorporating transfer learning. A novel contribution of this paper is the
application of curriculum learning to neural network models built for time
series forecasting. We illustrate the performance of our models using
Microsoft's revenue data corresponding to Enterprise, and Small, Medium &
Corporate products, spanning approximately 60 regions across the globe for 8
different business segments, and totaling in the order of tens of billions of
USD. We compare our models' performance to the ensemble model of traditional
statistics and machine learning techniques currently used by Microsoft Finance.
With this in-production model as a baseline, our experiments yield an
approximately 30% improvement in overall accuracy on test data. We find that
our curriculum learning LSTM-based model performs best, showing that it is
reasonable to implement our proposed methods without overfitting on
medium-sized data.
",2019-04-29T18:09:31Z,http://arxiv.org/abs/1904.12887v2,"Allison Koenecke, Amita Gajewar"
"Adapt or Get Left Behind: Domain Adaptation through BERT Language Model
  Finetuning for Aspect-Target Sentiment Classification","  Aspect-Target Sentiment Classification (ATSC) is a subtask of Aspect-Based
Sentiment Analysis (ABSA), which has many applications e.g. in e-commerce,
where data and insights from reviews can be leveraged to create value for
businesses and customers. Recently, deep transfer-learning methods have been
applied successfully to a myriad of Natural Language Processing (NLP) tasks,
including ATSC. Building on top of the prominent BERT language model, we
approach ATSC using a two-step procedure: self-supervised domain-specific BERT
language model finetuning, followed by supervised task-specific finetuning. Our
findings on how to best exploit domain-specific language model finetuning
enable us to produce new state-of-the-art performance on the SemEval 2014 Task
4 restaurants dataset. In addition, to explore the real-world robustness of our
models, we perform cross-domain evaluation. We show that a cross-domain adapted
BERT language model performs significantly better than strong baseline models
like vanilla BERT-base and XLNet-base. Finally, we conduct a case study to
interpret model prediction errors.
",2019-08-30T17:44:30Z,http://arxiv.org/abs/1908.11860v2,"Alexander Rietzler, Sebastian Stabinger, Paul Opitz, Stefan Engl"
"Natural Language Processing Methods for Symbolic Music Generation and
  Information Retrieval: a Survey","  Several adaptations of Transformers models have been developed in various
domains since its breakthrough in Natural Language Processing (NLP). This trend
has spread into the field of Music Information Retrieval (MIR), including
studies processing music data. However, the practice of leveraging NLP tools
for symbolic music data is not novel in MIR. Music has been frequently compared
to language, as they share several similarities, including sequential
representations of text and music. These analogies are also reflected through
similar tasks in MIR and NLP. This survey reviews NLP methods applied to
symbolic music generation and information retrieval studies following two axes.
We first propose an overview of representations of symbolic music adapted from
natural language sequential representations. Such representations are designed
by considering the specificities of symbolic music. These representations are
then processed by models. Such models, possibly originally developed for text
and adapted for symbolic music, are trained on various tasks. We describe these
models, in particular deep learning models, through different prisms,
highlighting music-specialized mechanisms. We finally present a discussion
surrounding the effective use of NLP tools for symbolic music data. This
includes technical issues regarding NLP methods and fundamental differences
between text and music, which may open several doors for further research into
more effectively adapting NLP tools to symbolic MIR.
",2024-02-27T12:48:01Z,http://arxiv.org/abs/2402.17467v1,"Dinh-Viet-Toan Le, Louis Bigo, Mikaela Keller, Dorien Herremans"
"Deep Unsupervised Domain Adaptation for Time Series Classification: a
  Benchmark","  Unsupervised Domain Adaptation (UDA) aims to harness labeled source data to
train models for unlabeled target data. Despite extensive research in domains
like computer vision and natural language processing, UDA remains underexplored
for time series data, which has widespread real-world applications ranging from
medicine and manufacturing to earth observation and human activity recognition.
Our paper addresses this gap by introducing a comprehensive benchmark for
evaluating UDA techniques for time series classification, with a focus on deep
learning methods. We provide seven new benchmark datasets covering various
domain shifts and temporal dynamics, facilitating fair and standardized UDA
method assessments with state of the art neural network backbones (e.g.
Inception) for time series data. This benchmark offers insights into the
strengths and limitations of the evaluated approaches while preserving the
unsupervised nature of domain adaptation, making it directly applicable to
practical problems. Our paper serves as a vital resource for researchers and
practitioners, advancing domain adaptation solutions for time series data and
fostering innovation in this critical field. The implementation code of this
benchmark is available at https://github.com/EricssonResearch/UDA-4-TSC.
",2023-12-15T15:03:55Z,http://arxiv.org/abs/2312.09857v2,"Hassan Ismail Fawaz, Ganesh Del Grosso, Tanguy Kerdoncuff, Aurelie Boisbunon, Illyyne Saffar"
Does Synthetic Data Make Large Language Models More Efficient?,"  Natural Language Processing (NLP) has undergone transformative changes with
the advent of deep learning methodologies. One challenge persistently
confronting researchers is the scarcity of high-quality, annotated datasets
that drive these models. This paper explores the nuances of synthetic data
generation in NLP, with a focal point on template-based question generation. By
assessing its advantages, including data augmentation potential and the
introduction of structured variety, we juxtapose these benefits against
inherent limitations, such as the risk of overfitting and the constraints posed
by pre-defined templates. Drawing from empirical evaluations, we demonstrate
the impact of template-based synthetic data on the performance of modern
transformer models. We conclude by emphasizing the delicate balance required
between synthetic and real-world data, and the future trajectories of
integrating synthetic data in model training pipelines. The findings aim to
guide NLP practitioners in harnessing synthetic data's potential, ensuring
optimal model performance in diverse applications.
",2023-10-11T19:16:09Z,http://arxiv.org/abs/2310.07830v1,"Sia Gholami, Marwan Omar"
End-to-End Speech Translation of Arabic to English Broadcast News,"  Speech translation (ST) is the task of directly translating acoustic speech
signals in a source language into text in a foreign language. ST task has been
addressed, for a long time, using a pipeline approach with two modules : first
an Automatic Speech Recognition (ASR) in the source language followed by a
text-to-text Machine translation (MT). In the past few years, we have seen a
paradigm shift towards the end-to-end approaches using sequence-to-sequence
deep neural network models. This paper presents our efforts towards the
development of the first Broadcast News end-to-end Arabic to English speech
translation system. Starting from independent ASR and MT LDC releases, we were
able to identify about 92 hours of Arabic audio recordings for which the manual
transcription was also translated into English at the segment level. These data
was used to train and compare pipeline and end-to-end speech translation
systems under multiple scenarios including transfer learning and data
augmentation techniques.
",2022-12-11T11:35:46Z,http://arxiv.org/abs/2212.05479v1,"Fethi Bougares, Salim Jouili"
"Memristors -- from In-memory computing, Deep Learning Acceleration,
  Spiking Neural Networks, to the Future of Neuromorphic and Bio-inspired
  Computing","  Machine learning, particularly in the form of deep learning, has driven most
of the recent fundamental developments in artificial intelligence. Deep
learning is based on computational models that are, to a certain extent,
bio-inspired, as they rely on networks of connected simple computing units
operating in parallel. Deep learning has been successfully applied in areas
such as object/pattern recognition, speech and natural language processing,
self-driving vehicles, intelligent self-diagnostics tools, autonomous robots,
knowledgeable personal assistants, and monitoring. These successes have been
mostly supported by three factors: availability of vast amounts of data,
continuous growth in computing power, and algorithmic innovations. The
approaching demise of Moore's law, and the consequent expected modest
improvements in computing power that can be achieved by scaling, raise the
question of whether the described progress will be slowed or halted due to
hardware limitations. This paper reviews the case for a novel beyond CMOS
hardware technology, memristors, as a potential solution for the implementation
of power-efficient in-memory computing, deep learning accelerators, and spiking
neural networks. Central themes are the reliance on non-von-Neumann computing
architectures and the need for developing tailored learning and inference
algorithms. To argue that lessons from biology can be useful in providing
directions for further progress in artificial intelligence, we briefly discuss
an example based reservoir computing. We conclude the review by speculating on
the big picture view of future neuromorphic and brain-inspired computing
systems.
",2020-04-30T16:49:03Z,http://arxiv.org/abs/2004.14942v1,"Adnan Mehonic, Abu Sebastian, Bipin Rajendran, Osvaldo Simeone, Eleni Vasilaki, Anthony J. Kenyon"
"Deep Transfer Learning & Beyond: Transformer Language Models in
  Information Systems Research","  AI is widely thought to be poised to transform business, yet current
perceptions of the scope of this transformation may be myopic. Recent progress
in natural language processing involving transformer language models (TLMs)
offers a potential avenue for AI-driven business and societal transformation
that is beyond the scope of what most currently foresee. We review this recent
progress as well as recent literature utilizing text mining in top IS journals
to develop an outline for how future IS research can benefit from these new
techniques. Our review of existing IS literature reveals that suboptimal text
mining techniques are prevalent and that the more advanced TLMs could be
applied to enhance and increase IS research involving text data, and to enable
new IS research topics, thus creating more value for the research community.
This is possible because these techniques make it easier to develop very
powerful custom systems and their performance is superior to existing methods
for a wide range of tasks and applications. Further, multilingual language
models make possible higher quality text analytics for research in multiple
languages. We also identify new avenues for IS research, like language user
interfaces, that may offer even greater potential for future IS research.
",2021-10-18T02:01:39Z,http://arxiv.org/abs/2110.08975v2,"Ross Gruetzemacher, David Paradice"
"Neural data-to-text generation: A comparison between pipeline and
  end-to-end architectures","  Traditionally, most data-to-text applications have been designed using a
modular pipeline architecture, in which non-linguistic input data is converted
into natural language through several intermediate transformations. In
contrast, recent neural models for data-to-text generation have been proposed
as end-to-end approaches, where the non-linguistic input is rendered in natural
language with much less explicit intermediate representations in-between. This
study introduces a systematic comparison between neural pipeline and end-to-end
data-to-text approaches for the generation of text from RDF triples. Both
architectures were implemented making use of state-of-the art deep learning
methods as the encoder-decoder Gated-Recurrent Units (GRU) and Transformer.
Automatic and human evaluations together with a qualitative analysis suggest
that having explicit intermediate steps in the generation process results in
better texts than the ones generated by end-to-end approaches. Moreover, the
pipeline models generalize better to unseen inputs. Data and code are publicly
available.
",2019-08-23T20:10:36Z,http://arxiv.org/abs/1908.09022v2,"Thiago Castro Ferreira, Chris van der Lee, Emiel van Miltenburg, Emiel Krahmer"
A novel hybrid methodology of measuring sentence similarity,"  The problem of measuring sentence similarity is an essential issue in the
natural language processing (NLP) area. It is necessary to measure the
similarity between sentences accurately. There are many approaches to measuring
sentence similarity. Deep learning methodology shows a state-of-the-art
performance in many natural language processing fields and is used a lot in
sentence similarity measurement methods. However, in the natural language
processing field, considering the structure of the sentence or the word
structure that makes up the sentence is also important. In this study, we
propose a methodology combined with both deep learning methodology and a method
considering lexical relationships. Our evaluation metric is the Pearson
correlation coefficient and Spearman correlation coefficient. As a result, the
proposed method outperforms the current approaches on a KorSTS standard
benchmark Korean dataset. Moreover, it performs a maximum of 65% increase than
only using deep learning methodology. Experiments show that our proposed method
generally results in better performance than those with only a deep learning
model.
",2021-05-03T06:50:54Z,http://arxiv.org/abs/2105.00648v5,"Yongmin Yoo, Tak-Sung Heo, Yeongjoon Park, Kyungsun Kim"
"A Comparative Study of the Application of Different Learning Techniques
  to Natural Language Interfaces","  In this paper we present first results from a comparative study. Its aim is
to test the feasibility of different inductive learning techniques to perform
the automatic acquisition of linguistic knowledge within a natural language
database interface. In our interface architecture the machine learning module
replaces an elaborate semantic analysis component. The learning module learns
the correct mapping of a user's input to the corresponding database command
based on a collection of past input data. We use an existing interface to a
production planning and control system as evaluation and compare the results
achieved by different instance-based and model-based learning algorithms.
",1997-05-16T03:50:14Z,http://arxiv.org/abs/cmp-lg/9705012v1,"Werner Winiwarter, Yahiko Kambayashi"
Natural Language Processing for Policymaking,"  Language is the medium for many political activities, from campaigns to news
reports. Natural language processing (NLP) uses computational tools to parse
text into key information that is needed for policymaking. In this chapter, we
introduce common methods of NLP, including text classification, topic modeling,
event extraction, and text scaling. We then overview how these methods can be
used for policymaking through four major applications including data collection
for evidence-based policymaking, interpretation of political decisions, policy
communication, and investigation of policy effects. Finally, we highlight some
potential limitations and ethical concerns when using NLP for policymaking.
  This text is from Chapter 7 (pages 141-162) of the Handbook of Computational
Social Science for Policy (2023). Open Access on Springer:
https://doi.org/10.1007/978-3-031-16624-2
",2023-02-07T14:34:39Z,http://arxiv.org/abs/2302.03490v1,"Zhijing Jin, Rada Mihalcea"
Key Information Extraction From Documents: Evaluation And Generator,"  Extracting information from documents usually relies on natural language
processing methods working on one-dimensional sequences of text. In some cases,
for example, for the extraction of key information from semi-structured
documents, such as invoice-documents, spatial and formatting information of
text are crucial to understand the contextual meaning. Convolutional neural
networks are already common in computer vision models to process and extract
relationships in multidimensional data. Therefore, natural language processing
models have already been combined with computer vision models in the past, to
benefit from e.g. positional information and to improve performance of these
key information extraction models. Existing models were either trained on
unpublished data sets or on an annotated collection of receipts, which did not
focus on PDF-like documents. Hence, in this research project a template-based
document generator was created to compare state-of-the-art models for
information extraction. An existing information extraction model ""Chargrid""
(Katti et al., 2019) was reconstructed and the impact of a bounding box
regression decoder, as well as the impact of an NLP pre-processing step was
evaluated for information extraction from documents. The results have shown
that NLP based pre-processing is beneficial for model performance. However, the
use of a bounding box regression decoder increases the model performance only
for fields that do not follow a rectangular shape.
",2021-06-09T16:12:21Z,http://arxiv.org/abs/2106.14624v1,"Oliver Bensch, Mirela Popa, Constantin Spille"
"To Compress, or Not to Compress: Characterizing Deep Learning Model
  Compression for Embedded Inference","  The recent advances in deep neural networks (DNNs) make them attractive for
embedded systems. However, it can take a long time for DNNs to make an
inference on resource-constrained computing devices. Model compression
techniques can address the computation issue of deep inference on embedded
devices. This technique is highly attractive, as it does not rely on
specialized hardware, or computation-offloading that is often infeasible due to
privacy concerns or high latency. However, it remains unclear how model
compression techniques perform across a wide range of DNNs. To design efficient
embedded deep learning solutions, we need to understand their behaviors. This
work develops a quantitative approach to characterize model compression
techniques on a representative embedded deep learning architecture, the NVIDIA
Jetson Tx2. We perform extensive experiments by considering 11 influential
neural network architectures from the image classification and the natural
language processing domains. We experimentally show that how two mainstream
compression techniques, data quantization and pruning, perform on these network
architectures and the implications of compression techniques to the model
storage size, inference time, energy consumption and performance metrics. We
demonstrate that there are opportunities to achieve fast deep inference on
embedded systems, but one must carefully choose the compression settings. Our
results provide insights on when and how to apply model compression techniques
and guidelines for designing efficient embedded deep learning systems.
",2018-10-21T05:09:45Z,http://arxiv.org/abs/1810.08899v1,"Qing Qin, Jie Ren, Jialong Yu, Ling Gao, Hai Wang, Jie Zheng, Yansong Feng, Jianbin Fang, Zheng Wang"
A Survey on Silicon Photonics for Deep Learning,"  Deep learning has led to unprecedented successes in solving some very
difficult problems in domains such as computer vision, natural language
processing, and general pattern recognition. These achievements are the
culmination of decades-long research into better training techniques and deeper
neural network models, as well as improvements in hardware platforms that are
used to train and execute the deep neural network models. Many
application-specific integrated circuit (ASIC) hardware accelerators for deep
learning have garnered interest in recent years due to their improved
performance and energy-efficiency over conventional CPU and GPU architectures.
However, these accelerators are constrained by fundamental bottlenecks due to
1) the slowdown in CMOS scaling, which has limited computational and
performance-per-watt capabilities of emerging electronic processors, and 2) the
use of metallic interconnects for data movement, which do not scale well and
are a major cause of bandwidth, latency, and energy inefficiencies in almost
every contemporary processor. Silicon photonics has emerged as a promising
CMOS-compatible alternative to realize a new generation of deep learning
accelerators that can use light for both communication and computation. This
article surveys the landscape of silicon photonics to accelerate deep learning,
with a coverage of developments across design abstractions in a bottom-up
manner, to convey both the capabilities and limitations of the silicon
photonics paradigm in the context of deep learning acceleration.
",2021-01-05T19:35:29Z,http://arxiv.org/abs/2101.01751v2,"Febin P Sunny, Ebadollah Taheri, Mahdi Nikdast, Sudeep Pasricha"
"Semi-automatic Generation of Multilingual Datasets for Stance Detection
  in Twitter","  Popular social media networks provide the perfect environment to study the
opinions and attitudes expressed by users. While interactions in social media
such as Twitter occur in many natural languages, research on stance detection
(the position or attitude expressed with respect to a specific topic) within
the Natural Language Processing field has largely been done for English.
Although some efforts have recently been made to develop annotated data in
other languages, there is a telling lack of resources to facilitate
multilingual and crosslingual research on stance detection. This is partially
due to the fact that manually annotating a corpus of social media texts is a
difficult, slow and costly process. Furthermore, as stance is a highly domain-
and topic-specific phenomenon, the need for annotated data is specially
demanding. As a result, most of the manually labeled resources are hindered by
their relatively small size and skewed class distribution. This paper presents
a method to obtain multilingual datasets for stance detection in Twitter.
Instead of manually annotating on a per tweet basis, we leverage user-based
information to semi-automatically label large amounts of tweets. Empirical
monolingual and cross-lingual experimentation and qualitative analysis show
that our method helps to overcome the aforementioned difficulties to build
large, balanced and multilingual labeled corpora. We believe that our method
can be easily adapted to easily generate labeled social media data for other
Natural Language Processing tasks and domains.
",2021-01-28T13:05:09Z,http://arxiv.org/abs/2101.11978v1,"Elena Zotova, Rodrigo Agerri, German Rigau"
"NeCo@ALQAC 2023: Legal Domain Knowledge Acquisition for Low-Resource
  Languages through Data Enrichment","  In recent years, natural language processing has gained significant
popularity in various sectors, including the legal domain. This paper presents
NeCo Team's solutions to the Vietnamese text processing tasks provided in the
Automated Legal Question Answering Competition 2023 (ALQAC 2023), focusing on
legal domain knowledge acquisition for low-resource languages through data
enrichment. Our methods for the legal document retrieval task employ a
combination of similarity ranking and deep learning models, while for the
second task, which requires extracting an answer from a relevant legal article
in response to a question, we propose a range of adaptive techniques to handle
different question types. Our approaches achieve outstanding results on both
tasks of the competition, demonstrating the potential benefits and
effectiveness of question answering systems in the legal field, particularly
for low-resource languages.
",2023-09-11T14:43:45Z,http://arxiv.org/abs/2309.05500v1,"Hai-Long Nguyen, Dieu-Quynh Nguyen, Hoang-Trung Nguyen, Thu-Trang Pham, Huu-Dong Nguyen, Thach-Anh Nguyen, Thi-Hai-Yen Vuong, Ha-Thanh Nguyen"
"From Black Boxes to Conversations: Incorporating XAI in a Conversational
  Agent","  The goal of Explainable AI (XAI) is to design methods to provide insights
into the reasoning process of black-box models, such as deep neural networks,
in order to explain them to humans. Social science research states that such
explanations should be conversational, similar to human-to-human explanations.
In this work, we show how to incorporate XAI in a conversational agent, using a
standard design for the agent comprising natural language understanding and
generation components. We build upon an XAI question bank, which we extend by
quality-controlled paraphrases, to understand the user's information needs. We
further systematically survey the literature for suitable explanation methods
that provide the information to answer those questions, and present a
comprehensive list of suggestions. Our work is the first step towards truly
natural conversations about machine learning models with an explanation agent.
The comprehensive list of XAI questions and the corresponding explanation
methods may support other researchers in providing the necessary information to
address users' demands. To facilitate future work, we release our source code
and data.
",2022-09-06T15:01:06Z,http://arxiv.org/abs/2209.02552v3,"Van Bach Nguyen, J√∂rg Schl√∂tterer, Christin Seifert"
"Visual Question Answering using Deep Learning: A Survey and Performance
  Analysis","  The Visual Question Answering (VQA) task combines challenges for processing
data with both Visual and Linguistic processing, to answer basic `common sense'
questions about given images. Given an image and a question in natural
language, the VQA system tries to find the correct answer to it using visual
elements of the image and inference gathered from textual questions. In this
survey, we cover and discuss the recent datasets released in the VQA domain
dealing with various types of question-formats and robustness of the
machine-learning models. Next, we discuss about new deep learning models that
have shown promising results over the VQA datasets. At the end, we present and
discuss some of the results computed by us over the vanilla VQA model, Stacked
Attention Network and the VQA Challenge 2017 winner model. We also provide the
detailed analysis along with the challenges and future research directions.
",2019-08-27T07:03:03Z,http://arxiv.org/abs/1909.01860v2,"Yash Srivastava, Vaishnav Murali, Shiv Ram Dubey, Snehasis Mukherjee"
"Text Mining for Processing Interview Data in Computational Social
  Science","  We use commercially available text analysis technology to process interview
text data from a computational social science study. We find that topical
clustering and terminological enrichment provide for convenient exploration and
quantification of the responses. This makes it possible to generate and test
hypotheses and to compare textual and non-textual variables, and saves analyst
effort. We encourage studies in social science to use text analysis, especially
for exploratory open-ended studies. We discuss how replicability requirements
are met by text analysis technology. We note that the most recent learning
models are not designed with transparency in mind, and that research requires a
model to be editable and its decisions to be explainable. The tools available
today, such as the one used in the present study, are not built for processing
interview texts. While many of the variables under consideration are
quantifiable using lexical statistics, we find that some interesting and
potentially valuable features are difficult or impossible to automatise
reliably at present. We note that there are some potentially interesting
applications for traditional natural language processing mechanisms such as
named entity recognition and anaphora resolution in this application area. We
conclude with a suggestion for language technologists to investigate the
challenge of processing interview data comprehensively, especially the
interplay between question and response, and we encourage social science
researchers not to hesitate to use text analysis tools, especially for the
exploratory phase of processing interview data.?
",2020-11-28T00:44:35Z,http://arxiv.org/abs/2011.14037v1,"Jussi Karlgren, Renee Li, Eva M Meyersson Milgrom"
File mapping Rule-based DBMS and Natural Language Processing,"  This paper describes the system of storage, extract and processing of
information structured similarly to the natural language. For recursive
inference the system uses the rules having the same representation, as the
data. The environment of storage of information is provided with the File
Mapping (SHM) mechanism of operating system. In the paper the main principles
of construction of dynamic data structure and language for record of the
inference rules are stated; the features of available implementation are
considered and the description of the application realizing semantic
information retrieval on the natural language is given.
",2001-06-10T14:56:51Z,http://arxiv.org/abs/cs/0106016v1,Vjacheslav M. Novikov
"Semantic maps and metrics for science Semantic maps and metrics for
  science using deep transformer encoders","  The growing deluge of scientific publications demands text analysis tools
that can help scientists and policy-makers navigate, forecast and beneficially
guide scientific research. Recent advances in natural language understanding
driven by deep transformer networks offer new possibilities for mapping
science. Because the same surface text can take on multiple and sometimes
contradictory specialized senses across distinct research communities,
sensitivity to context is critical for infometric applications. Transformer
embedding models such as BERT capture shades of association and connotation
that vary across the different linguistic contexts of any particular word or
span of text. Here we report a procedure for encoding scientific documents with
these tools, measuring their improvement over static word embeddings in a
nearest-neighbor retrieval task. We find discriminability of contextual
representations is strongly influenced by choice of pooling strategy for
summarizing the high-dimensional network activations. Importantly, we note that
fundamentals such as domain-matched training data are more important than
state-of-the-art NLP tools. Yet state-of-the-art models did offer significant
gains. The best approach we investigated combined domain-matched pretraining,
sound pooling, and state-of-the-art deep transformer network encoders. Finally,
with the goal of leveraging contextual representations from deep encoders, we
present a range of measurements for understanding and forecasting research
communities in science.
",2021-04-13T04:12:20Z,http://arxiv.org/abs/2104.05928v1,"Brendan Chambers, James Evans"
"Listen, Interact and Talk: Learning to Speak via Interaction","  One of the long-term goals of artificial intelligence is to build an agent
that can communicate intelligently with human in natural language. Most
existing work on natural language learning relies heavily on training over a
pre-collected dataset with annotated labels, leading to an agent that
essentially captures the statistics of the fixed external training data. As the
training data is essentially a static snapshot representation of the knowledge
from the annotator, the agent trained this way is limited in adaptiveness and
generalization of its behavior. Moreover, this is very different from the
language learning process of humans, where language is acquired during
communication by taking speaking action and learning from the consequences of
speaking action in an interactive manner. This paper presents an interactive
setting for grounded natural language learning, where an agent learns natural
language by interacting with a teacher and learning from feedback, thus
learning and improving language skills while taking part in the conversation.
To achieve this goal, we propose a model which incorporates both imitation and
reinforcement by leveraging jointly sentence and reward feedbacks from the
teacher. Experiments are conducted to validate the effectiveness of the
proposed approach.
",2017-05-28T07:48:14Z,http://arxiv.org/abs/1705.09906v1,"Haichao Zhang, Haonan Yu, Wei Xu"
"On the Linguistic Representational Power of Neural Machine Translation
  Models","  Despite the recent success of deep neural networks in natural language
processing (NLP), their interpretability remains a challenge. We analyze the
representations learned by neural machine translation models at various levels
of granularity and evaluate their quality through relevant extrinsic
properties. In particular, we seek answers to the following questions: (i) How
accurately is word-structure captured within the learned representations, an
important aspect in translating morphologically-rich languages? (ii) Do the
representations capture long-range dependencies, and effectively handle
syntactically divergent languages? (iii) Do the representations capture lexical
semantics? We conduct a thorough investigation along several parameters: (i)
Which layers in the architecture capture each of these linguistic phenomena;
(ii) How does the choice of translation unit (word, character, or subword unit)
impact the linguistic properties captured by the underlying representations?
(iii) Do the encoder and decoder learn differently and independently? (iv) Do
the representations learned by multilingual NMT models capture the same amount
of linguistic information as their bilingual counterparts? Our data-driven,
quantitative evaluation illuminates important aspects in NMT models and their
ability to capture various linguistic phenomena. We show that deep NMT models
learn a non-trivial amount of linguistic information. Notable findings include:
i) Word morphology and part-of-speech information are captured at the lower
layers of the model; (ii) In contrast, lexical semantics or non-local syntactic
and semantic dependencies are better represented at the higher layers; (iii)
Representations learned using characters are more informed about wordmorphology
compared to those learned using subword units; and (iv) Representations learned
by multilingual models are richer compared to bilingual models.
",2019-11-01T12:13:45Z,http://arxiv.org/abs/1911.00317v1,"Yonatan Belinkov, Nadir Durrani, Fahim Dalvi, Hassan Sajjad, James Glass"
"Towards Enhancing Database Education: Natural Language Generation Meets
  Query Execution Plans","  The database systems course is offered as part of an undergraduate computer
science degree program in many major universities. A key learning goal of
learners taking such a course is to understand how SQL queries are processed in
a RDBMS in practice. Since a query execution plan (QEP) describes the execution
steps of a query, learners can acquire the understanding by perusing the QEPs
generated by a RDBMS. Unfortunately, in practice, it is often daunting for a
learner to comprehend these QEPs containing vendor-specific implementation
details, hindering her learning process. In this paper, we present a novel,
end-to-end, generic system called lantern that generates a natural language
description of a qep to facilitate understanding of the query execution steps.
It takes as input an SQL query and its QEP, and generates a natural language
description of the execution strategy deployed by the underlying RDBMS.
Specifically, it deploys a declarative framework called pool that enables
subject matter experts to efficiently create and maintain natural language
descriptions of physical operators used in QEPs. A rule-based framework called
RULE-LANTERN is proposed that exploits pool to generate natural language
descriptions of QEPs. Despite the high accuracy of RULE-LANTERN, our engagement
with learners reveal that, consistent with existing psychology theories,
perusing such rule-based descriptions lead to boredom due to repetitive
statements across different QEPs. To address this issue, we present a novel
deep learning-based language generation framework called NEURAL-LANTERN that
infuses language variability in the generated description by exploiting a set
of paraphrasing tools and word embedding. Our experimental study with real
learners shows the effectiveness of lantern in facilitating comprehension of
QEPs.
",2021-03-01T04:13:21Z,http://arxiv.org/abs/2103.00740v3,"Weiguo Wang, Sourav S Bhowmick, Hui Li, Shafiq R Joty, Siyuan Liu, Peng Chen"
Deep Anomaly Detection in Text,"  Deep anomaly detection methods have become increasingly popular in recent
years, with methods like Stacked Autoencoders, Variational Autoencoders, and
Generative Adversarial Networks greatly improving the state-of-the-art. Other
methods rely on augmenting classical models (such as the One-Class Support
Vector Machine), by learning an appropriate kernel function using Neural
Networks. Recent developments in representation learning by self-supervision
are proving to be very beneficial in the context of anomaly detection. Inspired
by the advancements in anomaly detection using self-supervised learning in the
field of computer vision, this thesis aims to develop a method for detecting
anomalies by exploiting pretext tasks tailored for text corpora. This approach
greatly improves the state-of-the-art on two datasets, 20Newsgroups, and AG
News, for both semi-supervised and unsupervised anomaly detection, thus proving
the potential for self-supervised anomaly detectors in the field of natural
language processing.
",2023-12-14T22:04:43Z,http://arxiv.org/abs/2401.02971v1,Andrei Manolache
"Recent advances in deep learning and language models for studying the
  microbiome","  Recent advancements in deep learning, particularly large language models
(LLMs), made a significant impact on how researchers study microbiome and
metagenomics data. Microbial protein and genomic sequences, like natural
languages, form a language of life, enabling the adoption of LLMs to extract
useful insights from complex microbial ecologies. In this paper, we review
applications of deep learning and language models in analyzing microbiome and
metagenomics data. We focus on problem formulations, necessary datasets, and
the integration of language modeling techniques. We provide an extensive
overview of protein/genomic language modeling and their contributions to
microbiome studies. We also discuss applications such as novel viromics
language modeling, biosynthetic gene cluster prediction, and knowledge
integration for metagenomics studies.
",2024-09-15T18:32:31Z,http://arxiv.org/abs/2409.10579v1,"Binghao Yan, Yunbi Nam, Lingyao Li, Rebecca A. Deek, Hongzhe Li, Siyuan Ma"
"A Survey in Automatic Irony Processing: Linguistic, Cognitive, and
  Multi-X Perspectives","  Irony is a ubiquitous figurative language in daily communication. Previously,
many researchers have approached irony from linguistic, cognitive science, and
computational aspects. Recently, some progress have been witnessed in automatic
irony processing due to the rapid development in deep neural models in natural
language processing (NLP). In this paper, we will provide a comprehensive
overview of computational irony, insights from linguistic theory and cognitive
science, as well as its interactions with downstream NLP tasks and newly
proposed multi-X irony processing perspectives.
",2022-09-10T17:03:34Z,http://arxiv.org/abs/2209.04712v1,"Qingcheng Zeng, An-Ran Li"
Transfer Learning for Speech and Language Processing,"  Transfer learning is a vital technique that generalizes models trained for
one setting or task to other settings or tasks. For example in speech
recognition, an acoustic model trained for one language can be used to
recognize speech in another language, with little or no re-training data.
Transfer learning is closely related to multi-task learning (cross-lingual vs.
multilingual), and is traditionally studied in the name of `model adaptation'.
Recent advance in deep learning shows that transfer learning becomes much
easier and more effective with high-level abstract features learned by deep
models, and the `transfer' can be conducted not only between data distributions
and data types, but also between model structures (e.g., shallow nets and deep
nets) or even model types (e.g., Bayesian models and neural models). This
review paper summarizes some recent prominent research towards this direction,
particularly for speech and language processing. We also report some results
from our group and highlight the potential of this very interesting research
field.
",2015-11-19T05:54:45Z,http://arxiv.org/abs/1511.06066v1,"Dong Wang, Thomas Fang Zheng"
"The RFML Ecosystem: A Look at the Unique Challenges of Applying Deep
  Learning to Radio Frequency Applications","  While deep machine learning technologies are now pervasive in
state-of-the-art image recognition and natural language processing
applications, only in recent years have these technologies started to
sufficiently mature in applications related to wireless communications. In
particular, recent research has shown deep machine learning to be an enabling
technology for cognitive radio applications as well as a useful tool for
supplementing expertly defined algorithms for spectrum sensing applications
such as signal detection, estimation, and classification (termed here as Radio
Frequency Machine Learning, or RFML). A major driver for the usage of deep
machine learning in the context of wireless communications is that little, to
no, a priori knowledge of the intended spectral environment is required, given
that there is an abundance of representative data to facilitate training and
evaluation. However, in addition to this fundamental need for sufficient data,
there are other key considerations, such as trust, security, and
hardware/software issues, that must be taken into account before deploying deep
machine learning systems in real-world wireless communication applications.
This paper provides an overview and survey of prior work related to these major
research considerations. In particular, we present their unique considerations
in the RFML application space, which are not generally present in the image,
audio, and/or text application spaces.
",2020-10-01T14:27:28Z,http://arxiv.org/abs/2010.00432v1,"Lauren J. Wong, William H. Clark IV, Bryse Flowers, R. Michael Buehrer, Alan J. Michaels, William C. Headley"
Evolution of transfer learning in natural language processing,"  In this paper, we present a study of the recent advancements which have
helped bring Transfer Learning to NLP through the use of semi-supervised
training. We discuss cutting-edge methods and architectures such as BERT, GPT,
ELMo, ULMFit among others. Classically, tasks in natural language processing
have been performed through rule-based and statistical methodologies. However,
owing to the vast nature of natural languages these methods do not generalise
well and failed to learn the nuances of language. Thus machine learning
algorithms such as Naive Bayes and decision trees coupled with traditional
models such as Bag-of-Words and N-grams were used to usurp this problem.
Eventually, with the advent of advanced recurrent neural network architectures
such as the LSTM, we were able to achieve state-of-the-art performance in
several natural language processing tasks such as text classification and
machine translation. We talk about how Transfer Learning has brought about the
well-known ImageNet moment for NLP. Several advanced architectures such as the
Transformer and its variants have allowed practitioners to leverage knowledge
gained from unrelated task to drastically fasten convergence and provide better
performance on the target task. This survey represents an effort at providing a
succinct yet complete understanding of the recent advances in natural language
processing using deep learning in with a special focus on detailing transfer
learning and its potential advantages.
",2019-10-16T14:24:37Z,http://arxiv.org/abs/1910.07370v1,"Aditya Malte, Pratik Ratadiya"
"EEGDiR: Electroencephalogram denoising network for temporal information
  storage and global modeling through Retentive Network","  Electroencephalogram (EEG) signals play a pivotal role in clinical medicine,
brain research, and neurological disease studies. However, susceptibility to
various physiological and environmental artifacts introduces noise in recorded
EEG data, impeding accurate analysis of underlying brain activity. Denoising
techniques are crucial to mitigate this challenge. Recent advancements in deep
learningbased approaches exhibit substantial potential for enhancing the
signal-to-noise ratio of EEG data compared to traditional methods. In the realm
of large-scale language models (LLMs), the Retentive Network (Retnet)
infrastructure, prevalent for some models, demonstrates robust feature
extraction and global modeling capabilities. Recognizing the temporal
similarities between EEG signals and natural language, we introduce the Retnet
from natural language processing to EEG denoising. This integration presents a
novel approach to EEG denoising, opening avenues for a profound understanding
of brain activities and accurate diagnosis of neurological diseases.
Nonetheless, direct application of Retnet to EEG denoising is unfeasible due to
the one-dimensional nature of EEG signals, while natural language processing
deals with two-dimensional data. To facilitate Retnet application to EEG
denoising, we propose the signal embedding method, transforming one-dimensional
EEG signals into two dimensions for use as network inputs. Experimental results
validate the substantial improvement in denoising effectiveness achieved by the
proposed method.
",2024-03-20T15:04:21Z,http://arxiv.org/abs/2404.15289v2,"Bin Wang, Fei Deng, Peifan Jiang"
"Rethinking Tokenization: Crafting Better Tokenizers for Large Language
  Models","  Tokenization significantly influences language models(LMs)' performance. This
paper traces the evolution of tokenizers from word-level to subword-level,
analyzing how they balance tokens and types to enhance model adaptability while
controlling complexity. Despite subword tokenizers like Byte Pair Encoding
(BPE) overcoming many word tokenizer limitations, they encounter difficulties
in handling non-Latin languages and depend heavily on extensive training data
and computational resources to grasp the nuances of multiword expressions
(MWEs). This article argues that tokenizers, more than mere technical tools,
should drawing inspiration from the cognitive science about human language
processing. This study then introduces the ""Principle of Least Effort"" from
cognitive science, that humans naturally seek to reduce cognitive effort, and
discusses the benefits of this principle for tokenizer development. Based on
this principle, the paper proposes that the Less-is-Better (LiB) model could be
a new approach for LLM tokenizer. The LiB model can autonomously learn an
integrated vocabulary consisting of subwords, words, and MWEs, which
effectively reduces both the numbers of tokens and types. Comparative
evaluations show that the LiB tokenizer outperforms existing word and BPE
tokenizers, presenting an innovative method for tokenizer development, and
hinting at the possibility of future cognitive science-based tokenizers being
more efficient.
",2024-03-01T10:03:07Z,http://arxiv.org/abs/2403.00417v1,Jinbiao Yang
"MetaPred: Meta-Learning for Clinical Risk Prediction with Limited
  Patient Electronic Health Records","  In recent years, increasingly augmentation of health data, such as patient
Electronic Health Records (EHR), are becoming readily available. This provides
an unprecedented opportunity for knowledge discovery and data mining algorithms
to dig insights from them, which can, later on, be helpful to the improvement
of the quality of care delivery. Predictive modeling of clinical risk,
including in-hospital mortality, hospital readmission, chronic disease onset,
condition exacerbation, etc., from patient EHR, is one of the health data
analytic problems that attract most of the interests. The reason is not only
because the problem is important in clinical settings, but also there are
challenges working with EHR such as sparsity, irregularity, temporality, etc.
Different from applications in other domains such as computer vision and
natural language processing, the labeled data samples in medicine (patients)
are relatively limited, which creates lots of troubles for effective predictive
model learning, especially for complicated models such as deep learning. In
this paper, we propose MetaPred, a meta-learning for clinical risk prediction
from longitudinal patient EHRs. In particular, in order to predict the target
risk where there are limited data samples, we train a meta-learner from a set
of related risk prediction tasks which learns how a good predictor is learned.
The meta-learned can then be directly used in target risk prediction, and the
limited available samples can be used for further fine-tuning the model
performance. The effectiveness of MetaPred is tested on a real patient EHR
repository from Oregon Health & Science University. We are able to demonstrate
that with CNN and RNN as base predictors, MetaPred can achieve much better
performance for predicting target risk with low resources comparing with the
predictor trained on the limited samples available for this risk.
",2019-05-08T17:07:51Z,http://arxiv.org/abs/1905.03218v1,"Xi Sheryl Zhang, Fengyi Tang, Hiroko Dodge, Jiayu Zhou, Fei Wang"
"On Sensitivity of Deep Learning Based Text Classification Algorithms to
  Practical Input Perturbations","  Text classification is a fundamental Natural Language Processing task that
has a wide variety of applications, where deep learning approaches have
produced state-of-the-art results. While these models have been heavily
criticized for their black-box nature, their robustness to slight perturbations
in input text has been a matter of concern. In this work, we carry out a
data-focused study evaluating the impact of systematic practical perturbations
on the performance of the deep learning based text classification models like
CNN, LSTM, and BERT-based algorithms. The perturbations are induced by the
addition and removal of unwanted tokens like punctuation and stop-words that
are minimally associated with the final performance of the model. We show that
these deep learning approaches including BERT are sensitive to such legitimate
input perturbations on four standard benchmark datasets SST2, TREC-6, BBC News,
and tweet_eval. We observe that BERT is more susceptible to the removal of
tokens as compared to the addition of tokens. Moreover, LSTM is slightly more
sensitive to input perturbations as compared to CNN based model. The work also
serves as a practical guide to assessing the impact of discrepancies in
train-test conditions on the final performance of models.
",2022-01-02T08:33:49Z,http://arxiv.org/abs/2201.00318v2,"Aamir Miyajiwala, Arnav Ladkat, Samiksha Jagadale, Raviraj Joshi"
"LINDA: Unsupervised Learning to Interpolate in Natural Language
  Processing","  Despite the success of mixup in data augmentation, its applicability to
natural language processing (NLP) tasks has been limited due to the discrete
and variable-length nature of natural languages. Recent studies have thus
relied on domain-specific heuristics and manually crafted resources, such as
dictionaries, in order to apply mixup in NLP. In this paper, we instead propose
an unsupervised learning approach to text interpolation for the purpose of data
augmentation, to which we refer as ""Learning to INterpolate for Data
Augmentation"" (LINDA), that does not require any heuristics nor manually
crafted resources but learns to interpolate between any pair of natural
language sentences over a natural language manifold. After empirically
demonstrating the LINDA's interpolation capability, we show that LINDA indeed
allows us to seamlessly apply mixup in NLP and leads to better generalization
in text classification both in-domain and out-of-domain.
",2021-12-28T02:56:41Z,http://arxiv.org/abs/2112.13969v1,"Yekyung Kim, Seohyeong Jeong, Kyunghyun Cho"
"Cross-lingual Transfer of Abstractive Summarizer to Less-resource
  Language","  Automatic text summarization extracts important information from texts and
presents the information in the form of a summary. Abstractive summarization
approaches progressed significantly by switching to deep neural networks, but
results are not yet satisfactory, especially for languages where large training
sets do not exist. In several natural language processing tasks, a
cross-lingual model transfer is successfully applied in less-resource
languages. For summarization, the cross-lingual model transfer was not
attempted due to a non-reusable decoder side of neural models that cannot
correct target language generation. In our work, we use a pre-trained English
summarization model based on deep neural networks and sequence-to-sequence
architecture to summarize Slovene news articles. We address the problem of
inadequate decoder by using an additional language model for the evaluation of
the generated text in target language. We test several cross-lingual
summarization models with different amounts of target data for fine-tuning. We
assess the models with automatic evaluation measures and conduct a small-scale
human evaluation. Automatic evaluation shows that the summaries of our best
cross-lingual model are useful and of quality similar to the model trained only
in the target language. Human evaluation shows that our best model generates
summaries with high accuracy and acceptable readability. However, similar to
other abstractive models, our models are not perfect and may occasionally
produce misleading or absurd content.
",2020-12-08T09:30:38Z,http://arxiv.org/abs/2012.04307v2,"Ale≈° ≈Ωagar, Marko Robnik-≈†ikonja"
Using NLP on news headlines to predict index trends,"  This paper attempts to provide a state of the art in trend prediction using
news headlines. We present the research done on predicting DJIA trends using
Natural Language Processing. We will explain the different algorithms we have
used as well as the various embedding techniques attempted. We rely on
statistical and deep learning models in order to extract information from the
corpuses.
",2018-06-22T15:37:35Z,http://arxiv.org/abs/1806.09533v1,"Marc Velay, Fabrice Daniel"
Seq2Seq AI Chatbot with Attention Mechanism,"  Intelligent Conversational Agent development using Artificial Intelligence or
Machine Learning technique is an interesting problem in the field of Natural
Language Processing. With the rise of deep learning, these models were quickly
replaced by end to end trainable neural networks.
",2020-06-04T10:54:43Z,http://arxiv.org/abs/2006.02767v1,Abonia Sojasingarayar
"Analyzing Deep Transformer Models for Time Series Forecasting via
  Manifold Learning","  Transformer models have consistently achieved remarkable results in various
domains such as natural language processing and computer vision. However,
despite ongoing research efforts to better understand these models, the field
still lacks a comprehensive understanding. This is particularly true for deep
time series forecasting methods, where analysis and understanding work is
relatively limited. Time series data, unlike image and text information, can be
more challenging to interpret and analyze. To address this, we approach the
problem from a manifold learning perspective, assuming that the latent
representations of time series forecasting models lie next to a low-dimensional
manifold. In our study, we focus on analyzing the geometric features of these
latent data manifolds, including intrinsic dimension and principal curvatures.
Our findings reveal that deep transformer models exhibit similar geometric
behavior across layers, and these geometric features are correlated with model
performance. Additionally, we observe that untrained models initially have
different structures, but they rapidly converge during training. By leveraging
our geometric analysis and differentiable tools, we can potentially design new
and improved deep forecasting neural networks. This approach complements
existing analysis studies and contributes to a better understanding of
transformer models in the context of time series forecasting. Code is released
at https://github.com/azencot-group/GATLM.
",2024-10-17T17:32:35Z,http://arxiv.org/abs/2410.13792v1,"Ilya Kaufman, Omri Azencot"
"How to keep text private? A systematic review of deep learning methods
  for privacy-preserving natural language processing","  Deep learning (DL) models for natural language processing (NLP) tasks often
handle private data, demanding protection against breaches and disclosures.
Data protection laws, such as the European Union's General Data Protection
Regulation (GDPR), thereby enforce the need for privacy. Although many
privacy-preserving NLP methods have been proposed in recent years, no
categories to organize them have been introduced yet, making it hard to follow
the progress of the literature. To close this gap, this article systematically
reviews over sixty DL methods for privacy-preserving NLP published between 2016
and 2020, covering theoretical foundations, privacy-enhancing technologies, and
analysis of their suitability for real-world scenarios. First, we introduce a
novel taxonomy for classifying the existing methods into three categories: data
safeguarding methods, trusted methods, and verification methods. Second, we
present an extensive summary of privacy threats, datasets for applications, and
metrics for privacy evaluation. Third, throughout the review, we describe
privacy issues in the NLP pipeline in a holistic view. Further, we discuss open
challenges in privacy-preserving NLP regarding data traceability, computation
overhead, dataset size, the prevalence of human biases in embeddings, and the
privacy-utility tradeoff. Finally, this review presents future research
directions to guide successive research and development of privacy-preserving
NLP models.
",2022-05-20T11:29:44Z,http://arxiv.org/abs/2205.10095v1,"Samuel Sousa, Roman Kern"
Hindi to English: Transformer-Based Neural Machine Translation,"  Machine Translation (MT) is one of the most prominent tasks in Natural
Language Processing (NLP) which involves the automatic conversion of texts from
one natural language to another while preserving its meaning and fluency.
Although the research in machine translation has been going on since multiple
decades, the newer approach of integrating deep learning techniques in natural
language processing has led to significant improvements in the translation
quality. In this paper, we have developed a Neural Machine Translation (NMT)
system by training the Transformer model to translate texts from Indian
Language Hindi to English. Hindi being a low resource language has made it
difficult for neural networks to understand the language thereby leading to a
slow growth in the development of neural machine translators. Thus, to address
this gap, we implemented back-translation to augment the training data and for
creating the vocabulary, we experimented with both word and subword level
tokenization using Byte Pair Encoding (BPE) thereby ending up training the
Transformer in 10 different configurations. This led us to achieve a
state-of-the-art BLEU score of 24.53 on the test set of IIT Bombay
English-Hindi Corpus in one of the configurations.
",2023-09-23T00:00:09Z,http://arxiv.org/abs/2309.13222v1,"Kavit Gangar, Hardik Ruparel, Shreyas Lele"
Knowledge-based Biomedical Data Science 2019,"  Knowledge-based biomedical data science (KBDS) involves the design and
implementation of computer systems that act as if they knew about biomedicine.
Such systems depend on formally represented knowledge in computer systems,
often in the form of knowledge graphs. Here we survey the progress in the last
year in systems that use formally represented knowledge to address data science
problems in both clinical and biological domains, as well as on approaches for
creating knowledge graphs. Major themes include the relationships between
knowledge graphs and machine learning, the use of natural language processing,
and the expansion of knowledge-based approaches to novel domains, such as
Chinese Traditional Medicine and biodiversity.
",2019-10-08T17:28:16Z,http://arxiv.org/abs/1910.06710v1,"Tiffany J. Callahan, Harrison Pielke-Lombardo, Ignacio J. Tripodi, Lawrence E. Hunter"
Comparative Analysis of Word Embeddings for Capturing Word Similarities,"  Distributed language representation has become the most widely used technique
for language representation in various natural language processing tasks. Most
of the natural language processing models that are based on deep learning
techniques use already pre-trained distributed word representations, commonly
called word embeddings. Determining the most qualitative word embeddings is of
crucial importance for such models. However, selecting the appropriate word
embeddings is a perplexing task since the projected embedding space is not
intuitive to humans. In this paper, we explore different approaches for
creating distributed word representations. We perform an intrinsic evaluation
of several state-of-the-art word embedding methods. Their performance on
capturing word similarities is analysed with existing benchmark datasets for
word pairs similarities. The research in this paper conducts a correlation
analysis between ground truth word similarities and similarities obtained by
different word embedding methods.
",2020-05-08T01:16:03Z,http://arxiv.org/abs/2005.03812v1,"Martina Toshevska, Frosina Stojanovska, Jovan Kalajdjieski"
"Incorporating Voice Instructions in Model-Based Reinforcement Learning
  for Self-Driving Cars","  This paper presents a novel approach that supports natural language voice
instructions to guide deep reinforcement learning (DRL) algorithms when
training self-driving cars. DRL methods are popular approaches for autonomous
vehicle (AV) agents. However, most existing methods are sample- and
time-inefficient and lack a natural communication channel with the human
expert. In this paper, how new human drivers learn from human coaches motivates
us to study new ways of human-in-the-loop learning and a more natural and
approachable training interface for the agents. We propose incorporating
natural language voice instructions (NLI) in model-based deep reinforcement
learning to train self-driving cars. We evaluate the proposed method together
with a few state-of-the-art DRL methods in the CARLA simulator. The results
show that NLI can help ease the training process and significantly boost the
agents' learning speed.
",2022-06-21T10:55:39Z,http://arxiv.org/abs/2206.10249v1,"Mingze Wang, Ziyang Zhang, Grace Hui Yang"
Semi-supervised Classification for Natural Language Processing,"  Semi-supervised classification is an interesting idea where classification
models are learned from both labeled and unlabeled data. It has several
advantages over supervised classification in natural language processing
domain. For instance, supervised classification exploits only labeled data that
are expensive, often difficult to get, inadequate in quantity, and require
human experts for annotation. On the other hand, unlabeled data are inexpensive
and abundant. Despite the fact that many factors limit the wide-spread use of
semi-supervised classification, it has become popular since its level of
performance is empirically as good as supervised classification. This study
explores the possibilities and achievements as well as complexity and
limitations of semi-supervised classification for several natural langue
processing tasks like parsing, biomedical information processing, text
classification, and summarization.
",2014-09-25T15:18:44Z,http://arxiv.org/abs/1409.7612v1,Rushdi Shams
"Deep Learning the EEG Manifold for Phonological Categorization from
  Active Thoughts","  Speech-related Brain Computer Interfaces (BCI) aim primarily at finding an
alternative vocal communication pathway for people with speaking disabilities.
As a step towards full decoding of imagined speech from active thoughts, we
present a BCI system for subject-independent classification of phonological
categories exploiting a novel deep learning based hierarchical feature
extraction scheme. To better capture the complex representation of
high-dimensional electroencephalography (EEG) data, we compute the joint
variability of EEG electrodes into a channel cross-covariance matrix. We then
extract the spatio-temporal information encoded within the matrix using a mixed
deep neural network strategy. Our model framework is composed of a
convolutional neural network (CNN), a long-short term network (LSTM), and a
deep autoencoder. We train the individual networks hierarchically, feeding
their combined outputs in a final gradient boosting classification step. Our
best models achieve an average accuracy of 77.9% across five different binary
classification tasks, providing a significant 22.5% improvement over previous
methods. As we also show visually, our work demonstrates that the speech
imagery EEG possesses significant discriminative information about the intended
articulatory movements responsible for natural speech synthesis.
",2019-04-08T21:11:40Z,http://arxiv.org/abs/1904.04358v1,"Pramit Saha, Muhammad Abdul-Mageed, Sidney Fels"
"Deep Learning Acceleration Techniques for Real Time Mobile Vision
  Applications","  Deep Learning (DL) has become a crucial technology for Artificial
Intelligence (AI). It is a powerful technique to automatically extract
high-level features from complex data which can be exploited for applications
such as computer vision, natural language processing, cybersecurity,
communications, and so on. For the particular case of computer vision, several
algorithms like object detection in real time videos have been proposed and
they work well on Desktop GPUs and distributed computing platforms. However
these algorithms are still heavy for mobile and embedded visual applications.
The rapid spreading of smart portable devices and the emerging 5G network are
introducing new smart multimedia applications in mobile environments. As a
consequence, the possibility of implementing deep neural networks to mobile
environments has attracted a lot of researchers. This paper presents emerging
deep learning acceleration techniques that can enable the delivery of real time
visual recognition into the hands of end users, anytime and anywhere.
",2019-05-09T02:39:37Z,http://arxiv.org/abs/1905.03418v2,Gael Kamdem De Teyou
"Long-range and hierarchical language predictions in brains and
  algorithms","  Deep learning has recently made remarkable progress in natural language
processing. Yet, the resulting algorithms remain far from competing with the
language abilities of the human brain. Predictive coding theory offers a
potential explanation to this discrepancy: while deep language algorithms are
optimized to predict adjacent words, the human brain would be tuned to make
long-range and hierarchical predictions. To test this hypothesis, we analyze
the fMRI brain signals of 304 subjects each listening to 70min of short
stories. After confirming that the activations of deep language algorithms
linearly map onto those of the brain, we show that enhancing these models with
long-range forecast representations improves their brain-mapping. The results
further reveal a hierarchy of predictions in the brain, whereby the
fronto-parietal cortices forecast more abstract and more distant
representations than the temporal cortices. Overall, this study strengthens
predictive coding theory and suggests a critical role of long-range and
hierarchical predictions in natural language processing.
",2021-11-28T20:26:07Z,http://arxiv.org/abs/2111.14232v1,"Charlotte Caucheteux, Alexandre Gramfort, Jean-Remi King"
Learning Latent Representations for Speech Generation and Transformation,"  An ability to model a generative process and learn a latent representation
for speech in an unsupervised fashion will be crucial to process vast
quantities of unlabelled speech data. Recently, deep probabilistic generative
models such as Variational Autoencoders (VAEs) have achieved tremendous success
in modeling natural images. In this paper, we apply a convolutional VAE to
model the generative process of natural speech. We derive latent space
arithmetic operations to disentangle learned latent representations. We
demonstrate the capability of our model to modify the phonetic content or the
speaker identity for speech segments using the derived operations, without the
need for parallel supervisory data.
",2017-04-13T17:41:11Z,http://arxiv.org/abs/1704.04222v2,"Wei-Ning Hsu, Yu Zhang, James Glass"
"Continuous Sign Language Recognition with Adapted Conformer via
  Unsupervised Pretraining","  Conventional Deep Learning frameworks for continuous sign language
recognition (CSLR) are comprised of a single or multi-modal feature extractor,
a sequence-learning module, and a decoder for outputting the glosses. The
sequence learning module is a crucial part wherein transformers have
demonstrated their efficacy in the sequence-to-sequence tasks. Analyzing the
research progress in the field of Natural Language Processing and Speech
Recognition, a rapid introduction of various transformer variants is observed.
However, in the realm of sign language, experimentation in the sequence
learning component is limited. In this work, the state-of-the-art Conformer
model for Speech Recognition is adapted for CSLR and the proposed model is
termed ConSignformer. This marks the first instance of employing Conformer for
a vision-based task. ConSignformer has bimodal pipeline of CNN as feature
extractor and Conformer for sequence learning. For improved context learning we
also introduce Cross-Modal Relative Attention (CMRA). By incorporating CMRA
into the model, it becomes more adept at learning and utilizing complex
relationships within the data. To further enhance the Conformer model,
unsupervised pretraining called Regressional Feature Extraction is conducted on
a curated sign language dataset. The pretrained Conformer is then fine-tuned
for the downstream recognition task. The experimental results confirm the
effectiveness of the adopted pretraining strategy and demonstrate how CMRA
contributes to the recognition process. Remarkably, leveraging a
Conformer-based backbone, our model achieves state-of-the-art performance on
the benchmark datasets: PHOENIX-2014 and PHOENIX-2014T.
",2024-05-20T13:40:52Z,http://arxiv.org/abs/2405.12018v1,"Neena Aloysius, Geetha M, Prema Nedungadi"
"Transgender Community Sentiment Analysis from Social Media Data: A
  Natural Language Processing Approach","  Transgender community is experiencing a huge disparity in mental health
conditions compared with the general population. Interpreting the social medial
data posted by transgender people may help us understand the sentiments of
these sexual minority groups better and apply early interventions. In this
study, we manually categorize 300 social media comments posted by transgender
people to the sentiment of negative, positive, and neutral. 5 machine learning
algorithms and 2 deep neural networks are adopted to build sentiment analysis
classifiers based on the annotated data. Results show that our annotations are
reliable with a high Cohen's Kappa score over 0.8 across all three classes.
LSTM model yields an optimal performance of accuracy over 0.85 and AUC of
0.876. Our next step will focus on using advanced natural language processing
algorithms on a larger annotated dataset.
",2020-10-25T08:13:34Z,http://arxiv.org/abs/2010.13062v2,"Yuqiao Liu, Yudan Wang, Ying Zhao, Zhixiang Li"
"Deep learning applied to EEG data with different montages using spatial
  attention","  The ability of Deep Learning to process and extract relevant information in
complex brain dynamics from raw EEG data has been demonstrated in various
recent works. Deep learning models, however, have also been shown to perform
best on large corpora of data. When processing EEG, a natural approach is to
combine EEG datasets from different experiments to train large deep-learning
models. However, most EEG experiments use custom channel montages, requiring
the data to be transformed into a common space. Previous methods have used the
raw EEG signal to extract features of interest and focused on using a common
feature space across EEG datasets. While this is a sensible approach, it
underexploits the potential richness of EEG raw data. Here, we explore using
spatial attention applied to EEG electrode coordinates to perform channel
harmonization of raw EEG data, allowing us to train deep learning on EEG data
using different montages. We test this model on a gender classification task.
We first show that spatial attention increases model performance. Then, we show
that a deep learning model trained on data using different channel montages
performs significantly better than deep learning models trained on fixed 23-
and 128-channel data montages.
",2023-10-16T16:17:33Z,http://arxiv.org/abs/2310.10550v1,"Dung Truong, Muhammad Abdullah Khalid, Arnaud Delorme"
"Brief Introduction to Contrastive Learning Pretext Tasks for Visual
  Representation","  To improve performance in visual feature representation from photos or videos
for practical applications, we generally require large-scale human-annotated
labeled data while training deep neural networks. However, the cost of
gathering and annotating human-annotated labeled data is expensive. Given that
there is a lot of unlabeled data in the actual world, it is possible to
introduce self-defined pseudo labels as supervisions to prevent this issue.
Self-supervised learning, specifically contrastive learning, is a subset of
unsupervised learning methods that has grown popular in computer vision,
natural language processing, and other domains. The purpose of contrastive
learning is to embed augmented samples from the same sample near to each other
while pushing away those that are not. In the following sections, we will
introduce the regular formulation among different learnings. In the next
sections, we will discuss the regular formulation of various learnings.
Furthermore, we offer some strategies from contrastive learning that have
recently been published and are focused on pretext tasks for visual
representation.
",2022-10-06T18:54:10Z,http://arxiv.org/abs/2210.03163v1,Zhenyuan Lu
"Active$^2$ Learning: Actively reducing redundancies in Active Learning
  methods for Sequence Tagging and Machine Translation","  While deep learning is a powerful tool for natural language processing (NLP)
problems, successful solutions to these problems rely heavily on large amounts
of annotated samples. However, manually annotating data is expensive and
time-consuming. Active Learning (AL) strategies reduce the need for huge
volumes of labeled data by iteratively selecting a small number of examples for
manual annotation based on their estimated utility in training the given model.
In this paper, we argue that since AL strategies choose examples independently,
they may potentially select similar examples, all of which may not contribute
significantly to the learning process. Our proposed approach,
Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L), actively adapts to the deep
learning model being trained to eliminate further such redundant examples
chosen by an AL strategy. We show that A$\mathbf{^2}$L is widely applicable by
using it in conjunction with several different AL strategies and NLP tasks. We
empirically demonstrate that the proposed approach is further able to reduce
the data requirements of state-of-the-art AL strategies by an absolute
percentage reduction of $\approx\mathbf{3-25\%}$ on multiple NLP tasks while
achieving the same performance with no additional computation overhead.
",2021-03-11T06:27:31Z,http://arxiv.org/abs/2103.06490v2,"Rishi Hazra, Parag Dutta, Shubham Gupta, Mohammed Abdul Qaathir, Ambedkar Dukkipati"
Low Resource Summarization using Pre-trained Language Models,"  With the advent of Deep Learning based Artificial Neural Networks models,
Natural Language Processing (NLP) has witnessed significant improvements in
textual data processing in terms of its efficiency and accuracy. However, the
research is mostly restricted to high-resource languages such as English and
low-resource languages still suffer from a lack of available resources in terms
of training datasets as well as models with even baseline evaluation results.
Considering the limited availability of resources for low-resource languages,
we propose a methodology for adapting self-attentive transformer-based
architecture models (mBERT, mT5) for low-resource summarization, supplemented
by the construction of a new baseline dataset (76.5k article, summary pairs) in
a low-resource language Urdu. Choosing news (a publicly available source) as
the application domain has the potential to make the proposed methodology
useful for reproducing in other languages with limited resources. Our adapted
summarization model \textit{urT5} with up to 44.78\% reduction in size as
compared to \textit{mT5} can capture contextual information of low resource
language effectively with evaluation score (up to 46.35 ROUGE-1, 77 BERTScore)
at par with state-of-the-art models in high resource language English
\textit{(PEGASUS: 47.21, BART: 45.14 on XSUM Dataset)}. The proposed method
provided a baseline approach towards extractive as well as abstractive
summarization with competitive evaluation results in a limited resource setup.
",2023-10-04T13:09:39Z,http://arxiv.org/abs/2310.02790v1,"Mubashir Munaf, Hammad Afzal, Naima Iltaf, Khawir Mahmood"
TextMage: The Automated Bangla Caption Generator Based On Deep Learning,"  Neural Networks and Deep Learning have seen an upsurge of research in the
past decade due to the improved results. Generates text from the given image is
a crucial task that requires the combination of both sectors which are computer
vision and natural language processing in order to understand an image and
represent it using a natural language. However existing works have all been
done on a particular lingual domain and on the same set of data. This leads to
the systems being developed to perform poorly on images that belong to specific
locales' geographical context. TextMage is a system that is capable of
understanding visual scenes that belong to the Bangladeshi geographical context
and use its knowledge to represent what it understands in Bengali. Hence, we
have trained a model on our previously developed and published dataset named
BanglaLekhaImageCaptions. This dataset contains 9,154 images along with two
annotations for each image. In order to access performance, the proposed model
has been implemented and evaluated.
",2020-10-15T23:24:15Z,http://arxiv.org/abs/2010.08066v1,"Abrar Hasin Kamal, Md. Asifuzzaman Jishan, Nafees Mansoor"
Packet2Vec: Utilizing Word2Vec for Feature Extraction in Packet Data,"  One of deep learning's attractive benefits is the ability to automatically
extract relevant features for a target problem from largely raw data, instead
of utilizing human engineered and error prone handcrafted features. While deep
learning has shown success in fields such as image classification and natural
language processing, its application for feature extraction on raw network
packet data for intrusion detection is largely unexplored. In this paper we
modify a Word2Vec approach, used for text processing, and apply it to packet
data for automatic feature extraction. We call this approach Packet2Vec. For
the classification task of benign versus malicious traffic on a 2009 DARPA
network data set, we obtain an area under the curve (AUC) of the receiver
operating characteristic (ROC) between 0.988-0.996 and an AUC of the
Precision/Recall curve between 0.604-0.667.
",2020-04-29T21:03:48Z,http://arxiv.org/abs/2004.14477v1,"Eric L. Goodman, Chase Zimmerman, Corey Hudson"
"Multi-Step Deductive Reasoning Over Natural Language: An Empirical Study
  on Out-of-Distribution Generalisation","  Combining deep learning with symbolic logic reasoning aims to capitalize on
the success of both fields and is drawing increasing attention. Inspired by
DeepLogic, an end-to-end model trained to perform inference on logic programs,
we introduce IMA-GloVe-GA, an iterative neural inference network for multi-step
reasoning expressed in natural language. In our model, reasoning is performed
using an iterative memory neural network based on RNN with a gated attention
mechanism. We evaluate IMA-GloVe-GA on three datasets: PARARULES, CONCEPTRULES
V1 and CONCEPTRULES V2. Experimental results show DeepLogic with gated
attention can achieve higher test accuracy than DeepLogic and other RNN
baseline models. Our model achieves better out-of-distribution generalisation
than RoBERTa-Large when the rules have been shuffled. Furthermore, to address
the issue of unbalanced distribution of reasoning depths in the current
multi-step reasoning datasets, we develop PARARULE-Plus, a large dataset with
more examples that require deeper reasoning steps. Experimental results show
that the addition of PARARULE-Plus can increase the model's performance on
examples requiring deeper reasoning depths. The source code and data are
available at
https://github.com/Strong-AI-Lab/Multi-Step-Deductive-Reasoning-Over-Natural-Language.
",2022-07-28T10:44:46Z,http://arxiv.org/abs/2207.14000v3,"Qiming Bao, Alex Yuxuan Peng, Tim Hartill, Neset Tan, Zhenyun Deng, Michael Witbrock, Jiamou Liu"
Efficacy of Transformer Networks for Classification of Raw EEG Data,"  With the unprecedented success of transformer networks in natural language
processing (NLP), recently, they have been successfully adapted to areas like
computer vision, generative adversarial networks (GAN), and reinforcement
learning. Classifying electroencephalogram (EEG) data has been challenging and
researchers have been overly dependent on pre-processing and hand-crafted
feature extraction. Despite having achieved automated feature extraction in
several other domains, deep learning has not yet been accomplished for EEG. In
this paper, the efficacy of the transformer network for the classification of
raw EEG data (cleaned and pre-processed) is explored. The performance of
transformer networks was evaluated on a local (age and gender data) and a
public dataset (STEW). First, a classifier using a transformer network is built
to classify the age and gender of a person with raw resting-state EEG data.
Second, the classifier is tuned for mental workload classification with open
access raw multi-tasking mental workload EEG data (STEW). The network achieves
an accuracy comparable to state-of-the-art accuracy on both the local (Age and
Gender dataset; 94.53% (gender) and 87.79% (age)) and the public (STEW dataset;
95.28% (two workload levels) and 88.72% (three workload levels)) dataset. The
accuracy values have been achieved using raw EEG data without feature
extraction. Results indicate that the transformer-based deep learning models
can successfully abate the need for heavy feature-extraction of EEG data for
successful classification.
",2022-02-08T17:12:27Z,http://arxiv.org/abs/2202.05170v1,"Gourav Siddhad, Anmol Gupta, Debi Prosad Dogra, Partha Pratim Roy"
"Personality Trait Detection Using Bagged SVM over BERT Word Embedding
  Ensembles","  Recently, the automatic prediction of personality traits has received
increasing attention and has emerged as a hot topic within the field of
affective computing. In this work, we present a novel deep learning-based
approach for automated personality detection from text. We leverage state of
the art advances in natural language understanding, namely the BERT language
model to extract contextualized word embeddings from textual data for automated
author personality detection. Our primary goal is to develop a computationally
efficient, high-performance personality prediction model which can be easily
used by a large number of people without access to huge computation resources.
Our extensive experiments with this ideology in mind, led us to develop a novel
model which feeds contextualized embeddings along with psycholinguistic
features toa Bagged-SVM classifier for personality trait prediction. Our model
outperforms the previous state of the art by 1.04% and, at the same time is
significantly more computationally efficient to train. We report our results on
the famous gold standard Essays dataset for personality detection.
",2020-10-03T09:25:51Z,http://arxiv.org/abs/2010.01309v1,"Amirmohammad Kazameini, Samin Fatehi, Yash Mehta, Sauleh Eetemadi, Erik Cambria"
"Beqi: Revitalize the Senegalese Wolof Language with a Robust Spelling
  Corrector","  The progress of Natural Language Processing (NLP), although fast in recent
years, is not at the same pace for all languages. African languages in
particular are still behind and lack automatic processing tools. Some of these
tools are very important for the development of these languages but also have
an important role in many NLP applications. This is particularly the case for
automatic spell checkers. Several approaches have been studied to address this
task and the one modeling spelling correction as a translation task from
misspelled (noisy) text to well-spelled (correct) text shows promising results.
However, this approach requires a parallel corpus of noisy data on the one hand
and correct data on the other hand, whereas Wolof is a low-resource language
and does not have such a corpus. In this paper, we present a way to address the
constraint related to the lack of data by generating synthetic data and we
present sequence-to-sequence models using Deep Learning for spelling correction
in Wolof. We evaluated these models in three different scenarios depending on
the subwording method applied to the data and showed that the latter had a
significant impact on the performance of the models, which opens the way for
future research in Wolof spelling correction.
",2023-05-15T10:28:36Z,http://arxiv.org/abs/2305.08518v1,"Derguene Mbaye, Moussa Diallo"
"Outlier Gradient Analysis: Efficiently Identifying Detrimental Training
  Samples for Deep Learning Models","  A core data-centric learning challenge is the identification of training
samples that are detrimental to model performance. Influence functions serve as
a prominent tool for this task and offer a robust framework for assessing
training data influence on model predictions. Despite their widespread use,
their high computational cost associated with calculating the inverse of the
Hessian matrix pose constraints, particularly when analyzing large-sized deep
models. In this paper, we establish a bridge between identifying detrimental
training samples via influence functions and outlier gradient detection. This
transformation not only presents a straightforward and Hessian-free formulation
but also provides insights into the role of the gradient in sample impact.
Through systematic empirical evaluations, we first validate the hypothesis of
our proposed outlier gradient analysis approach on synthetic datasets. We then
demonstrate its effectiveness in detecting mislabeled samples in vision models
and selecting data samples for improving performance of natural language
processing transformer models. We also extend its use to influential sample
identification for fine-tuning Large Language Models.
",2024-05-06T21:34:46Z,http://arxiv.org/abs/2405.03869v4,"Anshuman Chhabra, Bo Li, Jian Chen, Prasant Mohapatra, Hongfu Liu"
"Automated Medical Report Generation for ECG Data: Bridging Medical Text
  and Signal Processing with Deep Learning","  Recent advances in deep learning and natural language generation have
significantly improved image captioning, enabling automated, human-like
descriptions for visual content. In this work, we apply these captioning
techniques to generate clinician-like interpretations of ECG data. This study
leverages existing ECG datasets accompanied by free-text reports authored by
healthcare professionals (HCPs) as training data. These reports, while often
inconsistent, provide a valuable foundation for automated learning. We
introduce an encoder-decoder-based method that uses these reports to train
models to generate detailed descriptions of ECG episodes. This represents a
significant advancement in ECG analysis automation, with potential applications
in zero-shot classification and automated clinical decision support.
  The model is tested on various datasets, including both 1- and 12-lead ECGs.
It significantly outperforms the state-of-the-art reference model by Qiu et
al., achieving a METEOR score of 55.53% compared to 24.51% achieved by the
reference model. Furthermore, several key design choices are discussed,
providing a comprehensive overview of current challenges and innovations in
this domain.
  The source codes for this research are publicly available in our Git
repository https://git.zib.de/ableich/ecg-comment-generation-public
",2024-12-05T11:05:12Z,http://arxiv.org/abs/2412.04067v1,"Amnon Bleich, Antje Linnemann, Bjoern H. Diem, Tim OF Conrad"
"The NLP Cookbook: Modern Recipes for Transformer based Deep Learning
  Architectures","  In recent years, Natural Language Processing (NLP) models have achieved
phenomenal success in linguistic and semantic tasks like text classification,
machine translation, cognitive dialogue systems, information retrieval via
Natural Language Understanding (NLU), and Natural Language Generation (NLG).
This feat is primarily attributed due to the seminal Transformer architecture,
leading to designs such as BERT, GPT (I, II, III), etc. Although these
large-size models have achieved unprecedented performances, they come at high
computational costs. Consequently, some of the recent NLP architectures have
utilized concepts of transfer learning, pruning, quantization, and knowledge
distillation to achieve moderate model sizes while keeping nearly similar
performances as achieved by their predecessors. Additionally, to mitigate the
data size challenge raised by language models from a knowledge extraction
perspective, Knowledge Retrievers have been built to extricate explicit data
documents from a large corpus of databases with greater efficiency and
accuracy. Recent research has also focused on superior inference by providing
efficient attention to longer input sequences. In this paper, we summarize and
examine the current state-of-the-art (SOTA) NLP models that have been employed
for numerous NLP tasks for optimal performance and efficiency. We provide a
detailed understanding and functioning of the different architectures, a
taxonomy of NLP designs, comparative evaluations, and future directions in NLP.
",2021-03-23T22:38:20Z,http://arxiv.org/abs/2104.10640v3,"Sushant Singh, Ausif Mahmood"
"""I'm sorry Dave, I'm afraid I can't do that"": Linguistics, Statistics,
  and Natural Language Processing circa 2001","  A brief, general-audience overview of the history of natural language
processing, focusing on data-driven approaches.Topics include ""Ambiguity and
language analysis"", ""Firth things first"", ""A 'C' change"", and ""The empiricists
strike back"".
",2003-04-21T22:10:21Z,http://arxiv.org/abs/cs/0304027v1,Lillian Lee
"Improving Entity Recognition Using Ensembles of Deep Learning and
  Fine-tuned Large Language Models: A Case Study on Adverse Event Extraction
  from Multiple Sources","  Adverse event (AE) extraction following COVID-19 vaccines from text data is
crucial for monitoring and analyzing the safety profiles of immunizations.
Traditional deep learning models are adept at learning intricate feature
representations and dependencies in sequential data, but often require
extensive labeled data. In contrast, large language models (LLMs) excel in
understanding contextual information, but exhibit unstable performance on named
entity recognition tasks, possibly due to their broad but unspecific training.
This study aims to evaluate the effectiveness of LLMs and traditional deep
learning models in AE extraction, and to assess the impact of ensembling these
models on performance. In this study, we utilized reports and posts from the
VAERS (n=621), Twitter (n=9,133), and Reddit (n=131) as our corpora. Our goal
was to extract three types of entities: ""vaccine"", ""shot"", and ""ae"". We
explored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5,
GPT-4, and Llama-2, as well as traditional deep learning models like RNN and
BioBERT. To enhance performance, we created ensembles of the three models with
the best performance. For evaluation, we used strict and relaxed F1 scores to
evaluate the performance for each entity type, and micro-average F1 was used to
assess the overall performance. The ensemble model achieved the highest
performance in ""vaccine"", ""shot"", and ""ae"" with strict F1-scores of 0.878,
0.930, and 0.925, respectively, along with a micro-average score of 0.903. In
conclusion, this study demonstrates the effectiveness and robustness of
ensembling fine-tuned traditional deep learning models and LLMs, for extracting
AE-related information. This study contributes to the advancement of biomedical
natural language processing, providing valuable insights into improving AE
extraction from text data for pharmacovigilance and public health surveillance.
",2024-06-26T03:56:21Z,http://arxiv.org/abs/2406.18049v1,"Yiming Li, Deepthi Viswaroopan, William He, Jianfu Li, Xu Zuo, Hua Xu, Cui Tao"
"Automated Multi-Language to English Machine Translation Using Generative
  Pre-Trained Transformers","  The task of accurate and efficient language translation is an extremely
important information processing task. Machine learning enabled and automated
translation that is accurate and fast is often a large topic of interest in the
machine learning and data science communities. In this study, we examine using
local Generative Pretrained Transformer (GPT) models to perform automated zero
shot black-box, sentence wise, multi-natural-language translation into English
text. We benchmark 16 different open-source GPT models, with no custom
fine-tuning, from the Huggingface LLM repository for translating 50 different
non-English languages into English using translated TED Talk transcripts as the
reference dataset. These GPT model inference calls are performed strictly
locally, on single A100 Nvidia GPUs. Benchmark metrics that are reported are
language translation accuracy, using BLEU, GLEU, METEOR, and chrF text overlap
measures, and wall-clock time for each sentence translation. The best overall
performing GPT model for translating into English text for the BLEU metric is
ReMM-v2-L2-13B with a mean score across all tested languages of $0.152$, for
the GLEU metric is ReMM-v2-L2-13B with a mean score across all tested languages
of $0.256$, for the chrF metric is Llama2-chat-AYT-13B with a mean score across
all tested languages of $0.448$, and for the METEOR metric is ReMM-v2-L2-13B
with a mean score across all tested languages of $0.438$.
",2024-04-23T02:19:35Z,http://arxiv.org/abs/2404.14680v1,"Elijah Pelofske, Vincent Urias, Lorie M. Liebrock"
"Profile Prediction: An Alignment-Based Pre-Training Task for Protein
  Sequence Models","  For protein sequence datasets, unlabeled data has greatly outpaced labeled
data due to the high cost of wet-lab characterization. Recent deep-learning
approaches to protein prediction have shown that pre-training on unlabeled data
can yield useful representations for downstream tasks. However, the optimal
pre-training strategy remains an open question. Instead of strictly borrowing
from natural language processing (NLP) in the form of masked or autoregressive
language modeling, we introduce a new pre-training task: directly predicting
protein profiles derived from multiple sequence alignments. Using a set of
five, standardized downstream tasks for protein models, we demonstrate that our
pre-training task along with a multi-task objective outperforms masked language
modeling alone on all five tasks. Our results suggest that protein sequence
models may benefit from leveraging biologically-inspired inductive biases that
go beyond existing language modeling techniques in NLP.
",2020-12-01T01:01:34Z,http://arxiv.org/abs/2012.00195v1,"Pascal Sturmfels, Jesse Vig, Ali Madani, Nazneen Fatema Rajani"
An Integrated Approach for Video Captioning and Applications,"  Physical computing infrastructure, data gathering, and algorithms have
recently had significant advances to extract information from images and
videos. The growth has been especially outstanding in image captioning and
video captioning. However, most of the advancements in video captioning still
take place in short videos. In this research, we caption longer videos only by
using the keyframes, which are a small subset of the total video frames.
Instead of processing thousands of frames, only a few frames are processed
depending on the number of keyframes. There is a trade-off between the
computation of many frames and the speed of the captioning process. The
approach in this research is to allow the user to specify the trade-off between
execution time and accuracy. In addition, we argue that linking images, videos,
and natural language offers many practical benefits and immediate practical
applications. From the modeling perspective, instead of designing and staging
explicit algorithms to process videos and generate captions in complex
processing pipelines, our contribution lies in designing hybrid deep learning
architectures to apply in long videos by captioning video keyframes. We
consider the technology and the methodology that we have developed as steps
toward the applications discussed in this research.
",2022-01-23T01:06:00Z,http://arxiv.org/abs/2201.09153v1,"Soheyla Amirian, Thiab R. Taha, Khaled Rasheed, Hamid R. Arabnia"
"Reinforcement Learning and Bandits for Speech and Language Processing:
  Tutorial, Review and Outlook","  In recent years, reinforcement learning and bandits have transformed a wide
range of real-world applications including healthcare, finance, recommendation
systems, robotics, and last but not least, the speech and natural language
processing. While most speech and language applications of reinforcement
learning algorithms are centered around improving the training of deep neural
networks with its flexible optimization properties, there are still many
grounds to explore to utilize the benefits of reinforcement learning, such as
its reward-driven adaptability, state representations, temporal structures and
generalizability. In this survey, we present an overview of recent advancements
of reinforcement learning and bandits, and discuss how they can be effectively
employed to solve speech and natural language processing problems with models
that are adaptive, interactive and scalable.
",2022-10-24T21:49:12Z,http://arxiv.org/abs/2210.13623v3,Baihan Lin
A Multimodal Approach for Advanced Pest Detection and Classification,"  This paper presents a novel multi modal deep learning framework for enhanced
agricultural pest detection, combining tiny-BERT's natural language processing
with R-CNN and ResNet-18's image processing. Addressing limitations of
traditional CNN-based visual methods, this approach integrates textual context
for more accurate pest identification. The R-CNN and ResNet-18 integration
tackles deep CNN issues like vanishing gradients, while tiny-BERT ensures
computational efficiency. Employing ensemble learning with linear regression
and random forest models, the framework demonstrates superior discriminate
ability, as shown in ROC and AUC analyses. This multi modal approach, blending
text and image data, significantly boosts pest detection in agriculture. The
study highlights the potential of multi modal deep learning in complex
real-world scenarios, suggesting future expansions in diversity of datasets,
advanced data augmentation, and cross-modal attention mechanisms to enhance
model performance.
",2023-12-18T05:54:20Z,http://arxiv.org/abs/2312.10948v1,"Jinli Duan, Haoyu Ding, Sung Kim"
"Temporal Embeddings and Transformer Models for Narrative Text
  Understanding","  We present two deep learning approaches to narrative text understanding for
character relationship modelling. The temporal evolution of these relations is
described by dynamic word embeddings, that are designed to learn semantic
changes over time. An empirical analysis of the corresponding character
trajectories shows that such approaches are effective in depicting dynamic
evolution. A supervised learning approach based on the state-of-the-art
transformer model BERT is used instead to detect static relations between
characters. The empirical validation shows that such events (e.g., two
characters belonging to the same family) might be spotted with good accuracy,
even when using automatically annotated data. This provides a deeper
understanding of narrative plots based on the identification of key facts.
Standard clustering techniques are finally used for character de-aliasing, a
necessary pre-processing step for both approaches. Overall, deep learning
models appear to be suitable for narrative text understanding, while also
providing a challenging and unexploited benchmark for general natural language
understanding.
",2020-03-19T14:23:12Z,http://arxiv.org/abs/2003.08811v1,"Vani K, Simone Mellace, Alessandro Antonucci"
Deep learning evaluation using deep linguistic processing,"  We discuss problems with the standard approaches to evaluation for tasks like
visual question answering, and argue that artificial data can be used to
address these as a complement to current practice. We demonstrate that with the
help of existing 'deep' linguistic processing technology we are able to create
challenging abstract datasets, which enable us to investigate the language
understanding abilities of multimodal deep learning models in detail, as
compared to a single performance value on a static and monolithic dataset.
",2017-06-05T13:53:56Z,http://arxiv.org/abs/1706.01322v2,"Alexander Kuhnle, Ann Copestake"
"Implications of Deep Circuits in Improving Quality of Quantum Question
  Answering","  Question Answering (QA) has proved to be an arduous challenge in the area of
natural language processing (NLP) and artificial intelligence (AI). Many
attempts have been made to develop complete solutions for QA as well as
improving significant sub-modules of the QA systems to improve the overall
performance through the course of time. Questions are the most important piece
of QA, because knowing the question is equivalent to knowing what counts as an
answer (Harrah in Philos Sci, 1961 [1]). In this work, we have attempted to
understand questions in a better way by using Quantum Machine Learning (QML).
The properties of Quantum Computing (QC) have enabled classically intractable
data processing. So, in this paper, we have performed question classification
on questions from two classes of SelQA (Selection-based Question Answering)
dataset using quantum-based classifier algorithms-quantum support vector
machine (QSVM) and variational quantum classifier (VQC) from Qiskit (Quantum
Information Science toolKIT) for Python. We perform classification with both
classifiers in almost similar environments and study the effects of circuit
depths while comparing the results of both classifiers. We also use these
classification results with our own rule-based QA system and observe
significant performance improvement. Hence, this experiment has helped in
improving the quality of QA in general.
",2023-05-12T10:52:13Z,http://arxiv.org/abs/2305.07374v1,"Pragya Katyayan, Nisheeth Joshi"
Self-Supervised Speech Representation Learning: A Review,"  Although supervised deep learning has revolutionized speech and audio
processing, it has necessitated the building of specialist models for
individual tasks and application scenarios. It is likewise difficult to apply
this to dialects and languages for which only limited labeled data is
available. Self-supervised representation learning methods promise a single
universal model that would benefit a wide variety of tasks and domains. Such
methods have shown success in natural language processing and computer vision
domains, achieving new levels of performance while reducing the number of
labels required for many downstream scenarios. Speech representation learning
is experiencing similar progress in three main categories: generative,
contrastive, and predictive methods. Other approaches rely on multi-modal data
for pre-training, mixing text or visual data streams with speech. Although
self-supervised speech representation is still a nascent research area, it is
closely related to acoustic word embedding and learning with zero lexical
resources, both of which have seen active research for many years. This review
presents approaches for self-supervised speech representation learning and
their connection to other research areas. Since many current methods focus
solely on automatic speech recognition as a downstream task, we review recent
efforts on benchmarking learned representations to extend the application
beyond speech recognition.
",2022-05-21T16:52:57Z,http://arxiv.org/abs/2205.10643v3,"Abdelrahman Mohamed, Hung-yi Lee, Lasse Borgholt, Jakob D. Havtorn, Joakim Edin, Christian Igel, Katrin Kirchhoff, Shang-Wen Li, Karen Livescu, Lars Maal√∏e, Tara N. Sainath, Shinji Watanabe"
Including Signed Languages in Natural Language Processing,"  Signed languages are the primary means of communication for many deaf and
hard of hearing individuals. Since signed languages exhibit all the fundamental
linguistic properties of natural language, we believe that tools and theories
of Natural Language Processing (NLP) are crucial towards its modeling. However,
existing research in Sign Language Processing (SLP) seldom attempt to explore
and leverage the linguistic organization of signed languages. This position
paper calls on the NLP community to include signed languages as a research area
with high social and scientific impact. We first discuss the linguistic
properties of signed languages to consider during their modeling. Then, we
review the limitations of current SLP models and identify the open challenges
to extend NLP to signed languages. Finally, we urge (1) the adoption of an
efficient tokenization method; (2) the development of linguistically-informed
models; (3) the collection of real-world signed language data; (4) the
inclusion of local signed language communities as an active and leading voice
in the direction of research.
",2021-05-11T17:37:55Z,http://arxiv.org/abs/2105.05222v2,"Kayo Yin, Amit Moryossef, Julie Hochgesang, Yoav Goldberg, Malihe Alikhani"
"A Critical Review of Physics-Informed Machine Learning Applications in
  Subsurface Energy Systems","  Machine learning has emerged as a powerful tool in various fields, including
computer vision, natural language processing, and speech recognition. It can
unravel hidden patterns within large data sets and reveal unparalleled
insights, revolutionizing many industries and disciplines. However, machine and
deep learning models lack interpretability and limited domain-specific
knowledge, especially in applications such as physics and engineering.
Alternatively, physics-informed machine learning (PIML) techniques integrate
physics principles into data-driven models. By combining deep learning with
domain knowledge, PIML improves the generalization of the model, abidance by
the governing physical laws, and interpretability. This paper comprehensively
reviews PIML applications related to subsurface energy systems, mainly in the
oil and gas industry. The review highlights the successful utilization of PIML
for tasks such as seismic applications, reservoir simulation, hydrocarbons
production forecasting, and intelligent decision-making in the exploration and
production stages. Additionally, it demonstrates PIML's capabilities to
revolutionize the oil and gas industry and other emerging areas of interest,
such as carbon and hydrogen storage; and geothermal systems by providing more
accurate and reliable predictions for resource management and operational
efficiency.
",2023-08-06T18:20:24Z,http://arxiv.org/abs/2308.04457v1,"Abdeldjalil Latrach, Mohamed Lamine Malki, Misael Morales, Mohamed Mehana, Minou Rabiei"
A Tour of TensorFlow,"  Deep learning is a branch of artificial intelligence employing deep neural
network architectures that has significantly advanced the state-of-the-art in
computer vision, speech recognition, natural language processing and other
domains. In November 2015, Google released $\textit{TensorFlow}$, an open
source deep learning software library for defining, training and deploying
machine learning models. In this paper, we review TensorFlow and put it in
context of modern deep learning concepts and software. We discuss its basic
computational paradigms and distributed execution model, its programming
interface as well as accompanying visualization toolkits. We then compare
TensorFlow to alternative libraries such as Theano, Torch or Caffe on a
qualitative as well as quantitative basis and finally comment on observed
use-cases of TensorFlow in academia and industry.
",2016-10-01T11:32:03Z,http://arxiv.org/abs/1610.01178v1,Peter Goldsborough
SELFormer: Molecular Representation Learning via SELFIES Language Models,"  Automated computational analysis of the vast chemical space is critical for
numerous fields of research such as drug discovery and material science.
Representation learning techniques have recently been employed with the primary
objective of generating compact and informative numerical expressions of
complex data. One approach to efficiently learn molecular representations is
processing string-based notations of chemicals via natural language processing
(NLP) algorithms. Majority of the methods proposed so far utilize SMILES
notations for this purpose; however, SMILES is associated with numerous
problems related to validity and robustness, which may prevent the model from
effectively uncovering the knowledge hidden in the data. In this study, we
propose SELFormer, a transformer architecture-based chemical language model
that utilizes a 100% valid, compact and expressive notation, SELFIES, as input,
in order to learn flexible and high-quality molecular representations.
SELFormer is pre-trained on two million drug-like compounds and fine-tuned for
diverse molecular property prediction tasks. Our performance evaluation has
revealed that, SELFormer outperforms all competing methods, including graph
learning-based approaches and SMILES-based chemical language models, on
predicting aqueous solubility of molecules and adverse drug reactions. We also
visualized molecular representations learned by SELFormer via dimensionality
reduction, which indicated that even the pre-trained model can discriminate
molecules with differing structural properties. We shared SELFormer as a
programmatic tool, together with its datasets and pre-trained models. Overall,
our research demonstrates the benefit of using the SELFIES notations in the
context of chemical language modeling and opens up new possibilities for the
design and discovery of novel drug candidates with desired features.
",2023-04-10T15:38:25Z,http://arxiv.org/abs/2304.04662v2,"Atakan Y√ºksel, Erva Ulusoy, Atabey √únl√º, Tunca Doƒüan"
"A scoping review on multimodal deep learning in biomedical images and
  texts","  Computer-assisted diagnostic and prognostic systems of the future should be
capable of simultaneously processing multimodal data. Multimodal deep learning
(MDL), which involves the integration of multiple sources of data, such as
images and text, has the potential to revolutionize the analysis and
interpretation of biomedical data. However, it only caught researchers'
attention recently. To this end, there is a critical need to conduct a
systematic review on this topic, identify the limitations of current work, and
explore future directions. In this scoping review, we aim to provide a
comprehensive overview of the current state of the field and identify key
concepts, types of studies, and research gaps with a focus on biomedical images
and texts joint learning, mainly because these two were the most commonly
available data types in MDL research. This study reviewed the current uses of
multimodal deep learning on five tasks: (1) Report generation, (2) Visual
question answering, (3) Cross-modal retrieval, (4) Computer-aided diagnosis,
and (5) Semantic segmentation. Our results highlight the diverse applications
and potential of MDL and suggest directions for future research in the field.
We hope our review will facilitate the collaboration of natural language
processing (NLP) and medical imaging communities and support the next
generation of decision-making and computer-assisted diagnostic system
development.
",2023-07-14T14:08:54Z,http://arxiv.org/abs/2307.07362v3,"Zhaoyi Sun, Mingquan Lin, Qingqing Zhu, Qianqian Xie, Fei Wang, Zhiyong Lu, Yifan Peng"
Large language models in bioinformatics: applications and perspectives,"  Large language models (LLMs) are a class of artificial intelligence models
based on deep learning, which have great performance in various tasks,
especially in natural language processing (NLP). Large language models
typically consist of artificial neural networks with numerous parameters,
trained on large amounts of unlabeled input using self-supervised or
semi-supervised learning. However, their potential for solving bioinformatics
problems may even exceed their proficiency in modeling human language. In this
review, we will present a summary of the prominent large language models used
in natural language processing, such as BERT and GPT, and focus on exploring
the applications of large language models at different omics levels in
bioinformatics, mainly including applications of large language models in
genomics, transcriptomics, proteomics, drug discovery and single cell analysis.
Finally, this review summarizes the potential and prospects of large language
models in solving bioinformatic problems.
",2024-01-08T17:26:59Z,http://arxiv.org/abs/2401.04155v1,"Jiajia Liu, Mengyuan Yang, Yankai Yu, Haixia Xu, Kang Li, Xiaobo Zhou"
"GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural
  Language Processing","  We present GluonCV and GluonNLP, the deep learning toolkits for computer
vision and natural language processing based on Apache MXNet (incubating).
These toolkits provide state-of-the-art pre-trained models, training scripts,
and training logs, to facilitate rapid prototyping and promote reproducible
research. We also provide modular APIs with flexible building blocks to enable
efficient customization. Leveraging the MXNet ecosystem, the deep learning
models in GluonCV and GluonNLP can be deployed onto a variety of platforms with
different programming languages. The Apache 2.0 license has been adopted by
GluonCV and GluonNLP to allow for software distribution, modification, and
usage.
",2019-07-09T21:59:44Z,http://arxiv.org/abs/1907.04433v2,"Jian Guo, He He, Tong He, Leonard Lausen, Mu Li, Haibin Lin, Xingjian Shi, Chenguang Wang, Junyuan Xie, Sheng Zha, Aston Zhang, Hang Zhang, Zhi Zhang, Zhongyue Zhang, Shuai Zheng, Yi Zhu"
"Towards a neural architecture of language: Deep learning versus
  logistics of access in neural architectures for compositional processing","  Recently, a number of articles have argued that deep learning models such as
GPT could also capture key aspects of language processing in the human mind and
brain. However, I will argue that these models are not suitable as neural
models of human language. Firstly, because they fail on fundamental boundary
conditions, such as the amount of learning they require. This would in fact
imply that the mechanisms of GPT and brain language processing are
fundamentally different. Secondly, because they do not possess the logistics of
access needed for compositional and productive human language processing.
Neural architectures could possess logistics of access based on small-world
like network structures, in which processing does not consist of symbol
manipulation but of controlling the flow of activation. In this view, two
complementary approaches would be needed to investigate the relation between
brain and cognition. Investigating learning methods could reveal how 'learned
cognition' as found in deep learning could develop in the brain. However,
neural architectures with logistics of access should also be developed to
account for 'productive cognition' as required for natural or artificial human
language processing. Later on, these approaches could perhaps be combined to
see how such architectures could develop by learning and development from a
simpler basis.
",2022-10-19T13:31:26Z,http://arxiv.org/abs/2210.10543v1,Frank van der Velde
Interpreting Deep Neural Networks Through Variable Importance,"  While the success of deep neural networks (DNNs) is well-established across a
variety of domains, our ability to explain and interpret these methods is
limited. Unlike previously proposed local methods which try to explain
particular classification decisions, we focus on global interpretability and
ask a universally applicable question: given a trained model, which features
are the most important? In the context of neural networks, a feature is rarely
important on its own, so our strategy is specifically designed to leverage
partial covariance structures and incorporate variable dependence into feature
ranking. Our methodological contributions in this paper are two-fold. First, we
propose an effect size analogue for DNNs that is appropriate for applications
with highly collinear predictors (ubiquitous in computer vision). Second, we
extend the recently proposed ""RelATive cEntrality"" (RATE) measure (Crawford et
al., 2019) to the Bayesian deep learning setting. RATE applies an information
theoretic criterion to the posterior distribution of effect sizes to assess
feature significance. We apply our framework to three broad application areas:
computer vision, natural language processing, and social science.
",2019-01-28T17:34:06Z,http://arxiv.org/abs/1901.09839v3,"Jonathan Ish-Horowicz, Dana Udwin, Seth Flaxman, Sarah Filippi, Lorin Crawford"
"Harnessing the Power of Beta Scoring in Deep Active Learning for
  Multi-Label Text Classification","  Within the scope of natural language processing, the domain of multi-label
text classification is uniquely challenging due to its expansive and uneven
label distribution. The complexity deepens due to the demand for an extensive
set of annotated data for training an advanced deep learning model, especially
in specialized fields where the labeling task can be labor-intensive and often
requires domain-specific knowledge. Addressing these challenges, our study
introduces a novel deep active learning strategy, capitalizing on the Beta
family of proper scoring rules within the Expected Loss Reduction framework. It
computes the expected increase in scores using the Beta Scoring Rules, which
are then transformed into sample vector representations. These vector
representations guide the diverse selection of informative samples, directly
linking this process to the model's expected proper score. Comprehensive
evaluations across both synthetic and real datasets reveal our method's
capability to often outperform established acquisition techniques in
multi-label text classification, presenting encouraging outcomes across various
architectural and dataset scenarios.
",2024-01-15T00:06:24Z,http://arxiv.org/abs/2401.07395v1,"Wei Tan, Ngoc Dang Nguyen, Lan Du, Wray Buntine"
Morphosyntactic Analysis for CHILDES,"  Language development researchers are interested in comparing the process of
language learning across languages. Unfortunately, it has been difficult to
construct a consistent quantitative framework for such comparisons. However,
recent advances in AI (Artificial Intelligence) and ML (Machine Learning) are
providing new methods for ASR (automatic speech recognition) and NLP (natural
language processing) that can be brought to bear on this problem. Using the
Batchalign2 program (Liu et al., 2023), we have been transcribing and linking
data for the CHILDES database and have applied the UD (Universal Dependencies)
framework to provide a consistent and comparable morphosyntactic analysis for
27 languages. These new resources open possibilities for deeper crosslinguistic
study of language learning.
",2024-07-17T08:11:24Z,http://arxiv.org/abs/2407.12389v1,"Houjun Liu, Brian MacWhinney"
"Can Large Language Models Aid in Annotating Speech Emotional Data?
  Uncovering New Frontiers","  Despite recent advancements in speech emotion recognition (SER) models,
state-of-the-art deep learning (DL) approaches face the challenge of the
limited availability of annotated data. Large language models (LLMs) have
revolutionised our understanding of natural language, introducing emergent
properties that broaden comprehension in language, speech, and vision. This
paper examines the potential of LLMs to annotate abundant speech data, aiming
to enhance the state-of-the-art in SER. We evaluate this capability across
various settings using publicly available speech emotion classification
datasets. Leveraging ChatGPT, we experimentally demonstrate the promising role
of LLMs in speech emotion data annotation. Our evaluation encompasses
single-shot and few-shots scenarios, revealing performance variability in SER.
Notably, we achieve improved results through data augmentation, incorporating
ChatGPT-annotated samples into existing datasets. Our work uncovers new
frontiers in speech emotion classification, highlighting the increasing
significance of LLMs in this field moving forward.
",2023-07-12T11:27:40Z,http://arxiv.org/abs/2307.06090v3,"Siddique Latif, Muhammad Usama, Mohammad Ibrahim Malik, Bj√∂rn W. Schuller"
"LinkTransformer: A Unified Package for Record Linkage with Transformer
  Language Models","  Linking information across sources is fundamental to a variety of analyses in
social science, business, and government. While large language models (LLMs)
offer enormous promise for improving record linkage in noisy datasets, in many
domains approximate string matching packages in popular softwares such as R and
Stata remain predominant. These packages have clean, simple interfaces and can
be easily extended to a diversity of languages. Our open-source package
LinkTransformer aims to extend the familiarity and ease-of-use of popular
string matching methods to deep learning. It is a general purpose package for
record linkage with transformer LLMs that treats record linkage as a text
retrieval problem. At its core is an off-the-shelf toolkit for applying
transformer models to record linkage with four lines of code. LinkTransformer
contains a rich repository of pre-trained transformer semantic similarity
models for multiple languages and supports easy integration of any transformer
language model from Hugging Face or OpenAI. It supports standard functionality
such as blocking and linking on multiple noisy fields. LinkTransformer APIs
also perform other common text data processing tasks, e.g., aggregation, noisy
de-duplication, and translation-free cross-lingual linkage. Importantly,
LinkTransformer also contains comprehensive tools for efficient model tuning,
to facilitate different levels of customization when off-the-shelf models do
not provide the required accuracy. Finally, to promote reusability,
reproducibility, and extensibility, LinkTransformer makes it easy for users to
contribute their custom-trained models to its model hub. By combining
transformer language models with intuitive APIs that will be familiar to many
users of popular string matching packages, LinkTransformer aims to democratize
the benefits of LLMs among those who may be less familiar with deep learning
frameworks.
",2023-09-02T01:45:27Z,http://arxiv.org/abs/2309.00789v2,"Abhishek Arora, Melissa Dell"
"Nemesyst: A Hybrid Parallelism Deep Learning-Based Framework Applied for
  Internet of Things Enabled Food Retailing Refrigeration Systems","  Deep Learning has attracted considerable attention across multiple
application domains, including computer vision, signal processing and natural
language processing. Although quite a few single node deep learning frameworks
exist, such as tensorflow, pytorch and keras, we still lack a complete
processing structure that can accommodate large scale data processing, version
control, and deployment, all while staying agnostic of any specific single node
framework. To bridge this gap, this paper proposes a new, higher level
framework, i.e. Nemesyst, which uses databases along with model
sequentialisation to allow processes to be fed unique and transformed data at
the point of need. This facilitates near real-time application and makes models
available for further training or use at any node that has access to the
database simultaneously. Nemesyst is well suited as an application framework
for internet of things aggregated control systems, deploying deep learning
techniques to optimise individual machines in massive networks. To demonstrate
this framework, we adopted a case study in a novel domain; deploying deep
learning to optimise the high speed control of electrical power consumed by a
massive internet of things network of retail refrigeration systems in
proportion to load available on the UK National Grid (a demand side response).
The case study demonstrated for the first time in such a setting how deep
learning models, such as Recurrent Neural Networks (vanilla and Long-Short-Term
Memory) and Generative Adversarial Networks paired with Nemesyst, achieve
compelling performance, whilst still being malleable to future adjustments as
both the data and requirements inevitably change over time.
",2019-06-04T17:23:09Z,http://arxiv.org/abs/1906.01600v2,"George Onoufriou, Ronald Bickerton, Simon Pearson, Georgios Leontidis"
"Deep Learning for Quantile Regression under Right Censoring:
  DeepQuantreg","  The computational prediction algorithm of neural network, or deep learning,
has drawn much attention recently in statistics as well as in image recognition
and natural language processing. Particularly in statistical application for
censored survival data, the loss function used for optimization has been mainly
based on the partial likelihood from Cox's model and its variations to utilize
existing neural network library such as Keras, which was built upon the open
source library of TensorFlow. This paper presents a novel application of the
neural network to the quantile regression for survival data with right
censoring, which is adjusted by the inverse of the estimated censoring
distribution in the check function. The main purpose of this work is to show
that the deep learning method could be flexible enough to predict nonlinear
patterns more accurately compared to existing quantile regression methods such
as traditional linear quantile regression and nonparametric quantile regression
with total variation regularization, emphasizing practicality of the method for
censored survival data. Simulation studies were performed to generate nonlinear
censored survival data and compare the deep learning method with existing
quantile regression methods in terms of prediction accuracy. The proposed
method is illustrated with two publicly available breast cancer data sets with
gene signatures. The method has been built into a package and is freely
available at \url{https://github.com/yicjia/DeepQuantreg}.
",2020-07-14T14:31:11Z,http://arxiv.org/abs/2007.07056v2,"Yichen Jia, Jong-Hyeon Jeong"
"Around the GLOBE: Numerical Aggregation Question-Answering on
  Heterogeneous Genealogical Knowledge Graphs with Deep Neural Networks","  One of the key AI tools for textual corpora exploration is natural language
question-answering (QA). Unlike keyword-based search engines, QA algorithms
receive and process natural language questions and produce precise answers to
these questions, rather than long lists of documents that need to be manually
scanned by the users. State-of-the-art QA algorithms based on DNNs were
successfully employed in various domains. However, QA in the genealogical
domain is still underexplored, while researchers in this field (and other
fields in humanities and social sciences) can highly benefit from the ability
to ask questions in natural language, receive concrete answers and gain
insights hidden within large corpora. While some research has been recently
conducted for factual QA in the genealogical domain, to the best of our
knowledge, there is no previous research on the more challenging task of
numerical aggregation QA (i.e., answering questions combining aggregation
functions, e.g., count, average, max). Numerical aggregation QA is critical for
distant reading and analysis for researchers (and the general public)
interested in investigating cultural heritage domains. Therefore, in this
study, we present a new end-to-end methodology for numerical aggregation QA for
genealogical trees that includes: 1) an automatic method for training dataset
generation; 2) a transformer-based table selection method, and 3) an optimized
transformer-based numerical aggregation QA model. The findings indicate that
the proposed architecture, GLOBE, outperforms the state-of-the-art models and
pipelines by achieving 87% accuracy for this task compared to only 21% by
current state-of-the-art models. This study may have practical implications for
genealogical information centers and museums, making genealogical data research
easy and scalable for experts as well as the general public.
",2023-07-30T12:09:00Z,http://arxiv.org/abs/2307.16208v1,"Omri Suissa, Maayan Zhitomirsky-Geffet, Avshalom Elmalech"
"A natural language processing-based approach: mapping human perception
  by understanding deep semantic features in street view images","  In the past decade, using Street View images and machine learning to measure
human perception has become a mainstream research approach in urban science.
However, this approach using only image-shallow information makes it difficult
to comprehensively understand the deep semantic features of human perception of
a scene. In this study, we proposed a new framework based on a pre-train
natural language model to understand the relationship between human perception
and the sense of a scene. Firstly, Place Pulse 2.0 was used as our base
dataset, which contains a variety of human-perceived labels, namely, beautiful,
safe, wealthy, depressing, boring, and lively. An image captioning network was
used to extract the description information of each street view image.
Secondly, a pre-trained BERT model was finetuning and added a regression
function for six human perceptual dimensions. Furthermore, we compared the
performance of five traditional regression methods with our approach and
conducted a migration experiment in Hong Kong. Our results show that human
perception scoring by deep semantic features performed better than previous
studies by machine learning methods with shallow features. The use of deep
scene semantic features provides new ideas for subsequent human perception
research, as well as better explanatory power in the face of spatial
heterogeneity.
",2023-11-29T05:00:43Z,http://arxiv.org/abs/2311.17354v1,"Haoran Ma, Dongdong Wu"
Decoding the Diversity: A Review of the Indic AI Research Landscape,"  This review paper provides a comprehensive overview of large language model
(LLM) research directions within Indic languages. Indic languages are those
spoken in the Indian subcontinent, including India, Pakistan, Bangladesh, Sri
Lanka, Nepal, and Bhutan, among others. These languages have a rich cultural
and linguistic heritage and are spoken by over 1.5 billion people worldwide.
With the tremendous market potential and growing demand for natural language
processing (NLP) based applications in diverse languages, generative
applications for Indic languages pose unique challenges and opportunities for
research. Our paper deep dives into the recent advancements in Indic generative
modeling, contributing with a taxonomy of research directions, tabulating 84
recent publications. Research directions surveyed in this paper include LLM
development, fine-tuning existing LLMs, development of corpora, benchmarking
and evaluation, as well as publications around specific techniques, tools, and
applications. We found that researchers across the publications emphasize the
challenges associated with limited data availability, lack of standardization,
and the peculiar linguistic complexities of Indic languages. This work aims to
serve as a valuable resource for researchers and practitioners working in the
field of NLP, particularly those focused on Indic languages, and contributes to
the development of more accurate and efficient LLM applications for these
languages.
",2024-06-13T19:55:20Z,http://arxiv.org/abs/2406.09559v1,"Sankalp KJ, Vinija Jain, Sreyoshi Bhaduri, Tamoghna Roy, Aman Chadha"
"Deep Learning for Plasma Tomography and Disruption Prediction from
  Bolometer Data","  The use of deep learning is facilitating a wide range of data processing
tasks in many areas. The analysis of fusion data is no exception, since there
is a need to process large amounts of data collected from the diagnostic
systems attached to a fusion device. Fusion data involves images and time
series, and are a natural candidate for the use of convolutional and recurrent
neural networks. In this work, we describe how CNNs can be used to reconstruct
the plasma radiation profile, and we discuss the potential of using RNNs for
disruption prediction based on the same input data. Both approaches have been
applied at JET using data from a multi-channel diagnostic system. Similar
approaches can be applied to other fusion devices and diagnostics.
",2019-10-27T11:37:24Z,http://arxiv.org/abs/1910.13257v1,"Diogo R. Ferreira, Pedro J. Carvalho, Hor√°cio Fernandes"
"Adaptivity of deep ReLU network for learning in Besov and mixed smooth
  Besov spaces: optimal rate and curse of dimensionality","  Deep learning has shown high performances in various types of tasks from
visual recognition to natural language processing, which indicates superior
flexibility and adaptivity of deep learning. To understand this phenomenon
theoretically, we develop a new approximation and estimation error analysis of
deep learning with the ReLU activation for functions in a Besov space and its
variant with mixed smoothness. The Besov space is a considerably general
function space including the Holder space and Sobolev space, and especially can
capture spatial inhomogeneity of smoothness. Through the analysis in the Besov
space, it is shown that deep learning can achieve the minimax optimal rate and
outperform any non-adaptive (linear) estimator such as kernel ridge regression,
which shows that deep learning has higher adaptivity to the spatial
inhomogeneity of the target function than other estimators such as linear ones.
In addition to this, it is shown that deep learning can avoid the curse of
dimensionality if the target function is in a mixed smooth Besov space. We also
show that the dependency of the convergence rate on the dimensionality is tight
due to its minimax optimality. These results support high adaptivity of deep
learning and its superior ability as a feature extractor.
",2018-10-18T13:17:20Z,http://arxiv.org/abs/1810.08033v1,Taiji Suzuki
"Autonomous Droplet Microfluidic Design Framework with Large Language
  Models","  Droplet-based microfluidic devices have substantial promise as cost-effective
alternatives to current assessment tools in biological research. Moreover,
machine learning models that leverage tabular data, including input design
parameters and their corresponding efficiency outputs, are increasingly
utilised to automate the design process of these devices and to predict their
performance. However, these models fail to fully leverage the data presented in
the tables, neglecting crucial contextual information, including column
headings and their associated descriptions. This study presents
MicroFluidic-LLMs, a framework designed for processing and feature extraction,
which effectively captures contextual information from tabular data formats.
MicroFluidic-LLMs overcomes processing challenges by transforming the content
into a linguistic format and leveraging pre-trained large language models
(LLMs) for analysis. We evaluate our MicroFluidic-LLMs framework on 11
prediction tasks, covering aspects such as geometry, flow conditions, regimes,
and performance, utilising a publicly available dataset on flow-focusing
droplet microfluidics. We demonstrate that our MicroFluidic-LLMs framework can
empower deep neural network models to be highly effective and straightforward
while minimising the need for extensive data preprocessing. Moreover, the
exceptional performance of deep neural network models, particularly when
combined with advanced natural language processing models such as DistilBERT
and GPT-2, reduces the mean absolute error in the droplet diameter and
generation rate by nearly 5- and 7-fold, respectively, and enhances the regime
classification accuracy by over 4%, compared with the performance reported in a
previous study. This study lays the foundation for the huge potential
applications of LLMs and machine learning in a wider spectrum of microfluidic
applications.
",2024-11-11T03:20:53Z,http://arxiv.org/abs/2411.06691v1,"Dinh-Nguyen Nguyen, Raymond Kai-Yu Tong, Ngoc-Duy Dinh"
A Survey of Active Learning for Natural Language Processing,"  In this work, we provide a survey of active learning (AL) for its
applications in natural language processing (NLP). In addition to a
fine-grained categorization of query strategies, we also investigate several
other important aspects of applying AL to NLP problems. These include AL for
structured prediction tasks, annotation cost, model learning (especially with
deep neural models), and starting and stopping AL. Finally, we conclude with a
discussion of related topics and future directions.
",2022-10-18T19:14:42Z,http://arxiv.org/abs/2210.10109v2,"Zhisong Zhang, Emma Strubell, Eduard Hovy"
"Process Knowledge-infused Learning for Suicidality Assessment on Social
  Media","  Improving the performance and natural language explanations of deep learning
algorithms is a priority for adoption by humans in the real world. In several
domains, such as healthcare, such technology has significant potential to
reduce the burden on humans by providing quality assistance at scale. However,
current methods rely on the traditional pipeline of predicting labels from
data, thus completely ignoring the process and guidelines used to obtain the
labels. Furthermore, post hoc explanations on the data to label prediction
using explainable AI (XAI) models, while satisfactory to computer scientists,
leave much to be desired to the end-users due to lacking explanations of the
process in terms of human-understandable concepts. We \textit{introduce},
\textit{formalize}, and \textit{develop} a novel Artificial Intelligence (A)
paradigm -- Process Knowledge-infused Learning (PK-iL). PK-iL utilizes a
structured process knowledge that explicitly explains the underlying prediction
process that makes sense to end-users. The qualitative human evaluation
confirms through a annotator agreement of 0.72, that humans are understand
explanations for the predictions. PK-iL also performs competitively with the
state-of-the-art (SOTA) baselines.
",2022-04-26T19:43:41Z,http://arxiv.org/abs/2204.12560v1,"Kaushik Roy, Manas Gaur, Qi Zhang, Amit Sheth"
Natural Language Processing using Hadoop and KOSHIK,"  Natural language processing, as a data analytics related technology, is used
widely in many research areas such as artificial intelligence, human language
processing, and translation. At present, due to explosive growth of data, there
are many challenges for natural language processing. Hadoop is one of the
platforms that can process the large amount of data required for natural
language processing. KOSHIK is one of the natural language processing
architectures, and utilizes Hadoop and contains language processing components
such as Stanford CoreNLP and OpenNLP. This study describes how to build a
KOSHIK platform with the relevant tools, and provides the steps to analyze wiki
data. Finally, it evaluates and discusses the advantages and disadvantages of
the KOSHIK architecture, and gives recommendations on improving the processing
performance.
",2016-08-15T23:09:21Z,http://arxiv.org/abs/1608.04434v1,"Emre Erturk, Hong Shi"
"Measuring Fine-Grained Domain Relevance of Terms: A Hierarchical
  Core-Fringe Approach","  We propose to measure fine-grained domain relevance - the degree that a term
is relevant to a broad (e.g., computer science) or narrow (e.g., deep learning)
domain. Such measurement is crucial for many downstream tasks in natural
language processing. To handle long-tail terms, we build a core-anchored
semantic graph, which uses core terms with rich description information to
bridge the vast remaining fringe terms semantically. To support a fine-grained
domain without relying on a matching corpus for supervision, we develop
hierarchical core-fringe learning, which learns core and fringe terms jointly
in a semi-supervised manner contextualized in the hierarchy of the domain. To
reduce expensive human efforts, we employ automatic annotation and hierarchical
positive-unlabeled learning. Our approach applies to big or small domains,
covers head or tail terms, and requires little human effort. Extensive
experiments demonstrate that our methods outperform strong baselines and even
surpass professional human performance.
",2021-05-27T15:52:34Z,http://arxiv.org/abs/2105.13255v1,"Jie Huang, Kevin Chen-Chuan Chang, Jinjun Xiong, Wen-mei Hwu"
"Generating Feasible and Plausible Counterfactual Explanations for
  Outcome Prediction of Business Processes","  In recent years, various machine and deep learning architectures have been
successfully introduced to the field of predictive process analytics.
Nevertheless, the inherent opacity of these algorithms poses a significant
challenge for human decision-makers, hindering their ability to understand the
reasoning behind the predictions. This growing concern has sparked the
introduction of counterfactual explanations, designed as human-understandable
what if scenarios, to provide clearer insights into the decision-making process
behind undesirable predictions. The generation of counterfactual explanations,
however, encounters specific challenges when dealing with the sequential nature
of the (business) process cases typically used in predictive process analytics.
Our paper tackles this challenge by introducing a data-driven approach,
REVISEDplus, to generate more feasible and plausible counterfactual
explanations. First, we restrict the counterfactual algorithm to generate
counterfactuals that lie within a high-density region of the process data,
ensuring that the proposed counterfactuals are realistic and feasible within
the observed process data distribution. Additionally, we ensure plausibility by
learning sequential patterns between the activities in the process cases,
utilising Declare language templates. Finally, we evaluate the properties that
define the validity of counterfactuals.
",2024-03-14T09:56:35Z,http://arxiv.org/abs/2403.09232v1,"Alexander Stevens, Chun Ouyang, Johannes De Smedt, Catarina Moreira"
"Semantic Similarity Measure of Natural Language Text through Machine
  Learning and a Keyword-Aware Cross-Encoder-Ranking Summarizer -- A Case Study
  Using UCGIS GIS&T Body of Knowledge","  Initiated by the University Consortium of Geographic Information Science
(UCGIS), GIS&T Body of Knowledge (BoK) is a community-driven endeavor to
define, develop, and document geospatial topics related to geographic
information science and technologies (GIS&T). In recent years, GIS&T BoK has
undergone rigorous development in terms of its topic re-organization and
content updating, resulting in a new digital version of the project. While the
BoK topics provide useful materials for researchers and students to learn about
GIS, the semantic relationships among the topics, such as semantic similarity,
should also be identified so that a better and automated topic navigation can
be achieved. Currently, the related topics are either defined manually by
editors or authors, which may result in an incomplete assessment of topic
relationship. To address this challenge, our research evaluates the
effectiveness of multiple natural language processing (NLP) techniques in
extracting semantics from text, including both deep neural networks and
traditional machine learning approaches. Besides, a novel text summarization -
KACERS (Keyword-Aware Cross-Encoder-Ranking Summarizer) - is proposed to
generate a semantic summary of scientific publications. By identifying the
semantic linkages among key topics, this work provides guidance for future
development and content organization of the GIS&T BoK project. It also offers a
new perspective on the use of machine learning techniques for analyzing
scientific publications, and demonstrate the potential of KACERS summarizer in
semantic understanding of long text documents.
",2023-05-17T01:17:57Z,http://arxiv.org/abs/2305.09877v1,"Yuanyuan Tian, Wenwen Li, Sizhe Wang, Zhining Gu"
Pre-trained Language Model Based Active Learning for Sentence Matching,"  Active learning is able to significantly reduce the annotation cost for
data-driven techniques. However, previous active learning approaches for
natural language processing mainly depend on the entropy-based uncertainty
criterion, and ignore the characteristics of natural language. In this paper,
we propose a pre-trained language model based active learning approach for
sentence matching. Differing from previous active learning, it can provide
linguistic criteria to measure instances and help select more efficient
instances for annotation. Experiments demonstrate our approach can achieve
greater accuracy with fewer labeled training instances.
",2020-10-12T08:24:36Z,http://arxiv.org/abs/2010.05522v1,"Guirong Bai, Shizhu He, Kang Liu, Jun Zhao, Zaiqing Nie"
Language Models sounds the Death Knell of Knowledge Graphs,"  Healthcare domain generates a lot of unstructured and semi-structured text.
Natural Language processing (NLP) has been used extensively to process this
data. Deep Learning based NLP especially Large Language Models (LLMs) such as
BERT have found broad acceptance and are used extensively for many
applications. A Language Model is a probability distribution over a word
sequence. Self-supervised Learning on a large corpus of data automatically
generates deep learning-based language models. BioBERT and Med-BERT are
language models pre-trained for the healthcare domain. Healthcare uses typical
NLP tasks such as question answering, information extraction, named entity
recognition, and search to simplify and improve processes. However, to ensure
robust application of the results, NLP practitioners need to normalize and
standardize them. One of the main ways of achieving normalization and
standardization is the use of Knowledge Graphs. A Knowledge Graph captures
concepts and their relationships for a specific domain, but their creation is
time-consuming and requires manual intervention from domain experts, which can
prove expensive. SNOMED CT (Systematized Nomenclature of Medicine -- Clinical
Terms), Unified Medical Language System (UMLS), and Gene Ontology (GO) are
popular ontologies from the healthcare domain. SNOMED CT and UMLS capture
concepts such as disease, symptoms and diagnosis and GO is the world's largest
source of information on the functions of genes. Healthcare has been dealing
with an explosion in information about different types of drugs, diseases, and
procedures. This paper argues that using Knowledge Graphs is not the best
solution for solving problems in this domain. We present experiments using LLMs
for the healthcare domain to demonstrate that language models provide the same
functionality as knowledge graphs, thereby making knowledge graphs redundant.
",2023-01-10T14:20:15Z,http://arxiv.org/abs/2301.03980v1,"Kunal Suri, Atul Singh, Prakhar Mishra, Swapna Sourav Rout, Rajesh Sabapathy"
"Survey of different Large Language Model Architectures: Trends,
  Benchmarks, and Challenges","  Large Language Models (LLMs) represent a class of deep learning models adept
at understanding natural language and generating coherent responses to various
prompts or queries. These models far exceed the complexity of conventional
neural networks, often encompassing dozens of neural network layers and
containing billions to trillions of parameters. They are typically trained on
vast datasets, utilizing architectures based on transformer blocks. Present-day
LLMs are multi-functional, capable of performing a range of tasks from text
generation and language translation to question answering, as well as code
generation and analysis. An advanced subset of these models, known as
Multimodal Large Language Models (MLLMs), extends LLM capabilities to process
and interpret multiple data modalities, including images, audio, and video.
This enhancement empowers MLLMs with capabilities like video editing, image
comprehension, and captioning for visual content. This survey provides a
comprehensive overview of the recent advancements in LLMs. We begin by tracing
the evolution of LLMs and subsequently delve into the advent and nuances of
MLLMs. We analyze emerging state-of-the-art MLLMs, exploring their technical
features, strengths, and limitations. Additionally, we present a comparative
analysis of these models and discuss their challenges, potential limitations,
and prospects for future development.
",2024-12-04T11:14:06Z,http://arxiv.org/abs/2412.03220v1,"Minghao Shao, Abdul Basit, Ramesh Karri, Muhammad Shafique"
Unsupervised Sentiment Analysis of Plastic Surgery Social Media Posts,"  The massive collection of user posts across social media platforms is
primarily untapped for artificial intelligence (AI) use cases based on the
sheer volume and velocity of textual data. Natural language processing (NLP) is
a subfield of AI that leverages bodies of documents, known as corpora, to train
computers in human-like language understanding. Using a word ranking method,
term frequency-inverse document frequency (TF-IDF), to create features across
documents, it is possible to perform unsupervised analytics, machine learning
(ML) that can group the documents without a human manually labeling the data.
For large datasets with thousands of features, t-distributed stochastic
neighbor embedding (t-SNE), k-means clustering and Latent Dirichlet allocation
(LDA) are employed to learn top words and generate topics for a Reddit and
Twitter combined corpus. Using extremely simple deep learning models, this
study demonstrates that the applied results of unsupervised analysis allow a
computer to predict either negative, positive, or neutral user sentiment
towards plastic surgery based on a tweet or subreddit post with almost 90%
accuracy. Furthermore, the model is capable of achieving higher accuracy on the
unsupervised sentiment task than on a rudimentary supervised document
classification task. Therefore, unsupervised learning may be considered a
viable option in labeling social media documents for NLP tasks.
",2023-07-05T20:16:20Z,http://arxiv.org/abs/2307.02640v1,Alexandrea K. Ramnarine
Sexism Detection on a Data Diet,"  There is an increase in the proliferation of online hate commensurate with
the rise in the usage of social media. In response, there is also a significant
advancement in the creation of automated tools aimed at identifying harmful
text content using approaches grounded in Natural Language Processing and Deep
Learning. Although it is known that training Deep Learning models require a
substantial amount of annotated data, recent line of work suggests that models
trained on specific subsets of the data still retain performance comparable to
the model that was trained on the full dataset. In this work, we show how we
can leverage influence scores to estimate the importance of a data point while
training a model and designing a pruning strategy applied to the case of sexism
detection. We evaluate the model performance trained on data pruned with
different pruning strategies on three out-of-domain datasets and find, that in
accordance with other work a large fraction of instances can be removed without
significant performance drop. However, we also discover that the strategies for
pruning data, previously successful in Natural Language Inference tasks, do not
readily apply to the detection of harmful content and instead amplify the
already prevalent class imbalance even more, leading in the worst-case to a
complete absence of the hateful class.
",2024-06-07T12:39:54Z,http://arxiv.org/abs/2406.04892v1,"Rabiraj Bandyopadhyay, Dennis Assenmacher, Jose M. Alonso Moral, Claudia Wagner"
"Probabilistic Generative Transformer Language models for Generative
  Design of Molecules","  Self-supervised neural language models have recently found wide applications
in generative design of organic molecules and protein sequences as well as
representation learning for downstream structure classification and functional
prediction. However, most of the existing deep learning models for molecule
design usually require a big dataset and have a black-box architecture, which
makes it difficult to interpret their design logic. Here we propose Generative
Molecular Transformer (GMTransformer), a probabilistic neural network model for
generative design of molecules. Our model is built on the blank filling
language model originally developed for text processing, which has demonstrated
unique advantages in learning the ""molecules grammars"" with high-quality
generation, interpretability, and data efficiency. Benchmarked on the MOSES
datasets, our models achieve high novelty and Scaf compared to other baselines.
The probabilistic generation steps have the potential in tinkering molecule
design due to their capability of recommending how to modify existing molecules
with explanation, guided by the learned implicit molecule chemistry. The source
code and datasets can be accessed freely at
https://github.com/usccolumbia/GMTransformer
",2022-09-20T01:51:57Z,http://arxiv.org/abs/2209.09406v1,"Lai Wei, Nihang Fu, Yuqi Song, Qian Wang, Jianjun Hu"
HELM: Hierarchical Encoding for mRNA Language Modeling,"  Messenger RNA (mRNA) plays a crucial role in protein synthesis, with its
codon structure directly impacting biological properties. While Language Models
(LMs) have shown promise in analyzing biological sequences, existing approaches
fail to account for the hierarchical nature of mRNA's codon structure. We
introduce Hierarchical Encoding for mRNA Language Modeling (HELM), a novel
pre-training strategy that incorporates codon-level hierarchical structure into
language model training. HELM modulates the loss function based on codon
synonymity, aligning the model's learning process with the biological reality
of mRNA sequences. We evaluate HELM on diverse mRNA datasets and tasks,
demonstrating that HELM outperforms standard language model pre-training as
well as existing foundation model baselines on six diverse downstream property
prediction tasks and an antibody region annotation tasks on average by around
8\%. Additionally, HELM enhances the generative capabilities of language model,
producing diverse mRNA sequences that better align with the underlying true
data distribution compared to non-hierarchical baselines.
",2024-10-16T11:16:47Z,http://arxiv.org/abs/2410.12459v1,"Mehdi Yazdani-Jahromi, Mangal Prakash, Tommaso Mansi, Artem Moskalev, Rui Liao"
"Explaining NonLinear Classification Decisions with Deep Taylor
  Decomposition","  Nonlinear methods such as Deep Neural Networks (DNNs) are the gold standard
for various challenging machine learning problems, e.g., image classification,
natural language processing or human action recognition. Although these methods
perform impressively well, they have a significant disadvantage, the lack of
transparency, limiting the interpretability of the solution and thus the scope
of application in practice. Especially DNNs act as black boxes due to their
multilayer nonlinear structure. In this paper we introduce a novel methodology
for interpreting generic multilayer neural networks by decomposing the network
classification decision into contributions of its input elements. Although our
focus is on image classification, the method is applicable to a broad set of
input data, learning tasks and network architectures. Our method is based on
deep Taylor decomposition and efficiently utilizes the structure of the network
by backpropagating the explanations from the output to the input layer. We
evaluate the proposed method empirically on the MNIST and ILSVRC data sets.
",2015-12-08T14:25:29Z,http://arxiv.org/abs/1512.02479v1,"Gr√©goire Montavon, Sebastian Bach, Alexander Binder, Wojciech Samek, Klaus-Robert M√ºller"
Deep Leakage from Gradients,"  Exchanging gradients is a widely used method in modern multi-node machine
learning system (e.g., distributed training, collaborative learning). For a
long time, people believed that gradients are safe to share: i.e., the training
data will not be leaked by gradient exchange. However, we show that it is
possible to obtain the private training data from the publicly shared
gradients. We name this leakage as Deep Leakage from Gradient and empirically
validate the effectiveness on both computer vision and natural language
processing tasks. Experimental results show that our attack is much stronger
than previous approaches: the recovery is pixel-wise accurate for images and
token-wise matching for texts. We want to raise people's awareness to rethink
the gradient's safety. Finally, we discuss several possible strategies to
prevent such deep leakage. The most effective defense method is gradient
pruning.
",2019-06-21T03:46:43Z,http://arxiv.org/abs/1906.08935v2,"Ligeng Zhu, Zhijian Liu, Song Han"
"Pre-Learning Environment Representations for Data-Efficient Neural
  Instruction Following","  We consider the problem of learning to map from natural language instructions
to state transitions (actions) in a data-efficient manner. Our method takes
inspiration from the idea that it should be easier to ground language to
concepts that have already been formed through pre-linguistic observation. We
augment a baseline instruction-following learner with an initial
environment-learning phase that uses observations of language-free state
transitions to induce a suitable latent representation of actions before
processing the instruction-following training data. We show that mapping to
pre-learned representations substantially improves performance over systems
whose representations are learned from limited instructional data alone.
",2019-07-23T03:11:07Z,http://arxiv.org/abs/1907.09671v1,"David Gaddy, Dan Klein"
"Who's to say what's funny? A computer using Language Models and Deep
  Learning, That's Who!","  Humor is a defining characteristic of human beings. Our goal is to develop
methods that automatically detect humorous statements and rank them on a
continuous scale. In this paper we report on results using a Language Model
approach, and outline our plans for using methods from Deep Learning.
",2017-05-29T16:20:21Z,http://arxiv.org/abs/1705.10272v1,"Xinru Yan, Ted Pedersen"
Investigating Masking-based Data Generation in Language Models,"  The current era of natural language processing (NLP) has been defined by the
prominence of pre-trained language models since the advent of BERT. A feature
of BERT and models with similar architecture is the objective of masked
language modeling, in which part of the input is intentionally masked and the
model is trained to predict this piece of masked information. Data augmentation
is a data-driven technique widely used in machine learning, including research
areas like computer vision and natural language processing, to improve model
performance by artificially augmenting the training data set by designated
techniques. Masked language models (MLM), an essential training feature of
BERT, have introduced a novel approach to perform effective pre-training on
Transformer based models in natural language processing tasks. Recent studies
have utilized masked language model to generate artificially augmented data for
NLP downstream tasks. The experimental results show that Mask based data
augmentation method provides a simple but efficient approach to improve the
model performance. In this paper, we explore and discuss the broader
utilization of these data augmentation methods based on MLM.
",2023-06-16T16:48:27Z,http://arxiv.org/abs/2307.00008v1,Ed S. Ma
A Deep Neural Network Approach To Parallel Sentence Extraction,"  Parallel sentence extraction is a task addressing the data sparsity problem
found in multilingual natural language processing applications. We propose an
end-to-end deep neural network approach to detect translational equivalence
between sentences in two different languages. In contrast to previous
approaches, which typically rely on multiples models and various word alignment
features, by leveraging continuous vector representation of sentences we remove
the need of any domain specific feature engineering. Using a siamese
bidirectional recurrent neural networks, our results against a strong baseline
based on a state-of-the-art parallel sentence extraction system show a
significant improvement in both the quality of the extracted parallel sentences
and the translation performance of statistical machine translation systems. We
believe this study is the first one to investigate deep learning for the
parallel sentence extraction task.
",2017-09-28T02:09:04Z,http://arxiv.org/abs/1709.09783v1,"Francis Gr√©goire, Philippe Langlais"
"Detection of Hate Speech using BERT and Hate Speech Word Embedding with
  Deep Model","  The enormous amount of data being generated on the web and social media has
increased the demand for detecting online hate speech. Detecting hate speech
will reduce their negative impact and influence on others. A lot of effort in
the Natural Language Processing (NLP) domain aimed to detect hate speech in
general or detect specific hate speech such as religion, race, gender, or
sexual orientation. Hate communities tend to use abbreviations, intentional
spelling mistakes, and coded words in their communication to evade detection,
adding more challenges to hate speech detection tasks. Thus, word
representation will play an increasingly pivotal role in detecting hate speech.
This paper investigates the feasibility of leveraging domain-specific word
embedding in Bidirectional LSTM based deep model to automatically
detect/classify hate speech. Furthermore, we investigate the use of the
transfer learning language model (BERT) on hate speech problem as a binary
classification task. The experiments showed that domainspecific word embedding
with the Bidirectional LSTM based deep model achieved a 93% f1-score while BERT
achieved up to 96% f1-score on a combined balanced dataset from available hate
speech datasets.
",2021-11-02T11:42:54Z,http://arxiv.org/abs/2111.01515v1,"Hind Saleh, Areej Alhothali, Kawthar Moria"
"Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing?
  A Structured Review","  Advocates for Neuro-Symbolic Artificial Intelligence (NeSy) assert that
combining deep learning with symbolic reasoning will lead to stronger AI than
either paradigm on its own. As successful as deep learning has been, it is
generally accepted that even our best deep learning systems are not very good
at abstract reasoning. And since reasoning is inextricably linked to language,
it makes intuitive sense that Natural Language Processing (NLP), would be a
particularly well-suited candidate for NeSy. We conduct a structured review of
studies implementing NeSy for NLP, with the aim of answering the question of
whether NeSy is indeed meeting its promises: reasoning, out-of-distribution
generalization, interpretability, learning and reasoning from small data, and
transferability to new domains. We examine the impact of knowledge
representation, such as rules and semantic networks, language structure and
relational structure, and whether implicit or explicit reasoning contributes to
higher promise scores. We find that systems where logic is compiled into the
neural network lead to the most NeSy goals being satisfied, while other factors
such as knowledge representation, or type of neural architecture do not exhibit
a clear correlation with goals being met. We find many discrepancies in how
reasoning is defined, specifically in relation to human level reasoning, which
impact decisions about model architectures and drive conclusions which are not
always consistent across studies. Hence we advocate for a more methodical
approach to the application of theories of human reasoning as well as the
development of appropriate benchmarks, which we hope can lead to a better
understanding of progress in the field. We make our data and code available on
github for further analysis.
",2022-02-24T17:13:33Z,http://arxiv.org/abs/2202.12205v2,"Kyle Hamilton, Aparna Nayak, Bojan Bo≈æiƒá, Luca Longo"
"A Review of the Trends and Challenges in Adopting Natural Language
  Processing Methods for Education Feedback Analysis","  Artificial Intelligence (AI) is a fast-growing area of study that stretching
its presence to many business and research domains. Machine learning, deep
learning, and natural language processing (NLP) are subsets of AI to tackle
different areas of data processing and modelling. This review article presents
an overview of AI impact on education outlining with current opportunities. In
the education domain, student feedback data is crucial to uncover the merits
and demerits of existing services provided to students. AI can assist in
identifying the areas of improvement in educational infrastructure, learning
management systems, teaching practices and study environment. NLP techniques
play a vital role in analyzing student feedback in textual format. This
research focuses on existing NLP methodologies and applications that could be
adapted to educational domain applications like sentiment annotations, entity
annotations, text summarization, and topic modelling. Trends and challenges in
adopting NLP in education were reviewed and explored. Contextbased challenges
in NLP like sarcasm, domain-specific language, ambiguity, and aspect-based
sentiment analysis are explained with existing methodologies to overcome them.
Research community approaches to extract the semantic meaning of emoticons and
special characters in feedback which conveys user opinion and challenges in
adopting NLP in education are explored.
",2023-01-20T23:38:58Z,http://arxiv.org/abs/2301.08826v1,"Thanveer Shaik, Xiaohui Tao, Yan Li, Christopher Dann, Jacquie Mcdonald, Petrea Redmond, Linda Galligan"
Joint Learning of Set Cardinality and State Distribution,"  We present a novel approach for learning to predict sets using deep learning.
In recent years, deep neural networks have shown remarkable results in computer
vision, natural language processing and other related problems. Despite their
success, traditional architectures suffer from a serious limitation in that
they are built to deal with structured input and output data, i.e. vectors or
matrices. Many real-world problems, however, are naturally described as sets,
rather than vectors. Existing techniques that allow for sequential data, such
as recurrent neural networks, typically heavily depend on the input and output
order and do not guarantee a valid solution. Here, we derive in a principled
way, a mathematical formulation for set prediction where the output is
permutation invariant. In particular, our approach jointly learns both the
cardinality and the state distribution of the target set. We demonstrate the
validity of our method on the task of multi-label image classification and
achieve a new state of the art on the PASCAL VOC and MS COCO datasets.
",2017-09-13T00:33:50Z,http://arxiv.org/abs/1709.04093v2,"S. Hamid Rezatofighi, Anton Milan, Qinfeng Shi, Anthony Dick, Ian Reid"
Deep Learning-based Sentiment Analysis of Olympics Tweets,"  Sentiment analysis (SA), is an approach of natural language processing (NLP)
for determining a text's emotional tone by analyzing subjective information
such as views, feelings, and attitudes toward specific topics, products,
services, events, or experiences. This study attempts to develop an advanced
deep learning (DL) model for SA to understand global audience emotions through
tweets in the context of the Olympic Games. The findings represent global
attitudes around the Olympics and contribute to advancing the SA models. We
have used NLP for tweet pre-processing and sophisticated DL models for arguing
with SA, this research enhances the reliability and accuracy of sentiment
classification. The study focuses on data selection, preprocessing,
visualization, feature extraction, and model building, featuring a baseline
Na\""ive Bayes (NB) model and three advanced DL models: Convolutional Neural
Network (CNN), Bidirectional Long Short-Term Memory (BiLSTM), and Bidirectional
Encoder Representations from Transformers (BERT). The results of the
experiments show that the BERT model can efficiently classify sentiments
related to the Olympics, achieving the highest accuracy of 99.23%.
",2024-07-17T07:55:04Z,http://arxiv.org/abs/2407.12376v1,"Indranil Bandyopadhyay, Rahul Karmakar"
"Learning to Attack: Towards Textual Adversarial Attacking in Real-world
  Situations","  Adversarial attacking aims to fool deep neural networks with adversarial
examples. In the field of natural language processing, various textual
adversarial attack models have been proposed, varying in the accessibility to
the victim model. Among them, the attack models that only require the output of
the victim model are more fit for real-world situations of adversarial
attacking. However, to achieve high attack performance, these models usually
need to query the victim model too many times, which is neither efficient nor
viable in practice. To tackle this problem, we propose a reinforcement learning
based attack model, which can learn from attack history and launch attacks more
efficiently. In experiments, we evaluate our model by attacking several
state-of-the-art models on the benchmark datasets of multiple tasks including
sentiment analysis, text classification and natural language inference.
Experimental results demonstrate that our model consistently achieves both
better attack performance and higher efficiency than recently proposed baseline
methods. We also find our attack model can bring more robustness improvement to
the victim model by adversarial training. All the code and data of this paper
will be made public.
",2020-09-19T09:12:24Z,http://arxiv.org/abs/2009.09192v1,"Yuan Zang, Bairu Hou, Fanchao Qi, Zhiyuan Liu, Xiaojun Meng, Maosong Sun"
DeL-haTE: A Deep Learning Tunable Ensemble for Hate Speech Detection,"  Online hate speech on social media has become a fast-growing problem in
recent times. Nefarious groups have developed large content delivery networks
across several main-stream (Twitter and Facebook) and fringe (Gab, 4chan,
8chan, etc.) outlets to deliver cascades of hate messages directed both at
individuals and communities. Thus addressing these issues has become a top
priority for large-scale social media outlets. Three key challenges in
automated detection and classification of hateful content are the lack of
clearly labeled data, evolving vocabulary and lexicon - hashtags, emojis, etc.
- and the lack of baseline models for fringe outlets such as Gab. In this work,
we propose a novel framework with three major contributions. (a) We engineer an
ensemble of deep learning models that combines the strengths of
state-of-the-art approaches, (b) we incorporate a tuning factor into this
framework that leverages transfer learning to conduct automated hate speech
classification on unlabeled datasets, like Gab, and (c) we develop a weak
supervised learning methodology that allows our framework to train on unlabeled
data. Our ensemble models achieve an 83% hate recall on the HON dataset,
surpassing the performance of the state-of-the-art deep models. We demonstrate
that weak supervised training in combination with classifier tuning
significantly increases model performance on unlabeled data from Gab, achieving
a hate recall of 67%.
",2020-11-03T17:32:50Z,http://arxiv.org/abs/2011.01861v1,"Joshua Melton, Arunkumar Bagavathi, Siddharth Krishnan"
"Analyzing the Generalizability of Deep Contextualized Language
  Representations For Text Classification","  This study evaluates the robustness of two state-of-the-art deep contextual
language representations, ELMo and DistilBERT, on supervised learning of binary
protest news classification and sentiment analysis of product reviews. A
""cross-context"" setting is enabled using test sets that are distinct from the
training data. Specifically, in the news classification task, the models are
developed on local news from India and tested on the local news from China. In
the sentiment analysis task, the models are trained on movie reviews and tested
on customer reviews. This comparison is aimed at exploring the limits of the
representative power of today's Natural Language Processing systems on the path
to the systems that are generalizable to real-life scenarios. The models are
fine-tuned and fed into a Feed-Forward Neural Network and a Bidirectional Long
Short Term Memory network. Multinomial Naive Bayes and Linear Support Vector
Machine are used as traditional baselines. The results show that, in binary
text classification, DistilBERT is significantly better than ELMo on
generalizing to the cross-context setting. ELMo is observed to be significantly
more robust to the cross-context test data than both baselines. On the other
hand, the baselines performed comparably well to ELMo when the training and
test data are subsets of the same corpus (no cross-context). DistilBERT is also
found to be 30% smaller and 83% faster than ELMo. The results suggest that
DistilBERT can transfer generic semantic knowledge to other domains better than
ELMo. DistilBERT is also favorable in incorporating into real-life systems for
it requires a smaller computational training budget. When generalization is not
the utmost preference and test domain is similar to the training domain, the
traditional ML algorithms can still be considered as more economic alternatives
to deep language representations.
",2023-03-22T22:31:09Z,http://arxiv.org/abs/2303.12936v1,Berfu Buyukoz
"On the evolution of research in hypersonics: application of natural
  language processing and machine learning","  Research and development in hypersonics have progressed significantly in
recent years, with various military and commercial applications being
demonstrated increasingly. Public and private organizations in several
countries have been investing in hypersonics, with the aim to overtake their
competitors and secure/improve strategic advantage and deterrence. For these
organizations, being able to identify emerging technologies in a timely and
reliable manner is paramount. Recent advances in information technology have
made it possible to analyze large amounts of data, extract hidden patterns, and
provide decision-makers with new insights. In this study, we focus on
scientific publications about hypersonics within the period of 2000-2020, and
employ natural language processing and machine learning to characterize the
research landscape by identifying 12 key latent research themes and analyzing
their temporal evolution. Our publication similarity analysis revealed patterns
that are indicative of cycles during two decades of research. The study offers
a comprehensive analysis of the research field and the fact that the research
themes are algorithmically extracted removes subjectivity from the exercise and
enables consistent comparisons between topics and between time intervals.
",2022-08-17T19:57:31Z,http://arxiv.org/abs/2208.08507v1,"Ashkan Ebadi, Alain Auger, Yvan Gauthier"
Deep Human Answer Understanding for Natural Reverse QA,"  This study focuses on a reverse question answering (QA) procedure, in which
machines proactively raise questions and humans supply the answers. This
procedure exists in many real human-machine interaction applications. However,
a crucial problem in human-machine interaction is answer understanding. The
existing solutions have relied on mandatory option term selection to avoid
automatic answer understanding. However, these solutions have led to unnatural
human-computer interaction and negatively affected user experience. To this
end, the current study proposes a novel deep answer understanding network,
called AntNet, for reverse QA. The network consists of three new modules,
namely, skeleton attention for questions, relevance-aware representation of
answers, and multi-hop based fusion. As answer understanding for reverse QA has
not been explored, a new data corpus is compiled in this study. Experimental
results indicate that our proposed network is significantly better than
existing methods and those modified from classical natural language processing
deep models. The effectiveness of the three new modules is also verified.
",2019-12-01T13:03:03Z,http://arxiv.org/abs/1912.00398v2,"Rujing Yao, Linlin Hou, Lei Yang, Jie Gui, Qing Yin, Ou Wu"
Survey on reinforcement learning for language processing,"  In recent years some researchers have explored the use of reinforcement
learning (RL) algorithms as key components in the solution of various natural
language processing tasks. For instance, some of these algorithms leveraging
deep neural learning have found their way into conversational systems. This
paper reviews the state of the art of RL methods for their possible use for
different problems of natural language processing, focusing primarily on
conversational systems, mainly due to their growing relevance. We provide
detailed descriptions of the problems as well as discussions of why RL is
well-suited to solve them. Also, we analyze the advantages and limitations of
these methods. Finally, we elaborate on promising research directions in
natural language processing that might benefit from reinforcement learning.
",2021-04-12T15:33:11Z,http://arxiv.org/abs/2104.05565v3,"Victor Uc-Cetina, Nicolas Navarro-Guerrero, Anabel Martin-Gonzalez, Cornelius Weber, Stefan Wermter"
PERLEX: A Bilingual Persian-English Gold Dataset for Relation Extraction,"  Relation extraction is the task of extracting semantic relations between
entities in a sentence. It is an essential part of some natural language
processing tasks such as information extraction, knowledge extraction, and
knowledge base population. The main motivations of this research stem from a
lack of a dataset for relation extraction in the Persian language as well as
the necessity of extracting knowledge from the growing big-data in the Persian
language for different applications. In this paper, we present ""PERLEX"" as the
first Persian dataset for relation extraction, which is an expert-translated
version of the ""Semeval-2010-Task-8"" dataset. Moreover, this paper addresses
Persian relation extraction utilizing state-of-the-art language-agnostic
algorithms. We employ six different models for relation extraction on the
proposed bilingual dataset, including a non-neural model (as the baseline),
three neural models, and two deep learning models fed by multilingual-BERT
contextual word representations. The experiments result in the maximum f-score
77.66% (provided by BERTEM-MTB method) as the state-of-the-art of relation
extraction in the Persian language.
",2020-05-13T21:06:59Z,http://arxiv.org/abs/2005.06588v1,"Majid Asgari-Bidhendi, Mehrdad Nasser, Behrooz Janfada, Behrouz Minaei-Bidgoli"
"A Transfer Learning Method for Goal Recognition Exploiting Cross-Domain
  Spatial Features","  The ability to infer the intentions of others, predict their goals, and
deduce their plans are critical features for intelligent agents. For a long
time, several approaches investigated the use of symbolic representations and
inferences with limited success, principally because it is difficult to capture
the cognitive knowledge behind human decisions explicitly. The trend, nowadays,
is increasingly focusing on learning to infer intentions directly from data,
using deep learning in particular. We are now observing interesting
applications of intent classification in natural language processing, visual
activity recognition, and emerging approaches in other domains. This paper
discusses a novel approach combining few-shot and transfer learning with
cross-domain features, to learn to infer the intent of an agent navigating in
physical environments, executing arbitrary long sequences of actions to achieve
their goals. Experiments in synthetic environments demonstrate improved
performance in terms of learning from few samples and generalizing to unseen
configurations, compared to a deep-learning baseline approach.
",2019-11-22T16:53:19Z,http://arxiv.org/abs/1911.10134v1,"Thibault Duhamel, Mariane Maynard, Froduald Kabanza"
Task Transfer and Domain Adaptation for Zero-Shot Question Answering,"  Pretrained language models have shown success in various areas of natural
language processing, including reading comprehension tasks. However, when
applying machine learning methods to new domains, labeled data may not always
be available. To address this, we use supervised pretraining on source-domain
data to reduce sample complexity on domain-specific downstream tasks. We
evaluate zero-shot performance on domain-specific reading comprehension tasks
by combining task transfer with domain adaptation to fine-tune a pretrained
model with no labelled data from the target task. Our approach outperforms
Domain-Adaptive Pretraining on downstream domain-specific reading comprehension
tasks in 3 out of 4 domains.
",2022-06-14T09:10:48Z,http://arxiv.org/abs/2206.06705v1,"Xiang Pan, Alex Sheng, David Shimshoni, Aditya Singhal, Sara Rosenthal, Avirup Sil"
SHAP values for Explaining CNN-based Text Classification Models,"  Deep neural networks are increasingly used in natural language processing
(NLP) models. However, the need to interpret and explain the results from
complex algorithms are limiting their widespread adoption in regulated
industries such as banking. There has been recent work on interpretability of
machine learning algorithms with structured data. But there are only limited
techniques for NLP applications where the problem is more challenging due to
the size of the vocabulary, high-dimensional nature, and the need to consider
textual coherence and language structure. This paper develops a methodology to
compute SHAP values for local explainability of CNN-based text classification
models. The approach is also extended to compute global scores to assess the
importance of features. The results are illustrated on sentiment analysis of
Amazon Electronic Review data.
",2020-08-26T21:28:41Z,http://arxiv.org/abs/2008.11825v2,"Wei Zhao, Tarun Joshi, Vijayan N. Nair, Agus Sudjianto"
"From Rule-Based Models to Deep Learning Transformers Architectures for
  Natural Language Processing and Sign Language Translation Systems: Survey,
  Taxonomy and Performance Evaluation","  With the growing Deaf and Hard of Hearing population worldwide and the
persistent shortage of certified sign language interpreters, there is a
pressing need for an efficient, signs-driven, integrated end-to-end translation
system, from sign to gloss to text and vice-versa. There has been a wealth of
research on machine translations and related reviews. However, there are few
works on sign language machine translation considering the particularity of the
language being continuous and dynamic. This paper aims to address this void,
providing a retrospective analysis of the temporal evolution of sign language
machine translation algorithms and a taxonomy of the Transformers
architectures, the most used approach in language translation. We also present
the requirements of a real-time Quality-of-Service sign language ma-chine
translation system underpinned by accurate deep learning algorithms. We propose
future research directions for sign language translation systems.
",2024-08-27T07:11:45Z,http://arxiv.org/abs/2408.14825v1,"Nada Shahin, Leila Ismail"
Learning Representations of Graph Data -- A Survey,"  Deep Neural Networks have shown tremendous success in the area of object
recognition, image classification and natural language processing. However,
designing optimal Neural Network architectures that can learn and output
arbitrary graphs is an ongoing research problem. The objective of this survey
is to summarize and discuss the latest advances in methods to Learn
Representations of Graph Data. We start by identifying commonly used types of
graph data and review basics of graph theory. This is followed by a discussion
of the relationships between graph kernel methods and neural networks. Next we
identify the major approaches used for learning representations of graph data
namely: Kernel approaches, Convolutional approaches, Graph neural networks
approaches, Graph embedding approaches and Probabilistic approaches. A variety
of methods under each of the approaches are discussed and the survey is
concluded with a brief discussion of the future of learning representation of
graph data.
",2019-06-07T09:52:53Z,http://arxiv.org/abs/1906.02989v2,Mital Kinderkhedia
"Natural Language Processing to Detect Cognitive Concerns in Electronic
  Health Records Using Deep Learning","  Dementia is under-recognized in the community, under-diagnosed by healthcare
professionals, and under-coded in claims data. Information on cognitive
dysfunction, however, is often found in unstructured clinician notes within
medical records but manual review by experts is time consuming and often prone
to errors. Automated mining of these notes presents a potential opportunity to
label patients with cognitive concerns who could benefit from an evaluation or
be referred to specialist care. In order to identify patients with cognitive
concerns in electronic medical records, we applied natural language processing
(NLP) algorithms and compared model performance to a baseline model that used
structured diagnosis codes and medication data only. An attention-based deep
learning model outperformed the baseline model and other simpler models.
",2020-11-12T16:59:56Z,http://arxiv.org/abs/2011.06489v1,"Zhuoqiao Hong, Colin G. Magdamo, Yi-han Sheu, Prathamesh Mohite, Ayush Noori, Elissa M. Ye, Wendong Ge, Haoqi Sun, Laura Brenner, Gregory Robbins, Shibani Mukerji, Sahar Zafar, Nicole Benson, Lidia Moura, John Hsu, Bradley T. Hyman, Michael B. Westover, Deborah Blacker, Sudeshna Das"
Automatic Code Generation using Pre-Trained Language Models,"  Recent advancements in natural language processing \cite{gpt2} \cite{BERT}
have led to near-human performance in multiple natural language tasks. In this
paper, we seek to understand whether similar techniques can be applied to a
highly structured environment with strict syntax rules. Specifically, we
propose an end-to-end machine learning model for code generation in the Python
language built on-top of pre-trained language models. We demonstrate that a
fine-tuned model can perform well in code generation tasks, achieving a BLEU
score of 0.22, an improvement of 46\% over a reasonable sequence-to-sequence
baseline. All results and related code used for training and data processing
are available on GitHub.
",2021-02-21T07:21:26Z,http://arxiv.org/abs/2102.10535v1,"Luis Perez, Lizi Ottens, Sudharshan Viswanathan"
"PiggyBack: Pretrained Visual Question Answering Environment for Backing
  up Non-deep Learning Professionals","  We propose a PiggyBack, a Visual Question Answering platform that allows
users to apply the state-of-the-art visual-language pretrained models easily.
The PiggyBack supports the full stack of visual question answering tasks,
specifically data processing, model fine-tuning, and result visualisation. We
integrate visual-language models, pretrained by HuggingFace, an open-source API
platform of deep learning technologies; however, it cannot be runnable without
programming skills or deep learning understanding. Hence, our PiggyBack
supports an easy-to-use browser-based user interface with several deep learning
visual language pretrained models for general users and domain experts. The
PiggyBack includes the following benefits: Free availability under the MIT
License, Portability due to web-based and thus runs on almost any platform, A
comprehensive data creation and processing technique, and ease of use on deep
learning-based visual language pretrained models. The demo video is available
on YouTube and can be found at https://youtu.be/iz44RZ1lF4s.
",2022-11-29T05:37:27Z,http://arxiv.org/abs/2211.15940v3,"Zhihao Zhang, Siwen Luo, Junyi Chen, Sijia Lai, Siqu Long, Hyunsuk Chung, Soyeon Caren Han"
Semantic Representation and Inference for NLP,"  Semantic representation and inference is essential for Natural Language
Processing (NLP). The state of the art for semantic representation and
inference is deep learning, and particularly Recurrent Neural Networks (RNNs),
Convolutional Neural Networks (CNNs), and transformer Self-Attention models.
This thesis investigates the use of deep learning for novel semantic
representation and inference, and makes contributions in the following three
areas: creating training data, improving semantic representations and extending
inference learning. In terms of creating training data, we contribute the
largest publicly available dataset of real-life factual claims for the purpose
of automatic claim verification (MultiFC), and we present a novel inference
model composed of multi-scale CNNs with different kernel sizes that learn from
external sources to infer fact checking labels. In terms of improving semantic
representations, we contribute a novel model that captures non-compositional
semantic indicators. By definition, the meaning of a non-compositional phrase
cannot be inferred from the individual meanings of its composing words (e.g.,
hot dog). Motivated by this, we operationalize the compositionality of a phrase
contextually by enriching the phrase representation with external word
embeddings and knowledge graphs. Finally, in terms of inference learning, we
propose a series of novel deep learning architectures that improve inference by
using syntactic dependencies, by ensembling role guided attention heads,
incorporating gating layers, and concatenating multiple heads in novel and
effective ways. This thesis consists of seven publications (five published and
two under review).
",2021-06-15T13:22:48Z,http://arxiv.org/abs/2106.08117v1,Dongsheng Wang
Semantic Adversarial Deep Learning,"  Fueled by massive amounts of data, models produced by machine-learning (ML)
algorithms, especially deep neural networks, are being used in diverse domains
where trustworthiness is a concern, including automotive systems, finance,
health care, natural language processing, and malware detection. Of particular
concern is the use of ML algorithms in cyber-physical systems (CPS), such as
self-driving cars and aviation, where an adversary can cause serious
consequences. However, existing approaches to generating adversarial examples
and devising robust ML algorithms mostly ignore the semantics and context of
the overall system containing the ML component. For example, in an autonomous
vehicle using deep learning for perception, not every adversarial example for
the neural network might lead to a harmful consequence. Moreover, one may want
to prioritize the search for adversarial examples towards those that
significantly modify the desired semantics of the overall system. Along the
same lines, existing algorithms for constructing robust ML algorithms ignore
the specification of the overall system. In this paper, we argue that the
semantics and specification of the overall system has a crucial role to play in
this line of research. We present preliminary research results that support
this claim.
",2018-04-19T09:15:58Z,http://arxiv.org/abs/1804.07045v2,"Tommaso Dreossi, Somesh Jha, Sanjit A. Seshia"
Improving Transparency of Deep Neural Inference Process,"  Deep learning techniques are rapidly advanced recently, and becoming a
necessity component for widespread systems. However, the inference process of
deep learning is black-box, and not very suitable to safety-critical systems
which must exhibit high transparency. In this paper, to address this black-box
limitation, we develop a simple analysis method which consists of 1) structural
feature analysis: lists of the features contributing to inference process, 2)
linguistic feature analysis: lists of the natural language labels describing
the visual attributes for each feature contributing to inference process, and
3) consistency analysis: measuring consistency among input data, inference
(label), and the result of our structural and linguistic feature analysis. Our
analysis is simplified to reflect the actual inference process for high
transparency, whereas it does not include any additional black-box mechanisms
such as LSTM for highly human readable results. We conduct experiments and
discuss the results of our analysis qualitatively and quantitatively, and come
to believe that our work improves the transparency of neural networks.
Evaluated through 12,800 human tasks, 75% workers answer that input data and
result of our feature analysis are consistent, and 70% workers answer that
inference (label) and result of our feature analysis are consistent. In
addition to the evaluation of the proposed analysis, we find that our analysis
also provide suggestions, or possible next actions such as expanding neural
network complexity or collecting training data to improve a neural network.
",2019-03-13T14:11:44Z,http://arxiv.org/abs/1903.05501v1,"Hiroshi Kuwajima, Masayuki Tanaka, Masatoshi Okutomi"
"Mixture of Expert/Imitator Networks: Scalable Semi-supervised Learning
  Framework","  The current success of deep neural networks (DNNs) in an increasingly broad
range of tasks involving artificial intelligence strongly depends on the
quality and quantity of labeled training data. In general, the scarcity of
labeled data, which is often observed in many natural language processing
tasks, is one of the most important issues to be addressed. Semi-supervised
learning (SSL) is a promising approach to overcoming this issue by
incorporating a large amount of unlabeled data. In this paper, we propose a
novel scalable method of SSL for text classification tasks. The unique property
of our method, Mixture of Expert/Imitator Networks, is that imitator networks
learn to ""imitate"" the estimated label distribution of the expert network over
the unlabeled data, which potentially contributes a set of features for the
classification. Our experiments demonstrate that the proposed method
consistently improves the performance of several types of baseline DNNs. We
also demonstrate that our method has the more data, better performance property
with promising scalability to the amount of unlabeled data.
",2018-10-13T02:39:39Z,http://arxiv.org/abs/1810.05788v2,"Shun Kiyono, Jun Suzuki, Kentaro Inui"
BIM: Block-Wise Self-Supervised Learning with Masked Image Modeling,"  Like masked language modeling (MLM) in natural language processing, masked
image modeling (MIM) aims to extract valuable insights from image patches to
enhance the feature extraction capabilities of the underlying deep neural
network (DNN). Contrasted with other training paradigms like supervised
learning and unsupervised contrastive learning, masked image modeling (MIM)
pretraining typically demands significant computational resources in order to
manage large training data batches (e.g., 4096). The significant memory and
computation requirements pose a considerable challenge to its broad adoption.
To mitigate this, we introduce a novel learning framework,
termed~\textit{Block-Wise Masked Image Modeling} (BIM). This framework involves
decomposing the MIM tasks into several sub-tasks with independent computation
patterns, resulting in block-wise back-propagation operations instead of the
traditional end-to-end approach. Our proposed BIM maintains superior
performance compared to conventional MIM while greatly reducing peak memory
consumption. Moreover, BIM naturally enables the concurrent training of
numerous DNN backbones of varying depths. This leads to the creation of
multiple trained DNN backbones, each tailored to different hardware platforms
with distinct computing capabilities. This approach significantly reduces
computational costs in comparison with training each DNN backbone individually.
Our framework offers a promising solution for resource constrained training of
MIM.
",2023-11-28T20:42:30Z,http://arxiv.org/abs/2311.17218v1,"Yixuan Luo, Mengye Ren, Sai Qian Zhang"
SINGA-Easy: An Easy-to-Use Framework for MultiModal Analysis,"  Deep learning has achieved great success in a wide spectrum of multimedia
applications such as image classification, natural language processing and
multimodal data analysis. Recent years have seen the development of many deep
learning frameworks that provide a high-level programming interface for users
to design models, conduct training and deploy inference. However, it remains
challenging to build an efficient end-to-end multimedia application with most
existing frameworks. Specifically, in terms of usability, it is demanding for
non-experts to implement deep learning models, obtain the right settings for
the entire machine learning pipeline, manage models and datasets, and exploit
external data sources all together. Further, in terms of adaptability, elastic
computation solutions are much needed as the actual serving workload fluctuates
constantly, and scaling the hardware resources to handle the fluctuating
workload is typically infeasible. To address these challenges, we introduce
SINGA-Easy, a new deep learning framework that provides distributed
hyper-parameter tuning at the training stage, dynamic computational cost
control at the inference stage, and intuitive user interactions with multimedia
contents facilitated by model explanation. Our experiments on the training and
deployment of multi-modality data analysis applications show that the framework
is both usable and adaptable to dynamic inference loads. We implement
SINGA-Easy on top of Apache SINGA and demonstrate our system with the entire
machine learning life cycle.
",2021-08-03T08:39:54Z,http://arxiv.org/abs/2108.02572v1,"Naili Xing, Sai Ho Yeung, Chenghao Cai, Teck Khim Ng, Wei Wang, Kaiyuan Yang, Nan Yang, Meihui Zhang, Gang Chen, Beng Chin Ooi"
An overview of deep learning in medical imaging focusing on MRI,"  What has happened in machine learning lately, and what does it mean for the
future of medical image analysis? Machine learning has witnessed a tremendous
amount of attention over the last few years. The current boom started around
2009 when so-called deep artificial neural networks began outperforming other
established models on a number of important benchmarks. Deep neural networks
are now the state-of-the-art machine learning models across a variety of areas,
from image analysis to natural language processing, and widely deployed in
academia and industry. These developments have a huge potential for medical
imaging technology, medical data analysis, medical diagnostics and healthcare
in general, slowly being realized. We provide a short overview of recent
advances and some associated challenges in machine learning applied to medical
image processing and image analysis. As this has become a very broad and fast
expanding field we will not survey the entire landscape of applications, but
put particular focus on deep learning in MRI.
  Our aim is threefold: (i) give a brief introduction to deep learning with
pointers to core references; (ii) indicate how deep learning has been applied
to the entire MRI processing chain, from acquisition to image retrieval, from
segmentation to disease prediction; (iii) provide a starting point for people
interested in experimenting and perhaps contributing to the field of machine
learning for medical imaging by pointing out good educational resources,
state-of-the-art open-source code, and interesting sources of data and problems
related medical imaging.
",2018-11-25T16:40:42Z,http://arxiv.org/abs/1811.10052v2,"Alexander Selvikv√•g Lundervold, Arvid Lundervold"
"Neural Natural Language Processing for Unstructured Data in Electronic
  Health Records: a Review","  Electronic health records (EHRs), digital collections of patient healthcare
events and observations, are ubiquitous in medicine and critical to healthcare
delivery, operations, and research. Despite this central role, EHRs are
notoriously difficult to process automatically. Well over half of the
information stored within EHRs is in the form of unstructured text (e.g.
provider notes, operation reports) and remains largely untapped for secondary
use. Recently, however, newer neural network and deep learning approaches to
Natural Language Processing (NLP) have made considerable advances,
outperforming traditional statistical and rule-based systems on a variety of
tasks. In this survey paper, we summarize current neural NLP methods for EHR
applications. We focus on a broad scope of tasks, namely, classification and
prediction, word embeddings, extraction, generation, and other topics such as
question answering, phenotyping, knowledge graphs, medical dialogue,
multilinguality, interpretability, etc.
",2021-07-07T01:50:02Z,http://arxiv.org/abs/2107.02975v1,"Irene Li, Jessica Pan, Jeremy Goldwasser, Neha Verma, Wai Pan Wong, Muhammed Yavuz Nuzumlalƒ±, Benjamin Rosand, Yixin Li, Matthew Zhang, David Chang, R. Andrew Taylor, Harlan M. Krumholz, Dragomir Radev"
"The value of text for small business default prediction: A deep learning
  approach","  Compared to consumer lending, Micro, Small and Medium Enterprise (mSME)
credit risk modelling is particularly challenging, as, often, the same sources
of information are not available. Therefore, it is standard policy for a loan
officer to provide a textual loan assessment to mitigate limited data
availability. In turn, this statement is analysed by a credit expert alongside
any available standard credit data. In our paper, we exploit recent advances
from the field of Deep Learning and Natural Language Processing (NLP),
including the BERT (Bidirectional Encoder Representations from Transformers)
model, to extract information from 60 000 textual assessments provided by a
lender. We consider the performance in terms of the AUC (Area Under the
receiver operating characteristic Curve) and Brier Score metrics and find that
the text alone is surprisingly effective for predicting default. However, when
combined with traditional data, it yields no additional predictive capability,
with performance dependent on the text's length. Our proposed deep learning
model does, however, appear to be robust to the quality of the text and
therefore suitable for partly automating the mSME lending process. We also
demonstrate how the content of loan assessments influences performance, leading
us to a series of recommendations on a new strategy for collecting future mSME
loan assessments.
",2020-03-19T18:15:05Z,http://arxiv.org/abs/2003.08964v4,"Matthew Stevenson, Christophe Mues, Cristi√°n Bravo"
"Deep Active Learning for Sequence Labeling Based on Diversity and
  Uncertainty in Gradient","  Recently, several studies have investigated active learning (AL) for natural
language processing tasks to alleviate data dependency. However, for query
selection, most of these studies mainly rely on uncertainty-based sampling,
which generally does not exploit the structural information of the unlabeled
data. This leads to a sampling bias in the batch active learning setting, which
selects several samples at once. In this work, we demonstrate that the amount
of labeled training data can be reduced using active learning when it
incorporates both uncertainty and diversity in the sequence labeling task. We
examined the effects of our sequence-based approach by selecting weighted
diverse in the gradient embedding approach across multiple tasks, datasets,
models, and consistently outperform classic uncertainty-based sampling and
diversity-based sampling.
",2020-11-27T06:03:27Z,http://arxiv.org/abs/2011.13570v1,Yekyung Kim
Neurosymbolic AI for Situated Language Understanding,"  In recent years, data-intensive AI, particularly the domain of natural
language processing and understanding, has seen significant progress driven by
the advent of large datasets and deep neural networks that have sidelined more
classic AI approaches to the field. These systems can apparently demonstrate
sophisticated linguistic understanding or generation capabilities, but often
fail to transfer their skills to situations they have not encountered before.
We argue that computational situated grounding provides a solution to some of
these learning challenges by creating situational representations that both
serve as a formal model of the salient phenomena, and contain rich amounts of
exploitable, task-appropriate data for training new, flexible computational
models. Our model reincorporates some ideas of classic AI into a framework of
neurosymbolic intelligence, using multimodal contextual modeling of interactive
situations, events, and object properties. We discuss how situated grounding
provides diverse data and multiple levels of modeling for a variety of AI
learning challenges, including learning how to interact with object
affordances, learning semantics for novel structures and configurations, and
transferring such learned knowledge to new objects and situations.
",2020-12-05T05:03:28Z,http://arxiv.org/abs/2012.02947v1,"Nikhil Krishnaswamy, James Pustejovsky"
"Fair Differentiable Neural Network Architecture Search for Long-Tailed
  Data with Self-Supervised Learning","  Recent advancements in artificial intelligence (AI) have positioned deep
learning (DL) as a pivotal technology in fields like computer vision, data
mining, and natural language processing. A critical factor in DL performance is
the selection of neural network architecture. Traditional predefined
architectures often fail to adapt to different data distributions, making it
challenging to achieve optimal performance. Neural architecture search (NAS)
offers a solution by automatically designing architectures tailored to specific
datasets. However, the effectiveness of NAS diminishes on long-tailed datasets,
where a few classes have abundant samples, and many have few, leading to biased
models.In this paper, we explore to improve the searching and training
performance of NAS on long-tailed datasets. Specifically, we first discuss the
related works about NAS and the deep learning method for long-tailed
datasets.Then, we focus on an existing work, called SSF-NAS, which integrates
the self-supervised learning and fair differentiable NAS to making NAS achieve
better performance on long-tailed datasets.An detailed description about the
fundamental techniques for SSF-NAS is provided in this paper, including DARTS,
FairDARTS, and Barlow Twins. Finally, we conducted a series of experiments on
the CIFAR10-LT dataset for performance evaluation, where the results are align
with our expectation.
",2024-06-19T12:39:02Z,http://arxiv.org/abs/2406.16949v1,Jiaming Yan
"Causality Extraction from Nuclear Licensee Event Reports Using a Hybrid
  Framework","  Industry-wide nuclear power plant operating experience is a critical source
of raw data for performing parameter estimations in reliability and risk
models. Much operating experience information pertains to failure events and is
stored as reports containing unstructured data, such as narratives. Event
reports are essential for understanding how failures are initiated and
propagated, including the numerous causal relations involved. Causal relation
extraction using deep learning represents a significant frontier in the field
of natural language processing (NLP), and is crucial since it enables the
interpretation of intricate narratives and connections contained within vast
amounts of written information. This paper proposed a hybrid framework for
causality detection and extraction from nuclear licensee event reports. The
main contributions include: (1) we compiled an LER corpus with 20,129 text
samples for causality analysis, (2) developed an interactive tool for labeling
cause effect pairs, (3) built a deep-learning-based approach for causal
relation detection, and (4) developed a knowledge based cause-effect extraction
approach.
",2024-04-08T16:39:34Z,http://arxiv.org/abs/2404.05656v2,"Shahidur Rahoman Sohag, Sai Zhang, Min Xian, Shoukun Sun, Fei Xu, Zhegang Ma"
"Grassmannian Learning: Embedding Geometry Awareness in Shallow and Deep
  Learning","  Modern machine learning algorithms have been adopted in a range of
signal-processing applications spanning computer vision, natural language
processing, and artificial intelligence. Many relevant problems involve
subspace-structured features, orthogonality constrained or low-rank constrained
objective functions, or subspace distances. These mathematical characteristics
are expressed naturally using the Grassmann manifold. Unfortunately, this fact
is not yet explored in many traditional learning algorithms. In the last few
years, there have been growing interests in studying Grassmann manifold to
tackle new learning problems. Such attempts have been reassured by substantial
performance improvements in both classic learning and learning using deep
neural networks. We term the former as shallow and the latter deep Grassmannian
learning. The aim of this paper is to introduce the emerging area of
Grassmannian learning by surveying common mathematical problems and primary
solution approaches, and overviewing various applications. We hope to inspire
practitioners in different fields to adopt the powerful tool of Grassmannian
learning in their research.
",2018-08-07T06:54:06Z,http://arxiv.org/abs/1808.02229v2,"Jiayao Zhang, Guangxu Zhu, Robert W. Heath Jr., Kaibin Huang"
"Striking a Balance between Classical and Deep Learning Approaches in
  Natural Language Processing Pedagogy","  While deep learning approaches represent the state-of-the-art of natural
language processing (NLP) today, classical algorithms and approaches still find
a place in NLP textbooks and courses of recent years. This paper discusses the
perspectives of conveners of two introductory NLP courses taught in Australia
and India, and examines how classical and deep learning approaches can be
balanced within the lecture plan and assessments of the courses. We also draw
parallels with the objects-first and objects-later debate in CS1 education. We
observe that teaching classical approaches adds value to student learning by
building an intuitive understanding of NLP problems, potential solutions, and
even deep learning models themselves. Despite classical approaches not being
state-of-the-art, the paper makes a case for their inclusion in NLP courses
today.
",2024-05-16T07:14:13Z,http://arxiv.org/abs/2405.09854v2,"Aditya Joshi, Jake Renzella, Pushpak Bhattacharyya, Saurav Jha, Xiangyu Zhang"
Deep Latent Defence,"  Deep learning methods have shown state of the art performance in a range of
tasks from computer vision to natural language processing. However, it is well
known that such systems are vulnerable to attackers who craft inputs in order
to cause misclassification. The level of perturbation an attacker needs to
introduce in order to cause such a misclassification can be extremely small,
and often imperceptible. This is of significant security concern, particularly
where misclassification can cause harm to humans.
  We thus propose Deep Latent Defence, an architecture which seeks to combine
adversarial training with a detection system. At its core Deep Latent Defence
has a adversarially trained neural network. A series of encoders take the
intermediate layer representation of data as it passes though the network and
project it to a latent space which we use for detecting adversarial samples via
a $k$-nn classifier. We present results using both grey and white box
attackers, as well as an adaptive $L_{\infty}$ bounded attack which was
constructed specifically to try and evade our defence. We find that even under
the strongest attacker model that we have investigated our defence is able to
offer significant defensive benefits.
",2019-10-09T12:00:52Z,http://arxiv.org/abs/1910.03916v2,"Giulio Zizzo, Chris Hankin, Sergio Maffeis, Kevin Jones"
"Audacity of huge: overcoming challenges of data scarcity and data
  quality for machine learning in computational materials discovery","  Machine learning (ML)-accelerated discovery requires large amounts of
high-fidelity data to reveal predictive structure-property relationships. For
many properties of interest in materials discovery, the challenging nature and
high cost of data generation has resulted in a data landscape that is both
scarcely populated and of dubious quality. Data-driven techniques starting to
overcome these limitations include the use of consensus across functionals in
density functional theory, the development of new functionals or accelerated
electronic structure theories, and the detection of where computationally
demanding methods are most necessary. When properties cannot be reliably
simulated, large experimental data sets can be used to train ML models. In the
absence of manual curation, increasingly sophisticated natural language
processing and automated image analysis are making it possible to learn
structure-property relationships from the literature. Models trained on these
data sets will improve as they incorporate community feedback.
",2021-11-02T21:43:58Z,http://arxiv.org/abs/2111.01905v1,"Aditya Nandy, Chenru Duan, Heather J. Kulik"
A Survey on Few-Shot Class-Incremental Learning,"  Large deep learning models are impressive, but they struggle when real-time
data is not available. Few-shot class-incremental learning (FSCIL) poses a
significant challenge for deep neural networks to learn new tasks from just a
few labeled samples without forgetting the previously learned ones. This setup
easily leads to catastrophic forgetting and overfitting problems, severely
affecting model performance. Studying FSCIL helps overcome deep learning model
limitations on data volume and acquisition time, while improving practicality
and adaptability of machine learning models. This paper provides a
comprehensive survey on FSCIL. Unlike previous surveys, we aim to synthesize
few-shot learning and incremental learning, focusing on introducing FSCIL from
two perspectives, while reviewing over 30 theoretical research studies and more
than 20 applied research studies. From the theoretical perspective, we provide
a novel categorization approach that divides the field into five subcategories,
including traditional machine learning methods, meta-learning based methods,
feature and feature space-based methods, replay-based methods, and dynamic
network structure-based methods. We also evaluate the performance of recent
theoretical research on benchmark datasets of FSCIL. From the application
perspective, FSCIL has achieved impressive achievements in various fields of
computer vision such as image classification, object detection, and image
segmentation, as well as in natural language processing and graph. We summarize
the important applications. Finally, we point out potential future research
directions, including applications, problem setups, and theory development.
Overall, this paper offers a comprehensive analysis of the latest advances in
FSCIL from a methodological, performance, and application perspective.
",2023-04-17T10:15:08Z,http://arxiv.org/abs/2304.08130v2,"Songsong Tian, Lusi Li, Weijun Li, Hang Ran, Xin Ning, Prayag Tiwari"
"Reducing Labeling Costs in Sentiment Analysis via Semi-Supervised
  Learning","  Labeling datasets is a noteworthy challenge in machine learning, both in
terms of cost and time. This research, however, leverages an efficient answer.
By exploring label propagation in semi-supervised learning, we can
significantly reduce the number of labels required compared to traditional
methods. We employ a transductive label propagation method based on the
manifold assumption for text classification. Our approach utilizes a
graph-based method to generate pseudo-labels for unlabeled data for the text
classification task, which are then used to train deep neural networks. By
extending labels based on cosine proximity within a nearest neighbor graph from
network embeddings, we combine unlabeled data into supervised learning, thereby
reducing labeling costs. Based on previous successes in other domains, this
study builds and evaluates this approach's effectiveness in sentiment analysis,
presenting insights into semi-supervised learning.
",2024-10-15T07:25:33Z,http://arxiv.org/abs/2410.11355v1,"Minoo Jafarlou, Mario M. Kubek"
"Hindi/Bengali Sentiment Analysis Using Transfer Learning and Joint Dual
  Input Learning with Self Attention","  Sentiment Analysis typically refers to using natural language processing,
text analysis and computational linguistics to extract affect and emotion based
information from text data. Our work explores how we can effectively use deep
neural networks in transfer learning and joint dual input learning settings to
effectively classify sentiments and detect hate speech in Hindi and Bengali
data. We start by training Word2Vec word embeddings for Hindi \textbf{HASOC
dataset} and Bengali hate speech and then train LSTM and subsequently, employ
parameter sharing based transfer learning to Bengali sentiment classifiers by
reusing and fine-tuning the trained weights of Hindi classifiers with both
classifier being used as baseline in our study. Finally, we use BiLSTM with
self attention in joint dual input learning setting where we train a single
neural network on Hindi and Bengali dataset simultaneously using their
respective embeddings.
",2022-02-11T05:36:11Z,http://arxiv.org/abs/2202.05457v1,"Shahrukh Khan, Mahnoor Shahid"
ChatGPT as your Personal Data Scientist,"  The rise of big data has amplified the need for efficient, user-friendly
automated machine learning (AutoML) tools. However, the intricacy of
understanding domain-specific data and defining prediction tasks necessitates
human intervention making the process time-consuming while preventing full
automation. Instead, envision an intelligent agent capable of assisting users
in conducting AutoML tasks through intuitive, natural conversations without
requiring in-depth knowledge of the underlying machine learning (ML) processes.
This agent's key challenge is to accurately comprehend the user's prediction
goals and, consequently, formulate precise ML tasks, adjust data sets and model
parameters accordingly, and articulate results effectively. In this paper, we
take a pioneering step towards this ambitious goal by introducing a
ChatGPT-based conversational data-science framework to act as a ""personal data
scientist"". Precisely, we utilize Large Language Models (ChatGPT) to build a
natural interface between the users and the ML models (Scikit-Learn), which in
turn, allows us to approach this ambitious problem with a realistic solution.
  Our model pivots around four dialogue states: Data Visualization, Task
Formulation, Prediction Engineering, and Result Summary and Recommendation.
Each state marks a unique conversation phase, impacting the overall user-system
interaction. Multiple LLM instances, serving as ""micro-agents"", ensure a
cohesive conversation flow, granting us granular control over the
conversation's progression. In summary, we developed an end-to-end system that
not only proves the viability of the novel concept of conversational data
science but also underscores the potency of LLMs in solving complex tasks.
Interestingly, its development spotlighted several critical weaknesses in the
current LLMs (ChatGPT) and highlighted substantial opportunities for
improvement.
",2023-05-23T04:00:16Z,http://arxiv.org/abs/2305.13657v1,"Md Mahadi Hassan, Alex Knipper, Shubhra Kanti Karmaker Santu"
"TCM-SD: A Benchmark for Probing Syndrome Differentiation via Natural
  Language Processing","  Traditional Chinese Medicine (TCM) is a natural, safe, and effective therapy
that has spread and been applied worldwide. The unique TCM diagnosis and
treatment system requires a comprehensive analysis of a patient's symptoms
hidden in the clinical record written in free text. Prior studies have shown
that this system can be informationized and intelligentized with the aid of
artificial intelligence (AI) technology, such as natural language processing
(NLP). However, existing datasets are not of sufficient quality nor quantity to
support the further development of data-driven AI technology in TCM. Therefore,
in this paper, we focus on the core task of the TCM diagnosis and treatment
system -- syndrome differentiation (SD) -- and we introduce the first public
large-scale dataset for SD, called TCM-SD. Our dataset contains 54,152
real-world clinical records covering 148 syndromes. Furthermore, we collect a
large-scale unlabelled textual corpus in the field of TCM and propose a
domain-specific pre-trained language model, called ZY-BERT. We conducted
experiments using deep neural networks to establish a strong performance
baseline, reveal various challenges in SD, and prove the potential of
domain-specific pre-trained language model. Our study and analysis reveal
opportunities for incorporating computer science and linguistics knowledge to
explore the empirical validity of TCM theories.
",2022-03-21T09:59:54Z,http://arxiv.org/abs/2203.10839v2,"Mucheng Ren, Heyan Huang, Yuxiang Zhou, Qianwen Cao, Yuan Bu, Yang Gao"
"The Unreasonable Effectiveness of Deep Learning in Artificial
  Intelligence","  Deep learning networks have been trained to recognize speech, caption
photographs and translate text between languages at high levels of performance.
Although applications of deep learning networks to real world problems have
become ubiquitous, our understanding of why they are so effective is lacking.
These empirical results should not be possible according to sample complexity
in statistics and non-convex optimization theory. However, paradoxes in the
training and effectiveness of deep learning networks are being investigated and
insights are being found in the geometry of high-dimensional spaces. A
mathematical theory of deep learning would illuminate how they function, allow
us to assess the strengths and weaknesses of different network architectures
and lead to major improvements. Deep learning has provided natural ways for
humans to communicate with digital devices and is foundational for building
artificial general intelligence. Deep learning was inspired by the architecture
of the cerebral cortex and insights into autonomy and general intelligence may
be found in other brain regions that are essential for planning and survival,
but major breakthroughs will be needed to achieve these goals.
",2020-02-12T05:25:15Z,http://arxiv.org/abs/2002.04806v1,Terrence J. Sejnowski
Active Learning for Classifying 2D Grid-Based Level Completability,"  Determining the completability of levels generated by procedural generators
such as machine learning models can be challenging, as it can involve the use
of solver agents that often require a significant amount of time to analyze and
solve levels. Active learning is not yet widely adopted in game evaluations,
although it has been used successfully in natural language processing, image
and speech recognition, and computer vision, where the availability of labeled
data is limited or expensive. In this paper, we propose the use of active
learning for learning level completability classification. Through an active
learning approach, we train deep-learning models to classify the completability
of generated levels for Super Mario Bros., Kid Icarus, and a Zelda-like game.
We compare active learning for querying levels to label with completability
against random queries. Our results show using an active learning approach to
label levels results in better classifier performance with the same amount of
labeled data.
",2023-09-08T14:56:22Z,http://arxiv.org/abs/2309.04367v1,"Mahsa Bazzaz, Seth Cooper"
Deep Learning for Digital Text Analytics: Sentiment Analysis,"  In today's scenario, imagining a world without negativity is something very
unrealistic, as bad NEWS spreads more virally than good ones. Though it seems
impractical in real life, this could be implemented by building a system using
Machine Learning and Natural Language Processing techniques in identifying the
news datum with negative shade and filter them by taking only the news with
positive shade (good news) to the end user. In this work, around two lakhs
datum have been trained and tested using a combination of rule-based and data
driven approaches. VADER along with a filtration method has been used as an
annotating tool followed by statistical Machine Learning approach that have
used Document Term Matrix (representation) and Support Vector Machine
(classification). Deep Learning algorithms then came into picture to make this
system reliable (Doc2Vec) which finally ended up with Convolutional Neural
Network(CNN) that yielded better results than the other experimented modules.
It showed up a training accuracy of 96%, while a test accuracy of (internal and
external news datum) above 85% was obtained.
",2018-04-10T18:10:33Z,http://arxiv.org/abs/1804.03673v1,"Reshma U, Barathi Ganesh H B, Mandar Kale, Prachi Mankame, Gouri Kulkarni"
"Comparative Study of Sentiment Analysis for Multi-Sourced Social Media
  Platforms","  There is a vast amount of data generated every second due to the rapidly
growing technology in the current world. This area of research attempts to
determine the feelings or opinions of people on social media posts. The dataset
we used was a multi-source dataset from the comment section of various social
networking sites like Twitter, Reddit, etc. Natural Language Processing
Techniques were employed to perform sentiment analysis on the obtained dataset.
In this paper, we provide a comparative analysis using techniques of
lexicon-based, machine learning and deep learning approaches. The Machine
Learning algorithm used in this work is Naive Bayes, the Lexicon-based approach
used in this work is TextBlob, and the deep-learning algorithm used in this
work is LSTM.
",2022-12-09T06:33:49Z,http://arxiv.org/abs/2212.04688v1,"Keshav Kapur, Rajitha Harikrishnan"
"Learn to Explain: Multimodal Reasoning via Thought Chains for Science
  Question Answering","  When answering a question, humans utilize the information available across
different modalities to synthesize a consistent and complete chain of thought
(CoT). This process is normally a black box in the case of deep learning models
like large-scale language models. Recently, science question benchmarks have
been used to diagnose the multi-hop reasoning ability and interpretability of
an AI system. However, existing datasets fail to provide annotations for the
answers, or are restricted to the textual-only modality, small scales, and
limited domain diversity. To this end, we present Science Question Answering
(ScienceQA), a new benchmark that consists of ~21k multimodal multiple choice
questions with a diverse set of science topics and annotations of their answers
with corresponding lectures and explanations. We further design language models
to learn to generate lectures and explanations as the chain of thought (CoT) to
mimic the multi-hop reasoning process when answering ScienceQA questions.
ScienceQA demonstrates the utility of CoT in language models, as CoT improves
the question answering performance by 1.20% in few-shot GPT-3 and 3.99% in
fine-tuned UnifiedQA. We also explore the upper bound for models to leverage
explanations by feeding those in the input; we observe that it improves the
few-shot performance of GPT-3 by 18.96%. Our analysis further shows that
language models, similar to humans, benefit from explanations to learn from
fewer data and achieve the same performance with just 40% of the data. The data
and code are available at https://scienceqa.github.io.
",2022-09-20T07:04:24Z,http://arxiv.org/abs/2209.09513v2,"Pan Lu, Swaroop Mishra, Tony Xia, Liang Qiu, Kai-Wei Chang, Song-Chun Zhu, Oyvind Tafjord, Peter Clark, Ashwin Kalyan"
"Autonomous development and learning in artificial intelligence and
  robotics: Scaling up deep learning to human--like learning","  Autonomous lifelong development and learning is a fundamental capability of
humans, differentiating them from current deep learning systems. However, other
branches of artificial intelligence have designed crucial ingredients towards
autonomous learning: curiosity and intrinsic motivation, social learning and
natural interaction with peers, and embodiment. These mechanisms guide
exploration and autonomous choice of goals, and integrating them with deep
learning opens stimulating perspectives. Deep learning (DL) approaches made
great advances in artificial intelligence, but are still far away from human
learning. As argued convincingly by Lake et al., differences include human
capabilities to learn causal models of the world from very little data,
leveraging compositional representations and priors like intuitive physics and
psychology. However, there are other fundamental differences between current DL
systems and human learning, as well as technical ingredients to fill this gap,
that are either superficially, or not adequately, discussed by Lake et al.
These fundamental mechanisms relate to autonomous development and learning.
They are bound to play a central role in artificial intelligence in the future.
Current DL systems require engineers to manually specify a task-specific
objective function for every new task, and learn through off-line processing of
large training databases. On the contrary, humans learn autonomously open-ended
repertoires of skills, deciding for themselves which goals to pursue or value,
and which skills to explore, driven by intrinsic motivation/curiosity and
social learning through natural interaction with peers. Such learning processes
are incremental, online, and progressive. Human child development involves a
progressive increase of complexity in a curriculum of learning where skills are
explored, acquired, and built on each other, through particular ordering and
timing. Finally, human learning happens in the physical world, and through
bodily and physical experimentation, under severe constraints on energy, time,
and computational resources. In the two last decades, the field of
Developmental and Cognitive Robotics (Cangelosi and Schlesinger, 2015, Asada et
al., 2009), in strong interaction with developmental psychology and
neuroscience, has achieved significant advances in computational
",2017-12-05T14:03:56Z,http://arxiv.org/abs/1712.01626v1,Pierre-Yves Oudeyer
"Few-Shot Cross-Lingual Transfer for Prompting Large Language Models in
  Low-Resource Languages","  Large pre-trained language models (PLMs) are at the forefront of advances in
Natural Language Processing. One widespread use case of PLMs is ""prompting"" -
or in-context learning - where a user provides a description of a task and some
completed examples of the task to a PLM as context before prompting the PLM to
perform the task on a new example. Only the largest, most capable PLMs are able
to perform in-context learning effectively, and these models are typically
trained with a predominantly English corpus, leaving all other languages
behind. The data limitations in most languages preclude the training of
language-specific PLMs capable of prompting. Albeit the surge in work of
prompting settings, it is still unclear how PLMs should be adapted
cross-lingually specifically for prompting. We evaluate the possible methods to
adapt LLaMa, a 7B parameter open-source PLM mainly trained in English, for
prompting in low-resource languages, namely for Kinyarwanda, Hausa, and
Luganda. We consider three methods: few-shot prompting (prompt),
language-adaptive fine-tuning (LAFT), and neural machine translation
(translate), and evaluate on abstractive summarization, multi-class topic
classification, and named-entity recognition. Although LAFT carries the
greatest compute cost and intuitively should lead to the best results, our
experiments exhibit that LAFT is only occasionally the optimal choice for
adapting PLMs for prompting. Rather, the translate and prompt settings are a
compute-efficient and cost-effective method of few-shot prompting for the
selected low-resource languages. We find that the results are task and language
dependent but find that the prompting method is the best on average across all
tasks and languages. Results show that the prompt setting performs better than
both translating and LAFT with statistical significance for all shots when
aggregated across all tasks and languages.
",2024-03-09T21:36:13Z,http://arxiv.org/abs/2403.06018v1,Christopher Toukmaji
"Digestion Algorithm in Hierarchical Symbolic Forests: A Fast Text
  Normalization Algorithm and Semantic Parsing Framework for Specific Scenarios
  and Lightweight Deployment","  Text Normalization and Semantic Parsing have numerous applications in natural
language processing, such as natural language programming, paraphrasing, data
augmentation, constructing expert systems, text matching, and more. Despite the
prominent achievements of deep learning in Large Language Models (LLMs), the
interpretability of neural network architectures is still poor, which affects
their credibility and hence limits the deployments of risk-sensitive scenarios.
In certain scenario-specific domains with scarce data, rapidly obtaining a
large number of supervised learning labels is challenging, and the workload of
manually labeling data would be enormous. Catastrophic forgetting in neural
networks further leads to low data utilization rates. In situations where swift
responses are vital, the density of the model makes local deployment difficult
and the response time long, which is not conducive to local applications of
these fields. Inspired by the multiplication rule, a principle of combinatorial
mathematics, and human thinking patterns, a multilayer framework along with its
algorithm, the Digestion Algorithm in Hierarchical Symbolic Forests (DAHSF), is
proposed to address these above issues, combining text normalization and
semantic parsing workflows. The Chinese Scripting Language ""Fire Bunny
Intelligent Development Platform V2.0"" is an important test and application of
the technology discussed in this paper. DAHSF can run locally in
scenario-specific domains on little datasets, with model size and memory usage
optimized by at least two orders of magnitude, thus improving the execution
speed, and possessing a promising optimization outlook.
",2024-12-18T17:05:49Z,http://arxiv.org/abs/2412.14054v1,Kevin You
GenAug: Data Augmentation for Finetuning Text Generators,"  In this paper, we investigate data augmentation for text generation, which we
call GenAug. Text generation and language modeling are important tasks within
natural language processing, and are especially challenging for low-data
regimes. We propose and evaluate various augmentation methods, including some
that incorporate external knowledge, for finetuning GPT-2 on a subset of Yelp
Reviews. We also examine the relationship between the amount of augmentation
and the quality of the generated text. We utilize several metrics that evaluate
important aspects of the generated text including its diversity and fluency.
Our experiments demonstrate that insertion of character-level synthetic noise
and keyword replacement with hypernyms are effective augmentation methods, and
that the quality of generations improves to a peak at approximately three times
the amount of original data.
",2020-10-05T05:46:39Z,http://arxiv.org/abs/2010.01794v2,"Steven Y. Feng, Varun Gangal, Dongyeop Kang, Teruko Mitamura, Eduard Hovy"
"One Single Deep Bidirectional LSTM Network for Word Sense Disambiguation
  of Text Data","  Due to recent technical and scientific advances, we have a wealth of
information hidden in unstructured text data such as offline/online narratives,
research articles, and clinical reports. To mine these data properly,
attributable to their innate ambiguity, a Word Sense Disambiguation (WSD)
algorithm can avoid numbers of difficulties in Natural Language Processing
(NLP) pipeline. However, considering a large number of ambiguous words in one
language or technical domain, we may encounter limiting constraints for proper
deployment of existing WSD models. This paper attempts to address the problem
of one-classifier-per-one-word WSD algorithms by proposing a single
Bidirectional Long Short-Term Memory (BLSTM) network which by considering
senses and context sequences works on all ambiguous words collectively.
Evaluated on SensEval-3 benchmark, we show the result of our model is
comparable with top-performing WSD algorithms. We also discuss how applying
additional modifications alleviates the model fault and the need for more
training data.
",2018-02-25T18:51:53Z,http://arxiv.org/abs/1802.09059v1,"Ahmad Pesaranghader, Ali Pesaranghader, Stan Matwin, Marina Sokolova"
A Comprehensive Review on Summarizing Financial News Using Deep Learning,"  Investors make investment decisions depending on several factors such as
fundamental analysis, technical analysis, and quantitative analysis. Another
factor on which investors can make investment decisions is through sentiment
analysis of news headlines, the sole purpose of this study. Natural Language
Processing techniques are typically used to deal with such a large amount of
data and get valuable information out of it. NLP algorithms convert raw text
into numerical representations that machines can easily understand and
interpret. This conversion can be done using various embedding techniques. In
this research, embedding techniques used are BoW, TF-IDF, Word2Vec, BERT,
GloVe, and FastText, and then fed to deep learning models such as RNN and LSTM.
This work aims to evaluate these model's performance to choose the robust model
in identifying the significant factors influencing the prediction. During this
research, it was expected that Deep Leaming would be applied to get the desired
results or achieve better accuracy than the state-of-the-art. The models are
compared to check their outputs to know which one has performed better.
",2021-09-21T12:00:31Z,http://arxiv.org/abs/2109.10118v1,"Saurabh Kamal, Sahil Sharma"
"Feature-rich multiplex lexical networks reveal mental strategies of
  early language learning","  Knowledge in the human mind exhibits a dualistic vector/network nature.
Modelling words as vectors is key to natural language processing, whereas
networks of word associations can map the nature of semantic memory. We
reconcile these paradigms - fragmented across linguistics, psychology and
computer science - by introducing FEature-Rich MUltiplex LEXical (FERMULEX)
networks. This novel framework merges structural similarities in networks and
vector features of words, which can be combined or explored independently.
Similarities model heterogenous word associations across
semantic/syntactic/phonological aspects of knowledge. Words are enriched with
multi-dimensional feature embeddings including frequency, age of acquisition,
length and polysemy. These aspects enable unprecedented explorations of
cognitive knowledge. Through CHILDES data, we use FERMULEX networks to model
normative language acquisition by 1000 toddlers between 18 and 30 months.
Similarities and embeddings capture word homophily via conformity, which
measures assortative mixing via distance and features. Conformity unearths a
language kernel of frequent/polysemous/short nouns and verbs key for basic
sentence production, supporting recent evidence of children's syntactic
constructs emerging at 30 months. This kernel is invisible to network
core-detection and feature-only clustering: It emerges from the dual
vector/network nature of words. Our quantitative analysis reveals two key
strategies in early word learning. Modelling word acquisition as random walks
on FERMULEX topology, we highlight non-uniform filling of communicative
developmental inventories (CDIs). Conformity-based walkers lead to accurate
(75%), precise (55%) and partially well-recalled (34%) predictions of early
word learning in CDIs, providing quantitative support to previous empirical
findings and developmental theories.
",2022-01-13T16:44:51Z,http://arxiv.org/abs/2201.05061v1,"Salvatore Citraro, Michael S. Vitevitch, Massimo Stella, Giulio Rossetti"
"Complex-Valued Neural Networks for Data-Driven Signal Processing and
  Signal Understanding","  Complex-valued neural networks have emerged boasting superior modeling
performance for many tasks across the signal processing, sensing, and
communications arenas. However, developing complex-valued models currently
demands development of basic deep learning operations, such as linear or
convolution layers, as modern deep learning frameworks like PyTorch and Tensor
flow do not adequately support complex-valued neural networks. This paper
overviews a package built on PyTorch with the intention of implementing
light-weight interfaces for common complex-valued neural network operations and
architectures. Similar to natural language understanding (NLU), which as
recently made tremendous leaps towards text-based intelligence, RF Signal
Understanding (RFSU) is a promising field extending conventional signal
processing algorithms using a hybrid approach of signal mechanics-based insight
with data-driven modeling power. Notably, we include efficient implementations
for linear, convolution, and attention modules in addition to activation
functions and normalization layers such as batchnorm and layernorm.
Additionally, we include efficient implementations of manifold-based
complex-valued neural network layers that have shown tremendous promise but
remain relatively unexplored in many research contexts. Although there is an
emphasis on 1-D data tensors, due to a focus on signal processing,
communications, and radar data, many of the routines are implemented for 2-D
and 3-D data as well. Specifically, the proposed approach offers a useful set
of tools and documentation for data-driven signal processing research and
practical implementation.
",2023-09-14T16:55:28Z,http://arxiv.org/abs/2309.07948v1,Josiah W. Smith
"An ensemble deep learning technique for detecting suicidal ideation from
  posts in social media platforms","  Suicidal ideation detection from social media is an evolving research with
great challenges. Many of the people who have the tendency to suicide share
their thoughts and opinions through social media platforms. As part of many
researches it is observed that the publicly available posts from social media
contain valuable criteria to effectively detect individuals with suicidal
thoughts. The most difficult part to prevent suicide is to detect and
understand the complex risk factors and warning signs that may lead to suicide.
This can be achieved by identifying the sudden changes in a user behavior
automatically. Natural language processing techniques can be used to collect
behavioral and textual features from social media interactions and these
features can be passed to a specially designed framework to detect anomalies in
human interactions that are indicators of suicidal intentions. We can achieve
fast detection of suicidal ideation using deep learning and/or machine learning
based classification approaches. For such a purpose, we can employ the
combination of LSTM and CNN models to detect such emotions from posts of the
users. In order to improve the accuracy, some approaches like using more data
for training, using attention model to improve the efficiency of existing
models etc. could be done. This paper proposes a LSTM-Attention-CNN combined
model to analyze social media submissions to detect any underlying suicidal
intentions. During evaluations, the proposed model demonstrated an accuracy of
90.3 percent and an F1-score of 92.6 percent, which is greater than the
baseline models.
",2021-12-17T15:34:03Z,http://arxiv.org/abs/2112.10609v1,"Shini Renjith, Annie Abraham, Surya B. Jyothi, Lekshmi Chandran, Jincy Thomson"
Deep Joint Entity Disambiguation with Local Neural Attention,"  We propose a novel deep learning model for joint document-level entity
disambiguation, which leverages learned neural representations. Key components
are entity embeddings, a neural attention mechanism over local context windows,
and a differentiable joint inference stage for disambiguation. Our approach
thereby combines benefits of deep learning with more traditional approaches
such as graphical models and probabilistic mention-entity maps. Extensive
experiments show that we are able to obtain competitive or state-of-the-art
accuracy at moderate computational costs.
",2017-04-17T10:18:32Z,http://arxiv.org/abs/1704.04920v3,"Octavian-Eugen Ganea, Thomas Hofmann"
"Automated Utterance Labeling of Conversations Using Natural Language
  Processing","  Conversational data is essential in psychology because it can help
researchers understand individuals cognitive processes, emotions, and
behaviors. Utterance labelling is a common strategy for analyzing this type of
data. The development of NLP algorithms allows researchers to automate this
task. However, psychological conversational data present some challenges to NLP
researchers, including multilabel classification, a large number of classes,
and limited available data. This study explored how automated labels generated
by NLP methods are comparable to human labels in the context of conversations
on adulthood transition. We proposed strategies to handle three common
challenges raised in psychological studies. Our findings showed that the deep
learning method with domain adaptation (RoBERTa-CON) outperformed all other
machine learning methods; and the hierarchical labelling system that we
proposed was shown to help researchers strategically analyze conversational
data. Our Python code and NLP model are available at
https://github.com/mlaricheva/automated_labeling.
",2022-08-12T23:03:45Z,http://arxiv.org/abs/2208.06525v1,"Maria Laricheva, Chiyu Zhang, Yan Liu, Guanyu Chen, Terence Tracey, Richard Young, Giuseppe Carenini"
"UIT-ViIC: A Dataset for the First Evaluation on Vietnamese Image
  Captioning","  Image Captioning, the task of automatic generation of image captions, has
attracted attentions from researchers in many fields of computer science, being
computer vision, natural language processing and machine learning in recent
years. This paper contributes to research on Image Captioning task in terms of
extending dataset to a different language - Vietnamese. So far, there is no
existed Image Captioning dataset for Vietnamese language, so this is the
foremost fundamental step for developing Vietnamese Image Captioning. In this
scope, we first build a dataset which contains manually written captions for
images from Microsoft COCO dataset relating to sports played with balls, we
called this dataset UIT-ViIC. UIT-ViIC consists of 19,250 Vietnamese captions
for 3,850 images. Following that, we evaluate our dataset on deep neural
network models and do comparisons with English dataset and two Vietnamese
datasets built by different methods. UIT-ViIC is published on our lab website
for research purposes.
",2020-02-01T09:26:07Z,http://arxiv.org/abs/2002.00175v1,"Quan Hoang Lam, Quang Duy Le, Kiet Van Nguyen, Ngan Luu-Thuy Nguyen"
"One Model to Rule them all: Multitask and Multilingual Modelling for
  Lexical Analysis","  When learning a new skill, you take advantage of your preexisting skills and
knowledge. For instance, if you are a skilled violinist, you will likely have
an easier time learning to play cello. Similarly, when learning a new language
you take advantage of the languages you already speak. For instance, if your
native language is Norwegian and you decide to learn Dutch, the lexical overlap
between these two languages will likely benefit your rate of language
acquisition. This thesis deals with the intersection of learning multiple tasks
and learning multiple languages in the context of Natural Language Processing
(NLP), which can be defined as the study of computational processing of human
language. Although these two types of learning may seem different on the
surface, we will see that they share many similarities.
  The traditional approach in NLP is to consider a single task for a single
language at a time. However, recent advances allow for broadening this
approach, by considering data for multiple tasks and languages simultaneously.
This is an important approach to explore further as the key to improving the
reliability of NLP, especially for low-resource languages, is to take advantage
of all relevant data whenever possible. In doing so, the hope is that in the
long term, low-resource languages can benefit from the advances made in NLP
which are currently to a large extent reserved for high-resource languages.
This, in turn, may then have positive consequences for, e.g., language
preservation, as speakers of minority languages will have a lower degree of
pressure to using high-resource languages. In the short term, answering the
specific research questions posed should be of use to NLP researchers working
towards the same goal.
",2017-11-03T10:53:05Z,http://arxiv.org/abs/1711.01100v1,Johannes Bjerva
An Overview of Multi-Task Learning in Deep Neural Networks,"  Multi-task learning (MTL) has led to successes in many applications of
machine learning, from natural language processing and speech recognition to
computer vision and drug discovery. This article aims to give a general
overview of MTL, particularly in deep neural networks. It introduces the two
most common methods for MTL in Deep Learning, gives an overview of the
literature, and discusses recent advances. In particular, it seeks to help ML
practitioners apply MTL by shedding light on how MTL works and providing
guidelines for choosing appropriate auxiliary tasks.
",2017-06-15T21:38:12Z,http://arxiv.org/abs/1706.05098v1,Sebastian Ruder
"Aquila: A Hierarchically Aligned Visual-Language Model for Enhanced
  Remote Sensing Image Comprehension","  Recently, large vision language models (VLMs) have made significant strides
in visual language capabilities through visual instruction tuning, showing
great promise in the field of remote sensing image interpretation. However,
existing remote sensing vision language models (RSVLMs) often fall short in
capturing the complex characteristics of remote sensing scenes, as they
typically rely on low resolution, single scale visual features and simplistic
methods to map visual features to language features. In this paper, we present
Aquila, an advanced visual language foundation model designed to enable richer
visual feature representation and more precise visual-language feature
alignment for remote sensing images. Our approach introduces a learnable
Hierarchical Spatial Feature Integration (SFI) module that supports high
resolution image inputs and aggregates multi scale visual features, allowing
for the detailed representation of complex visual information. Additionally,
the SFI module is repeatedly integrated into the layers of the large language
model (LLM) to achieve deep visual language feature alignment, without
compromising the model's performance in natural language processing tasks.
These innovations, capturing detailed visual effects through higher resolution
and multi scale input, and enhancing feature alignment significantly improve
the model's ability to learn from image text data. We validate the
effectiveness of Aquila through extensive quantitative experiments and
qualitative analyses, demonstrating its superior performance.
",2024-11-09T05:31:56Z,http://arxiv.org/abs/2411.06074v1,"Kaixuan Lu, Ruiqian Zhang, Xiao Huang, Yuxing Xie"
"FollowNet: Robot Navigation by Following Natural Language Directions
  with Deep Reinforcement Learning","  Understanding and following directions provided by humans can enable robots
to navigate effectively in unknown situations. We present FollowNet, an
end-to-end differentiable neural architecture for learning multi-modal
navigation policies. FollowNet maps natural language instructions as well as
visual and depth inputs to locomotion primitives. FollowNet processes
instructions using an attention mechanism conditioned on its visual and depth
input to focus on the relevant parts of the command while performing the
navigation task. Deep reinforcement learning (RL) a sparse reward learns
simultaneously the state representation, the attention function, and control
policies. We evaluate our agent on a dataset of complex natural language
directions that guide the agent through a rich and realistic dataset of
simulated homes. We show that the FollowNet agent learns to execute previously
unseen instructions described with a similar vocabulary, and successfully
navigates along paths not encountered during training. The agent shows 30%
improvement over a baseline model without the attention mechanism, with 52%
success rate at novel instructions.
",2018-05-16T06:29:18Z,http://arxiv.org/abs/1805.06150v1,"Pararth Shah, Marek Fiser, Aleksandra Faust, J. Chase Kew, Dilek Hakkani-Tur"
"Combat COVID-19 Infodemic Using Explainable Natural Language Processing
  Models","  Misinformation of COVID-19 is prevalent on social media as the pandemic
unfolds, and the associated risks are extremely high. Thus, it is critical to
detect and combat such misinformation. Recently, deep learning models using
natural language processing techniques, such as BERT (Bidirectional Encoder
Representations from Transformers), have achieved great successes in detecting
misinformation. In this paper, we proposed an explainable natural language
processing model based on DistilBERT and SHAP (Shapley Additive exPlanations)
to combat misinformation about COVID-19 due to their efficiency and
effectiveness. First, we collected a dataset of 984 claims about COVID-19 with
fact checking. By augmenting the data using back-translation, we doubled the
sample size of the dataset and the DistilBERT model was able to obtain good
performance (accuracy: 0.972; areas under the curve: 0.993) in detecting
misinformation about COVID-19. Our model was also tested on a larger dataset
for AAAI2021 - COVID-19 Fake News Detection Shared Task and obtained good
performance (accuracy: 0.938; areas under the curve: 0.985). The performance on
both datasets was better than traditional machine learning models. Second, in
order to boost public trust in model prediction, we employed SHAP to improve
model explainability, which was further evaluated using a between-subjects
experiment with three conditions, i.e., text (T), text+SHAP explanation (TSE),
and text+SHAP explanation+source and evidence (TSESE). The participants were
significantly more likely to trust and share information related to COVID-19 in
the TSE and TSESE conditions than in the T condition. Our results provided good
implications in detecting misinformation about COVID-19 and improving public
trust.
",2021-03-01T04:28:39Z,http://arxiv.org/abs/2103.00747v1,"Jackie Ayoub, X. Jessie Yang, Feng Zhou"
"A Deep Causal Inference Approach to Measuring the Effects of Forming
  Group Loans in Online Non-profit Microfinance Platform","  Kiva is an online non-profit crowdsouring microfinance platform that raises
funds for the poor in the third world. The borrowers on Kiva are small business
owners and individuals in urgent need of money. To raise funds as fast as
possible, they have the option to form groups and post loan requests in the
name of their groups. While it is generally believed that group loans pose less
risk for investors than individual loans do, we study whether this is the case
in a philanthropic online marketplace. In particular, we measure the effect of
group loans on funding time while controlling for the loan sizes and other
factors. Because loan descriptions (in the form of texts) play an important
role in lenders' decision process on Kiva, we make use of this information
through deep learning in natural language processing. In this aspect, this is
the first paper that uses one of the most advanced deep learning techniques to
deal with unstructured data in a way that can take advantage of its superior
prediction power to answer causal questions. We find that on average, forming
group loans speeds up the funding time by about 3.3 days.
",2017-06-08T23:43:12Z,http://arxiv.org/abs/1706.02795v1,"Thai T. Pham, Yuanyuan Shen"
"Deep Generative Modeling-based Data Augmentation with Demonstration
  using the BFBT Benchmark Void Fraction Datasets","  Deep learning (DL) has achieved remarkable successes in many disciplines such
as computer vision and natural language processing due to the availability of
``big data''. However, such success cannot be easily replicated in many nuclear
engineering problems because of the limited amount of training data, especially
when the data comes from high-cost experiments. To overcome such a data
scarcity issue, this paper explores the applications of deep generative models
(DGMs) that have been widely used for image data generation to scientific data
augmentation. DGMs, such as generative adversarial networks (GANs), normalizing
flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can
be trained to learn the underlying probabilistic distribution of the training
dataset. Once trained, they can be used to generate synthetic data that are
similar to the training data and significantly expand the dataset size. By
employing DGMs to augment TRACE simulated data of the steady-state void
fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle
Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have
comparable generative performance with similar errors in the synthetic data,
with CVAEs achieving the smallest errors. The findings shows that DGMs have a
great potential to augment scientific data in nuclear engineering, which proves
effective for expanding the training dataset and enabling other DL models to be
trained more accurately.
",2023-08-19T22:19:41Z,http://arxiv.org/abs/2308.10120v1,"Farah Alsafadi, Xu Wu"
DeepSI: Interactive Deep Learning for Semantic Interaction,"  In this paper, we design novel interactive deep learning methods to improve
semantic interactions in visual analytics applications. The ability of semantic
interaction to infer analysts' precise intents during sensemaking is dependent
on the quality of the underlying data representation. We propose the
$\text{DeepSI}_{\text{finetune}}$ framework that integrates deep learning into
the human-in-the-loop interactive sensemaking pipeline, with two important
properties. First, deep learning extracts meaningful representations from raw
data, which improves semantic interaction inference. Second, semantic
interactions are exploited to fine-tune the deep learning representations,
which then further improves semantic interaction inference. This feedback loop
between human interaction and deep learning enables efficient learning of user-
and task-specific representations. To evaluate the advantage of embedding the
deep learning within the semantic interaction loop, we compare
$\text{DeepSI}_{\text{finetune}}$ against a state-of-the-art but more basic use
of deep learning as only a feature extractor pre-processed outside of the
interactive loop. Results of two complementary studies, a human-centered
qualitative case study and an algorithm-centered simulation-based quantitative
experiment, show that $\text{DeepSI}_{\text{finetune}}$ more accurately
captures users' complex mental models with fewer interactions.
",2023-05-26T18:05:57Z,http://arxiv.org/abs/2305.18357v1,"Yali Bian, Chris North"
A Survey on Extraction of Causal Relations from Natural Language Text,"  As an essential component of human cognition, cause-effect relations appear
frequently in text, and curating cause-effect relations from text helps in
building causal networks for predictive tasks. Existing causality extraction
techniques include knowledge-based, statistical machine learning(ML)-based, and
deep learning-based approaches. Each method has its advantages and weaknesses.
For example, knowledge-based methods are understandable but require extensive
manual domain knowledge and have poor cross-domain applicability. Statistical
machine learning methods are more automated because of natural language
processing (NLP) toolkits. However, feature engineering is labor-intensive, and
toolkits may lead to error propagation. In the past few years, deep learning
techniques attract substantial attention from NLP researchers because of its'
powerful representation learning ability and the rapid increase in
computational resources. Their limitations include high computational costs and
a lack of adequate annotated training data. In this paper, we conduct a
comprehensive survey of causality extraction. We initially introduce primary
forms existing in the causality extraction: explicit intra-sentential
causality, implicit causality, and inter-sentential causality. Next, we list
benchmark datasets and modeling assessment methods for causal relation
extraction. Then, we present a structured overview of the three techniques with
their representative systems. Lastly, we highlight existing open challenges
with their potential directions.
",2021-01-16T10:49:39Z,http://arxiv.org/abs/2101.06426v2,"Jie Yang, Soyeon Caren Han, Josiah Poon"
"Where's the Question? A Multi-channel Deep Convolutional Neural Network
  for Question Identification in Textual Data","  In most clinical practice settings, there is no rigorous reviewing of the
clinical documentation, resulting in inaccurate information captured in the
patient medical records. The gold standard in clinical data capturing is
achieved via ""expert-review"", where clinicians can have a dialogue with a
domain expert (reviewers) and ask them questions about data entry rules.
Automatically identifying ""real questions"" in these dialogues could uncover
ambiguities or common problems in data capturing in a given clinical setting.
  In this study, we proposed a novel multi-channel deep convolutional neural
network architecture, namely Quest-CNN, for the purpose of separating real
questions that expect an answer (information or help) about an issue from
sentences that are not questions, as well as from questions referring to an
issue mentioned in a nearby sentence (e.g., can you clarify this?), which we
will refer as ""c-questions"". We conducted a comprehensive performance
comparison analysis of the proposed multi-channel deep convolutional neural
network against other deep neural networks. Furthermore, we evaluated the
performance of traditional rule-based and learning-based methods for detecting
question sentences. The proposed Quest-CNN achieved the best F1 score both on a
dataset of data entry-review dialogue in a dialysis care setting, and on a
general domain dataset.
",2020-10-15T15:11:22Z,http://arxiv.org/abs/2010.07816v1,"George Michalopoulos, Helen Chen, Alexander Wong"
"HEIDL: Learning Linguistic Expressions with Deep Learning and
  Human-in-the-Loop","  While the role of humans is increasingly recognized in machine learning
community, representation of and interaction with models in current
human-in-the-loop machine learning (HITL-ML) approaches are too low-level and
far-removed from human's conceptual models. We demonstrate HEIDL, a prototype
HITL-ML system that exposes the machine-learned model through high-level,
explainable linguistic expressions formed of predicates representing semantic
structure of text. In HEIDL, human's role is elevated from simply evaluating
model predictions to interpreting and even updating the model logic directly by
enabling interaction with rule predicates themselves. Raising the currency of
interaction to such semantic levels calls for new interaction paradigms between
humans and machines that result in improved productivity for text analytics
model development process. Moreover, by involving humans in the process, the
human-machine co-created models generalize better to unseen data as domain
experts are able to instill their expertise by extrapolating from what has been
learned by automated algorithms from few labelled data.
",2019-07-25T16:45:06Z,http://arxiv.org/abs/1907.11184v1,"Yiwei Yang, Eser Kandogan, Yunyao Li, Walter S. Lasecki, Prithviraj Sen"
Lexical semantics enhanced neural word embeddings,"  Current breakthroughs in natural language processing have benefited
dramatically from neural language models, through which distributional
semantics can leverage neural data representations to facilitate downstream
applications. Since neural embeddings use context prediction on word
co-occurrences to yield dense vectors, they are inevitably prone to capture
more semantic association than semantic similarity. To improve vector space
models in deriving semantic similarity, we post-process neural word embeddings
through deep metric learning, through which we can inject lexical-semantic
relations, including syn/antonymy and hypo/hypernymy, into a distributional
space. We introduce hierarchy-fitting, a novel semantic specialization approach
to modelling semantic similarity nuances inherently stored in the IS-A
hierarchies. Hierarchy-fitting attains state-of-the-art results on the common-
and rare-word benchmark datasets for deriving semantic similarity from neural
word embeddings. It also incorporates an asymmetric distance function to
specialize hypernymy's directionality explicitly, through which it
significantly improves vanilla embeddings in multiple evaluation tasks of
detecting hypernymy and directionality without negative impacts on semantic
similarity judgement. The results demonstrate the efficacy of hierarchy-fitting
in specializing neural embeddings with semantic relations in late fusion,
potentially expanding its applicability to aggregating heterogeneous data and
various knowledge resources for learning multimodal semantic spaces.
",2022-10-03T08:10:23Z,http://arxiv.org/abs/2210.00754v1,"Dongqiang Yang, Ning Li, Li Zou, Hongwei Ma"
"Unsupervised Cross-Domain Prerequisite Chain Learning using Variational
  Graph Autoencoders","  Learning prerequisite chains is an essential task for efficiently acquiring
knowledge in both known and unknown domains. For example, one may be an expert
in the natural language processing (NLP) domain but want to determine the best
order to learn new concepts in an unfamiliar Computer Vision domain (CV). Both
domains share some common concepts, such as machine learning basics and deep
learning models. In this paper, we propose unsupervised cross-domain concept
prerequisite chain learning using an optimized variational graph autoencoder.
Our model learns to transfer concept prerequisite relations from an
information-rich domain (source domain) to an information-poor domain (target
domain), substantially surpassing other baseline models. Also, we expand an
existing dataset by introducing two new domains: CV and Bioinformatics (BIO).
The annotated data and resources, as well as the code, will be made publicly
available.
",2021-05-07T21:02:41Z,http://arxiv.org/abs/2105.03505v3,"Irene Li, Vanessa Yan, Tianxiao Li, Rihao Qu, Dragomir Radev"
Curriculum Learning with Adam: The Devil Is in the Wrong Details,"  Curriculum learning (CL) posits that machine learning models -- similar to
humans -- may learn more efficiently from data that match their current
learning progress. However, CL methods are still poorly understood and, in
particular for natural language processing (NLP), have achieved only limited
success. In this paper, we explore why. Starting from an attempt to replicate
and extend a number of recent curriculum methods, we find that their results
are surprisingly brittle when applied to NLP. A deep dive into the
(in)effectiveness of the curricula in some scenarios shows us why: when
curricula are employed in combination with the popular Adam optimisation
algorithm, they oftentimes learn to adapt to suboptimally chosen optimisation
parameters for this algorithm. We present a number of different case studies
with different common hand-crafted and automated CL approaches to illustrate
this phenomenon, and we find that none of them outperforms optimisation with
only Adam with well-chosen hyperparameters. As such, our results contribute to
understanding why CL methods work, but at the same time urge caution when
claiming positive results.
",2023-08-23T15:39:42Z,http://arxiv.org/abs/2308.12202v1,"Lucas Weber, Jaap Jumelet, Paul Michel, Elia Bruni, Dieuwke Hupkes"
"Breaking Language Barriers: A Question Answering Dataset for Hindi and
  Marathi","  The recent advances in deep-learning have led to the development of highly
sophisticated systems with an unquenchable appetite for data. On the other
hand, building good deep-learning models for low-resource languages remains a
challenging task. This paper focuses on developing a Question Answering dataset
for two such languages- Hindi and Marathi. Despite Hindi being the 3rd most
spoken language worldwide, with 345 million speakers, and Marathi being the
11th most spoken language globally, with 83.2 million speakers, both languages
face limited resources for building efficient Question Answering systems. To
tackle the challenge of data scarcity, we have developed a novel approach for
translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the
largest Question-Answering dataset available for these languages, with each
dataset containing 28,000 samples. We evaluate the dataset on various
architectures and release the best-performing models for both Hindi and
Marathi, which will facilitate further research in these languages. Leveraging
similarity tools, our method holds the potential to create datasets in diverse
languages, thereby enhancing the understanding of natural language across
varied linguistic contexts. Our fine-tuned models, code, and dataset will be
made publicly available.
",2023-08-19T00:39:21Z,http://arxiv.org/abs/2308.09862v3,"Maithili Sabane, Onkar Litake, Aman Chadha"
"Learning to Selectively Transfer: Reinforced Transfer Learning for Deep
  Text Matching","  Deep text matching approaches have been widely studied for many applications
including question answering and information retrieval systems. To deal with a
domain that has insufficient labeled data, these approaches can be used in a
Transfer Learning (TL) setting to leverage labeled data from a resource-rich
source domain. To achieve better performance, source domain data selection is
essential in this process to prevent the ""negative transfer"" problem. However,
the emerging deep transfer models do not fit well with most existing data
selection methods, because the data selection policy and the transfer learning
model are not jointly trained, leading to sub-optimal training efficiency.
  In this paper, we propose a novel reinforced data selector to select
high-quality source domain data to help the TL model. Specifically, the data
selector ""acts"" on the source domain data to find a subset for optimization of
the TL model, and the performance of the TL model can provide ""rewards"" in turn
to update the selector. We build the reinforced data selector based on the
actor-critic framework and integrate it to a DNN based transfer learning model,
resulting in a Reinforced Transfer Learning (RTL) method. We perform a thorough
experimental evaluation on two major tasks for text matching, namely,
paraphrase identification and natural language inference. Experimental results
show the proposed RTL can significantly improve the performance of the TL
model. We further investigate different settings of states, rewards, and policy
optimization methods to examine the robustness of our method. Last, we conduct
a case study on the selected data and find our method is able to select source
domain data whose Wasserstein distance is close to the target domain data. This
is reasonable and intuitive as such source domain data can provide more
transferability power to the model.
",2018-12-30T15:39:57Z,http://arxiv.org/abs/1812.11561v1,"Chen Qu, Feng Ji, Minghui Qiu, Liu Yang, Zhiyu Min, Haiqing Chen, Jun Huang, W. Bruce Croft"
Multi-Task Learning for Argumentation Mining,"  Multi-task learning has recently become a very active field in deep learning
research. In contrast to learning a single task in isolation, multiple tasks
are learned at the same time, thereby utilizing the training signal of related
tasks to improve the performance on the respective machine learning tasks.
Related work shows various successes in different domains when applying this
paradigm and this thesis extends the existing empirical results by evaluating
multi-task learning in four different scenarios: argumentation mining,
epistemic segmentation, argumentation component segmentation, and
grapheme-to-phoneme conversion. We show that multi-task learning can, indeed,
improve the performance compared to single-task learning in all these
scenarios, but may also hurt the performance. Therefore, we investigate the
reasons for successful and less successful applications of this paradigm and
find that dataset properties such as entropy or the size of the label inventory
are good indicators for a potential multi-task learning success and that
multi-task learning is particularly useful if the task at hand suffers from
data sparsity, i.e. a lack of training data. Moreover, multi-task learning is
particularly effective for long input sequences in our experiments. We have
observed this trend in all evaluated scenarios. Finally, we develop a highly
configurable and extensible sequence tagging framework which supports
multi-task learning to conduct our empirical experiments and to aid future
research regarding the multi-task learning paradigm and natural language
processing.
",2019-04-23T05:58:54Z,http://arxiv.org/abs/1904.10162v1,Tobias Kahse
"Deep Learning on FPGAs: Past, Present, and Future","  The rapid growth of data size and accessibility in recent years has
instigated a shift of philosophy in algorithm design for artificial
intelligence. Instead of engineering algorithms by hand, the ability to learn
composable systems automatically from massive amounts of data has led to
ground-breaking performance in important domains such as computer vision,
speech recognition, and natural language processing. The most popular class of
techniques used in these domains is called deep learning, and is seeing
significant attention from industry. However, these models require incredible
amounts of data and compute power to train, and are limited by the need for
better hardware acceleration to accommodate scaling beyond current data and
model sizes. While the current solution has been to use clusters of graphics
processing units (GPU) as general purpose processors (GPGPU), the use of field
programmable gate arrays (FPGA) provide an interesting alternative. Current
trends in design tools for FPGAs have made them more compatible with the
high-level software practices typically practiced in the deep learning
community, making FPGAs more accessible to those who build and deploy models.
Since FPGA architectures are flexible, this could also allow researchers the
ability to explore model-level optimizations beyond what is possible on fixed
architectures such as GPUs. As well, FPGAs tend to provide high performance per
watt of power consumption, which is of particular importance for application
scientists interested in large scale server-based deployment or
resource-limited embedded applications. This review takes a look at deep
learning and FPGAs from a hardware acceleration perspective, identifying trends
and innovations that make these technologies a natural fit, and motivates a
discussion on how FPGAs may best serve the needs of the deep learning community
moving forward.
",2016-02-13T03:50:37Z,http://arxiv.org/abs/1602.04283v1,"Griffin Lacey, Graham W. Taylor, Shawki Areibi"
Teaching Data Science,"  We describe an introductory data science course, entitled Introduction to
Data Science, offered at the University of Illinois at Urbana-Champaign. The
course introduced general programming concepts by using the Python programming
language with an emphasis on data preparation, processing, and presentation.
The course had no prerequisites, and students were not expected to have any
programming experience. This introductory course was designed to cover a wide
range of topics, from the nature of data, to storage, to visualization, to
probability and statistical analysis, to cloud and high performance computing,
without becoming overly focused on any one subject. We conclude this article
with a discussion of lessons learned and our plans to develop new data science
courses.
",2016-04-25T18:26:51Z,http://arxiv.org/abs/1604.07397v1,"Robert J. Brunner, Edward J. Kim"
"Learning Universal Graph Neural Network Embeddings With Aid Of Transfer
  Learning","  Learning powerful data embeddings has become a center piece in machine
learning, especially in natural language processing and computer vision
domains. The crux of these embeddings is that they are pretrained on huge
corpus of data in a unsupervised fashion, sometimes aided with transfer
learning. However currently in the graph learning domain, embeddings learned
through existing graph neural networks (GNNs) are task dependent and thus
cannot be shared across different datasets. In this paper, we present a first
powerful and theoretically guaranteed graph neural network that is designed to
learn task-independent graph embeddings, thereafter referred to as deep
universal graph embedding (DUGNN). Our DUGNN model incorporates a novel graph
neural network (as a universal graph encoder) and leverages rich Graph Kernels
(as a multi-task graph decoder) for both unsupervised learning and
(task-specific) adaptive supervised learning. By learning task-independent
graph embeddings across diverse datasets, DUGNN also reaps the benefits of
transfer learning. Through extensive experiments and ablation studies, we show
that the proposed DUGNN model consistently outperforms both the existing
state-of-art GNN models and Graph Kernels by an increased accuracy of 3% - 8%
on graph classification benchmark datasets.
",2019-09-22T20:21:15Z,http://arxiv.org/abs/1909.10086v3,"Saurabh Verma, Zhi-Li Zhang"
"TransPolymer: a Transformer-based language model for polymer property
  predictions","  Accurate and efficient prediction of polymer properties is of great
significance in polymer design. Conventionally, expensive and time-consuming
experiments or simulations are required to evaluate polymer functions.
Recently, Transformer models, equipped with self-attention mechanisms, have
exhibited superior performance in natural language processing. However, such
methods have not been investigated in polymer sciences. Herein, we report
TransPolymer, a Transformer-based language model for polymer property
prediction. Our proposed polymer tokenizer with chemical awareness enables
learning representations from polymer sequences. Rigorous experiments on ten
polymer property prediction benchmarks demonstrate the superior performance of
TransPolymer. Moreover, we show that TransPolymer benefits from pretraining on
large unlabeled dataset via Masked Language Modeling. Experimental results
further manifest the important role of self-attention in modeling polymer
sequences. We highlight this model as a promising computational tool for
promoting rational polymer design and understanding structure-property
relationships from a data science view.
",2022-09-03T01:29:59Z,http://arxiv.org/abs/2209.01307v4,"Changwen Xu, Yuyang Wang, Amir Barati Farimani"
Deep Regression Unlearning,"  With the introduction of data protection and privacy regulations, it has
become crucial to remove the lineage of data on demand from a machine learning
(ML) model. In the last few years, there have been notable developments in
machine unlearning to remove the information of certain training data
efficiently and effectively from ML models. In this work, we explore unlearning
for the regression problem, particularly in deep learning models. Unlearning in
classification and simple linear regression has been considerably investigated.
However, unlearning in deep regression models largely remains an untouched
problem till now. In this work, we introduce deep regression unlearning methods
that generalize well and are robust to privacy attacks. We propose the
Blindspot unlearning method which uses a novel weight optimization process. A
randomly initialized model, partially exposed to the retain samples and a copy
of the original model are used together to selectively imprint knowledge about
the data that we wish to keep and scrub off the information of the data we wish
to forget. We also propose a Gaussian fine tuning method for regression
unlearning. The existing unlearning metrics for classification are not directly
applicable to regression unlearning. Therefore, we adapt these metrics for the
regression setting. We conduct regression unlearning experiments for computer
vision, natural language processing and forecasting applications. Our methods
show excellent performance for all these datasets across all the metrics.
Source code: https://github.com/ayu987/deep-regression-unlearning
",2022-10-15T05:00:20Z,http://arxiv.org/abs/2210.08196v2,"Ayush K Tarun, Vikram S Chundawat, Murari Mandal, Mohan Kankanhalli"
DNF-Net: A Neural Architecture for Tabular Data,"  A challenging open question in deep learning is how to handle tabular data.
Unlike domains such as image and natural language processing, where deep
architectures prevail, there is still no widely accepted neural architecture
that dominates tabular data. As a step toward bridging this gap, we present
DNF-Net a novel generic architecture whose inductive bias elicits models whose
structure corresponds to logical Boolean formulas in disjunctive normal form
(DNF) over affine soft-threshold decision terms. In addition, DNF-Net promotes
localized decisions that are taken over small subsets of the features. We
present an extensive empirical study showing that DNF-Nets significantly and
consistently outperform FCNs over tabular data. With relatively few
hyperparameters, DNF-Nets open the door to practical end-to-end handling of
tabular data using neural networks. We present ablation studies, which justify
the design choices of DNF-Net including the three inductive bias elements,
namely, Boolean formulation, locality, and feature selection.
",2020-06-11T14:21:45Z,http://arxiv.org/abs/2006.06465v1,"Ami Abutbul, Gal Elidan, Liran Katzir, Ran El-Yaniv"
Delving into Deep Imbalanced Regression,"  Real-world data often exhibit imbalanced distributions, where certain target
values have significantly fewer observations. Existing techniques for dealing
with imbalanced data focus on targets with categorical indices, i.e., different
classes. However, many tasks involve continuous targets, where hard boundaries
between classes do not exist. We define Deep Imbalanced Regression (DIR) as
learning from such imbalanced data with continuous targets, dealing with
potential missing data for certain target values, and generalizing to the
entire target range. Motivated by the intrinsic difference between categorical
and continuous label space, we propose distribution smoothing for both labels
and features, which explicitly acknowledges the effects of nearby targets, and
calibrates both label and learned feature distributions. We curate and
benchmark large-scale DIR datasets from common real-world tasks in computer
vision, natural language processing, and healthcare domains. Extensive
experiments verify the superior performance of our strategies. Our work fills
the gap in benchmarks and techniques for practical imbalanced regression
problems. Code and data are available at
https://github.com/YyzHarry/imbalanced-regression.
",2021-02-18T18:56:03Z,http://arxiv.org/abs/2102.09554v2,"Yuzhe Yang, Kaiwen Zha, Ying-Cong Chen, Hao Wang, Dina Katabi"
"Convolutional Neural Network (CNN) to reduce construction loss in JPEG
  compression caused by Discrete Fourier Transform (DFT)","  In recent decades, digital image processing has gained enormous popularity.
Consequently, a number of data compression strategies have been put forth, with
the goal of minimizing the amount of information required to represent images.
Among them, JPEG compression is one of the most popular methods that has been
widely applied in multimedia and digital applications. The periodic nature of
DFT makes it impossible to meet the periodic condition of an image's opposing
edges without producing severe artifacts, which lowers the image's perceptual
visual quality. On the other hand, deep learning has recently achieved
outstanding results for applications like speech recognition, image reduction,
and natural language processing. Convolutional Neural Networks (CNN) have
received more attention than most other types of deep neural networks. The use
of convolution in feature extraction results in a less redundant feature map
and a smaller dataset, both of which are crucial for image compression. In this
work, an effective image compression method is purposed using autoencoders. The
study's findings revealed a number of important trends that suggested better
reconstruction along with good compression can be achieved using autoencoders.
",2022-08-26T12:46:16Z,http://arxiv.org/abs/2209.03475v2,Suman Kunwar
Adaptive Transfer Learning of Multi-View Time Series Classification,"  Time Series Classification (TSC) has been an important and challenging task
in data mining, especially on multivariate time series and multi-view time
series data sets. Meanwhile, transfer learning has been widely applied in
computer vision and natural language processing applications to improve deep
neural network's generalization capabilities. However, very few previous works
applied transfer learning framework to time series mining problems.
Particularly, the technique of measuring similarities between source domain and
target domain based on dynamic representation such as density estimation with
importance sampling has never been combined with transfer learning framework.
In this paper, we first proposed a general adaptive transfer learning framework
for multi-view time series data, which shows strong ability in storing
inter-view importance value in the process of knowledge transfer. Next, we
represented inter-view importance through some time series similarity
measurements and approximated the posterior distribution in latent space for
the importance sampling via density estimation techniques. We then computed the
matrix norm of sampled importance value, which controls the degree of knowledge
transfer in pre-training process. We further evaluated our work, applied it to
many other time series classification tasks, and observed that our architecture
maintained desirable generalization ability. Finally, we concluded that our
framework could be adapted with deep learning techniques to receive significant
model performance improvements.
",2019-10-14T21:46:03Z,http://arxiv.org/abs/1910.07632v1,"Donglin Zhan, Shiyu Yi, Dongli Xu, Xiao Yu, Denglin Jiang, Siqi Yu, Haoting Zhang, Wenfang Shangguan, Weihua Zhang"
Optimization Methods in Deep Learning: A Comprehensive Overview,"  In recent years, deep learning has achieved remarkable success in various
fields such as image recognition, natural language processing, and speech
recognition. The effectiveness of deep learning largely depends on the
optimization methods used to train deep neural networks. In this paper, we
provide an overview of first-order optimization methods such as Stochastic
Gradient Descent, Adagrad, Adadelta, and RMSprop, as well as recent
momentum-based and adaptive gradient methods such as Nesterov accelerated
gradient, Adam, Nadam, AdaMax, and AMSGrad. We also discuss the challenges
associated with optimization in deep learning and explore techniques for
addressing these challenges, including weight initialization, batch
normalization, and layer normalization. Finally, we provide recommendations for
selecting optimization methods for different deep learning tasks and datasets.
This paper serves as a comprehensive guide to optimization methods in deep
learning and can be used as a reference for researchers and practitioners in
the field.
",2023-02-19T13:01:53Z,http://arxiv.org/abs/2302.09566v2,David Shulman
PreTraM: Self-Supervised Pre-training via Connecting Trajectory and Map,"  Deep learning has recently achieved significant progress in trajectory
forecasting. However, the scarcity of trajectory data inhibits the data-hungry
deep-learning models from learning good representations. While mature
representation learning methods exist in computer vision and natural language
processing, these pre-training methods require large-scale data. It is hard to
replicate these approaches in trajectory forecasting due to the lack of
adequate trajectory data (e.g., 34K samples in the nuScenes dataset). To work
around the scarcity of trajectory data, we resort to another data modality
closely related to trajectories-HD-maps, which is abundantly provided in
existing datasets. In this paper, we propose PreTraM, a self-supervised
pre-training scheme via connecting trajectories and maps for trajectory
forecasting. Specifically, PreTraM consists of two parts: 1) Trajectory-Map
Contrastive Learning, where we project trajectories and maps to a shared
embedding space with cross-modal contrastive learning, and 2) Map Contrastive
Learning, where we enhance map representation with contrastive learning on
large quantities of HD-maps. On top of popular baselines such as AgentFormer
and Trajectron++, PreTraM boosts their performance by 5.5% and 6.9% relatively
in FDE-10 on the challenging nuScenes dataset. We show that PreTraM improves
data efficiency and scales well with model size.
",2022-04-21T23:01:21Z,http://arxiv.org/abs/2204.10435v1,"Chenfeng Xu, Tian Li, Chen Tang, Lingfeng Sun, Kurt Keutzer, Masayoshi Tomizuka, Alireza Fathi, Wei Zhan"
Privacy Guarantees for De-identifying Text Transformations,"  Machine Learning approaches to Natural Language Processing tasks benefit from
a comprehensive collection of real-life user data. At the same time, there is a
clear need for protecting the privacy of the users whose data is collected and
processed. For text collections, such as, e.g., transcripts of voice
interactions or patient records, replacing sensitive parts with benign
alternatives can provide de-identification. However, how much privacy is
actually guaranteed by such text transformations, and are the resulting texts
still useful for machine learning? In this paper, we derive formal privacy
guarantees for general text transformation-based de-identification methods on
the basis of Differential Privacy. We also measure the effect that different
ways of masking private information in dialog transcripts have on a subsequent
machine learning task. To this end, we formulate different masking strategies
and compare their privacy-utility trade-offs. In particular, we compare a
simple redact approach with more sophisticated word-by-word replacement using
deep learning models on multiple natural language understanding tasks like
named entity recognition, intent detection, and dialog act classification. We
find that only word-by-word replacement is robust against performance drops in
various tasks.
",2020-08-07T12:06:42Z,http://arxiv.org/abs/2008.03101v2,"David Ifeoluwa Adelani, Ali Davody, Thomas Kleinbauer, Dietrich Klakow"
Labeled Data Generation with Inexact Supervision,"  The recent advanced deep learning techniques have shown the promising results
in various domains such as computer vision and natural language processing. The
success of deep neural networks in supervised learning heavily relies on a
large amount of labeled data. However, obtaining labeled data with target
labels is often challenging due to various reasons such as cost of labeling and
privacy issues, which challenges existing deep models. In spite of that, it is
relatively easy to obtain data with \textit{inexact supervision}, i.e., having
labels/tags related to the target task. For example, social media platforms are
overwhelmed with billions of posts and images with self-customized tags, which
are not the exact labels for target classification tasks but are usually
related to the target labels. It is promising to leverage these tags (inexact
supervision) and their relations with target classes to generate labeled data
to facilitate the downstream classification tasks. However, the work on this is
rather limited. Therefore, we study a novel problem of labeled data generation
with inexact supervision. We propose a novel generative framework named as
ADDES which can synthesize high-quality labeled data for target classification
tasks by learning from data with inexact supervision and the relations between
inexact supervision and target classes. Experimental results on image and text
datasets demonstrate the effectiveness of the proposed ADDES for generating
realistic labeled data from inexact supervision to facilitate the target
classification task.
",2021-06-08T22:22:26Z,http://arxiv.org/abs/2106.04716v1,"Enyan Dai, Kai Shu, Yiwei Sun, Suhang Wang"
"DARVIZ: Deep Abstract Representation, Visualization, and Verification of
  Deep Learning Models","  Traditional software engineering programming paradigms are mostly object or
procedure oriented, driven by deterministic algorithms. With the advent of deep
learning and cognitive sciences there is an emerging trend for data-driven
programming, creating a shift in the programming paradigm among the software
engineering communities. Visualizing and interpreting the execution of a
current large scale data-driven software development is challenging. Further,
for deep learning development there are many libraries in multiple programming
languages such as TensorFlow (Python), CAFFE (C++), Theano (Python), Torch
(Lua), and Deeplearning4j (Java), driving a huge need for interoperability
across libraries.
",2017-08-16T14:46:27Z,http://arxiv.org/abs/1708.04915v1,"Anush Sankaran, Rahul Aralikatte, Senthil Mani, Shreya Khare, Naveen Panwar, Neelamadhav Gantayat"
Deep Reinforcement Learning: An Overview,"  We give an overview of recent exciting achievements of deep reinforcement
learning (RL). We discuss six core elements, six important mechanisms, and
twelve applications. We start with background of machine learning, deep
learning and reinforcement learning. Next we discuss core RL elements,
including value function, in particular, Deep Q-Network (DQN), policy, reward,
model, planning, and exploration. After that, we discuss important mechanisms
for RL, including attention and memory, unsupervised learning, transfer
learning, multi-agent RL, hierarchical RL, and learning to learn. Then we
discuss various applications of RL, including games, in particular, AlphaGo,
robotics, natural language processing, including dialogue systems, machine
translation, and text generation, computer vision, neural architecture design,
business management, finance, healthcare, Industry 4.0, smart grid, intelligent
transportation systems, and computer systems. We mention topics not reviewed
yet, and list a collection of RL resources. After presenting a brief summary,
we close with discussions.
  Please see Deep Reinforcement Learning, arXiv:1810.06339, for a significant
update.
",2017-01-25T11:52:11Z,http://arxiv.org/abs/1701.07274v6,Yuxi Li
"Pretraining with Artificial Language: Studying Transferable Knowledge in
  Language Models","  We investigate what kind of structural knowledge learned in neural network
encoders is transferable to processing natural language. We design artificial
languages with structural properties that mimic natural language, pretrain
encoders on the data, and see how much performance the encoder exhibits on
downstream tasks in natural language. Our experimental results show that
pretraining with an artificial language with a nesting dependency structure
provides some knowledge transferable to natural language. A follow-up probing
analysis indicates that its success in the transfer is related to the amount of
encoded contextual information and what is transferred is the knowledge of
position-aware context dependence of language. Our results provide insights
into how neural network encoders process human languages and the source of
cross-lingual transferability of recent multilingual language models.
",2022-03-19T13:29:48Z,http://arxiv.org/abs/2203.10326v2,"Ryokan Ri, Yoshimasa Tsuruoka"
BADM: Batch ADMM for Deep Learning,"  Stochastic gradient descent-based algorithms are widely used for training
deep neural networks but often suffer from slow convergence. To address the
challenge, we leverage the framework of the alternating direction method of
multipliers (ADMM) to develop a novel data-driven algorithm, called batch ADMM
(BADM). The fundamental idea of the proposed algorithm is to split the training
data into batches, which is further divided into sub-batches where primal and
dual variables are updated to generate global parameters through aggregation.
We evaluate the performance of BADM across various deep learning tasks,
including graph modelling, computer vision, image generation, and natural
language processing. Extensive numerical experiments demonstrate that BADM
achieves faster convergence and superior testing accuracy compared to other
state-of-the-art optimizers.
",2024-06-30T20:47:15Z,http://arxiv.org/abs/2407.01640v1,"Ouya Wang, Shenglong Zhou, Geoffrey Ye Li"
Self-supervised Learning: Generative or Contrastive,"  Deep supervised learning has achieved great success in the last decade.
However, its deficiencies of dependence on manual labels and vulnerability to
attacks have driven people to explore a better solution. As an alternative,
self-supervised learning attracts many researchers for its soaring performance
on representation learning in the last several years. Self-supervised
representation learning leverages input data itself as supervision and benefits
almost all types of downstream tasks. In this survey, we take a look into new
self-supervised learning methods for representation in computer vision, natural
language processing, and graph learning. We comprehensively review the existing
empirical methods and summarize them into three main categories according to
their objectives: generative, contrastive, and generative-contrastive
(adversarial). We further investigate related theoretical analysis work to
provide deeper thoughts on how self-supervised learning works. Finally, we
briefly discuss open problems and future directions for self-supervised
learning. An outline slide for the survey is provided.
",2020-06-15T08:40:03Z,http://arxiv.org/abs/2006.08218v5,"Xiao Liu, Fanjin Zhang, Zhenyu Hou, Zhaoyu Wang, Li Mian, Jing Zhang, Jie Tang"
Towards Deep Conversational Recommendations,"  There has been growing interest in using neural networks and deep learning
techniques to create dialogue systems. Conversational recommendation is an
interesting setting for the scientific exploration of dialogue with natural
language as the associated discourse involves goal-driven dialogue that often
transforms naturally into more free-form chat. This paper provides two
contributions. First, until now there has been no publicly available
large-scale dataset consisting of real-world dialogues centered around
recommendations. To address this issue and to facilitate our exploration here,
we have collected ReDial, a dataset consisting of over 10,000 conversations
centered around the theme of providing movie recommendations. We make this data
available to the community for further research. Second, we use this dataset to
explore multiple facets of conversational recommendations. In particular we
explore new neural architectures, mechanisms, and methods suitable for
composing conversational recommendation systems. Our dataset allows us to
systematically probe model sub-components addressing different parts of the
overall problem domain ranging from: sentiment analysis and cold-start
recommendation generation to detailed aspects of how natural language is used
in this setting in the real world. We combine such sub-components into a
full-blown dialogue system and examine its behavior.
",2018-12-18T19:34:32Z,http://arxiv.org/abs/1812.07617v2,"Raymond Li, Samira Kahou, Hannes Schulz, Vincent Michalski, Laurent Charlin, Chris Pal"
Grounded Language Acquisition From Object and Action Imagery,"  Deep learning approaches to natural language processing have made great
strides in recent years. While these models produce symbols that convey vast
amounts of diverse knowledge, it is unclear how such symbols are grounded in
data from the world. In this paper, we explore the development of a private
language for visual data representation by training emergent language (EL)
encoders/decoders in both i) a traditional referential game environment and ii)
a contrastive learning environment utilizing a within-class matching training
paradigm. An additional classification layer utilizing neural machine
translation and random forest classification was used to transform symbolic
representations (sequences of integer symbols) to class labels. These methods
were applied in two experiments focusing on object recognition and action
recognition. For object recognition, a set of sketches produced by human
participants from real imagery was used (Sketchy dataset) and for action
recognition, 2D trajectories were generated from 3D motion capture systems
(MOVI dataset). In order to interpret the symbols produced for data in each
experiment, gradient-weighted class activation mapping (Grad-CAM) methods were
used to identify pixel regions indicating semantic features which contribute
evidence towards symbols in learned languages. Additionally, a t-distributed
stochastic neighbor embedding (t-SNE) method was used to investigate embeddings
learned by CNN feature extractors.
",2023-09-12T15:52:08Z,http://arxiv.org/abs/2309.06335v1,"James Robert Kubricht, Zhaoyuan Yang, Jianwei Qiu, Peter Henry Tu"
Multimodal Recommender Systems in the Prediction of Disease Comorbidity,"  While deep-learning based recommender systems utilizing collaborative
filtering have been commonly used for recommendation in other domains, their
application in the medical domain have been limited. In addition to modeling
user-item interactions, we show that deep-learning based recommender systems
can be used to model subject-disease code interactions. Two novel applications
of deep learning-based recommender systems using Neural Collaborative Filtering
(NCF) and Deep Hybrid Filtering (DHF) were utilized for disease diagnosis based
on known past patient comorbidities. Two datasets, one incorporating all
subject-disease code pairs present in the MIMIC-III database, and the other
incorporating the top 50 most commonly occurring diseases, were used for
prediction. Accuracy and Hit Ratio@10 were utilized as metrics to estimate
model performance. The performance of the NCF model making use of the reduced
""top 50"" ICD-9 code dataset was found to be lower (accuracy of ~80% and hit
ratio@10 of 35%) as compared to the performance of the NCF model trained on all
ICD-9 codes (accuracy of ~90% and hit ratio@10 of ~80%). Reasons for the
superior performance of the sparser dataset with all ICD codes can be mainly
attributed to the higher volume of data and the robustness of deep-learning
based recommender systems with modeling sparse data. Additionally, results from
the DHF models reflect better performance than the NCF models, with a better
accuracy of 94.4% and hit ratio@10 of 85.36%, reflecting the importance of the
incorporation of clinical note information. Additionally, compared to
literature reports utilizing primarily natural language processing-based
predictions for the task of ICD-9 code co-occurrence, the novel deep
learning-based recommender systems approach performed better. Overall, the deep
learning-based recommender systems have shown promise in predicting disease
comorbidity.
",2023-08-30T01:40:45Z,http://arxiv.org/abs/2309.08613v1,Aashish Cheruvu
TookaBERT: A Step Forward for Persian NLU,"  The field of natural language processing (NLP) has seen remarkable
advancements, thanks to the power of deep learning and foundation models.
Language models, and specifically BERT, have been key players in this progress.
In this study, we trained and introduced two new BERT models using Persian
data. We put our models to the test, comparing them to seven existing models
across 14 diverse Persian natural language understanding (NLU) tasks. The
results speak for themselves: our larger model outperforms the competition,
showing an average improvement of at least +2.8 points. This highlights the
effectiveness and potential of our new BERT models for Persian NLU tasks.
",2024-07-23T11:12:47Z,http://arxiv.org/abs/2407.16382v1,"MohammadAli SadraeiJavaheri, Ali Moghaddaszadeh, Milad Molazadeh, Fariba Naeiji, Farnaz Aghababaloo, Hamideh Rafiee, Zahra Amirmahani, Tohid Abedini, Fatemeh Zahra Sheikhi, Amirmohammad Salehoof"
Bayesian Neural Networks: An Introduction and Survey,"  Neural Networks (NNs) have provided state-of-the-art results for many
challenging machine learning tasks such as detection, regression and
classification across the domains of computer vision, speech recognition and
natural language processing. Despite their success, they are often implemented
in a frequentist scheme, meaning they are unable to reason about uncertainty in
their predictions. This article introduces Bayesian Neural Networks (BNNs) and
the seminal research regarding their implementation. Different approximate
inference methods are compared, and used to highlight where future research can
improve on current methods.
",2020-06-22T06:30:15Z,http://arxiv.org/abs/2006.12024v1,"Ethan Goan, Clinton Fookes"
ChatDev: Communicative Agents for Software Development,"  Software development is a complex task that necessitates cooperation among
multiple members with diverse skills. Numerous studies used deep learning to
improve specific phases in a waterfall model, such as design, coding, and
testing. However, the deep learning model in each phase requires unique
designs, leading to technical inconsistencies across various phases, which
results in a fragmented and ineffective development process. In this paper, we
introduce ChatDev, a chat-powered software development framework in which
specialized agents driven by large language models (LLMs) are guided in what to
communicate (via chat chain) and how to communicate (via communicative
dehallucination). These agents actively contribute to the design, coding, and
testing phases through unified language-based communication, with solutions
derived from their multi-turn dialogues. We found their utilization of natural
language is advantageous for system design, and communicating in programming
language proves helpful in debugging. This paradigm demonstrates how linguistic
communication facilitates multi-agent collaboration, establishing language as a
unifying bridge for autonomous task-solving among LLM agents. The code and data
are available at https://github.com/OpenBMB/ChatDev.
",2023-07-16T02:11:34Z,http://arxiv.org/abs/2307.07924v5,"Chen Qian, Wei Liu, Hongzhang Liu, Nuo Chen, Yufan Dang, Jiahao Li, Cheng Yang, Weize Chen, Yusheng Su, Xin Cong, Juyuan Xu, Dahai Li, Zhiyuan Liu, Maosong Sun"
"Detection of Increased Time Intervals of Anti-Vaccine Tweets for
  COVID-19 Vaccine with BERT Model","  The most effective of the solutions against Covid-19 is the various vaccines
developed. Distrust of vaccines can hinder the rapid and effective use of this
remedy. One of the means of expressing the thoughts of society is social media.
Determining the time intervals during which anti-vaccination increases in
social media can help institutions determine the strategy to be used in
combating anti-vaccination. Recording and tracking every tweet entered with
human labor would be inefficient, so various automation solutions are needed.
In this study, The Bidirectional Encoder Representations from Transformers
(BERT) model, which is a deep learning-based natural language processing (NLP)
model, was used. In a dataset of 1506 tweets divided into four different
categories as news, irrelevant, anti-vaccine, and vaccine supporters, the model
was trained with a learning rate of 5e-6 for 25 epochs. To determine the
intervals in which anti-vaccine tweets are concentrated, the categories to
which 652840 tweets belong were determined by using the trained model. The
change of the determined categories overtime was visualized and the events that
could cause the change were determined. As a result of model training, in the
test dataset, the f-score of 0.81 and AUC values for different classes were
obtained as 0.99,0.91, 0.92, 0.92, respectively. In this model, unlike the
studies in the literature, an auxiliary system is designed that provides data
that institutions can use when determining their strategy by measuring and
visualizing the frequency of anti-vaccine tweets in a time interval, different
from detecting and censoring such tweets.
",2022-01-12T18:30:23Z,http://arxiv.org/abs/2202.00477v1,"√úlk√º Tuncer K√º√ß√ºkta≈ü, Fatih Uysal, Fƒ±rat Hardala√ß, ƒ∞smail Biri"
"Psychomatics -- A Multidisciplinary Framework for Understanding
  Artificial Minds","  Although LLMs and other artificial intelligence systems demonstrate cognitive
skills similar to humans, like concept learning and language acquisition, the
way they process information fundamentally differs from biological cognition.
To better understand these differences this paper introduces Psychomatics, a
multidisciplinary framework bridging cognitive science, linguistics, and
computer science. It aims to better understand the high-level functioning of
LLMs, focusing specifically on how LLMs acquire, learn, remember, and use
information to produce their outputs. To achieve this goal, Psychomatics will
rely on a comparative methodology, starting from a theory-driven research
question - is the process of language development and use different in humans
and LLMs? - drawing parallels between LLMs and biological systems. Our analysis
shows how LLMs can map and manipulate complex linguistic patterns in their
training data. Moreover, LLMs can follow Grice's Cooperative Principle to
provide relevant and informative responses. However, human cognition draws from
multiple sources of meaning, including experiential, emotional, and imaginative
facets, which transcend mere language processing and are rooted in our social
and developmental trajectories. Moreover, current LLMs lack physical
embodiment, reducing their ability to make sense of the intricate interplay
between perception, action, and cognition that shapes human understanding and
expression. Ultimately, Psychomatics holds the potential to yield
transformative insights into the nature of language, cognition, and
intelligence, both artificial and biological. Moreover, by drawing parallels
between LLMs and human cognitive processes, Psychomatics can inform the
development of more robust and human-like AI systems.
",2024-07-23T12:53:41Z,http://arxiv.org/abs/2407.16444v1,"Giuseppe Riva, Fabrizia Mantovani, Brenda K. Wiederhold, Antonella Marchetti, Andrea Gaggioli"
Few-shot Learning for Slot Tagging with Attentive Relational Network,"  Metric-based learning is a well-known family of methods for few-shot
learning, especially in computer vision. Recently, they have been used in many
natural language processing applications but not for slot tagging. In this
paper, we explore metric-based learning methods in the slot tagging task and
propose a novel metric-based learning architecture - Attentive Relational
Network. Our proposed method extends relation networks, making them more
suitable for natural language processing applications in general, by leveraging
pretrained contextual embeddings such as ELMO and BERT and by using attention
mechanism. The results on SNIPS data show that our proposed method outperforms
other state-of-the-art metric-based learning methods.
",2021-03-03T11:24:24Z,http://arxiv.org/abs/2103.02333v1,"Cennet Oguz, Ngoc Thang Vu"
"Rethinking Sparse Lexical Representations for Image Retrieval in the Age
  of Rising Multi-Modal Large Language Models","  In this paper, we rethink sparse lexical representations for image retrieval.
By utilizing multi-modal large language models (M-LLMs) that support visual
prompting, we can extract image features and convert them into textual data,
enabling us to utilize efficient sparse retrieval algorithms employed in
natural language processing for image retrieval tasks. To assist the LLM in
extracting image features, we apply data augmentation techniques for key
expansion and analyze the impact with a metric for relevance between images and
textual data. We empirically show the superior precision and recall performance
of our image retrieval method compared to conventional vision-language
model-based methods on the MS-COCO, PASCAL VOC, and NUS-WIDE datasets in a
keyword-based image retrieval scenario, where keywords serve as search queries.
We also demonstrate that the retrieval performance can be improved by
iteratively incorporating keywords into search queries.
",2024-08-29T06:54:03Z,http://arxiv.org/abs/2408.16296v1,"Kengo Nakata, Daisuke Miyashita, Youyang Ng, Yasuto Hoshi, Jun Deguchi"
"Entangling Solid Solutions: Machine Learning of Tensor Networks for
  Materials Property Prediction","  Progress in the application of machine learning techniques to the prediction
of solid-state and molecular materials properties has been greatly facilitated
by the development state-of-the-art feature representations and novel deep
learning architectures. A large class of atomic structure representations based
on expansions of smoothed atomic densities have been shown to correspond to
specific choices of basis sets in an abstract many-body Hilbert space.
Concurrently, tensor network structures, conventionally the purview of quantum
many-body physics and quantum information, have been successfully applied in
supervised and unsupervised learning tasks in computer vision and natural
language processing. In this work, we argue that architectures based on tensor
networks are well-suited to machine learning on Hilbert-space representations
of atomic structures. This is demonstrated on supervised learning tasks
involving widely available datasets of density functional theory calculations
of metal and semiconductor alloys. In particular, we show that certain standard
tensor network topologies exhibit strong generalizability even on small
training datasets while being parametrically efficient. We further relate this
generalizability to the presence of complex entanglement in the trained tensor
networks. We also discuss connections to learning with generalized structural
kernels and related strategies for compressing large input feature spaces.
",2022-03-17T21:02:58Z,http://arxiv.org/abs/2203.09613v1,"David E. Sommer, Scott T. Dunham"
"Large-scale representation learning from visually grounded untranscribed
  speech","  Systems that can associate images with their spoken audio captions are an
important step towards visually grounded language learning. We describe a
scalable method to automatically generate diverse audio for image captioning
datasets. This supports pretraining deep networks for encoding both audio and
images, which we do via a dual encoder that learns to align latent
representations from both modalities. We show that a masked margin softmax loss
for such models is superior to the standard triplet loss. We fine-tune these
models on the Flickr8k Audio Captions Corpus and obtain state-of-the-art
results---improving recall in the top 10 from 29.6% to 49.5%. We also obtain
human ratings on retrieval outputs to better assess the impact of incidentally
matching image-caption pairs that were not associated in the data, finding that
automatic evaluation substantially underestimates the quality of the retrieved
results.
",2019-09-19T02:50:23Z,http://arxiv.org/abs/1909.08782v1,"Gabriel Ilharco, Yuan Zhang, Jason Baldridge"
"Perceiving the World: Question-guided Reinforcement Learning for
  Text-based Games","  Text-based games provide an interactive way to study natural language
processing. While deep reinforcement learning has shown effectiveness in
developing the game playing agent, the low sample efficiency and the large
action space remain to be the two major challenges that hinder the DRL from
being applied in the real world. In this paper, we address the challenges by
introducing world-perceiving modules, which automatically decompose tasks and
prune actions by answering questions about the environment. We then propose a
two-phase training framework to decouple language learning from reinforcement
learning, which further improves the sample efficiency. The experimental
results show that the proposed method significantly improves the performance
and sample efficiency. Besides, it shows robustness against compound error and
limited pre-training data.
",2022-03-20T04:23:57Z,http://arxiv.org/abs/2204.09597v2,"Yunqiu Xu, Meng Fang, Ling Chen, Yali Du, Joey Tianyi Zhou, Chengqi Zhang"
"A Decade of In-text Citation Analysis based on Natural Language
  Processing and Machine Learning Techniques: An overview of empirical studies","  Citation analysis is one of the most frequently used methods in research
evaluation. We are seeing significant growth in citation analysis through
bibliometric metadata, primarily due to the availability of citation databases
such as the Web of Science, Scopus, Google Scholar, Microsoft Academic, and
Dimensions. Due to better access to full-text publication corpora in recent
years, information scientists have gone far beyond traditional bibliometrics by
tapping into advancements in full-text data processing techniques to measure
the impact of scientific publications in contextual terms. This has led to
technical developments in citation context and content analysis, citation
classifications, citation sentiment analysis, citation summarisation, and
citation-based recommendation. This article aims to narratively review the
studies on these developments. Its primary focus is on publications that have
used natural language processing and machine learning techniques to analyse
citations.
",2020-08-29T17:27:08Z,http://arxiv.org/abs/2008.13020v1,"Sehrish Iqbal, Saeed-Ul Hassan, Naif Radi Aljohani, Salem Alelyani, Raheel Nawaz, Lutz Bornmann"
"Language and Intelligence, Artificial vs. Natural or What Can and What
  Cannot AI Do with NL?","  In this talk, I argue that there are certain pragmatic features of natural
language (that I will call 'productivity' and 'malleability', on top of
syntactical generativity and semantical compositionality), which are not only
hard, but even impossible to capture in an artificial language used by an AI
system, and the reason for this is to be found in certain deep, metaphysical
differences between artificial and natural intelligence, accounting for the
differences in their respective processes of concept-formation.
",2022-08-31T10:11:50Z,http://arxiv.org/abs/2209.12829v1,Gyula Klima
"Medical code prediction with multi-view convolution and
  description-regularized label-dependent attention","  A ubiquitous task in processing electronic medical data is the assignment of
standardized codes representing diagnoses and/or procedures to free-text
documents such as medical reports. This is a difficult natural language
processing task that requires parsing long, heterogeneous documents and
selecting a set of appropriate codes from tens of thousands of
possibilities---many of which have very few positive training samples. We
present a deep learning system that advances the state of the art for the
MIMIC-III dataset, achieving a new best micro F1-measure of 55.85\%,
significantly outperforming the previous best result (Mullenbach et al. 2018).
We achieve this through a number of enhancements, including two major novel
contributions: multi-view convolutional channels, which effectively learn to
adjust kernel sizes throughout the input; and attention regularization,
mediated by natural-language code descriptions, which helps overcome sparsity
for thousands of uncommon codes. These and other modifications are selected to
address difficulties inherent to both automated coding specifically and deep
learning generally. Finally, we investigate our accuracy results in detail to
individually measure the impact of these contributions and point the way
towards future algorithmic improvements.
",2018-11-05T00:54:03Z,http://arxiv.org/abs/1811.01468v1,"Najmeh Sadoughi, Greg P. Finley, James Fone, Vignesh Murali, Maxim Korenevski, Slava Baryshnikov, Nico Axtmann, Mark Miller, David Suendermann-Oeft"
A Multi-cascaded Deep Model for Bilingual SMS Classification,"  Most studies on text classification are focused on the English language.
However, short texts such as SMS are influenced by regional languages. This
makes the automatic text classification task challenging due to the
multilingual, informal, and noisy nature of language in the text. In this work,
we propose a novel multi-cascaded deep learning model called McM for bilingual
SMS classification. McM exploits $n$-gram level information as well as
long-term dependencies of text for learning. Our approach aims to learn a model
without any code-switching indication, lexical normalization, language
translation, or language transliteration. The model relies entirely upon the
text as no external knowledge base is utilized for learning. For this purpose,
a 12 class bilingual text dataset is developed from SMS feedbacks of citizens
on public services containing mixed Roman Urdu and English languages. Our model
achieves high accuracy for classification on this dataset and outperforms the
previous model for multilingual text classification, highlighting language
independence of McM.
",2019-11-29T11:35:13Z,http://arxiv.org/abs/1911.13066v1,"Muhammad Haroon Shakeel, Asim Karim, Imdadullah Khan"
"Deep Learning Transformer Architecture for Named Entity Recognition on
  Low Resourced Languages: State of the art results","  This paper reports on the evaluation of Deep Learning (DL) transformer
architecture models for Named-Entity Recognition (NER) on ten low-resourced
South African (SA) languages. In addition, these DL transformer models were
compared to other Neural Network and Machine Learning (ML) NER models. The
findings show that transformer models substantially improve performance when
applying discrete fine-tuning parameters per language. Furthermore, fine-tuned
transformer models outperform other neural network and machine learning models
on NER with the low-resourced SA languages. For example, the transformer models
obtained the highest F-scores for six of the ten SA languages and the highest
average F-score surpassing the Conditional Random Fields ML model. Practical
implications include developing high-performance NER capability with less
effort and resource costs, potentially improving downstream NLP tasks such as
Machine Translation (MT). Therefore, the application of DL transformer
architecture models for NLP NER sequence tagging tasks on low-resourced SA
languages is viable. Additional research could evaluate the more recent
transformer architecture models on other Natural Language Processing tasks and
applications, such as Phrase chunking, MT, and Part-of-Speech tagging.
",2021-11-01T11:02:01Z,http://arxiv.org/abs/2111.00830v2,Ridewaan Hanslo
Helix: Holistic Optimization for Accelerating Iterative Machine Learning,"  Machine learning workflow development is a process of trial-and-error:
developers iterate on workflows by testing out small modifications until the
desired accuracy is achieved. Unfortunately, existing machine learning systems
focus narrowly on model training---a small fraction of the overall development
time---and neglect to address iterative development. We propose Helix, a
machine learning system that optimizes the execution across
iterations---intelligently caching and reusing, or recomputing intermediates as
appropriate. Helix captures a wide variety of application needs within its
Scala DSL, with succinct syntax defining unified processes for data
preprocessing, model specification, and learning. We demonstrate that the reuse
problem can be cast as a Max-Flow problem, while the caching problem is
NP-Hard. We develop effective lightweight heuristics for the latter. Empirical
evaluation shows that Helix is not only able to handle a wide variety of use
cases in one unified workflow but also much faster, providing run time
reductions of up to 19x over state-of-the-art systems, such as DeepDive or
KeystoneML, on four real-world applications in natural language processing,
computer vision, social and natural sciences.
",2018-12-14T02:32:45Z,http://arxiv.org/abs/1812.05762v1,"Doris Xin, Stephen Macke, Litian Ma, Jialin Liu, Shuchen Song, Aditya Parameswaran"
"Adaptive Feature Fusion: Enhancing Generalization in Deep Learning
  Models","  In recent years, deep learning models have demonstrated remarkable success in
various domains, such as computer vision, natural language processing, and
speech recognition. However, the generalization capabilities of these models
can be negatively impacted by the limitations of their feature fusion
techniques. This paper introduces an innovative approach, Adaptive Feature
Fusion (AFF), to enhance the generalization of deep learning models by
dynamically adapting the fusion process of feature representations.
  The proposed AFF framework is designed to incorporate fusion layers into
existing deep learning architectures, enabling seamless integration and
improved performance. By leveraging a combination of data-driven and
model-based fusion strategies, AFF is able to adaptively fuse features based on
the underlying data characteristics and model requirements. This paper presents
a detailed description of the AFF framework, including the design and
implementation of fusion layers for various architectures.
  Extensive experiments are conducted on multiple benchmark datasets, with the
results demonstrating the superiority of the AFF approach in comparison to
traditional feature fusion techniques. The analysis showcases the effectiveness
of AFF in enhancing generalization capabilities, leading to improved
performance across different tasks and applications.
  Finally, the paper discusses various real-world use cases where AFF can be
employed, providing insights into its practical applicability. The conclusion
highlights the potential for future research directions, including the
exploration of advanced fusion strategies and the extension of AFF to other
machine learning paradigms.
",2023-04-04T21:41:38Z,http://arxiv.org/abs/2304.03290v1,Neelesh Mungoli
Data Readiness for Natural Language Processing,"  This document concerns data readiness in the context of machine learning and
Natural Language Processing. It describes how an organization may proceed to
identify, make available, validate, and prepare data to facilitate automated
analysis methods. The contents of the document is based on the practical
challenges and frequently asked questions we have encountered in our work as an
applied research institute with helping organizations and companies, both in
the public and private sectors, to use data in their business processes.
",2020-09-04T07:53:43Z,http://arxiv.org/abs/2009.02043v2,"Fredrik Olsson, Magnus Sahlgren"
"Learning What Makes a Difference from Counterfactual Examples and
  Gradient Supervision","  One of the primary challenges limiting the applicability of deep learning is
its susceptibility to learning spurious correlations rather than the underlying
mechanisms of the task of interest. The resulting failure to generalise cannot
be addressed by simply using more data from the same distribution. We propose
an auxiliary training objective that improves the generalization capabilities
of neural networks by leveraging an overlooked supervisory signal found in
existing datasets. We use pairs of minimally-different examples with different
labels, a.k.a counterfactual or contrasting examples, which provide a signal
indicative of the underlying causal structure of the task. We show that such
pairs can be identified in a number of existing datasets in computer vision
(visual question answering, multi-label image classification) and natural
language processing (sentiment analysis, natural language inference). The new
training objective orients the gradient of a model's decision function with
pairs of counterfactual examples. Models trained with this technique
demonstrate improved performance on out-of-distribution test sets.
",2020-04-20T02:47:49Z,http://arxiv.org/abs/2004.09034v1,"Damien Teney, Ehsan Abbasnedjad, Anton van den Hengel"
"Underwater-Art: Expanding Information Perspectives With Text Templates
  For Underwater Acoustic Target Recognition","  Underwater acoustic target recognition is an intractable task due to the
complex acoustic source characteristics and sound propagation patterns. Limited
by insufficient data and narrow information perspective, recognition models
based on deep learning seem far from satisfactory in practical underwater
scenarios. Although underwater acoustic signals are severely influenced by
distance, channel depth, or other factors, annotations of relevant information
are often non-uniform, incomplete, and hard to use. In our work, we propose to
implement Underwater Acoustic Recognition based on Templates made up of rich
relevant information (hereinafter called ""UART""). We design templates to
integrate relevant information from different perspectives into descriptive
natural language. UART adopts an audio-spectrogram-text tri-modal contrastive
learning framework, which endows UART with the ability to guide the learning of
acoustic representations by descriptive natural language. Our experiments
reveal that UART has better recognition capability and generalization
performance than traditional paradigms. Furthermore, the pre-trained UART model
could provide superior prior knowledge for the recognition model in the
scenario without any auxiliary annotation.
",2023-05-31T07:28:37Z,http://arxiv.org/abs/2305.19612v2,"Yuan Xie, Jiawei Ren, Ji Xu"
EZLearn: Exploiting Organic Supervision in Large-Scale Data Annotation,"  Many real-world applications require automated data annotation, such as
identifying tissue origins based on gene expressions and classifying images
into semantic categories. Annotation classes are often numerous and subject to
changes over time, and annotating examples has become the major bottleneck for
supervised learning methods. In science and other high-value domains, large
repositories of data samples are often available, together with two sources of
organic supervision: a lexicon for the annotation classes, and text
descriptions that accompany some data samples. Distant supervision has emerged
as a promising paradigm for exploiting such indirect supervision by
automatically annotating examples where the text description contains a class
mention in the lexicon. However, due to linguistic variations and ambiguities,
such training data is inherently noisy, which limits the accuracy of this
approach. In this paper, we introduce an auxiliary natural language processing
system for the text modality, and incorporate co-training to reduce noise and
augment signal in distant supervision. Without using any manually labeled data,
our EZLearn system learned to accurately annotate data samples in functional
genomics and scientific figure comprehension, substantially outperforming
state-of-the-art supervised methods trained on tens of thousands of annotated
examples.
",2017-09-25T17:10:46Z,http://arxiv.org/abs/1709.08600v3,"Maxim Grechkin, Hoifung Poon, Bill Howe"
"Learning User Preferences and Understanding Calendar Contexts for Event
  Scheduling","  With online calendar services gaining popularity worldwide, calendar data has
become one of the richest context sources for understanding human behavior.
However, event scheduling is still time-consuming even with the development of
online calendars. Although machine learning based event scheduling models have
automated scheduling processes to some extent, they often fail to understand
subtle user preferences and complex calendar contexts with event titles written
in natural language. In this paper, we propose Neural Event Scheduling
Assistant (NESA) which learns user preferences and understands calendar
contexts, directly from raw online calendars for fully automated and highly
effective event scheduling. We leverage over 593K calendar events for NESA to
learn scheduling personal events, and we further utilize NESA for
multi-attendee event scheduling. NESA successfully incorporates deep neural
networks such as Bidirectional Long Short-Term Memory, Convolutional Neural
Network, and Highway Network for learning the preferences of each user and
understanding calendar context based on natural languages. The experimental
results show that NESA significantly outperforms previous baseline models in
terms of various evaluation metrics on both personal and multi-attendee event
scheduling tasks. Our qualitative analysis demonstrates the effectiveness of
each layer in NESA and learned user preferences.
",2018-09-05T04:15:13Z,http://arxiv.org/abs/1809.01316v3,"Donghyeon Kim, Jinhyuk Lee, Donghee Choi, Jaehoon Choi, Jaewoo Kang"
"Translating synthetic natural language to database queries: a polyglot
  deep learning framework","  The number of databases as well as their size and complexity is increasing.
This creates a barrier to use especially for non-experts, who have to come to
grips with the nature of the data, the way it has been represented in the
database, and the specific query languages or user interfaces by which data are
accessed. These difficulties worsen in research settings, where it is common to
work with many different databases. One approach to improving this situation is
to allow users to pose their queries in natural language.
  In this work we describe a machine learning framework, Polyglotter, that in a
general way supports the mapping of natural language searches to database
queries. Importantly, it does not require the creation of manually annotated
data for training and therefore can be applied easily to multiple domains. The
framework is polyglot in the sense that it supports multiple different database
engines that are accessed with a variety of query languages, including SQL and
Cypher. Furthermore Polyglotter also supports multi-class queries.
  Our results indicate that our framework performs well on both synthetic and
real databases, and may provide opportunities for database maintainers to
improve accessibility to their resources.
",2021-04-14T17:43:51Z,http://arxiv.org/abs/2104.07010v1,"Adri√°n Bazaga, Nupur Gunwant, Gos Micklem"
"Colloquial Persian POS (CPPOS) Corpus: A Novel Corpus for Colloquial
  Persian Part of Speech Tagging","  Introduction: Part-of-Speech (POS) Tagging, the process of classifying words
into their respective parts of speech (e.g., verb or noun), is essential in
various natural language processing applications. POS tagging is a crucial
preprocessing task for applications like machine translation, question
answering, sentiment analysis, etc. However, existing corpora for POS tagging
in Persian mainly consist of formal texts, such as daily news and newspapers.
As a result, smart POS tools, machine learning models, and deep learning models
trained on these corpora may not perform optimally for processing colloquial
text in social network analysis. Method: This paper introduces a novel corpus,
""Colloquial Persian POS"" (CPPOS), specifically designed to support colloquial
Persian text. The corpus includes formal and informal text collected from
various domains such as political, social, and commercial on Telegram, Twitter,
and Instagram more than 520K labeled tokens. After collecting posts from these
social platforms for one year, special preprocessing steps were conducted,
including normalization, sentence tokenizing, and word tokenizing for social
text. The tokens and sentences were then manually annotated and verified by a
team of linguistic experts. This study also defines a POS tagging guideline for
annotating the data and conducting the annotation process. Results: To evaluate
the quality of CPPOS, various deep learning models, such as the RNN family,
were trained using the constructed corpus. A comparison with another well-known
Persian POS corpus named ""Bijankhan"" and the Persian Hazm POS tool trained on
Bijankhan revealed that our model trained on CPPOS outperforms them. With the
new corpus and the BiLSTM deep neural model, we achieved a 14% improvement over
the previous dataset.
",2023-10-01T05:06:33Z,http://arxiv.org/abs/2310.00572v1,"Leyla Rabiei, Farzaneh Rahmani, Mohammad Khansari, Zeinab Rajabi, Moein Salimi"
ModelHub.AI: Dissemination Platform for Deep Learning Models,"  Recent advances in artificial intelligence research have led to a profusion
of studies that apply deep learning to problems in image analysis and natural
language processing among others. Additionally, the availability of open-source
computational frameworks has lowered the barriers to implementing
state-of-the-art methods across multiple domains. Albeit leading to major
performance breakthroughs in some tasks, effective dissemination of deep
learning algorithms remains challenging, inhibiting reproducibility and
benchmarking studies, impeding further validation, and ultimately hindering
their effectiveness in the cumulative scientific progress. In developing a
platform for sharing research outputs, we present ModelHub.AI
(www.modelhub.ai), a community-driven container-based software engine and
platform for the structured dissemination of deep learning models. For
contributors, the engine controls data flow throughout the inference cycle,
while the contributor-facing standard template exposes model-specific functions
including inference, as well as pre- and post-processing. Python and RESTful
Application programming interfaces (APIs) enable users to interact with models
hosted on ModelHub.AI and allows both researchers and developers to utilize
models out-of-the-box. ModelHub.AI is domain-, data-, and framework-agnostic,
catering to different workflows and contributors' preferences.
",2019-11-26T22:48:11Z,http://arxiv.org/abs/1911.13218v1,"Ahmed Hosny, Michael Schwier, Christoph Berger, Evin P √ñrnek, Mehmet Turan, Phi V Tran, Leon Weninger, Fabian Isensee, Klaus H Maier-Hein, Richard McKinley, Michael T Lu, Udo Hoffmann, Bjoern Menze, Spyridon Bakas, Andriy Fedorov, Hugo JWL Aerts"
Who wrote this book? A challenge for e-commerce,"  Modern e-commerce catalogs contain millions of references, associated with
textual and visual information that is of paramount importance for the products
to be found via search or browsing. Of particular significance is the book
category, where the author name(s) field poses a significant challenge. Indeed,
books written by a given author (such as F. Scott Fitzgerald) might be listed
with different authors' names in a catalog due to abbreviations and spelling
variants and mistakes, among others. To solve this problem at scale, we design
a composite system involving open data sources for books as well as machine
learning components leveraging deep learning-based techniques for natural
language processing. In particular, we use Siamese neural networks for an
approximate match with known author names, and direct correction of the
provided author's name using sequence-to-sequence learning with neural
networks. We evaluate this approach on product data from the e-commerce website
Rakuten France, and find that the top proposal of the system is the normalized
author name with 72% accuracy.
",2019-04-19T10:13:07Z,http://arxiv.org/abs/1905.01973v1,"B√©ranger Dumont, Simona Maggio, Ghiles Sidi Said, Quoc-Tien Au"
"Integration of Neural Network-Based Symbolic Regression in Deep Learning
  for Scientific Discovery","  Symbolic regression is a powerful technique that can discover analytical
equations that describe data, which can lead to explainable models and
generalizability outside of the training data set. In contrast, neural networks
have achieved amazing levels of accuracy on image recognition and natural
language processing tasks, but are often seen as black-box models that are
difficult to interpret and typically extrapolate poorly. Here we use a neural
network-based architecture for symbolic regression called the Equation Learner
(EQL) network and integrate it with other deep learning architectures such that
the whole system can be trained end-to-end through backpropagation. To
demonstrate the power of such systems, we study their performance on several
substantially different tasks. First, we show that the neural network can
perform symbolic regression and learn the form of several functions. Next, we
present an MNIST arithmetic task where a separate part of the neural network
extracts the digits. Finally, we demonstrate prediction of dynamical systems
where an unknown parameter is extracted through an encoder. We find that the
EQL-based architecture can extrapolate quite well outside of the training data
set compared to a standard neural network-based architecture, paving the way
for deep learning to be applied in scientific exploration and discovery.
",2019-12-10T17:07:52Z,http://arxiv.org/abs/1912.04825v2,"Samuel Kim, Peter Y. Lu, Srijon Mukherjee, Michael Gilbert, Li Jing, Vladimir ƒåeperiƒá, Marin Soljaƒçiƒá"
"On Efficient Training of Large-Scale Deep Learning Models: A Literature
  Review","  The field of deep learning has witnessed significant progress, particularly
in computer vision (CV), natural language processing (NLP), and speech. The use
of large-scale models trained on vast amounts of data holds immense promise for
practical applications, enhancing industrial productivity and facilitating
social development. With the increasing demands on computational capacity,
though numerous studies have explored the efficient training, a comprehensive
summarization on acceleration techniques of training deep learning models is
still much anticipated. In this survey, we present a detailed review for
training acceleration. We consider the fundamental update formulation and split
its basic components into five main perspectives: (1) data-centric: including
dataset regularization, data sampling, and data-centric curriculum learning
techniques, which can significantly reduce the computational complexity of the
data samples; (2) model-centric, including acceleration of basic modules,
compression training, model initialization and model-centric curriculum
learning techniques, which focus on accelerating the training via reducing the
calculations on parameters; (3) optimization-centric, including the selection
of learning rate, the employment of large batchsize, the designs of efficient
objectives, and model average techniques, which pay attention to the training
policy and improving the generality for the large-scale models; (4) budgeted
training, including some distinctive acceleration methods on source-constrained
situations; (5) system-centric, including some efficient open-source
distributed libraries/systems which provide adequate hardware support for the
implementation of acceleration algorithms. By presenting this comprehensive
taxonomy, our survey presents a comprehensive review to understand the general
mechanisms within each component and their joint interaction.
",2023-04-07T11:13:23Z,http://arxiv.org/abs/2304.03589v1,"Li Shen, Yan Sun, Zhiyuan Yu, Liang Ding, Xinmei Tian, Dacheng Tao"
An Inference Approach To Question Answering Over Knowledge Graphs,"  Knowledge Graphs (KG) act as a great tool for holding distilled information
from large natural language text corpora. The problem of natural language
querying over knowledge graphs is essential for the human consumption of this
information. This problem is typically addressed by converting the natural
language query to a structured query and then firing the structured query on
the KG. Direct answering models over knowledge graphs in literature are very
few. The query conversion models and direct models both require specific
training data pertaining to the domain of the knowledge graph. In this work, we
convert the problem of natural language querying over knowledge graphs to an
inference problem over premise-hypothesis pairs. Using trained deep learning
models for the converted proxy inferencing problem, we provide the solution for
the original natural language querying problem. Our method achieves over 90%
accuracy on MetaQA dataset, beating the existing state-of-the-art. We also
propose a model for inferencing called Hierarchical Recurrent Path
Encoder(HRPE). The inferencing models can be fine-tuned to be used across
domains with less training data. Our approach does not require large
domain-specific training data for querying on new knowledge graphs from
different domains.
",2021-12-21T10:07:55Z,http://arxiv.org/abs/2112.11070v1,"Aayushee Gupta, K. M. Annervaz, Ambedkar Dukkipati, Shubhashis Sengupta"
"An Efficient Architecture for Predicting the Case of Characters using
  Sequence Models","  The dearth of clean textual data often acts as a bottleneck in several
natural language processing applications. The data available often lacks proper
case (uppercase or lowercase) information. This often comes up when text is
obtained from social media, messaging applications and other online platforms.
This paper attempts to solve this problem by restoring the correct case of
characters, commonly known as Truecasing. Doing so improves the accuracy of
several processing tasks further down in the NLP pipeline. Our proposed
architecture uses a combination of convolutional neural networks (CNN),
bi-directional long short-term memory networks (LSTM) and conditional random
fields (CRF), which work at a character level without any explicit feature
engineering. In this study we compare our approach to previous statistical and
deep learning based approaches. Our method shows an increment of 0.83 in F1
score over the current state of the art. Since truecasing acts as a
preprocessing step in several applications, every increment in the F1 score
leads to a significant improvement in the language processing tasks.
",2020-01-30T06:54:39Z,http://arxiv.org/abs/2002.00738v1,"Gopi Ramena, Divija Nagaraju, Sukumar Moharana, Debi Prasanna Mohanty, Naresh Purre"
Deep Neural Networks with Short Circuits for Improved Gradient Learning,"  Deep neural networks have achieved great success both in computer vision and
natural language processing tasks. However, mostly state-of-art methods highly
rely on external training or computing to improve the performance. To alleviate
the external reliance, we proposed a gradient enhancement approach, conducted
by the short circuit neural connections, to improve the gradient learning of
deep neural networks. The proposed short circuit is a unidirectional connection
that single back propagates the sensitive from the deep layer to the shallows.
Moreover, the short circuit formulates to be a gradient truncation of its
crossing layers which can plug into the backbone deep neural networks without
introducing external training parameters. Extensive experiments demonstrate
deep neural networks with our short circuit gain a large margin over the
baselines on both computer vision and natural language processing tasks.
",2020-09-23T15:51:37Z,http://arxiv.org/abs/2009.11719v1,"Ming Yan, Xueli Xiao, Joey Tianyi Zhou, Yi Pan"
"Graph Neural Network contextual embedding for Deep Learning on Tabular
  Data","  All industries are trying to leverage Artificial Intelligence (AI) based on
their existing big data which is available in so called tabular form, where
each record is composed of a number of heterogeneous continuous and categorical
columns also known as features. Deep Learning (DL) has constituted a major
breakthrough for AI in fields related to human skills like natural language
processing, but its applicability to tabular data has been more challenging.
More classical Machine Learning (ML) models like tree-based ensemble ones
usually perform better. This paper presents a novel DL model using Graph Neural
Network (GNN) more specifically Interaction Network (IN), for contextual
embedding and modelling interactions among tabular features. Its results
outperform those of a recently published survey with DL benchmark based on five
public datasets, also achieving competitive results when compared to
boosted-tree solutions.
",2023-03-11T17:13:24Z,http://arxiv.org/abs/2303.06455v2,"Mario Villaiz√°n-Vallelado, Matteo Salvatori, Bel√©n Carro Martinez, Antonio Javier Sanchez Esguevillas"
Posing Fair Generalization Tasks for Natural Language Inference,"  Deep learning models for semantics are generally evaluated using naturalistic
corpora. Adversarial methods, in which models are evaluated on new examples
with known semantic properties, have begun to reveal that good performance at
these naturalistic tasks can hide serious shortcomings. However, we should
insist that these evaluations be fair -that the models are given data
sufficient to support the requisite kinds of generalization. In this paper, we
define and motivate a formal notion of fairness in this sense. We then apply
these ideas to natural language inference by constructing very challenging but
provably fair artificial datasets and showing that standard neural models fail
to generalize in the required ways; only task-specific models that jointly
compose the premise and hypothesis are able to achieve high performance, and
even these models do not solve the task perfectly.
",2019-11-03T02:47:51Z,http://arxiv.org/abs/1911.00811v1,"Atticus Geiger, Ignacio Cases, Lauri Karttunen, Chris Potts"
"Active$^2$ Learning: Actively reducing redundancies in Active Learning
  methods for Sequence Tagging and Machine Translation","  While deep learning is a powerful tool for natural language processing (NLP)
problems, successful solutions to these problems rely heavily on large amounts
of annotated samples. However, manually annotating data is expensive and
time-consuming. Active Learning (AL) strategies reduce the need for huge
volumes of labeled data by iteratively selecting a small number of examples for
manual annotation based on their estimated utility in training the given model.
In this paper, we argue that since AL strategies choose examples independently,
they may potentially select similar examples, all of which may not contribute
significantly to the learning process. Our proposed approach,
Active$\mathbf{^2}$ Learning (A$\mathbf{^2}$L), actively adapts to the deep
learning model being trained to eliminate such redundant examples chosen by an
AL strategy. We show that A$\mathbf{^2}$L is widely applicable by using it in
conjunction with several different AL strategies and NLP tasks. We empirically
demonstrate that the proposed approach is further able to reduce the data
requirements of state-of-the-art AL strategies by $\approx \mathbf{3-25\%}$ on
an absolute scale on multiple NLP tasks while achieving the same performance
with virtually no additional computation overhead.
",2019-11-01T07:31:02Z,http://arxiv.org/abs/1911.00234v4,"Rishi Hazra, Parag Dutta, Shubham Gupta, Mohammed Abdul Qaathir, Ambedkar Dukkipati"
Data Agnostic RoBERTa-based Natural Language to SQL Query Generation,"  Relational databases are among the most widely used architectures to store
massive amounts of data in the modern world. However, there is a barrier
between these databases and the average user. The user often lacks the
knowledge of a query language such as SQL required to interact with the
database. The NL2SQL task aims at finding deep learning approaches to solve
this problem by converting natural language questions into valid SQL queries.
Given the sensitive nature of some databases and the growing need for data
privacy, we have presented an approach with data privacy at its core. We have
passed RoBERTa embeddings and data-agnostic knowledge vectors into LSTM based
submodels to predict the final query. Although we have not achieved state of
the art results, we have eliminated the need for the table data, right from the
training of the model, and have achieved a test set execution accuracy of
76.7%. By eliminating the table data dependency while training we have created
a model capable of zero shot learning based on the natural language question
and table schema alone.
",2020-10-11T13:18:46Z,http://arxiv.org/abs/2010.05243v3,"Debaditya Pal, Harsh Sharma, Kaustubh Chaudhari"
RF Signal Transformation and Classification using Deep Neural Networks,"  Deep neural networks (DNNs) designed for computer vision and natural language
processing tasks cannot be directly applied to the radio frequency (RF)
datasets. To address this challenge, we propose to convert the raw RF data to
data types that are suitable for off-the-shelf DNNs by introducing a
convolutional transform technique. In addition, we propose a simple 5-layer
convolutional neural network architecture (CONV-5) that can operate with raw RF
I/Q data without any transformation. Further, we put forward an RF dataset,
referred to as RF1024, to facilitate future RF research. RF1024 consists of 8
different RF modulation classes with each class having 1000/200 training/test
samples. Each sample of the RF1024 dataset contains 1024 complex I/Q values.
Lastly, the experiments are performed on the RadioML2016 and RF1024 datasets to
demonstrate the improved classification performance.
",2022-04-06T05:01:59Z,http://arxiv.org/abs/2204.03564v1,"Umar Khalid, Nazmul Karim, Nazanin Rahnavard"
Rock Guitar Tablature Generation via Natural Language Processing,"  Deep learning has recently empowered and democratized generative modeling of
images and text, with additional concurrent works exploring the possibility of
generating more complex forms of data, such as audio. However, the high
dimensionality, long-range dependencies, and lack of standardized datasets
currently makes generative modeling of audio and music very challenging. We
propose to model music as a series of discrete notes upon which we can use
autoregressive natural language processing techniques for successful generative
modeling. While previous works used similar pipelines on data such as sheet
music and MIDI, we aim to extend such approaches to the under-studied medium of
guitar tablature. Specifically, we develop the first work to our knowledge that
models one specific genre as guitar tablature: heavy rock. Unlike other works
in guitar tablature generation, we have a freely available public demo at
https://huggingface.co/spaces/josuelmet/Metal_Music_Interpolator
",2023-01-12T21:12:08Z,http://arxiv.org/abs/2301.05295v2,Josue Casco-Rodriguez
"Towards Coinductive Models for Natural Language Understanding. Bringing
  together Deep Learning and Deep Semantics","  This article contains a proposal to add coinduction to the computational
apparatus of natural language understanding. This, we argue, will provide a
basis for more realistic, computationally sound, and scalable models of natural
language dialogue, syntax and semantics. Given that the bottom up, inductively
constructed, semantic and syntactic structures are brittle, and seemingly
incapable of adequately representing the meaning of longer sentences or
realistic dialogues, natural language understanding is in need of a new
foundation. Coinduction, which uses top down constraints, has been successfully
used in the design of operating systems and programming languages. Moreover,
implicitly it has been present in text mining, machine translation, and in some
attempts to model intensionality and modalities, which provides evidence that
it works. This article shows high level formalizations of some of such uses.
  Since coinduction and induction can coexist, they can provide a common
language and a conceptual model for research in natural language understanding.
In particular, such an opportunity seems to be emerging in research on
compositionality. This article shows several examples of the joint appearance
of induction and coinduction in natural language processing. We argue that the
known individual limitations of induction and coinduction can be overcome in
empirical settings by a combination of the the two methods. We see an open
problem in providing a theory of their joint use.
",2020-12-09T03:10:36Z,http://arxiv.org/abs/2012.05715v1,Wlodek W. Zadrozny
"Genetic Bottleneck and the Emergence of High Intelligence by Scaling-out
  and High Throughput","  We study the biological evolution of low-latency natural neural networks for
short-term survival, and its parallels in the development of low latency
high-performance Central Processing Unit in computer design and architecture.
The necessity of accurate high-quality display of motion picture led to the
special processing units known as the GPU, just as how special visual cortex
regions of animals produced such low-latency computational capacity. The human
brain, especially considered as nothing but a scaled-up version of a primate
brain evolved in response to genomic bottleneck, producing a brain that is
trainable and prunable by society, and as a further extension, invents
language, writing and storage of narratives displaced in time and space. We
conclude that this modern digital invention of social media and the archived
collective common corpus has further evolved from just simple CPU-based
low-latency fast retrieval to high-throughput parallel processing of data using
GPUs to train Attention based Deep Learning Neural Networks producing
Generative AI with aspects like toxicity, bias, memorization, hallucination,
with intriguing close parallels in humans and their society. We show how this
paves the way for constructive approaches to eliminating such drawbacks from
human society and its proxy and collective large-scale mirror, the Generative
AI of the LLMs.
",2024-05-29T14:35:39Z,http://arxiv.org/abs/2407.08743v1,"Arifa Khan, Saravanan P, Venkatesan S. K."
On Inductive Biases for Machine Learning in Data Constrained Settings,"  Learning with limited data is one of the biggest problems of machine
learning. Current approaches to this issue consist in learning general
representations from huge amounts of data before fine-tuning the model on a
small dataset of interest. While such technique, coined transfer learning, is
very effective in domains such as computer vision or natural langage
processing, it does not yet solve common problems of deep learning such as
model interpretability or the overall need for data. This thesis explores a
different answer to the problem of learning expressive models in data
constrained settings: instead of relying on big datasets to learn neural
networks, we will replace some modules by known functions reflecting the
structure of the data. Very often, these functions will be drawn from the rich
literature of kernel methods. Indeed, many kernels can reflect the underlying
structure of the data, thus sparing learning parameters to some extent. Our
approach falls under the hood of ""inductive biases"", which can be defined as
hypothesis on the data at hand restricting the space of models to explore
during learning. We demonstrate the effectiveness of this approach in the
context of sequences, such as sentences in natural language or protein
sequences, and graphs, such as molecules. We also highlight the relationship
between our work and recent advances in deep learning. Additionally, we study
convex machine learning models. Here, rather than proposing new models, we
wonder which proportion of the samples in a dataset is really needed to learn a
""good"" model. More precisely, we study the problem of safe sample screening,
i.e, executing simple tests to discard uninformative samples from a dataset
even before fitting a machine learning model, without affecting the optimal
model. Such techniques can be used to prune datasets or mine for rare samples.
",2023-02-21T14:22:01Z,http://arxiv.org/abs/2302.10692v1,Gr√©goire Mialon
"Diversified Ensemble of Independent Sub-Networks for Robust
  Self-Supervised Representation Learning","  Ensembling a neural network is a widely recognized approach to enhance model
performance, estimate uncertainty, and improve robustness in deep supervised
learning. However, deep ensembles often come with high computational costs and
memory demands. In addition, the efficiency of a deep ensemble is related to
diversity among the ensemble members which is challenging for large,
over-parameterized deep neural networks. Moreover, ensemble learning has not
yet seen such widespread adoption, and it remains a challenging endeavor for
self-supervised or unsupervised representation learning. Motivated by these
challenges, we present a novel self-supervised training regime that leverages
an ensemble of independent sub-networks, complemented by a new loss function
designed to encourage diversity. Our method efficiently builds a sub-model
ensemble with high diversity, leading to well-calibrated estimates of model
uncertainty, all achieved with minimal computational overhead compared to
traditional deep self-supervised ensembles. To evaluate the effectiveness of
our approach, we conducted extensive experiments across various tasks,
including in-distribution generalization, out-of-distribution detection,
dataset corruption, and semi-supervised settings. The results demonstrate that
our method significantly improves prediction reliability. Our approach not only
achieves excellent accuracy but also enhances calibration, surpassing baseline
performance across a wide range of self-supervised architectures in computer
vision, natural language processing, and genomics data.
",2023-08-28T16:58:44Z,http://arxiv.org/abs/2308.14705v2,"Amirhossein Vahidi, Lisa Wimmer, H√ºseyin Anil G√ºnd√ºz, Bernd Bischl, Eyke H√ºllermeier, Mina Rezaei"
Offensive Language Analysis using Deep Learning Architecture,"  SemEval-2019 Task 6 (Zampieri et al., 2019b) requires us to identify and
categorise offensive language in social media. In this paper we will describe
the process we took to tackle this challenge. Our process is heavily inspired
by Sosa (2017) where he proposed CNN-LSTM and LSTM-CNN models to conduct
twitter sentiment analysis. We decided to follow his approach as well as
further his work by testing out different variations of RNN models with CNN.
Specifically, we have divided the challenge into two parts: data processing and
sampling and choosing the optimal deep learning architecture. In preprocessing,
we experimented with two techniques, SMOTE and Class Weights to counter the
imbalance between classes. Once we are happy with the quality of our input
data, we proceed to choosing the optimal deep learning architecture for this
task. Given the quality and quantity of data we have been given, we found that
the addition of CNN layer provides very little to no additional improvement to
our model's performance and sometimes even lead to a decrease in our F1-score.
In the end, the deep learning architecture that gives us the highest macro
F1-score is a simple BiLSTM-CNN.
",2019-03-12T09:36:25Z,http://arxiv.org/abs/1903.05280v3,Ryan Ong
Optimizing Federated Learning by Entropy-Based Client Selection,"  Deep learning is an emerging field revolutionizing various industries,
including natural language processing, computer vision, and many more. These
domains typically require an extensive amount of data for optimal performance,
potentially utilizing huge centralized data repositories. However, such
centralization could raise privacy issues concerning the storage of sensitive
data. To address this issue, federated learning was developed. It is a newly
distributed learning technique that enables to collaboratively train a deep
learning model on decentralized devices, referred to as clients, without
compromising their data privacy. Traditional federated learning methods often
suffer from severe performance degradation when the data distribution among
clients differs significantly. This becomes especially problematic in the case
of label distribution skew, where the distribution of labels varies across
clients. To address this, a novel method called FedEntOpt is proposed.
FedEntOpt is designed to mitigate performance issues caused by label
distribution skew by maximizing the entropy of the global label distribution of
the selected client subset in each federated learning round. This ensures that
the aggregated model parameters from the clients were exhibited to data from
all available labels, which improves the accuracy of the global model.
Extensive experiments on several benchmark datasets show that the proposed
method outperforms several state-of-the-art algorithms by up to 6% in
classification accuracy, demonstrating robust and superior performance,
particularly under low participation rates. In addition, it offers the
flexibility to be combined with them, enhancing their performance by over 40%.
",2024-11-02T13:31:36Z,http://arxiv.org/abs/2411.01240v1,"Andreas Lutz, Gabriele Steidl, Karsten M√ºller, Wojciech Samek"
PATO: Policy Assisted TeleOperation for Scalable Robot Data Collection,"  Large-scale data is an essential component of machine learning as
demonstrated in recent advances in natural language processing and computer
vision research. However, collecting large-scale robotic data is much more
expensive and slower as each operator can control only a single robot at a
time. To make this costly data collection process efficient and scalable, we
propose Policy Assisted TeleOperation (PATO), a system which automates part of
the demonstration collection process using a learned assistive policy. PATO
autonomously executes repetitive behaviors in data collection and asks for
human input only when it is uncertain about which subtask or behavior to
execute. We conduct teleoperation user studies both with a real robot and a
simulated robot fleet and demonstrate that our assisted teleoperation system
reduces human operators' mental load while improving data collection
efficiency. Further, it enables a single operator to control multiple robots in
parallel, which is a first step towards scalable robotic data collection. For
code and video results, see https://clvrai.com/pato
",2022-12-09T07:38:09Z,http://arxiv.org/abs/2212.04708v2,"Shivin Dass, Karl Pertsch, Hejia Zhang, Youngwoon Lee, Joseph J. Lim, Stefanos Nikolaidis"
"Semi-Supervised Natural Language Approach for Fine-Grained
  Classification of Medical Reports","  Although machine learning has become a powerful tool to augment doctors in
clinical analysis, the immense amount of labeled data that is necessary to
train supervised learning approaches burdens each development task as time and
resource intensive. The vast majority of dense clinical information is stored
in written reports, detailing pertinent patient information. The challenge with
utilizing natural language data for standard model development is due to the
complex nature of the modality. In this research, a model pipeline was
developed to utilize an unsupervised approach to train an encoder-language
model, a recurrent network, to generate document encodings; which then can be
used as features passed into a decoder-classifier model that requires
magnitudes less labeled data than previous approaches to differentiate between
fine-grained disease classes accurately. The language model was trained on
unlabeled radiology reports from the Massachusetts General Hospital Radiology
Department (n=218,159) and terminated with a loss of 1.62. The classification
models were trained on three labeled datasets of head CT studies of reported
patients, presenting large vessel occlusion (n=1403), acute ischemic strokes
(n=331), and intracranial hemorrhage (n=4350), to identify a variety of
different findings directly from the radiology report data; resulting in AUCs
of 0.98, 0.95, and 0.99, respectively, for the large vessel occlusion, acute
ischemic stroke, and intracranial hemorrhage datasets. The output encodings are
able to be used in conjunction with imaging data, to create models that can
process a multitude of different modalities. The ability to automatically
extract relevant features from textual data allows for faster model development
and integration of textual modality, overall, allowing clinical reports to
become a more viable input for more encompassing and accurate deep learning
models.
",2019-10-29T23:25:59Z,http://arxiv.org/abs/1910.13573v2,"Neil Deshmukh, Selin Gumustop, Romane Gauriau, Varun Buch, Bradley Wright, Christopher Bridge, Ram Naidu, Katherine Andriole, Bernardo Bizzo"
"LINX: A Language Driven Generative System for Goal-Oriented Automated
  Data Exploration","  Data exploration is a challenging process in which users examine a dataset by
iteratively employing a series of queries. While in some cases the user
explores a new dataset to become familiar with it, more often, the exploration
process is conducted with a specific analysis goal or question in mind. To
assist users in exploring a new dataset, Automated Data Exploration (ADE)
systems have been devised in previous work. These systems aim to auto-generate
a full exploration session, containing a sequence of queries that showcase
interesting elements of the data. However, existing ADE systems are often
constrained by a predefined objective function, thus always generating the same
session for a given dataset. Therefore, their effectiveness in goal-oriented
exploration, in which users need to answer specific questions about the data,
are extremely limited.
  To this end, this paper presents LINX, a generative system augmented with a
natural language interface for goal-oriented ADE. Given an input dataset and an
analytical goal described in natural language, LINX generates a personalized
exploratory session that is relevant to the user's goal. LINX utilizes a Large
Language Model (LLM) to interpret the input analysis goal, and then derive a
set of specifications for the desired output exploration session. These
specifications are then transferred to a novel, modular ADE engine based on
Constrained Deep Reinforcement Learning (CDRL), which can adapt its output
according to the specified instructions.
  To validate LINX's effectiveness, we introduce a new benchmark dataset for
goal-oriented exploration and conduct an extensive user study. Our analysis
underscores LINX's superior capability in producing exploratory notebooks that
are significantly more relevant and beneficial than those generated by existing
solutions, including ChatGPT, goal-agnostic ADE, and commercial systems.
",2024-06-07T17:37:05Z,http://arxiv.org/abs/2406.05107v1,"Tavor Lipman, Tova Milo, Amit Somech, Tomer Wolfson, Oz Zafar"
"PID Control-Based Self-Healing to Improve the Robustness of Large
  Language Models","  Despite the effectiveness of deep neural networks in numerous natural
language processing applications, recent findings have exposed the
vulnerability of these language models when minor perturbations are introduced.
While appearing semantically indistinguishable to humans, these perturbations
can significantly reduce the performance of well-trained language models,
raising concerns about the reliability of deploying them in safe-critical
situations. In this work, we construct a computationally efficient self-healing
process to correct undesired model behavior during online inference when
perturbations are applied to input data. This is formulated as a trajectory
optimization problem in which the internal states of the neural network layers
are automatically corrected using a PID (Proportional-Integral-Derivative)
control mechanism. The P controller targets immediate state adjustments, while
the I and D controllers consider past states and future dynamical trends,
respectively. We leverage the geometrical properties of the training data to
design effective linear PID controllers. This approach reduces the
computational cost to that of using just the P controller, instead of the full
PID control. Further, we introduce an analytical method for approximating the
optimal control solutions, enhancing the real-time inference capabilities of
this controlled system. Moreover, we conduct a theoretical error analysis of
the analytic solution in a simplified setting. The proposed PID control-based
self-healing is a low cost framework that improves the robustness of
pre-trained large language models, whether standard or robustly trained,
against a wide range of perturbations. A detailed implementation can be found
in:https://github.com/zhuotongchen/PID-Control-Based-Self-Healing-to-Improve-the-Robustness-of-Large-Language-Models.
",2024-03-31T23:46:51Z,http://arxiv.org/abs/2404.00828v1,"Zhuotong Chen, Zihu Wang, Yifan Yang, Qianxiao Li, Zheng Zhang"
"Beyond Text: A Deep Dive into Large Language Models' Ability on
  Understanding Graph Data","  Large language models (LLMs) have achieved impressive performance on many
natural language processing tasks. However, their capabilities on
graph-structured data remain relatively unexplored. In this paper, we conduct a
series of experiments benchmarking leading LLMs on diverse graph prediction
tasks spanning node, edge, and graph levels. We aim to assess whether LLMs can
effectively process graph data and leverage topological structures to enhance
performance, compared to specialized graph neural networks. Through varied
prompt formatting and task/dataset selection, we analyze how well LLMs can
interpret and utilize graph structures. By comparing LLMs' performance with
specialized graph models, we offer insights into the strengths and limitations
of employing LLMs for graph analytics. Our findings provide insights into LLMs'
capabilities and suggest avenues for further exploration in applying them to
graph analytics.
",2023-10-07T23:25:22Z,http://arxiv.org/abs/2310.04944v1,"Yuntong Hu, Zheng Zhang, Liang Zhao"
Deep Image-to-Recipe Translation,"  The modern saying, ""You Are What You Eat"" resonates on a profound level,
reflecting the intricate connection between our identities and the food we
consume. Our project, Deep Image-to-Recipe Translation, is an intersection of
computer vision and natural language generation that aims to bridge the gap
between cherished food memories and the art of culinary creation. Our primary
objective involves predicting ingredients from a given food image. For this
task, we first develop a custom convolutional network and then compare its
performance to a model that leverages transfer learning. We pursue an
additional goal of generating a comprehensive set of recipe steps from a list
of ingredients. We frame this process as a sequence-to-sequence task and
develop a recurrent neural network that utilizes pre-trained word embeddings.
We address several challenges of deep learning including imbalanced datasets,
data cleaning, overfitting, and hyperparameter selection. Our approach
emphasizes the importance of metrics such as Intersection over Union (IoU) and
F1 score in scenarios where accuracy alone might be misleading. For our recipe
prediction model, we employ perplexity, a commonly used and important metric
for language models. We find that transfer learning via pre-trained ResNet-50
weights and GloVe embeddings provide an exceptional boost to model performance,
especially when considering training resource constraints. Although we have
made progress on the image-to-recipe translation, there is an opportunity for
future exploration with advancements in model architectures, dataset
scalability, and enhanced user interaction.
",2024-07-01T02:33:07Z,http://arxiv.org/abs/2407.00911v1,"Jiangqin Ma, Bilal Mawji, Franz Williams"
"Language acquisition: do children and language models follow similar
  learning stages?","  During language acquisition, children follow a typical sequence of learning
stages, whereby they first learn to categorize phonemes before they develop
their lexicon and eventually master increasingly complex syntactic structures.
However, the computational principles that lead to this learning trajectory
remain largely unknown. To investigate this, we here compare the learning
trajectories of deep language models to those of children. Specifically, we
test whether, during its training, GPT-2 exhibits stages of language
acquisition comparable to those observed in children aged between 18 months and
6 years. For this, we train 48 GPT-2 models from scratch and evaluate their
syntactic and semantic abilities at each training step, using 96 probes curated
from the BLiMP, Zorro and BIG-Bench benchmarks. We then compare these
evaluations with the behavior of 54 children during language production. Our
analyses reveal three main findings. First, similarly to children, the language
models tend to learn linguistic skills in a systematic order. Second, this
learning scheme is parallel: the language tasks that are learned last improve
from the very first training steps. Third, some - but not all - learning stages
are shared between children and these language models. Overall, these results
shed new light on the principles of language acquisition, and highlight
important divergences in how humans and modern algorithms learn to process
natural language.
",2023-06-06T11:08:20Z,http://arxiv.org/abs/2306.03586v1,"Linnea Evanson, Yair Lakretz, Jean-R√©mi King"
"Symmetric Kernels with Non-Symmetric Data: A Data-Agnostic Learnability
  Bound","  Kernel ridge regression (KRR) and Gaussian processes (GPs) are fundamental
tools in statistics and machine learning with recent applications to highly
over-parameterized deep neural networks. The ability of these tools to learn a
target function is directly related to the eigenvalues of their kernel sampled
on the input data. Targets having support on higher eigenvalues are more
learnable. While kernels are often highly symmetric objects, the data is often
not. Thus kernel symmetry seems to have little to no bearing on the above
eigenvalues or learnability, making spectral analysis on real-world data
challenging. Here, we show that contrary to this common lure, one may use
eigenvalues and eigenfunctions associated with highly idealized data-measures
to bound learnability on realistic data. As a demonstration, we give a
theoretical lower bound on the sample complexity of copying heads for kernels
associated with generic transformers acting on natural language.
",2024-06-04T18:00:00Z,http://arxiv.org/abs/2406.02663v1,"Itay Lavie, Zohar Ringel"
"Data Augmentation with In-Context Learning and Comparative Evaluation in
  Math Word Problem Solving","  Math Word Problem (MWP) solving presents a challenging task in Natural
Language Processing (NLP). This study aims to provide MWP solvers with a more
diverse training set, ultimately improving their ability to solve various math
problems. We propose several methods for data augmentation by modifying the
problem texts and equations, such as synonym replacement, rule-based: question
replacement, and rule based: reversing question methodologies over two English
MWP datasets. This study extends by introducing a new in-context learning
augmentation method, employing the Llama-7b language model. This approach
involves instruction-based prompting for rephrasing the math problem texts.
Performance evaluations are conducted on 9 baseline models, revealing that
augmentation methods outperform baseline models. Moreover, concatenating
examples generated by various augmentation methods further improves
performance.
",2024-04-05T07:57:03Z,http://arxiv.org/abs/2404.03938v1,"Gulsum Yigit, Mehmet Fatih Amasyali"
Supervised learning model for parsing Arabic language,"  Parsing the Arabic language is a difficult task given the specificities of
this language and given the scarcity of digital resources (grammars and
annotated corpora). In this paper, we suggest a method for Arabic parsing based
on supervised machine learning. We used the SVMs algorithm to select the
syntactic labels of the sentence. Furthermore, we evaluated our parser
following the cross validation method by using the Penn Arabic Treebank. The
obtained results are very encouraging.
",2014-10-31T15:53:49Z,http://arxiv.org/abs/1410.8783v1,"Nabil Khoufi, Chafik Aloulou, Lamia Hadrich Belguith"
"Multi-Attribute Relation Extraction (MARE) -- Simplifying the
  Application of Relation Extraction","  Natural language understanding's relation extraction makes innovative and
encouraging novel business concepts possible and facilitates new digitilized
decision-making processes. Current approaches allow the extraction of relations
with a fixed number of entities as attributes. Extracting relations with an
arbitrary amount of attributes requires complex systems and costly
relation-trigger annotations to assist these systems. We introduce
multi-attribute relation extraction (MARE) as an assumption-less problem
formulation with two approaches, facilitating an explicit mapping from business
use cases to the data annotations. Avoiding elaborated annotation constraints
simplifies the application of relation extraction approaches. The evaluation
compares our models to current state-of-the-art event extraction and binary
relation extraction methods. Our approaches show improvement compared to these
on the extraction of general multi-attribute relations.
",2021-11-17T11:06:39Z,http://arxiv.org/abs/2111.09035v1,"Lars Kl√∂ser, Philipp Kohl, Bodo Kraft, Albert Z√ºndorf"
"Deep Learning-based Spatio Temporal Facial Feature Visual Speech
  Recognition","  In low-resource computing contexts, such as smartphones and other tiny
devices, Both deep learning and machine learning are being used in a lot of
identification systems. as authentication techniques. The transparent,
contactless, and non-invasive nature of these face recognition technologies
driven by AI has led to their meteoric rise in popularity in recent years.
While they are mostly successful, there are still methods to get inside without
permission by utilising things like pictures, masks, glasses, etc. In this
research, we present an alternate authentication process that makes use of both
facial recognition and the individual's distinctive temporal facial feature
motions while they speak a password. Because the suggested methodology allows
for a password to be specified in any language, it is not limited by language.
The suggested model attained an accuracy of 96.1% when tested on the
industry-standard MIRACL-VC1 dataset, demonstrating its efficacy as a reliable
and powerful solution. In addition to being data-efficient, the suggested
technique shows promising outcomes with as little as 10 positive video examples
for training the model. The effectiveness of the network's training is further
proved via comparisons with other combined facial recognition and lip reading
models.
",2023-04-30T18:52:29Z,http://arxiv.org/abs/2305.00552v1,"Pangoth Santhosh Kumar, Garika Akshay"
"A survey on natural language processing (nlp) and applications in
  insurance","  Text is the most widely used means of communication today. This data is
abundant but nevertheless complex to exploit within algorithms. For years,
scientists have been trying to implement different techniques that enable
computers to replicate some mechanisms of human reading. During the past five
years, research disrupted the capacity of the algorithms to unleash the value
of text data. It brings today, many opportunities for the insurance
industry.Understanding those methods and, above all, knowing how to apply them
is a major challenge and key to unleash the value of text data that have been
stored for many years. Processing language with computer brings many new
opportunities especially in the insurance sector where reports are central in
the information used by insurers. SCOR's Data Analytics team has been working
on the implementation of innovative tools or products that enable the use of
the latest research on text analysis. Understanding text mining techniques in
insurance enhances the monitoring of the underwritten risks and many processes
that finally benefit policyholders.This article proposes to explain
opportunities that Natural Language Processing (NLP) are providing to
insurance. It details different methods used today in practice traces back the
story of them. We also illustrate the implementation of certain methods using
open source libraries and python codes that we have developed to facilitate the
use of these techniques.After giving a general overview on the evolution of
text mining during the past few years,we share about how to conduct a full
study with text mining and share some examples to serve those models into
insurance products or services. Finally, we explained in more details every
step that composes a Natural Language Processing study to ensure the reader can
have a deep understanding on the implementation.
",2020-10-01T14:56:18Z,http://arxiv.org/abs/2010.00462v1,"Antoine Ly, Benno Uthayasooriyar, Tingting Wang"
Adaptive Prompt Learning-based Few-Shot Sentiment Analysis,"  In the field of natural language processing, sentiment analysis via deep
learning has a excellent performance by using large labeled datasets.
Meanwhile, labeled data are insufficient in many sentiment analysis, and
obtaining these data is time-consuming and laborious. Prompt learning devotes
to resolving the data deficiency by reformulating downstream tasks with the
help of prompt. In this way, the appropriate prompt is very important for the
performance of the model. This paper proposes an adaptive prompting(AP)
construction strategy using seq2seq-attention structure to acquire the semantic
information of the input sequence. Then dynamically construct adaptive prompt
which can not only improve the quality of the prompt, but also can effectively
generalize to other fields by pre-trained prompt which is constructed by
existing public labeled data. The experimental results on FewCLUE datasets
demonstrate that the proposed method AP can effectively construct appropriate
adaptive prompt regardless of the quality of hand-crafted prompt and outperform
the state-of-the-art baselines.
",2022-05-15T08:34:48Z,http://arxiv.org/abs/2205.07220v1,"Pengfei Zhang, Tingting Chai, Yongdong Xu"
"Colorful Cutout: Enhancing Image Data Augmentation with Curriculum
  Learning","  Data augmentation is one of the regularization strategies for the training of
deep learning models, which enhances generalizability and prevents overfitting,
leading to performance improvement. Although researchers have proposed various
data augmentation techniques, they often lack consideration for the difficulty
of augmented data. Recently, another line of research suggests incorporating
the concept of curriculum learning with data augmentation in the field of
natural language processing. In this study, we adopt curriculum data
augmentation for image data augmentation and propose colorful cutout, which
gradually increases the noise and difficulty introduced in the augmented image.
Our experimental results highlight the possibility of curriculum data
augmentation for image data. We publicly released our source code to improve
the reproducibility of our study.
",2024-03-29T06:53:52Z,http://arxiv.org/abs/2403.20012v1,"Juhwan Choi, YoungBin Kim"
"Neural Skill Transfer from Supervised Language Tasks to Reading
  Comprehension","  Reading comprehension is a challenging task in natural language processing
and requires a set of skills to be solved. While current approaches focus on
solving the task as a whole, in this paper, we propose to use a neural network
`skill' transfer approach. We transfer knowledge from several lower-level
language tasks (skills) including textual entailment, named entity recognition,
paraphrase detection and question type classification into the reading
comprehension model.
  We conduct an empirical evaluation and show that transferring language skill
knowledge leads to significant improvements for the task with much fewer steps
compared to the baseline model. We also show that the skill transfer approach
is effective even with small amounts of training data. Another finding of this
work is that using token-wise deep label supervision for text classification
improves the performance of transfer learning.
",2017-11-10T10:13:51Z,http://arxiv.org/abs/1711.03754v1,"Todor Mihaylov, Zornitsa Kozareva, Anette Frank"
"Leveraging Dependency Grammar for Fine-Grained Offensive Language
  Detection using Graph Convolutional Networks","  The last few years have witnessed an exponential rise in the propagation of
offensive text on social media. Identification of this text with high precision
is crucial for the well-being of society. Most of the existing approaches tend
to give high toxicity scores to innocuous statements (e.g., ""I am a gay man"").
These false positives result from over-generalization on the training data
where specific terms in the statement may have been used in a pejorative sense
(e.g., ""gay""). Emphasis on such words alone can lead to discrimination against
the classes these systems are designed to protect. In this paper, we address
the problem of offensive language detection on Twitter, while also detecting
the type and the target of the offence. We propose a novel approach called
SyLSTM, which integrates syntactic features in the form of the dependency parse
tree of a sentence and semantic features in the form of word embeddings into a
deep learning architecture using a Graph Convolutional Network. Results show
that the proposed approach significantly outperforms the state-of-the-art BERT
model with orders of magnitude fewer number of parameters.
",2022-05-26T05:27:50Z,http://arxiv.org/abs/2205.13164v1,"Divyam Goel, Raksha Sharma"
A Survey on Large Language Models from Concept to Implementation,"  Recent advancements in Large Language Models (LLMs), particularly those built
on Transformer architectures, have significantly broadened the scope of natural
language processing (NLP) applications, transcending their initial use in
chatbot technology. This paper investigates the multifaceted applications of
these models, with an emphasis on the GPT series. This exploration focuses on
the transformative impact of artificial intelligence (AI) driven tools in
revolutionizing traditional tasks like coding and problem-solving, while also
paving new paths in research and development across diverse industries. From
code interpretation and image captioning to facilitating the construction of
interactive systems and advancing computational domains, Transformer models
exemplify a synergy of deep learning, data analysis, and neural network design.
This survey provides an in-depth look at the latest research in Transformer
models, highlighting their versatility and the potential they hold for
transforming diverse application sectors, thereby offering readers a
comprehensive understanding of the current and future landscape of
Transformer-based LLMs in practical applications.
",2024-03-27T19:35:41Z,http://arxiv.org/abs/2403.18969v2,"Chen Wang, Jin Zhao, Jiaqi Gong"
"Towards Robust Evaluation: A Comprehensive Taxonomy of Datasets and
  Metrics for Open Domain Question Answering in the Era of Large Language
  Models","  Open Domain Question Answering (ODQA) within natural language processing
involves building systems that answer factual questions using large-scale
knowledge corpora. Recent advances stem from the confluence of several factors,
such as large-scale training datasets, deep learning techniques, and the rise
of large language models. High-quality datasets are used to train models on
realistic scenarios and enable the evaluation of the system on potentially
unseen data. Standardized metrics facilitate comparisons between different ODQA
systems, allowing researchers to objectively track advancements in the field.
Our study presents a thorough examination of the current landscape of ODQA
benchmarking by reviewing 52 datasets and 20 evaluation techniques across
textual and multimodal modalities. We introduce a novel taxonomy for ODQA
datasets that incorporates both the modality and difficulty of the question
types. Additionally, we present a structured organization of ODQA evaluation
metrics along with a critical analysis of their inherent trade-offs. Our study
aims to empower researchers by providing a framework for the robust evaluation
of modern question-answering systems. We conclude by identifying the current
challenges and outlining promising avenues for future research and development.
",2024-06-19T05:43:02Z,http://arxiv.org/abs/2406.13232v1,"Akchay Srivastava, Atif Memon"
"MT-GBM: A Multi-Task Gradient Boosting Machine with Shared Decision
  Trees","  Despite the success of deep learning in computer vision and natural language
processing, Gradient Boosted Decision Tree (GBDT) is yet one of the most
powerful tools for applications with tabular data such as e-commerce and
FinTech. However, applying GBDT to multi-task learning is still a challenge.
Unlike deep models that can jointly learn a shared latent representation across
multiple tasks, GBDT can hardly learn a shared tree structure. In this paper,
we propose Multi-task Gradient Boosting Machine (MT-GBM), a GBDT-based method
for multi-task learning. The MT-GBM can find the shared tree structures and
split branches according to multi-task losses. First, it assigns multiple
outputs to each leaf node. Next, it computes the gradient corresponding to each
output (task). Then, we also propose an algorithm to combine the gradients of
all tasks and update the tree. Finally, we apply MT-GBM to LightGBM.
Experiments show that our MT-GBM improves the performance of the main task
significantly, which means the proposed MT-GBM is efficient and effective.
",2022-01-17T06:43:14Z,http://arxiv.org/abs/2201.06239v2,"ZhenZhe Ying, Zhuoer Xu, Zhifeng Li, Weiqiang Wang, Changhua Meng"
"A New Era in Computational Pathology: A Survey on Foundation and
  Vision-Language Models","  Recent advances in deep learning have completely transformed the domain of
computational pathology (CPath). More specifically, it has altered the
diagnostic workflow of pathologists by integrating foundation models (FMs) and
vision-language models (VLMs) in their assessment and decision-making process.
The limitations of existing deep learning approaches in CPath can be overcome
by FMs through learning a representation space that can be adapted to a wide
variety of downstream tasks without explicit supervision. Deploying VLMs allow
pathology reports written in natural language be used as rich semantic
information sources to improve existing models as well as generate predictions
in natural language form. In this survey, a holistic and systematic overview of
recent innovations in FMs and VLMs in CPath is presented. Furthermore, the
tools, datasets and training schemes for these models are summarized in
addition to categorizing them into distinct groups. This extensive survey
highlights the current trends in CPath and its possible revolution through the
use of FMs and VLMs in the future.
",2024-08-23T16:33:57Z,http://arxiv.org/abs/2408.14496v3,"Dibaloke Chanda, Milan Aryal, Nasim Yahya Soltani, Masoud Ganji"
"ActKnow: Active External Knowledge Infusion Learning for Question
  Answering in Low Data Regime","  Deep learning models have set benchmark results in various Natural Language
Processing tasks. However, these models require an enormous amount of training
data, which is infeasible in many practical problems. While various techniques
like domain adaptation, fewshot learning techniques address this problem, we
introduce a new technique of actively infusing external knowledge into learning
to solve low data regime problems. We propose a technique called ActKnow that
actively infuses knowledge from Knowledge Graphs (KG) based ""on-demand"" into
learning for Question Answering (QA). By infusing world knowledge from
Concept-Net, we show significant improvements on the ARC Challenge-set
benchmark over purely text-based transformer models like RoBERTa in the low
data regime. For example, by using only 20% training examples, we demonstrate a
4% improvement in the accuracy for both ARC-challenge and OpenBookQA,
respectively.
",2021-12-17T10:39:41Z,http://arxiv.org/abs/2112.09423v1,"K. M. Annervaz, Pritam Kumar Nath, Ambedkar Dukkipati"
"TabDeco: A Comprehensive Contrastive Framework for Decoupled
  Representations in Tabular Data","  Representation learning is a fundamental aspect of modern artificial
intelligence, driving substantial improvements across diverse applications.
While selfsupervised contrastive learning has led to significant advancements
in fields like computer vision and natural language processing, its adaptation
to tabular data presents unique challenges. Traditional approaches often
prioritize optimizing model architecture and loss functions but may overlook
the crucial task of constructing meaningful positive and negative sample pairs
from various perspectives like feature interactions, instance-level patterns
and batch-specific contexts. To address these challenges, we introduce TabDeco,
a novel method that leverages attention-based encoding strategies across both
rows and columns and employs contrastive learning framework to effectively
disentangle feature representations at multiple levels, including features,
instances and data batches. With the innovative feature decoupling hierarchies,
TabDeco consistently surpasses existing deep learning methods and leading
gradient boosting algorithms, including XG-Boost, CatBoost, and LightGBM,
across various benchmark tasks, underscoring its effectiveness in advancing
tabular data representation learning.
",2024-11-17T18:42:46Z,http://arxiv.org/abs/2411.11148v1,"Suiyao Chen, Jing Wu, Yunxiao Wang, Cheng Ji, Tianpei Xie, Daniel Cociorva, Michael Sharps, Cecile Levasseur, Hakan Brunzell"
"Exploiting Synchronized Lyrics And Vocal Features For Music Emotion
  Detection","  One of the key points in music recommendation is authoring engaging playlists
according to sentiment and emotions. While previous works were mostly based on
audio for music discovery and playlists generation, we take advantage of our
synchronized lyrics dataset to combine text representations and music features
in a novel way; we therefore introduce the Synchronized Lyrics Emotion Dataset.
Unlike other approaches that randomly exploited the audio samples and the whole
text, our data is split according to the temporal information provided by the
synchronization between lyrics and audio. This work shows a comparison between
text-based and audio-based deep learning classification models using different
techniques from Natural Language Processing and Music Information Retrieval
domains. From the experiments on audio we conclude that using vocals only,
instead of the whole audio data improves the overall performances of the audio
classifier. In the lyrics experiments we exploit the state-of-the-art word
representations applied to the main Deep Learning architectures available in
literature. In our benchmarks the results show how the Bilinear LSTM classifier
with Attention based on fastText word embedding performs better than the CNN
applied on audio.
",2019-01-15T14:10:25Z,http://arxiv.org/abs/1901.04831v1,"Loreto Parisi, Simone Francia, Silvio Olivastri, Maria Stella Tavella"
Building Tamil Treebanks,"  Treebanks are important linguistic resources, which are structured and
annotated corpora with rich linguistic annotations. These resources are used in
Natural Language Processing (NLP) applications, supporting linguistic analyses,
and are essential for training and evaluating various computational models.
This paper discusses the creation of Tamil treebanks using three distinct
approaches: manual annotation, computational grammars, and machine learning
techniques. Manual annotation, though time-consuming and requiring linguistic
expertise, ensures high-quality and rich syntactic and semantic information.
Computational deep grammars, such as Lexical Functional Grammar (LFG), offer
deep linguistic analyses but necessitate significant knowledge of the
formalism. Machine learning approaches, utilising off-the-shelf frameworks and
tools like Stanza, UDpipe, and UUParser, facilitate the automated annotation of
large datasets but depend on the availability of quality annotated data,
cross-linguistic training resources, and computational power. The paper
discusses the challenges encountered in building Tamil treebanks, including
issues with Internet data, the need for comprehensive linguistic analysis, and
the difficulty of finding skilled annotators. Despite these challenges, the
development of Tamil treebanks is essential for advancing linguistic research
and improving NLP tools for Tamil.
",2024-09-23T01:58:50Z,http://arxiv.org/abs/2409.14657v1,Kengatharaiyer Sarveswaran
"A Non-Technical Survey on Deep Convolutional Neural Network
  Architectures","  Artificial neural networks have recently shown great results in many
disciplines and a variety of applications, including natural language
understanding, speech processing, games and image data generation. One
particular application in which the strong performance of artificial neural
networks was demonstrated is the recognition of objects in images, where deep
convolutional neural networks are commonly applied. In this survey, we give a
comprehensive introduction to this topic (object recognition with deep
convolutional neural networks), with a strong focus on the evolution of network
architectures. Therefore, we aim to compress the most important concepts in
this field in a simple and non-technical manner to allow for future researchers
to have a quick general understanding.
  This work is structured as follows:
  1. We will explain the basic ideas of (convolutional) neural networks and
deep learning and examine their usage for three object recognition tasks: image
classification, object localization and object detection.
  2. We give a review on the evolution of deep convolutional neural networks by
providing an extensive overview of the most important network architectures
presented in chronological order of their appearances.
",2018-03-06T11:40:46Z,http://arxiv.org/abs/1803.02129v1,"Felix Altenberger, Claus Lenz"
Reversible Architectures for Arbitrarily Deep Residual Neural Networks,"  Recently, deep residual networks have been successfully applied in many
computer vision and natural language processing tasks, pushing the
state-of-the-art performance with deeper and wider architectures. In this work,
we interpret deep residual networks as ordinary differential equations (ODEs),
which have long been studied in mathematics and physics with rich theoretical
and empirical success. From this interpretation, we develop a theoretical
framework on stability and reversibility of deep neural networks, and derive
three reversible neural network architectures that can go arbitrarily deep in
theory. The reversibility property allows a memory-efficient implementation,
which does not need to store the activations for most hidden layers. Together
with the stability of our architectures, this enables training deeper networks
using only modest computational resources. We provide both theoretical analyses
and empirical results. Experimental results demonstrate the efficacy of our
architectures against several strong baselines on CIFAR-10, CIFAR-100 and
STL-10 with superior or on-par state-of-the-art performance. Furthermore, we
show our architectures yield superior results when trained using fewer training
data.
",2017-09-12T05:41:13Z,http://arxiv.org/abs/1709.03698v2,"Bo Chang, Lili Meng, Eldad Haber, Lars Ruthotto, David Begert, Elliot Holtham"
"Deep Voice 3: Scaling Text-to-Speech with Convolutional Sequence
  Learning","  We present Deep Voice 3, a fully-convolutional attention-based neural
text-to-speech (TTS) system. Deep Voice 3 matches state-of-the-art neural
speech synthesis systems in naturalness while training ten times faster. We
scale Deep Voice 3 to data set sizes unprecedented for TTS, training on more
than eight hundred hours of audio from over two thousand speakers. In addition,
we identify common error modes of attention-based speech synthesis networks,
demonstrate how to mitigate them, and compare several different waveform
synthesis methods. We also describe how to scale inference to ten million
queries per day on one single-GPU server.
",2017-10-20T18:17:23Z,http://arxiv.org/abs/1710.07654v3,"Wei Ping, Kainan Peng, Andrew Gibiansky, Sercan O. Arik, Ajay Kannan, Sharan Narang, Jonathan Raiman, John Miller"
"Leveraging Natural Language Processing to Augment Structured Social
  Determinants of Health Data in the Electronic Health Record","  Objective: Social determinants of health (SDOH) impact health outcomes and
are documented in the electronic health record (EHR) through structured data
and unstructured clinical notes. However, clinical notes often contain more
comprehensive SDOH information, detailing aspects such as status, severity, and
temporality. This work has two primary objectives: i) develop a natural
language processing (NLP) information extraction model to capture detailed SDOH
information and ii) evaluate the information gain achieved by applying the SDOH
extractor to clinical narratives and combining the extracted representations
with existing structured data.
  Materials and Methods: We developed a novel SDOH extractor using a deep
learning entity and relation extraction architecture to characterize SDOH
across various dimensions. In an EHR case study, we applied the SDOH extractor
to a large clinical data set with 225,089 patients and 430,406 notes with
social history sections and compared the extracted SDOH information with
existing structured data.
  Results: The SDOH extractor achieved 0.86 F1 on a withheld test set. In the
EHR case study, we found extracted SDOH information complements existing
structured data with 32% of homeless patients, 19% of current tobacco users,
and 10% of drug users only having these health risk factors documented in the
clinical narrative.
  Conclusions: Utilizing EHR data to identify SDOH health risk factors and
social needs may improve patient care and outcomes. Semantic representations of
text-encoded SDOH information can augment existing structured data, and this
more comprehensive SDOH representation can assist health systems in identifying
and addressing these social needs.
",2022-12-14T22:51:49Z,http://arxiv.org/abs/2212.07538v2,"Kevin Lybarger, Nicholas J Dobbins, Ritche Long, Angad Singh, Patrick Wedgeworth, Ozlem Ozuner, Meliha Yetisgen"
"Listening to Chaotic Whispers: A Deep Learning Framework for
  News-oriented Stock Trend Prediction","  Stock trend prediction plays a critical role in seeking maximized profit from
stock investment. However, precise trend prediction is very difficult since the
highly volatile and non-stationary nature of stock market. Exploding
information on Internet together with advancing development of natural language
processing and text mining techniques have enable investors to unveil market
trends and volatility from online content. Unfortunately, the quality,
trustworthiness and comprehensiveness of online content related to stock market
varies drastically, and a large portion consists of the low-quality news,
comments, or even rumors. To address this challenge, we imitate the learning
process of human beings facing such chaotic online news, driven by three
principles: sequential content dependency, diverse influence, and effective and
efficient learning. In this paper, to capture the first two principles, we
designed a Hybrid Attention Networks to predict the stock trend based on the
sequence of recent related news. Moreover, we apply the self-paced learning
mechanism to imitate the third principle. Extensive experiments on real-world
stock market data demonstrate the effectiveness of our approach.
",2017-12-06T11:33:21Z,http://arxiv.org/abs/1712.02136v3,"Ziniu Hu, Weiqing Liu, Jiang Bian, Xuanzhe Liu, Tie-Yan Liu"
Foundation Model for Composite Materials and Microstructural Analysis,"  The rapid advancement of machine learning has unlocked numerous opportunities
for materials science, particularly in accelerating the design and analysis of
materials. However, a significant challenge lies in the scarcity and high cost
of obtaining high-quality materials datasets. In other fields, such as natural
language processing, foundation models pre-trained on large datasets have
achieved exceptional success in transfer learning, effectively leveraging
latent features to achieve high performance on tasks with limited data. Despite
this progress, the concept of foundation models remains underexplored in
materials science. Here, we present a foundation model specifically designed
for composite materials. Our model is pre-trained on a dataset of short-fiber
composites to learn robust latent features. During transfer learning, the MMAE
accurately predicts homogenized stiffness, with an R2 score reaching as high as
0.959 and consistently exceeding 0.91, even when trained on limited data. These
findings validate the feasibility and effectiveness of foundation models in
composite materials. We anticipate extending this approach to more complex
three-dimensional composite materials, polycrystalline materials, and beyond.
Moreover, this framework enables high-accuracy predictions even when
experimental data are scarce, paving the way for more efficient and
cost-effective materials design and analysis.
",2024-11-10T19:06:25Z,http://arxiv.org/abs/2411.06565v1,"Ting-Ju Wei, Chuin-Shan, Chen"
"Local Interpretations for Explainable Natural Language Processing: A
  Survey","  As the use of deep learning techniques has grown across various fields over
the past decade, complaints about the opaqueness of the black-box models have
increased, resulting in an increased focus on transparency in deep learning
models. This work investigates various methods to improve the interpretability
of deep neural networks for Natural Language Processing (NLP) tasks, including
machine translation and sentiment analysis. We provide a comprehensive
discussion on the definition of the term interpretability and its various
aspects at the beginning of this work. The methods collected and summarised in
this survey are only associated with local interpretation and are specifically
divided into three categories: 1) interpreting the model's predictions through
related input features; 2) interpreting through natural language explanation;
3) probing the hidden states of models and word representations.
",2021-03-20T02:28:33Z,http://arxiv.org/abs/2103.11072v3,"Siwen Luo, Hamish Ivison, Caren Han, Josiah Poon"
"CodeGRU: Context-aware Deep Learning with Gated Recurrent Unit for
  Source Code Modeling","  Recently deep learning based Natural Language Processing (NLP) models have
shown great potential in the modeling of source code. However, a major
limitation of these approaches is that they take source code as simple tokens
of text and ignore its contextual, syntactical and structural dependencies. In
this work, we present CodeGRU, a gated recurrent unit based source code
language model that is capable of capturing source code's contextual,
syntactical and structural dependencies. We introduce a novel approach which
can capture the source code context by leveraging the source code token types.
Further, we adopt a novel approach which can learn variable size context by
taking into account source code's syntax, and structural information. We
evaluate CodeGRU with real-world data set and it shows that CodeGRU outperforms
the state-of-the-art language models and help reduce the vocabulary size up to
24.93\%. Unlike previous works, we tested CodeGRU with an independent test set
which suggests that our methodology does not requisite the source code comes
from the same domain as training data while providing suggestions. We further
evaluate CodeGRU with two software engineering applications: source code
suggestion, and source code completion. Our experiment confirms that the source
code's contextual information can be vital and can help improve the software
language models. The extensive evaluation of CodeGRU shows that it outperforms
the state-of-the-art models. The results further suggest that the proposed
approach can help reduce the vocabulary size and is of practical use for
software developers.
",2019-03-03T11:44:08Z,http://arxiv.org/abs/1903.00884v2,"Yasir Hussain, Zhiqiu Huang, Yu Zhou, Senzhang Wang"
"NLP4PBM: A Systematic Review on Process Extraction using Natural
  Language Processing with Rule-based, Machine and Deep Learning Methods","  This literature review studies the field of automated process extraction,
i.e., transforming textual descriptions into structured processes using Natural
Language Processing (NLP). We found that Machine Learning (ML) / Deep Learning
(DL) methods are being increasingly used for the NLP component. In some cases,
they were chosen for their suitability towards process extraction, and results
show that they can outperform classic rule-based methods. We also found a
paucity of gold-standard, scalable annotated datasets, which currently hinders
objective evaluations as well as the training or fine-tuning of ML / DL
methods. Finally, we discuss preliminary work on the application of LLMs for
automated process extraction, as well as promising developments in this field.
",2024-09-10T15:16:02Z,http://arxiv.org/abs/2409.13738v1,"William Van Woensel, Soroor Motie"
"Time Majority Voting, a PC-based EEG Classifier for Non-expert Users","  Using Machine Learning and Deep Learning to predict cognitive tasks from
electroencephalography (EEG) signals is a rapidly advancing field in
Brain-Computer Interfaces (BCI). In contrast to the fields of computer vision
and natural language processing, the data amount of these trials is still
rather tiny. Developing a PC-based machine learning technique to increase the
participation of non-expert end-users could help solve this data collection
issue. We created a novel algorithm for machine learning called Time Majority
Voting (TMV). In our experiment, TMV performed better than cutting-edge
algorithms. It can operate efficiently on personal computers for classification
tasks involving the BCI. These interpretable data also assisted end-users and
researchers in comprehending EEG tests better.
",2022-07-26T05:43:54Z,http://arxiv.org/abs/2207.12662v1,"Guangyao Dou, Zheng Zhou, Xiaodong Qu"
Named entity recognition in resumes,"  Named entity recognition (NER) is used to extract information from various
documents and texts such as names and dates. It is important to extract
education and work experience information from resumes in order to filter them.
Considering the fact that all information in a resume has to be entered to the
companys system manually, automatizing this process will save time of the
companies. In this study, a deep learning-based semi-automatic named entity
recognition system has been implemented with a focus on resumes in the field of
IT. Firstly, resumes of employees from five different IT related fields has
been annotated. Six transformer based pre-trained models have been adapted to
named entity recognition problem using the annotated data. These models have
been selected among popular models in the natural language processing field.
The obtained system can recognize eight different entity types which are city,
date, degree, diploma major, job title, language, country and skill. Models
used in the experiments are compared using micro, macro and weighted F1 scores
and the performance of the methods was evaluated. Taking these scores into
account for test set the best micro and weighted F1 score is obtained by
RoBERTa and the best macro F1 score is obtained by Electra model.
",2023-06-22T17:30:37Z,http://arxiv.org/abs/2306.13062v1,"Ege Kesim, Aysu Deliahmetoglu"
Multilingual Entity Linking Using Dense Retrieval,"  Entity linking (EL) is the computational process of connecting textual
mentions to corresponding entities. Like many areas of natural language
processing, the EL field has greatly benefited from deep learning, leading to
significant performance improvements. However, present-day approaches are
expensive to train and rely on diverse data sources, complicating their
reproducibility. In this thesis, we develop multiple systems that are fast to
train, demonstrating that competitive entity linking can be achieved without a
large GPU cluster. Moreover, we train on a publicly available dataset, ensuring
reproducibility and accessibility. Our models are evaluated for 9 languages
giving an accurate overview of their strengths. Furthermore, we offer
a~detailed analysis of bi-encoder training hyperparameters, a popular approach
in EL, to guide their informed selection. Overall, our work shows that building
competitive neural network based EL systems that operate in multiple languages
is possible even with limited resources, thus making EL more approachable.
",2024-05-13T18:57:27Z,http://arxiv.org/abs/2406.16892v1,Dominik Farhan
On Learning the Structure of Clusters in Graphs,"  Graph clustering is a fundamental problem in unsupervised learning, with
numerous applications in computer science and in analysing real-world data. In
many real-world applications, we find that the clusters have a significant
high-level structure. This is often overlooked in the design and analysis of
graph clustering algorithms which make strong simplifying assumptions about the
structure of the graph. This thesis addresses the natural question of whether
the structure of clusters can be learned efficiently and describes four new
algorithmic results for learning such structure in graphs and hypergraphs.
  All of the presented theoretical results are extensively evaluated on both
synthetic and real-word datasets of different domains, including image
classification and segmentation, migration networks, co-authorship networks,
and natural language processing. These experimental results demonstrate that
the newly developed algorithms are practical, effective, and immediately
applicable for learning the structure of clusters in real-world data.
",2022-12-29T15:26:19Z,http://arxiv.org/abs/2212.14345v1,Peter Macgregor
Probing Pretrained Models of Source Code,"  Deep learning models are widely used for solving challenging code processing
tasks, such as code generation or code summarization. Traditionally, a specific
model architecture was carefully built to solve a particular code processing
task. However, recently general pretrained models such as CodeBERT or CodeT5
have been shown to outperform task-specific models in many applications. While
pretrained models are known to learn complex patterns from data, they may fail
to understand some properties of source code. To test diverse aspects of code
understanding, we introduce a set of diagnosting probing tasks. We show that
pretrained models of code indeed contain information about code syntactic
structure and correctness, the notions of identifiers, data flow and
namespaces, and natural language naming. We also investigate how probing
results are affected by using code-specific pretraining objectives, varying the
model size, or finetuning.
",2022-02-16T10:26:14Z,http://arxiv.org/abs/2202.08975v3,"Sergey Troshin, Nadezhda Chirkova"
Beyond Language Models: Byte Models are Digital World Simulators,"  Traditional deep learning often overlooks bytes, the basic units of the
digital world, where all forms of information and operations are encoded and
manipulated in binary format. Inspired by the success of next token prediction
in natural language processing, we introduce bGPT, a model with next byte
prediction to simulate the digital world. bGPT matches specialized models in
performance across various modalities, including text, audio, and images, and
offers new possibilities for predicting, simulating, and diagnosing algorithm
or hardware behaviour. It has almost flawlessly replicated the process of
converting symbolic music data, achieving a low error rate of 0.0011 bits per
byte in converting ABC notation to MIDI format. In addition, bGPT demonstrates
exceptional capabilities in simulating CPU behaviour, with an accuracy
exceeding 99.99% in executing various operations. Leveraging next byte
prediction, models like bGPT can directly learn from vast binary data,
effectively simulating the intricate patterns of the digital world.
",2024-02-29T13:38:07Z,http://arxiv.org/abs/2402.19155v1,"Shangda Wu, Xu Tan, Zili Wang, Rui Wang, Xiaobing Li, Maosong Sun"
"Addressing the Selection Bias in Voice Assistance: Training Voice
  Assistance Model in Python with Equal Data Selection","  In recent times, voice assistants have become a part of our day-to-day lives,
allowing information retrieval by voice synthesis, voice recognition, and
natural language processing. These voice assistants can be found in many
modern-day devices such as Apple, Amazon, Google, and Samsung. This project is
primarily focused on Virtual Assistance in Natural Language Processing. Natural
Language Processing is a form of AI that helps machines understand people and
create feedback loops. This project will use deep learning to create a Voice
Recognizer and use Commonvoice and data collected from the local community for
model training using Google Colaboratory. After recognizing a command, the AI
assistant will be able to perform the most suitable actions and then give a
response.
  The motivation for this project comes from the race and gender bias that
exists in many virtual assistants. The computer industry is primarily dominated
by the male gender, and because of this, many of the products produced do not
regard women. This bias has an impact on natural language processing. This
project will be utilizing various open-source projects to implement machine
learning algorithms and train the assistant algorithm to recognize different
types of voices, accents, and dialects. Through this project, the goal to use
voice data from underrepresented groups to build a voice assistant that can
recognize voices regardless of gender, race, or accent. Increasing the
representation of women in the computer industry is important for the future of
the industry. By representing women in the initial study of voice assistants,
it can be shown that females play a vital role in the development of this
technology. In line with related work, this project will use first-hand data
from the college population and middle-aged adults to train voice assistant to
combat gender bias.
",2022-12-20T21:26:05Z,http://arxiv.org/abs/2301.00646v1,"Kashav Piya, Srijal Shrestha, Cameran Frank, Estephanos Jebessa, Tauheed Khan Mohd"
"Network Representation Learning: From Traditional Feature Learning to
  Deep Learning","  Network representation learning (NRL) is an effective graph analytics
technique and promotes users to deeply understand the hidden characteristics of
graph data. It has been successfully applied in many real-world tasks related
to network science, such as social network data processing, biological
information processing, and recommender systems. Deep Learning is a powerful
tool to learn data features. However, it is non-trivial to generalize deep
learning to graph-structured data since it is different from the regular data
such as pictures having spatial information and sounds having temporal
information. Recently, researchers proposed many deep learning-based methods in
the area of NRL. In this survey, we investigate classical NRL from traditional
feature learning method to the deep learning-based model, analyze relationships
between them, and summarize the latest progress. Finally, we discuss open
issues considering NRL and point out the future directions in this field.
",2021-03-07T12:31:33Z,http://arxiv.org/abs/2103.04339v1,"Ke Sun, Lei Wang, Bo Xu, Wenhong Zhao, Shyh Wei Teng, Feng Xia"
"News-Driven Stock Price Forecasting in Indian Markets: A Comparative
  Study of Advanced Deep Learning Models","  Forecasting stock market prices remains a complex challenge for traders,
analysts, and engineers due to the multitude of factors that influence price
movements. Recent advancements in artificial intelligence (AI) and natural
language processing (NLP) have significantly enhanced stock price prediction
capabilities. AI's ability to process vast and intricate data sets has led to
more sophisticated forecasts. However, achieving consistently high accuracy in
stock price forecasting remains elusive. In this paper, we leverage 30 years of
historical data from national banks in India, sourced from the National Stock
Exchange, to forecast stock prices. Our approach utilizes state-of-the-art deep
learning models, including multivariate multi-step Long Short-Term Memory
(LSTM), Facebook Prophet with LightGBM optimized through Optuna, and Seasonal
Auto-Regressive Integrated Moving Average (SARIMA). We further integrate
sentiment analysis from tweets and reliable financial sources such as Business
Standard and Reuters, acknowledging their crucial influence on stock price
fluctuations.
",2024-10-14T15:30:06Z,http://arxiv.org/abs/2411.05788v1,"Kaushal Attaluri, Mukesh Tripathi, Srinithi Reddy, Shivendra"
"The Effect of Normalization for Bi-directional Amharic-English Neural
  Machine Translation","  Machine translation (MT) is one of the main tasks in natural language
processing whose objective is to translate texts automatically from one natural
language to another. Nowadays, using deep neural networks for MT tasks has
received great attention. These networks require lots of data to learn abstract
representations of the input and store it in continuous vectors. This paper
presents the first relatively large-scale Amharic-English parallel sentence
dataset. Using these compiled data, we build bi-directional Amharic-English
translation models by fine-tuning the existing Facebook M2M100 pre-trained
model achieving a BLEU score of 37.79 in Amharic-English 32.74 in
English-Amharic translation. Additionally, we explore the effects of Amharic
homophone normalization on the machine translation task. The results show that
the normalization of Amharic homophone characters increases the performance of
Amharic-English machine translation in both directions.
",2022-10-27T07:18:53Z,http://arxiv.org/abs/2210.15224v1,"Tadesse Destaw Belay, Atnafu Lambebo Tonja, Olga Kolesnikova, Seid Muhie Yimam, Abinew Ali Ayele, Silesh Bogale Haile, Grigori Sidorov, Alexander Gelbukh"
"BaitBuster-Bangla: A Comprehensive Dataset for Clickbait Detection in
  Bangla with Multi-Feature and Multi-Modal Analysis","  This study presents a large multi-modal Bangla YouTube clickbait dataset
consisting of 253,070 data points collected through an automated process using
the YouTube API and Python web automation frameworks. The dataset contains 18
diverse features categorized into metadata, primary content, engagement
statistics, and labels for individual videos from 58 Bangla YouTube channels. A
rigorous preprocessing step has been applied to denoise, deduplicate, and
remove bias from the features, ensuring unbiased and reliable analysis. As the
largest and most robust clickbait corpus in Bangla to date, this dataset
provides significant value for natural language processing and data science
researchers seeking to advance modeling of clickbait phenomena in low-resource
languages. Its multi-modal nature allows for comprehensive analyses of
clickbait across content, user interactions, and linguistic dimensions to
develop more sophisticated detection methods with cross-linguistic
applications.
",2023-10-13T13:25:16Z,http://arxiv.org/abs/2310.11465v1,"Abdullah Al Imran, Md Sakib Hossain Shovon, M. F. Mridha"
"Pre-Trained Neural Language Models for Automatic Mobile App User
  Feedback Answer Generation","  Studies show that developers' answers to the mobile app users' feedbacks on
app stores can increase the apps' star rating. To help app developers generate
answers that are related to the users' issues, recent studies develop models to
generate the answers automatically. Aims: The app response generation models
use deep neural networks and require training data. Pre-Trained neural language
Models (PTM) used in Natural Language Processing (NLP) take advantage of the
information they learned from a large corpora in an unsupervised manner, and
can reduce the amount of required training data. In this paper, we evaluate
PTMs to generate replies to the mobile app user feedbacks. Method: We train a
Transformer model from scratch and fine-tune two PTMs to evaluate the generated
responses, which are compared to RRGEN, a current app response model. We also
evaluate the models with different portions of the training data. Results: The
results on a large dataset evaluated by automatic metrics show that PTMs obtain
lower scores than the baselines. However, our human evaluation confirms that
PTMs can generate more relevant and meaningful responses to the posted
feedbacks. Moreover, the performance of PTMs has less drop compared to other
models when the amount of training data is reduced to 1/3. Conclusion: PTMs are
useful in generating responses to app reviews and are more robust models to the
amount of training data provided. However, the prediction time is 19X than
RRGEN. This study can provide new avenues for research in adapting the PTMs for
analyzing mobile app user feedbacks. Index Terms-mobile app user feedback
analysis, neural pre-trained language models, automatic answer generation
",2022-02-04T18:26:55Z,http://arxiv.org/abs/2202.02294v1,"Yue Cao, Fatemeh H. Fard"
LSTMs Exploit Linguistic Attributes of Data,"  While recurrent neural networks have found success in a variety of natural
language processing applications, they are general models of sequential data.
We investigate how the properties of natural language data affect an LSTM's
ability to learn a nonlinguistic task: recalling elements from its input. We
find that models trained on natural language data are able to recall tokens
from much longer sequences than models trained on non-language sequential data.
Furthermore, we show that the LSTM learns to solve the memorization task by
explicitly using a subset of its neurons to count timesteps in the input. We
hypothesize that the patterns and structure in natural language data enable
LSTMs to learn by providing approximate ways of reducing loss, but
understanding the effect of different training data on the learnability of
LSTMs remains an open question.
",2018-05-29T18:44:31Z,http://arxiv.org/abs/1805.11653v2,"Nelson F. Liu, Omer Levy, Roy Schwartz, Chenhao Tan, Noah A. Smith"
"Paraphrase Identification with Deep Learning: A Review of Datasets and
  Methods","  The rapid progress of Natural Language Processing (NLP) technologies has led
to the widespread availability and effectiveness of text generation tools such
as ChatGPT and Claude. While highly useful, these technologies also pose
significant risks to the credibility of various media forms if they are
employed for paraphrased plagiarism -- one of the most subtle forms of content
misuse in scientific literature and general text media. Although automated
methods for paraphrase identification have been developed, detecting this type
of plagiarism remains challenging due to the inconsistent nature of the
datasets used to train these methods. In this article, we examine traditional
and contemporary approaches to paraphrase identification, investigating how the
under-representation of certain paraphrase types in popular datasets, including
those used to train Large Language Models (LLMs), affects the ability to detect
plagiarism. We introduce and validate a new refined typology for paraphrases
(ReParaphrased, REfined PARAPHRASE typology definitions) to better understand
the disparities in paraphrase type representation. Lastly, we propose new
directions for future research and dataset development to enhance AI-based
paraphrase detection.
",2022-12-13T23:06:20Z,http://arxiv.org/abs/2212.06933v3,"Chao Zhou, Cheng Qiu, Lizhen Liang, Daniel E. Acuna"
Answer ranking in Community Question Answering: a deep learning approach,"  Community Question Answering is the field of computational linguistics that
deals with problems derived from the questions and answers posted to websites
such as Quora or Stack Overflow. Among some of these problems we find the issue
of ranking the multiple answers posted in reply to each question by how
informative they are in the attempt to solve the original question. This work
tries to advance the state of the art on answer ranking for community Question
Answering by proceeding with a deep learning approach. We started off by
creating a large data set of questions and answers posted to the Stack Overflow
website.
  We then leveraged the natural language processing capabilities of dense
embeddings and LSTM networks to produce a prediction for the accepted answer
attribute, and present the answers in a ranked form ordered by how likely they
are to be marked as accepted by the question asker. We also produced a set of
numerical features to assist with the answer ranking task. These numerical
features were either extracted from metadata found in the Stack Overflow posts
or derived from the questions and answers texts. We compared the performance of
our deep learning models against a set of forest and boosted trees ensemble
methods and found that our models could not improve the best baseline results.
We speculate that this lack of performance improvement versus the baseline
models may be caused by the large number of out of vocabulary words present in
the programming code snippets found in the questions and answers text. We
conclude that while a deep learning approach may be helpful in answer ranking
problems new methods should be developed to assist with the large number of out
of vocabulary words present in the programming code snippets
",2022-10-16T18:47:41Z,http://arxiv.org/abs/2212.01218v1,Lucas Valentin
Commit2Vec: Learning Distributed Representations of Code Changes,"  Deep learning methods, which have found successful applications in fields
like image classification and natural language processing, have recently been
applied to source code analysis too, due to the enormous amount of freely
available source code (e.g., from open-source software repositories).
  In this work, we elaborate upon a state-of-the-art approach to the
representation of source code that uses information about its syntactic
structure, and we adapt it to represent source changes (i.e., commits). We use
this representation to classify security-relevant commits.
  Because our method uses transfer learning (that is, we train a network on a
""pretext task"" for which abundant labeled data is available, and then we use
such network for the target task of commit classification, for which fewer
labeled instances are available), we studied the impact of pre-training the
network using two different pretext tasks versus a randomly initialized model.
  Our results indicate that representations that leverage the structural
information obtained through code syntax outperform token-based
representations. Furthermore, the performance metrics obtained when
pre-training on a loosely related pretext task with a very large dataset
($>10^6$ samples) were surpassed when pretraining on a smaller dataset ($>10^4$
samples) but for a pretext task that is more closely related to the target
task.
",2019-11-18T13:23:57Z,http://arxiv.org/abs/1911.07605v4,"Roc√¨o Cabrera Lozoya, Arnaud Baumann, Antonino Sabetta, Michele Bezzi"
"DIA-MOLE: An Unsupervised Learning Approach to Adaptive Dialogue Models
  for Spoken Dialogue Systems","  The DIAlogue MOdel Learning Environment supports an engineering-oriented
approach towards dialogue modelling for a spoken-language interface. Major
steps towards dialogue models is to know about the basic units that are used to
construct a dialogue model and possible sequences. In difference to many other
approaches a set of dialogue acts is not predefined by any theory or manually
during the engineering process, but is learned from data that are available in
an avised spoken dialogue system. The architecture is outlined and the approach
is applied to the domain of appointment scheduling. Even though based on a word
correctness of about 70% predictability of dialogue acts in DIA-MOLE turns out
to be comparable to human-assigned dialogue acts.
",1997-08-18T15:44:33Z,http://arxiv.org/abs/cmp-lg/9708009v1,Jens-Uwe Moeller
Review of Deep Learning,"  In recent years, China, the United States and other countries, Google and
other high-tech companies have increased investment in artificial intelligence.
Deep learning is one of the current artificial intelligence research's key
areas. This paper analyzes and summarizes the latest progress and future
research directions of deep learning. Firstly, three basic models of deep
learning are outlined, including multilayer perceptrons, convolutional neural
networks, and recurrent neural networks. On this basis, we further analyze the
emerging new models of convolution neural networks and recurrent neural
networks. This paper then summarizes deep learning's applications in many areas
of artificial intelligence, including speech processing, computer vision,
natural language processing and so on. Finally, this paper discusses the
existing problems of deep learning and gives the corresponding possible
solutions.
",2018-04-05T02:23:59Z,http://arxiv.org/abs/1804.01653v2,"Rong Zhang, Weiping Li, Tong Mo"
"A Survey of Active Learning for Text Classification using Deep Neural
  Networks","  Natural language processing (NLP) and neural networks (NNs) have both
undergone significant changes in recent years. For active learning (AL)
purposes, NNs are, however, less commonly used -- despite their current
popularity. By using the superior text classification performance of NNs for
AL, we can either increase a model's performance using the same amount of data
or reduce the data and therefore the required annotation efforts while keeping
the same performance. We review AL for text classification using deep neural
networks (DNNs) and elaborate on two main causes which used to hinder the
adoption: (a) the inability of NNs to provide reliable uncertainty estimates,
on which the most commonly used query strategies rely, and (b) the challenge of
training DNNs on small data. To investigate the former, we construct a taxonomy
of query strategies, which distinguishes between data-based, model-based, and
prediction-based instance selection, and investigate the prevalence of these
classes in recent research. Moreover, we review recent NN-based advances in NLP
like word embeddings or language models in the context of (D)NNs, survey the
current state-of-the-art at the intersection of AL, text classification, and
DNNs and relate recent advances in NLP to AL. Finally, we analyze recent work
in AL for text classification, connect the respective query strategies to the
taxonomy, and outline commonalities and shortcomings. As a result, we highlight
gaps in current research and present open research questions.
",2020-08-17T12:53:20Z,http://arxiv.org/abs/2008.07267v1,"Christopher Schr√∂der, Andreas Niekler"
"Learning Neural Models for Natural Language Processing in the Face of
  Distributional Shift","  The dominating NLP paradigm of training a strong neural predictor to perform
one task on a specific dataset has led to state-of-the-art performance in a
variety of applications (eg. sentiment classification, span-prediction based
question answering or machine translation). However, it builds upon the
assumption that the data distribution is stationary, ie. that the data is
sampled from a fixed distribution both at training and test time. This way of
training is inconsistent with how we as humans are able to learn from and
operate within a constantly changing stream of information. Moreover, it is
ill-adapted to real-world use cases where the data distribution is expected to
shift over the course of a model's lifetime.
  The first goal of this thesis is to characterize the different forms this
shift can take in the context of natural language processing, and propose
benchmarks and evaluation metrics to measure its effect on current deep
learning architectures. We then proceed to take steps to mitigate the effect of
distributional shift on NLP models. To this end, we develop methods based on
parametric reformulations of the distributionally robust optimization
framework. Empirically, we demonstrate that these approaches yield more robust
models as demonstrated on a selection of realistic problems. In the third and
final part of this thesis, we explore ways of efficiently adapting existing
models to new domains or tasks. Our contribution to this topic takes
inspiration from information geometry to derive a new gradient update rule
which alleviate catastrophic forgetting issues during adaptation.
",2021-09-03T14:29:20Z,http://arxiv.org/abs/2109.01558v1,Paul Michel
Visualizing RNN States with Predictive Semantic Encodings,"  Recurrent Neural Networks are an effective and prevalent tool used to model
sequential data such as natural language text. However, their deep nature and
massive number of parameters pose a challenge for those intending to study
precisely how they work. We present a visual technique that gives a high level
intuition behind the semantics of the hidden states within Recurrent Neural
Networks. This semantic encoding allows for hidden states to be compared
throughout the model independent of their internal details. The proposed
technique is displayed in a proof of concept visualization tool which is
demonstrated to visualize the natural language processing task of language
modelling.
",2019-08-01T19:24:59Z,http://arxiv.org/abs/1908.00588v1,"Lindsey Sawatzky, Steven Bergner, Fred Popowich"
Learning a Deep Generative Model like a Program: the Free Category Prior,"  Humans surpass the cognitive abilities of most other animals in our ability
to ""chunk"" concepts into words, and then combine the words to combine the
concepts. In this process, we make ""infinite use of finite means"", enabling us
to learn new concepts quickly and nest concepts within each-other. While
program induction and synthesis remain at the heart of foundational theories of
artificial intelligence, only recently has the community moved forward in
attempting to use program learning as a benchmark task itself. The cognitive
science community has thus often assumed that if the brain has simulation and
reasoning capabilities equivalent to a universal computer, then it must employ
a serialized, symbolic representation. Here we confront that assumption, and
provide a counterexample in which compositionality is expressed via network
structure: the free category prior over programs. We show how our formalism
allows neural networks to serve as primitives in probabilistic programs. We
learn both program structure and model parameters end-to-end.
",2020-11-22T17:16:17Z,http://arxiv.org/abs/2011.11063v1,Eli Sennesh
"torchdistill Meets Hugging Face Libraries for Reproducible, Coding-Free
  Deep Learning Studies: A Case Study on NLP","  Reproducibility in scientific work has been becoming increasingly important
in research communities such as machine learning, natural language processing,
and computer vision communities due to the rapid development of the research
domains supported by recent advances in deep learning. In this work, we present
a significantly upgraded version of torchdistill, a modular-driven coding-free
deep learning framework significantly upgraded from the initial release, which
supports only image classification and object detection tasks for reproducible
knowledge distillation experiments. To demonstrate that the upgraded framework
can support more tasks with third-party libraries, we reproduce the GLUE
benchmark results of BERT models using a script based on the upgraded
torchdistill, harmonizing with various Hugging Face libraries. All the 27
fine-tuned BERT models and configurations to reproduce the results are
published at Hugging Face, and the model weights have already been widely used
in research communities. We also reimplement popular small-sized models and new
knowledge distillation methods and perform additional experiments for computer
vision tasks.
",2023-10-26T17:57:15Z,http://arxiv.org/abs/2310.17644v1,Yoshitomo Matsubara
"Are Words Enough? On the semantic conditioning of affective music
  generation","  Music has been commonly recognized as a means of expressing emotions. In this
sense, an intense debate emerges from the need to verbalize musical emotions.
This concern seems highly relevant today, considering the exponential growth of
natural language processing using deep learning models where it is possible to
prompt semantic propositions to generate music automatically. This scoping
review aims to analyze and discuss the possibilities of music generation
conditioned by emotions. To address this topic, we propose a historical
perspective that encompasses the different disciplines and methods contributing
to this topic. In detail, we review two main paradigms adopted in automatic
music generation: rules-based and machine-learning models. Of note are the deep
learning architectures that aim to generate high-fidelity music from textual
descriptions. These models raise fundamental questions about the expressivity
of music, including whether emotions can be represented with words or expressed
through them. We conclude that overcoming the limitation and ambiguity of
language to express emotions through music, some of the use of deep learning
with natural language has the potential to impact the creative industries by
providing powerful tools to prompt and generate new musical works.
",2023-11-07T00:19:09Z,http://arxiv.org/abs/2311.03624v1,"Jorge Forero, Gilberto Bernardes, M√≥nica Mendes"
"Learning to Infer from Unlabeled Data: A Semi-supervised Learning
  Approach for Robust Natural Language Inference","  Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) aims
at predicting the relation between a pair of sentences (premise and hypothesis)
as entailment, contradiction or semantic independence. Although deep learning
models have shown promising performance for NLI in recent years, they rely on
large scale expensive human-annotated datasets. Semi-supervised learning (SSL)
is a popular technique for reducing the reliance on human annotation by
leveraging unlabeled data for training. However, despite its substantial
success on single sentence classification tasks where the challenge in making
use of unlabeled data is to assign ""good enough"" pseudo-labels, for NLI tasks,
the nature of unlabeled data is more complex: one of the sentences in the pair
(usually the hypothesis) along with the class label are missing from the data
and require human annotations, which makes SSL for NLI more challenging. In
this paper, we propose a novel way to incorporate unlabeled data in SSL for NLI
where we use a conditional language model, BART to generate the hypotheses for
the unlabeled sentences (used as premises). Our experiments show that our SSL
framework successfully exploits unlabeled data and substantially improves the
performance of four NLI datasets in low-resource settings. We release our code
at: https://github.com/msadat3/SSL_for_NLI.
",2022-11-05T20:34:08Z,http://arxiv.org/abs/2211.02971v1,"Mobashir Sadat, Cornelia Caragea"
"XLDA: Cross-Lingual Data Augmentation for Natural Language Inference and
  Question Answering","  While natural language processing systems often focus on a single language,
multilingual transfer learning has the potential to improve performance,
especially for low-resource languages. We introduce XLDA, cross-lingual data
augmentation, a method that replaces a segment of the input text with its
translation in another language. XLDA enhances performance of all 14 tested
languages of the cross-lingual natural language inference (XNLI) benchmark.
With improvements of up to $4.8\%$, training with XLDA achieves
state-of-the-art performance for Greek, Turkish, and Urdu. XLDA is in contrast
to, and performs markedly better than, a more naive approach that aggregates
examples in various languages in a way that each example is solely in one
language. On the SQuAD question answering task, we see that XLDA provides a
$1.0\%$ performance increase on the English evaluation set. Comprehensive
experiments suggest that most languages are effective as cross-lingual
augmentors, that XLDA is robust to a wide range of translation quality, and
that XLDA is even more effective for randomly initialized models than for
pretrained models.
",2019-05-27T19:44:33Z,http://arxiv.org/abs/1905.11471v1,"Jasdeep Singh, Bryan McCann, Nitish Shirish Keskar, Caiming Xiong, Richard Socher"
"The Bottleneck Simulator: A Model-based Deep Reinforcement Learning
  Approach","  Deep reinforcement learning has recently shown many impressive successes.
However, one major obstacle towards applying such methods to real-world
problems is their lack of data-efficiency. To this end, we propose the
Bottleneck Simulator: a model-based reinforcement learning method which
combines a learned, factorized transition model of the environment with rollout
simulations to learn an effective policy from few examples. The learned
transition model employs an abstract, discrete (bottleneck) state, which
increases sample efficiency by reducing the number of model parameters and by
exploiting structural properties of the environment. We provide a mathematical
analysis of the Bottleneck Simulator in terms of fixed points of the learned
policy, which reveals how performance is affected by four distinct sources of
error: an error related to the abstract space structure, an error related to
the transition model estimation variance, an error related to the transition
model estimation bias, and an error related to the transition model class bias.
Finally, we evaluate the Bottleneck Simulator on two natural language
processing tasks: a text adventure game and a real-world, complex dialogue
response selection task. On both tasks, the Bottleneck Simulator yields
excellent performance beating competing approaches.
",2018-07-12T16:59:28Z,http://arxiv.org/abs/1807.04723v1,"Iulian Vlad Serban, Chinnadhurai Sankar, Michael Pieper, Joelle Pineau, Yoshua Bengio"
"What is not where: the challenge of integrating spatial representations
  into deep learning architectures","  This paper examines to what degree current deep learning architectures for
image caption generation capture spatial language. On the basis of the
evaluation of examples of generated captions from the literature we argue that
systems capture what objects are in the image data but not where these objects
are located: the captions generated by these systems are the output of a
language model conditioned on the output of an object detector that cannot
capture fine-grained location information. Although language models provide
useful knowledge for image captions, we argue that deep learning image
captioning architectures should also model geometric relations between objects.
",2018-07-21T11:55:17Z,http://arxiv.org/abs/1807.08133v1,"John D. Kelleher, Simon Dobnik"
"AfroLM: A Self-Active Learning-based Multilingual Pretrained Language
  Model for 23 African Languages","  In recent years, multilingual pre-trained language models have gained
prominence due to their remarkable performance on numerous downstream Natural
Language Processing tasks (NLP). However, pre-training these large multilingual
language models requires a lot of training data, which is not available for
African Languages. Active learning is a semi-supervised learning algorithm, in
which a model consistently and dynamically learns to identify the most
beneficial samples to train itself on, in order to achieve better optimization
and performance on downstream tasks. Furthermore, active learning effectively
and practically addresses real-world data scarcity. Despite all its benefits,
active learning, in the context of NLP and especially multilingual language
models pretraining, has received little consideration. In this paper, we
present AfroLM, a multilingual language model pretrained from scratch on 23
African languages (the largest effort to date) using our novel self-active
learning framework. Pretrained on a dataset significantly (14x) smaller than
existing baselines, AfroLM outperforms many multilingual pretrained language
models (AfriBERTa, XLMR-base, mBERT) on various NLP downstream tasks (NER, text
classification, and sentiment analysis). Additional out-of-domain sentiment
analysis experiments show that \textbf{AfroLM} is able to generalize well
across various domains. We release the code source, and our datasets used in
our framework at https://github.com/bonaventuredossou/MLM_AL.
",2022-11-07T02:15:25Z,http://arxiv.org/abs/2211.03263v2,"Bonaventure F. P. Dossou, Atnafu Lambebo Tonja, Oreen Yousuf, Salomey Osei, Abigail Oppong, Iyanuoluwa Shode, Oluwabusayo Olufunke Awoyomi, Chris Chinenye Emezue"
"Audio-visual Generalised Zero-shot Learning with Cross-modal Attention
  and Language","  Learning to classify video data from classes not included in the training
data, i.e. video-based zero-shot learning, is challenging. We conjecture that
the natural alignment between the audio and visual modalities in video data
provides a rich training signal for learning discriminative multi-modal
representations. Focusing on the relatively underexplored task of audio-visual
zero-shot learning, we propose to learn multi-modal representations from
audio-visual data using cross-modal attention and exploit textual label
embeddings for transferring knowledge from seen classes to unseen classes.
Taking this one step further, in our generalised audio-visual zero-shot
learning setting, we include all the training classes in the test-time search
space which act as distractors and increase the difficulty while making the
setting more realistic. Due to the lack of a unified benchmark in this domain,
we introduce a (generalised) zero-shot learning benchmark on three audio-visual
datasets of varying sizes and difficulty, VGGSound, UCF, and ActivityNet,
ensuring that the unseen test classes do not appear in the dataset used for
supervised training of the backbone deep models. Comparing multiple relevant
and recent methods, we demonstrate that our proposed AVCA model achieves
state-of-the-art performance on all three datasets. Code and data are available
at \url{https://github.com/ExplainableML/AVCA-GZSL}.
",2022-03-07T18:52:13Z,http://arxiv.org/abs/2203.03598v2,"Otniel-Bogdan Mercea, Lukas Riesch, A. Sophia Koepke, Zeynep Akata"
"Boardwalk Empire: How Generative AI is Revolutionizing Economic
  Paradigms","  The relentless pursuit of technological advancements has ushered in a new era
where artificial intelligence (AI) is not only a powerful tool but also a
critical economic driver. At the forefront of this transformation is Generative
AI, which is catalyzing a paradigm shift across industries. Deep generative
models, an integration of generative and deep learning techniques, excel in
creating new data beyond analyzing existing ones, revolutionizing sectors from
production and manufacturing to finance. By automating design, optimization,
and innovation cycles, Generative AI is reshaping core industrial processes. In
the financial sector, it is transforming risk assessment, trading strategies,
and forecasting, demonstrating its profound impact. This paper explores the
sweeping changes driven by deep learning models like Large Language Models
(LLMs), highlighting their potential to foster innovative business models,
disruptive technologies, and novel economic landscapes. As we stand at the
threshold of an AI-driven economic era, Generative AI is emerging as a pivotal
force, driving innovation, disruption, and economic evolution on a global
scale.
",2024-10-19T20:57:16Z,http://arxiv.org/abs/2410.15212v2,"Subramanyam Sahoo, Kamlesh Dutta"
"TabLLM: Few-shot Classification of Tabular Data with Large Language
  Models","  We study the application of large language models to zero-shot and few-shot
classification of tabular data. We prompt the large language model with a
serialization of the tabular data to a natural-language string, together with a
short description of the classification problem. In the few-shot setting, we
fine-tune the large language model using some labeled examples. We evaluate
several serialization methods including templates, table-to-text models, and
large language models. Despite its simplicity, we find that this technique
outperforms prior deep-learning-based tabular classification methods on several
benchmark datasets. In most cases, even zero-shot classification obtains
non-trivial performance, illustrating the method's ability to exploit prior
knowledge encoded in large language models. Unlike many deep learning methods
for tabular datasets, this approach is also competitive with strong traditional
baselines like gradient-boosted trees, especially in the very-few-shot setting.
",2022-10-19T17:08:13Z,http://arxiv.org/abs/2210.10723v2,"Stefan Hegselmann, Alejandro Buendia, Hunter Lang, Monica Agrawal, Xiaoyi Jiang, David Sontag"
Machine Learning for Synthetic Data Generation: A Review,"  Machine learning heavily relies on data, but real-world applications often
encounter various data-related issues. These include data of poor quality,
insufficient data points leading to under-fitting of machine learning models,
and difficulties in data access due to concerns surrounding privacy, safety,
and regulations. In light of these challenges, the concept of synthetic data
generation emerges as a promising alternative that allows for data sharing and
utilization in ways that real-world data cannot facilitate. This paper presents
a comprehensive systematic review of existing studies that employ machine
learning models for the purpose of generating synthetic data. The review
encompasses various perspectives, starting with the applications of synthetic
data generation, spanning computer vision, speech, natural language processing,
healthcare, and business domains. Additionally, it explores different machine
learning methods, with particular emphasis on neural network architectures and
deep generative models. The paper also addresses the crucial aspects of privacy
and fairness concerns related to synthetic data generation. Furthermore, this
study identifies the challenges and opportunities prevalent in this emerging
field, shedding light on the potential avenues for future research. By delving
into the intricacies of synthetic data generation, this paper aims to
contribute to the advancement of knowledge and inspire further exploration in
synthetic data generation.
",2023-02-08T13:59:31Z,http://arxiv.org/abs/2302.04062v9,"Yingzhou Lu, Minjie Shen, Huazheng Wang, Xiao Wang, Capucine van Rechem, Tianfan Fu, Wenqi Wei"
DELTA: A DEep learning based Language Technology plAtform,"  In this paper we present DELTA, a deep learning based language technology
platform. DELTA is an end-to-end platform designed to solve industry level
natural language and speech processing problems. It integrates most popular
neural network models for training as well as comprehensive deployment tools
for production. DELTA aims to provide easy and fast experiences for using,
deploying, and developing natural language processing and speech models for
both academia and industry use cases. We demonstrate the reliable performance
with DELTA on several natural language processing and speech tasks, including
text classification, named entity recognition, natural language inference,
speech recognition, speaker verification, etc. DELTA has been used for
developing several state-of-the-art algorithms for publications and delivering
real production to serve millions of users.
",2019-08-02T01:13:50Z,http://arxiv.org/abs/1908.01853v1,"Kun Han, Junwen Chen, Hui Zhang, Haiyang Xu, Yiping Peng, Yun Wang, Ning Ding, Hui Deng, Yonghu Gao, Tingwei Guo, Yi Zhang, Yahao He, Baochang Ma, Yulong Zhou, Kangli Zhang, Chao Liu, Ying Lyu, Chenxi Wang, Cheng Gong, Yunbo Wang, Wei Zou, Hui Song, Xiangang Li"
"A Review of Hybrid and Ensemble in Deep Learning for Natural Language
  Processing","  This review presents a comprehensive exploration of hybrid and ensemble deep
learning models within Natural Language Processing (NLP), shedding light on
their transformative potential across diverse tasks such as Sentiment Analysis,
Named Entity Recognition, Machine Translation, Question Answering, Text
Classification, Generation, Speech Recognition, Summarization, and Language
Modeling. The paper systematically introduces each task, delineates key
architectures from Recurrent Neural Networks (RNNs) to Transformer-based models
like BERT, and evaluates their performance, challenges, and computational
demands. The adaptability of ensemble techniques is emphasized, highlighting
their capacity to enhance various NLP applications. Challenges in
implementation, including computational overhead, overfitting, and model
interpretation complexities, are addressed alongside the trade-off between
interpretability and performance. Serving as a concise yet invaluable guide,
this review synthesizes insights into tasks, architectures, and challenges,
offering a holistic perspective for researchers and practitioners aiming to
advance language-driven applications through ensemble deep learning in NLP.
",2023-12-09T14:49:34Z,http://arxiv.org/abs/2312.05589v2,"Jianguo Jia, Wen Liang, Youzhi Liang"
"Improving the Performance of English-Tamil Statistical Machine
  Translation System using Source-Side Pre-Processing","  Machine Translation is one of the major oldest and the most active research
area in Natural Language Processing. Currently, Statistical Machine Translation
(SMT) dominates the Machine Translation research. Statistical Machine
Translation is an approach to Machine Translation which uses models to learn
translation patterns directly from data, and generalize them to translate a new
unseen text. The SMT approach is largely language independent, i.e. the models
can be applied to any language pair. Statistical Machine Translation (SMT)
attempts to generate translations using statistical methods based on bilingual
text corpora. Where such corpora are available, excellent results can be
attained translating similar texts, but such corpora are still not available
for many language pairs. Statistical Machine Translation systems, in general,
have difficulty in handling the morphology on the source or the target side
especially for morphologically rich languages. Errors in morphology or syntax
in the target language can have severe consequences on meaning of the sentence.
They change the grammatical function of words or the understanding of the
sentence through the incorrect tense information in verb. Baseline SMT also
known as Phrase Based Statistical Machine Translation (PBSMT) system does not
use any linguistic information and it only operates on surface word form.
Recent researches shown that adding linguistic information helps to improve the
accuracy of the translation with less amount of bilingual corpora. Adding
linguistic information can be done using the Factored Statistical Machine
Translation system through pre-processing steps. This paper investigates about
how English side pre-processing is used to improve the accuracy of
English-Tamil SMT system.
",2014-09-29T04:54:03Z,http://arxiv.org/abs/1409.8581v1,"M. Anand Kumar, V. Dhanalakshmi, K. P. Soman, V. Sharmiladevi"
"Injecting structural hints: Using language models to study inductive
  biases in language learning","  Both humans and large language models are able to learn language without
explicit structural supervision. What inductive biases make this learning
possible? We address this fundamental cognitive question by leveraging
transformer language models: we inject inductive bias into language models by
pretraining on formally-structured data, and then evaluate the biased learners'
ability to learn typologically-diverse natural languages. Our experimental
setup creates a testbed for hypotheses about inductive bias in human language
learning. We investigate the effect of injecting models with three types of
inductive bias: 1) recursive, hierarchical processing, 2) crossing token-token
relationships that can't be modeled by context-free grammars, and 3) a Zipfian
power-law vocabulary distribution. We show that non-context-free relationships
form the best inductive biases. Our study leverages the capabilities of
transformer models to run controlled language learning experiments that are not
possible to run on humans, and surfaces hypotheses about the structures that
facilitate language learning in both humans and machines.
",2023-04-25T18:00:08Z,http://arxiv.org/abs/2304.13060v2,"Isabel Papadimitriou, Dan Jurafsky"
"Deep learning for language understanding of mental health concepts
  derived from Cognitive Behavioural Therapy","  In recent years, we have seen deep learning and distributed representations
of words and sentences make impact on a number of natural language processing
tasks, such as similarity, entailment and sentiment analysis. Here we introduce
a new task: understanding of mental health concepts derived from Cognitive
Behavioural Therapy (CBT). We define a mental health ontology based on the CBT
principles, annotate a large corpus where this phenomena is exhibited and
perform understanding using deep learning and distributed representations. Our
results show that the performance of deep learning models combined with word
embeddings or sentence embeddings significantly outperform non-deep-learning
models in this difficult task. This understanding module will be an essential
component of a statistical dialogue system delivering therapy.
",2018-09-03T16:17:11Z,http://arxiv.org/abs/1809.00640v1,"Lina Rojas-Barahona, Bo-Hsiang Tseng, Yinpei Dai, Clare Mansfield, Osman Ramadan, Stefan Ultes, Michael Crawford, Milica Gasic"
Graph Neural Networks for Text Classification: A Survey,"  Text Classification is the most essential and fundamental problem in Natural
Language Processing. While numerous recent text classification models applied
the sequential deep learning technique, graph neural network-based models can
directly deal with complex structured text data and exploit global information.
Many real text classification applications can be naturally cast into a graph,
which captures words, documents, and corpus global features. In this survey, we
bring the coverage of methods up to 2023, including corpus-level and
document-level graph neural networks. We discuss each of these methods in
detail, dealing with the graph construction mechanisms and the graph-based
learning process. As well as the technological survey, we look at issues behind
and future directions addressed in text classification using graph neural
networks. We also cover datasets, evaluation metrics, and experiment design and
present a summary of published performance on the publicly available
benchmarks. Note that we present a comprehensive comparison between different
techniques and identify the pros and cons of various evaluation metrics in this
survey.
",2023-04-23T04:21:50Z,http://arxiv.org/abs/2304.11534v3,"Kunze Wang, Yihao Ding, Soyeon Caren Han"
"SNOBERT: A Benchmark for clinical notes entity linking in the SNOMED CT
  clinical terminology","  The extraction and analysis of insights from medical data, primarily stored
in free-text formats by healthcare workers, presents significant challenges due
to its unstructured nature. Medical coding, a crucial process in healthcare,
remains minimally automated due to the complexity of medical ontologies and
restricted access to medical texts for training Natural Language Processing
models. In this paper, we proposed a method, ""SNOBERT,"" of linking text spans
in clinical notes to specific concepts in the SNOMED CT using BERT-based
models. The method consists of two stages: candidate selection and candidate
matching. The models were trained on one of the largest publicly available
dataset of labeled clinical notes. SNOBERT outperforms other classical methods
based on deep learning, as confirmed by the results of a challenge in which it
was applied.
",2024-05-25T08:00:44Z,http://arxiv.org/abs/2405.16115v1,"Mikhail Kulyabin, Gleb Sokolov, Aleksandr Galaida, Andreas Maier, Tomas Arias-Vergara"
"Advancements and Challenges in Bangla Question Answering Models: A
  Comprehensive Review","  The domain of Natural Language Processing (NLP) has experienced notable
progress in the evolution of Bangla Question Answering (QA) systems. This paper
presents a comprehensive review of seven research articles that contribute to
the progress in this domain. These research studies explore different aspects
of creating question-answering systems for the Bangla language. They cover
areas like collecting data, preparing it for analysis, designing models,
conducting experiments, and interpreting results. The papers introduce
innovative methods like using LSTM-based models with attention mechanisms,
context-based QA systems, and deep learning techniques based on prior
knowledge. However, despite the progress made, several challenges remain,
including the lack of well-annotated data, the absence of high-quality reading
comprehension datasets, and difficulties in understanding the meaning of words
in context. Bangla QA models' precision and applicability are constrained by
these challenges. This review emphasizes the significance of these research
contributions by highlighting the developments achieved in creating Bangla QA
systems as well as the ongoing effort required to get past roadblocks and
improve the performance of these systems for actual language comprehension
tasks.
",2024-12-16T14:42:26Z,http://arxiv.org/abs/2412.11823v1,"Md Iftekhar Islam Tashik, Abdullah Khondoker, Enam Ahmed Taufik, Antara Firoz Parsa, S M Ishtiak Mahmud"
"Who Wrote it and Why? Prompting Large-Language Models for Authorship
  Verification","  Authorship verification (AV) is a fundamental task in natural language
processing (NLP) and computational linguistics, with applications in forensic
analysis, plagiarism detection, and identification of deceptive content.
Existing AV techniques, including traditional stylometric and deep learning
approaches, face limitations in terms of data requirements and lack of
explainability. To address these limitations, this paper proposes PromptAV, a
novel technique that leverages Large-Language Models (LLMs) for AV by providing
step-by-step stylometric explanation prompts. PromptAV outperforms
state-of-the-art baselines, operates effectively with limited training data,
and enhances interpretability through intuitive explanations, showcasing its
potential as an effective and interpretable solution for the AV task.
",2023-10-12T08:24:15Z,http://arxiv.org/abs/2310.08123v1,"Chia-Yu Hung, Zhiqiang Hu, Yujia Hu, Roy Ka-Wei Lee"
A Comprehensive Survey on Graph Neural Networks,"  Deep learning has revolutionized many machine learning tasks in recent years,
ranging from image classification and video processing to speech recognition
and natural language understanding. The data in these tasks are typically
represented in the Euclidean space. However, there is an increasing number of
applications where data are generated from non-Euclidean domains and are
represented as graphs with complex relationships and interdependency between
objects. The complexity of graph data has imposed significant challenges on
existing machine learning algorithms. Recently, many studies on extending deep
learning approaches for graph data have emerged. In this survey, we provide a
comprehensive overview of graph neural networks (GNNs) in data mining and
machine learning fields. We propose a new taxonomy to divide the
state-of-the-art graph neural networks into four categories, namely recurrent
graph neural networks, convolutional graph neural networks, graph autoencoders,
and spatial-temporal graph neural networks. We further discuss the applications
of graph neural networks across various domains and summarize the open source
codes, benchmark data sets, and model evaluation of graph neural networks.
Finally, we propose potential research directions in this rapidly growing
field.
",2019-01-03T03:20:55Z,http://arxiv.org/abs/1901.00596v4,"Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, Philip S. Yu"
"Instance-based Inductive Deep Transfer Learning by Cross-Dataset
  Querying with Locality Sensitive Hashing","  Supervised learning models are typically trained on a single dataset and the
performance of these models rely heavily on the size of the dataset, i.e.,
amount of data available with the ground truth. Learning algorithms try to
generalize solely based on the data that is presented with during the training.
In this work, we propose an inductive transfer learning method that can augment
learning models by infusing similar instances from different learning tasks in
the Natural Language Processing (NLP) domain. We propose to use instance
representations from a source dataset, \textit{without inheriting anything}
from the source learning model. Representations of the instances of
\textit{source} \& \textit{target} datasets are learned, retrieval of relevant
source instances is performed using soft-attention mechanism and
\textit{locality sensitive hashing}, and then, augmented into the model during
training on the target dataset. Our approach simultaneously exploits the local
\textit{instance level information} as well as the macro statistical viewpoint
of the dataset. Using this approach we have shown significant improvements for
three major news classification datasets over the baseline. Experimental
evaluations also show that the proposed approach reduces dependency on labeled
data by a significant margin for comparable performance. With our proposed
cross dataset learning procedure we show that one can achieve
competitive/better performance than learning from a single dataset.
",2018-02-16T13:59:15Z,http://arxiv.org/abs/1802.05934v1,"Somnath Basu Roy Chowdhury, K M Annervaz, Ambedkar Dukkipati"
"Interpretable Sentence Representation with Variational Autoencoders and
  Attention","  In this thesis, we develop methods to enhance the interpretability of recent
representation learning techniques in natural language processing (NLP) while
accounting for the unavailability of annotated data. We choose to leverage
Variational Autoencoders (VAEs) due to their efficiency in relating
observations to latent generative factors and their effectiveness in
data-efficient learning and interpretable representation learning. As a first
contribution, we identify and remove unnecessary components in the functioning
scheme of semi-supervised VAEs making them faster, smaller and easier to
design. Our second and main contribution is to use VAEs and Transformers to
build two models with inductive bias to separate information in latent
representations into understandable concepts without annotated data. The first
model, Attention-Driven VAE (ADVAE), is able to separately represent and
control information about syntactic roles in sentences. The second model,
QKVAE, uses separate latent variables to form keys and values for its
Transformer decoder and is able to separate syntactic and semantic information
in its neural representations. In transfer experiments, QKVAE has competitive
performance compared to supervised models and equivalent performance to a
supervised model using 50K annotated samples. Additionally, QKVAE displays
improved syntactic role disentanglement capabilities compared to ADVAE.
Overall, we demonstrate that it is possible to enhance the interpretability of
state-of-the-art deep learning architectures for language modeling with
unannotated data in situations where text data is abundant but annotations are
scarce.
",2023-05-04T13:16:15Z,http://arxiv.org/abs/2305.02810v1,Ghazi Felhi
Semi-Automated Construction of Food Composition Knowledge Base,"  A food composition knowledge base, which stores the essential phyto-, micro-,
and macro-nutrients of foods is useful for both research and industrial
applications. Although many existing knowledge bases attempt to curate such
information, they are often limited by time-consuming manual curation
processes. Outside of the food science domain, natural language processing
methods that utilize pre-trained language models have recently shown promising
results for extracting knowledge from unstructured text. In this work, we
propose a semi-automated framework for constructing a knowledge base of food
composition from the scientific literature available online. To this end, we
utilize a pre-trained BioBERT language model in an active learning setup that
allows the optimal use of limited training data. Our work demonstrates how
human-in-the-loop models are a step toward AI-assisted food systems that scale
well to the ever-increasing big data.
",2023-01-24T22:08:49Z,http://arxiv.org/abs/2301.11322v1,"Jason Youn, Fangzhou Li, Ilias Tagkopoulos"
The Janus System: Multi-paradigm Programming in Prolog and Python,"  Python and Prolog express different programming paradigms, with different
strengths. Python is wildly popular because it is well-structured, easy to use,
and mixes well with thousands of scientific and machine learning programs
written in C. Prolog's logic-based approach provides powerful reasoning
capabilities, especially when combined with constraint evaluation,
probabilistic reasoning, well-founded negation, and other advances. Both
languages have commonalities as well: both are usually written in C, both are
dynamically typed, and both use data structures based on a small number of
recursive types.
  This paper describes the design and implementation of Janus, a system that
tightly combines Prolog and Python into a single process. Janus bi-translates
data structures and offers performance of many hundreds of thousands of
round-trip inter-language calls per second. Although Janus is still new, it has
been used in commercial applications including natural language processing,
visual query answering and robotic automation. Janus was developed for XSB, but
porting Janus code to a second Prolog has been straightforward, indicating that
Janus is a tool that other Prologs may easily adopt.
",2023-08-30T09:07:05Z,http://arxiv.org/abs/2308.15893v1,"Theresa Swift, Carl Andersen"
"Uncertainty-Informed Screening for Safer Solvents Used in the Synthesis
  of Perovskite via Language Models","  The challenge of accurately predicting toxicity of industrial solvents used
in perovskite synthesis is a necessary undertaking but is limited by a lack of
a targeted and structured toxicity data. This paper presents a novel framework
that combines an automated data extraction using language models, and an
uncertainty-informed prediction model to fill data gaps and improve prediction
confidence. First, we have utilized and compared two approaches to
automatically extract relevant data from a corpus of scientific literature on
solvents used in perovskite synthesis: smaller bidirectional language models
like BERT and ELMo are used for their repeatability and deterministic outputs,
while autoregressive large language model (LLM) such as GPT-3.5 is used to
leverage its larger training corpus and better response generation. Our novel
'prompting and verification' technique integrated with an LLM aims at targeted
extraction and refinement, thereby reducing hallucination and improving the
quality of the extracted data using the LLM. Next, the extracted data is fed
into our pre-trained multi-task binary classification deep learning to predict
the ED nature of extracted solvents. We have used a Shannon entropy-based
uncertainty quantification utilizing the class probabilities obtained from the
classification model to quantify uncertainty and identify data gaps in our
predictions. This approach leads to the curation of a structured dataset for
solvents used in perovskite synthesis and their uncertainty-informed virtual
toxicity assessment. Additionally, chord diagrams have been used to visualize
solvent interactions and prioritize those with potential hazards, revealing
that 70% of the solvent interactions were primarily associated with two
specific perovskites.
",2024-09-30T17:13:40Z,http://arxiv.org/abs/2409.20512v1,"Arpan Mukherjee, Deepesh Giri, Krishna Rajan"
"Long-range gene expression prediction with token alignment of large
  language model","  Gene expression is a cellular process that plays a fundamental role in human
phenotypical variations and diseases. Despite advances of deep learning models
for gene expression prediction, recent benchmarks have revealed their inability
to learn distal regulatory grammar. Here, we address this challenge by
leveraging a pretrained large language model to enhance gene expression
prediction. We introduce Genetic sequence Token Alignment (GTA), which aligns
genetic sequence features with natural language tokens, allowing for symbolic
reasoning of genomic sequence features via the frozen language model. This
cross-modal adaptation learns the regulatory grammar and allows us to further
incorporate gene-specific human annotations as prompts, enabling in-context
learning that is not possible with existing models. Trained on lymphoblastoid
cells, GTA was evaluated on cells from the Geuvadis consortium and outperforms
state-of-the-art models such as Enformer, achieving a Spearman correlation of
0.65, a 10\% improvement. Additionally, GTA offers improved interpretation of
long-range interactions through the identification of the most meaningful
sections of the input genetic context. GTA represents a powerful and novel
cross-modal approach to gene expression prediction by utilizing a pretrained
language model, in a paradigm shift from conventional gene expression models
trained only on sequence data.
",2024-10-02T02:42:29Z,http://arxiv.org/abs/2410.01858v1,"Edouardo Honig, Huixin Zhan, Ying Nian Wu, Zijun Frank Zhang"
A Web Scraping Methodology for Bypassing Twitter API Restrictions,"  Retrieving information from social networks is the first and primordial step
many data analysis fields such as Natural Language Processing, Sentiment
Analysis and Machine Learning. Important data science tasks relay on historical
data gathering for further predictive results. Most of the recent works use
Twitter API, a public platform for collecting public streams of information,
which allows querying chronological tweets for no more than three weeks old. In
this paper, we present a new methodology for collecting historical tweets
within any date range using web scraping techniques bypassing for Twitter API
restrictions.
",2018-03-27T03:23:19Z,http://arxiv.org/abs/1803.09875v1,"A. Hernandez-Suarez, G. Sanchez-Perez, K. Toscano-Medina, V. Martinez-Hernandez, V. Sanchez, H. Perez-Meana"
"Direct Feedback Alignment Scales to Modern Deep Learning Tasks and
  Architectures","  Despite being the workhorse of deep learning, the backpropagation algorithm
is no panacea. It enforces sequential layer updates, thus preventing efficient
parallelization of the training process. Furthermore, its biological
plausibility is being challenged. Alternative schemes have been devised; yet,
under the constraint of synaptic asymmetry, none have scaled to modern deep
learning tasks and architectures. Here, we challenge this perspective, and
study the applicability of Direct Feedback Alignment to neural view synthesis,
recommender systems, geometric learning, and natural language processing. In
contrast with previous studies limited to computer vision tasks, our findings
show that it successfully trains a large range of state-of-the-art deep
learning architectures, with performance close to fine-tuned backpropagation.
At variance with common beliefs, our work supports that challenging tasks can
be tackled in the absence of weight transport.
",2020-06-23T10:17:49Z,http://arxiv.org/abs/2006.12878v2,"Julien Launay, Iacopo Poli, Fran√ßois Boniface, Florent Krzakala"
"Predictive Insights into LGBTQ+ Minority Stress: A Transductive
  Exploration of Social Media Discourse","  Individuals who identify as sexual and gender minorities, including lesbian,
gay, bisexual, transgender, queer, and others (LGBTQ+) are more likely to
experience poorer health than their heterosexual and cisgender counterparts.
One primary source that drives these health disparities is minority stress
(i.e., chronic and social stressors unique to LGBTQ+ communities' experiences
adapting to the dominant culture). This stress is frequently expressed in
LGBTQ+ users' posts on social media platforms. However, these expressions are
not just straightforward manifestations of minority stress. They involve
linguistic complexity (e.g., idiom or lexical diversity), rendering them
challenging for many traditional natural language processing methods to detect.
In this work, we designed a hybrid model using Graph Neural Networks (GNN) and
Bidirectional Encoder Representations from Transformers (BERT), a pre-trained
deep language model to improve the classification performance of minority
stress detection. We experimented with our model on a benchmark social media
dataset for minority stress detection (LGBTQ+ MiSSoM+). The dataset is
comprised of 5,789 human-annotated Reddit posts from LGBTQ+ subreddits. Our
approach enables the extraction of hidden linguistic nuances through
pretraining on a vast amount of raw data, while also engaging in transductive
learning to jointly develop representations for both labeled training data and
unlabeled test data. The RoBERTa-GCN model achieved an accuracy of 0.86 and an
F1 score of 0.86, surpassing the performance of other baseline models in
predicting LGBTQ+ minority stress. Improved prediction of minority stress
expressions on social media could lead to digital health interventions to
improve the wellbeing of LGBTQ+ people-a community with high rates of
stress-sensitive health problems.
",2024-11-20T18:35:41Z,http://arxiv.org/abs/2411.13534v1,"S. Chapagain, Y. Zhao, T. K. Rohleen, S. M. Hamdi, S. F. Boubrahimi, R. E. Flinn, E. M. Lund, D. Klooster, J. R. Scheer, C. J. Cascalheira"
Machine Learning Technique Based Fake News Detection,"  False news has received attention from both the general public and the
scholarly world. Such false information has the ability to affect public
perception, giving nefarious groups the chance to influence the results of
public events like elections. Anyone can share fake news or facts about anyone
or anything for their personal gain or to cause someone trouble. Also,
information varies depending on the part of the world it is shared on. Thus, in
this paper, we have trained a model to classify fake and true news by utilizing
the 1876 news data from our collected dataset. We have preprocessed the data to
get clean and filtered texts by following the Natural Language Processing
approaches. Our research conducts 3 popular Machine Learning (Stochastic
gradient descent, Na\""ive Bayes, Logistic Regression,) and 2 Deep Learning
(Long-Short Term Memory, ASGD Weight-Dropped LSTM, or AWD-LSTM) algorithms.
After we have found our best Naive Bayes classifier with 56% accuracy and an
F1-macro score of an average of 32%.
",2023-09-18T19:26:54Z,http://arxiv.org/abs/2309.13069v1,"Biplob Kumar Sutradhar, Md. Zonaid, Nushrat Jahan Ria, Sheak Rashed Haider Noori"
"Deep learning for temporal data representation in electronic health
  records: A systematic review of challenges and methodologies","  Objective: Temporal electronic health records (EHRs) can be a wealth of
information for secondary uses, such as clinical events prediction or chronic
disease management. However, challenges exist for temporal data representation.
We therefore sought to identify these challenges and evaluate novel
methodologies for addressing them through a systematic examination of deep
learning solutions.
  Methods: We searched five databases (PubMed, EMBASE, the Institute of
Electrical and Electronics Engineers [IEEE] Xplore Digital Library, the
Association for Computing Machinery [ACM] digital library, and Web of Science)
complemented with hand-searching in several prestigious computer science
conference proceedings. We sought articles that reported deep learning
methodologies on temporal data representation in structured EHR data from
January 1, 2010, to August 30, 2020. We summarized and analyzed the selected
articles from three perspectives: nature of time series, methodology, and model
implementation.
  Results: We included 98 articles related to temporal data representation
using deep learning. Four major challenges were identified, including data
irregularity, data heterogeneity, data sparsity, and model opacity. We then
studied how deep learning techniques were applied to address these challenges.
Finally, we discuss some open challenges arising from deep learning.
  Conclusion: Temporal EHR data present several major challenges for clinical
prediction modeling and data utilization. To some extent, current deep learning
solutions can address these challenges. Future studies can consider designing
comprehensive and integrated solutions. Moreover, researchers should
incorporate additional clinical domain knowledge into study designs and enhance
the interpretability of the model to facilitate its implementation in clinical
practice.
",2021-07-21T09:00:40Z,http://arxiv.org/abs/2107.09951v1,"Feng Xie, Han Yuan, Yilin Ning, Marcus Eng Hock Ong, Mengling Feng, Wynne Hsu, Bibhas Chakraborty, Nan Liu"
Decoding EEG Brain Activity for Multi-Modal Natural Language Processing,"  Until recently, human behavioral data from reading has mainly been of
interest to researchers to understand human cognition. However, these human
language processing signals can also be beneficial in machine learning-based
natural language processing tasks. Using EEG brain activity to this purpose is
largely unexplored as of yet. In this paper, we present the first large-scale
study of systematically analyzing the potential of EEG brain activity data for
improving natural language processing tasks, with a special focus on which
features of the signal are most beneficial. We present a multi-modal machine
learning architecture that learns jointly from textual input as well as from
EEG features. We find that filtering the EEG signals into frequency bands is
more beneficial than using the broadband signal. Moreover, for a range of word
embedding types, EEG data improves binary and ternary sentiment classification
and outperforms multiple baselines. For more complex tasks such as relation
detection, further research is needed. Finally, EEG data shows to be
particularly promising when limited training data is available.
",2021-02-17T09:44:21Z,http://arxiv.org/abs/2102.08655v2,"Nora Hollenstein, Cedric Renggli, Benjamin Glaus, Maria Barrett, Marius Troendle, Nicolas Langer, Ce Zhang"
"Transfer Learning in the Field of Renewable Energies -- A Transfer
  Learning Framework Providing Power Forecasts Throughout the Lifecycle of Wind
  Farms After Initial Connection to the Electrical Grid","  In recent years, transfer learning gained particular interest in the field of
vision and natural language processing. In the research field of vision, e.g.,
deep neural networks and transfer learning techniques achieve almost perfect
classification scores within minutes. Nonetheless, these techniques are not yet
widely applied in other domains. Therefore, this article identifies critical
challenges and shows potential solutions for power forecasts in the field of
renewable energies. It proposes a framework utilizing transfer learning
techniques in wind power forecasts with limited or no historical data. On the
one hand, this allows evaluating the applicability of transfer learning in the
field of renewable energy. On the other hand, by developing automatic
procedures, we assure that the proposed methods provide a framework that
applies to domains in organic computing as well.
",2019-06-03T09:46:09Z,http://arxiv.org/abs/1906.01168v1,Jens Schreiber
GERNERMED++: Transfer Learning in German Medical NLP,"  We present a statistical model for German medical natural language processing
trained for named entity recognition (NER) as an open, publicly available
model. The work serves as a refined successor to our first GERNERMED model
which is substantially outperformed by our work. We demonstrate the
effectiveness of combining multiple techniques in order to achieve strong
results in entity recognition performance by the means of transfer-learning on
pretrained deep language models (LM), word-alignment and neural machine
translation. Due to the sparse situation on open, public medical entity
recognition models for German texts, this work offers benefits to the German
research community on medical NLP as a baseline model. Since our model is based
on public English data, its weights are provided without legal restrictions on
usage and distribution. The sample code and the statistical model is available
at: https://github.com/frankkramer-lab/GERNERMED-pp
",2022-06-29T09:53:10Z,http://arxiv.org/abs/2206.14504v2,"Johann Frei, Ludwig Frei-Stuber, Frank Kramer"
"Recurrent Neural Networks with Mixed Hierarchical Structures and EM
  Algorithm for Natural Language Processing","  How to obtain hierarchical representations with an increasing level of
abstraction becomes one of the key issues of learning with deep neural
networks. A variety of RNN models have recently been proposed to incorporate
both explicit and implicit hierarchical information in modeling languages in
the literature. In this paper, we propose a novel approach called the latent
indicator layer to identify and learn implicit hierarchical information (e.g.,
phrases), and further develop an EM algorithm to handle the latent indicator
layer in training. The latent indicator layer further simplifies a text's
hierarchical structure, which allows us to seamlessly integrate different
levels of attention mechanisms into the structure. We called the resulting
architecture as the EM-HRNN model. Furthermore, we develop two bootstrap
strategies to effectively and efficiently train the EM-HRNN model on long text
documents. Simulation studies and real data applications demonstrate that the
EM-HRNN model with bootstrap training outperforms other RNN-based models in
document classification tasks. The performance of the EM-HRNN model is
comparable to a Transformer-based method called Bert-base, though the former is
much smaller model and does not require pre-training.
",2022-01-21T23:08:33Z,http://arxiv.org/abs/2201.08919v1,"Zhaoxin Luo, Michael Zhu"
"Deep Neural Networks based Modrec: Some Results with Inter-Symbol
  Interference and Adversarial Examples","  Recent successes and advances in Deep Neural Networks (DNN) in machine vision
and Natural Language Processing (NLP) have motivated their use in traditional
signal processing and communications systems. In this paper, we present results
of such applications to the problem of automatic modulation recognition.
Variations in wireless communication channels are represented by statistical
channel models and their parameterization will increase with the advent of 5G.
In this paper, we report effect of simple two path channel model on our naive
deep neural network based implementation. We also report impact of adversarial
perturbation to the input signal.
",2018-11-14T22:36:47Z,http://arxiv.org/abs/1811.06103v1,"S. Asim Ahmed, Subhashish Chakravarty, Michael Newhouse"
An Overview of Neural Network Compression,"  Overparameterized networks trained to convergence have shown impressive
performance in domains such as computer vision and natural language processing.
Pushing state of the art on salient tasks within these domains corresponds to
these models becoming larger and more difficult for machine learning
practitioners to use given the increasing memory and storage requirements, not
to mention the larger carbon footprint. Thus, in recent years there has been a
resurgence in model compression techniques, particularly for deep convolutional
neural networks and self-attention based networks such as the Transformer.
  Hence, this paper provides a timely overview of both old and current
compression techniques for deep neural networks, including pruning,
quantization, tensor decomposition, knowledge distillation and combinations
thereof.
  We assume a basic familiarity with deep learning architectures\footnote{For
an introduction to deep learning, see ~\citet{goodfellow2016deep}}, namely,
Recurrent Neural
Networks~\citep[(RNNs)][]{rumelhart1985learning,hochreiter1997long},
Convolutional Neural Networks~\citep{fukushima1980neocognitron}~\footnote{For
an up to date overview see~\citet{khan2019survey}} and Self-Attention based
networks~\citep{vaswani2017attention}\footnote{For a general overview of
self-attention networks, see ~\citet{chaudhari2019attentive}.},\footnote{For
more detail and their use in natural language processing,
see~\citet{hu2019introductory}}. Most of the papers discussed are proposed in
the context of at least one of these DNN architectures.
",2020-06-05T20:28:56Z,http://arxiv.org/abs/2006.03669v2,James O' Neill
Lambek pregroups are Frobenius spiders in preorders,"  ""Spider"" is a nickname of special Frobenius algebras, a fundamental structure
from mathematics, physics, and computer science. Pregroups are a fundamental
structure from linguistics. Pregroups and spiders have been used together in
natural language processing: one for syntax, the other for semantics. It turns
out that pregroups themselves can be characterized as pointed spiders in the
category of preordered relations, where they naturally arise from grammars. The
other way around, preordered spider algebras in general can be characterized as
unions of pregroups. This extends the characterization of relational spider
algebras as disjoint unions of groups. The compositional framework that emerged
with the results suggests new ways to understand and apply the basis structures
in machine learning and data analysis.
",2021-05-07T02:42:03Z,http://arxiv.org/abs/2105.03038v4,Dusko Pavlovic
Costs to Consider in Adopting NLP for Your Business,"  Recent advances in Natural Language Processing (NLP) have largely pushed deep
transformer-based models as the go-to state-of-the-art technique without much
regard to the production and utilization cost. Companies planning to adopt
these methods into their business face difficulties because of the lack of
machine, data, and human resources to build them. We compare both the
performance and the cost of classical learning algorithms to the latest ones in
common sequence and text labeling tasks. In our industrial datasets, we find
that classical models often perform on par with deep neural ones despite the
lower cost. We show the trade-off between performance gain and the cost across
the models to give more insights for AI-pivoting business. Further, we call for
more research into low-cost models, especially for under-resourced languages.
",2020-12-16T13:57:31Z,http://arxiv.org/abs/2012.08958v2,"Made Nindyatama Nityasya, Haryo Akbarianto Wibowo, Radityo Eko Prasojo, Alham Fikri Aji"
"A Deep Learning Pipeline for Patient Diagnosis Prediction Using
  Electronic Health Records","  Augmentation of disease diagnosis and decision-making in healthcare with
machine learning algorithms is gaining much impetus in recent years. In
particular, in the current epidemiological situation caused by COVID-19
pandemic, swift and accurate prediction of disease diagnosis with machine
learning algorithms could facilitate identification and care of vulnerable
clusters of population, such as those having multi-morbidity conditions. In
order to build a useful disease diagnosis prediction system, advancement in
both data representation and development of machine learning architectures are
imperative. First, with respect to data collection and representation, we face
severe problems due to multitude of formats and lack of coherency prevalent in
Electronic Health Records (EHRs). This causes hindrance in extraction of
valuable information contained in EHRs. Currently, no universal global data
standard has been established. As a useful solution, we develop and publish a
Python package to transform public health dataset into an easy to access
universal format. This data transformation to an international health data
format facilitates researchers to easily combine EHR datasets with clinical
datasets of diverse formats. Second, machine learning algorithms that predict
multiple disease diagnosis categories simultaneously remain underdeveloped. We
propose two novel model architectures in this regard. First, DeepObserver,
which uses structured numerical data to predict the diagnosis categories and
second, ClinicalBERT_Multi, that incorporates rich information available in
clinical notes via natural language processing methods and also provides
interpretable visualizations to medical practitioners. We show that both models
can predict multiple diagnoses simultaneously with high accuracy.
",2020-06-23T14:58:58Z,http://arxiv.org/abs/2006.16926v1,"Leopold Franz, Yash Raj Shrestha, Bibek Paudel"
"Enhancing Source Code Representations for Deep Learning with Static
  Analysis","  Deep learning techniques applied to program analysis tasks such as code
classification, summarization, and bug detection have seen widespread interest.
Traditional approaches, however, treat programming source code as natural
language text, which may neglect significant structural or semantic details.
Additionally, most current methods of representing source code focus solely on
the code, without considering beneficial additional context. This paper
explores the integration of static analysis and additional context such as bug
reports and design patterns into source code representations for deep learning
models. We use the Abstract Syntax Tree-based Neural Network (ASTNN) method and
augment it with additional context information obtained from bug reports and
design patterns, creating an enriched source code representation that
significantly enhances the performance of common software engineering tasks
such as code classification and code clone detection. Utilizing existing
open-source code data, our approach improves the representation and processing
of source code, thereby improving task performance.
",2024-02-14T20:17:04Z,http://arxiv.org/abs/2402.09557v1,"Xueting Guan, Christoph Treude"
"Performance Modelling of Deep Learning on Intel Many Integrated Core
  Architectures","  Many complex problems, such as natural language processing or visual object
detection, are solved using deep learning. However, efficient training of
complex deep convolutional neural networks for large data sets is
computationally demanding and requires parallel computing resources. In this
paper, we present two parameterized performance models for estimation of
execution time of training convolutional neural networks on the Intel many
integrated core architecture. While for the first performance model we
minimally use measurement techniques for parameter value estimation, in the
second model we estimate more parameters based on measurements. We evaluate the
prediction accuracy of performance models in the context of training three
different convolutional neural network architectures on the Intel Xeon Phi. The
achieved average performance prediction accuracy is about 15% for the first
model and 11% for second model.
",2019-06-04T10:14:50Z,http://arxiv.org/abs/1906.01992v1,"Andre Viebke, Sabri Pllana, Suejb Memeti, Joanna Kolodziej"
Deep Learning,"  Deep learning (DL) is a high dimensional data reduction technique for
constructing high-dimensional predictors in input-output models. DL is a form
of machine learning that uses hierarchical layers of latent features. In this
article, we review the state-of-the-art of deep learning from a modeling and
algorithmic perspective. We provide a list of successful areas of applications
in Artificial Intelligence (AI), Image Processing, Robotics and Automation.
Deep learning is predictive in its nature rather then inferential and can be
viewed as a black-box methodology for high-dimensional function estimation.
",2018-07-20T18:20:34Z,http://arxiv.org/abs/1807.07987v2,"Nicholas G. Polson, Vadim O. Sokolov"
Automatic Question-Answering Using A Deep Similarity Neural Network,"  Automatic question-answering is a classical problem in natural language
processing, which aims at designing systems that can automatically answer a
question, in the same way as human does. In this work, we propose a deep
learning based model for automatic question-answering. First the questions and
answers are embedded using neural probabilistic modeling. Then a deep
similarity neural network is trained to find the similarity score of a pair of
answer and question. Then for each question, the best answer is found as the
one with the highest similarity score. We first train this model on a
large-scale public question-answering database, and then fine-tune it to
transfer to the customer-care chat data. We have also tested our framework on a
public question-answering database and achieved very good performance.
",2017-08-05T05:50:44Z,http://arxiv.org/abs/1708.01713v1,"Shervin Minaee, Zhu Liu"
XNLI: Evaluating Cross-lingual Sentence Representations,"  State-of-the-art natural language processing systems rely on supervision in
the form of annotated data to learn competent models. These models are
generally trained on data in a single language (usually English), and cannot be
directly used beyond that language. Since collecting data in every language is
not realistic, there has been a growing interest in cross-lingual language
understanding (XLU) and low-resource cross-language transfer. In this work, we
construct an evaluation set for XLU by extending the development and test sets
of the Multi-Genre Natural Language Inference Corpus (MultiNLI) to 15
languages, including low-resource languages such as Swahili and Urdu. We hope
that our dataset, dubbed XNLI, will catalyze research in cross-lingual sentence
understanding by providing an informative standard evaluation task. In
addition, we provide several baselines for multilingual sentence understanding,
including two based on machine translation systems, and two that use parallel
data to train aligned multilingual bag-of-words and LSTM encoders. We find that
XNLI represents a practical and challenging evaluation suite, and that directly
translating the test data yields the best performance among available
baselines.
",2018-09-13T16:39:53Z,http://arxiv.org/abs/1809.05053v1,"Alexis Conneau, Guillaume Lample, Ruty Rinott, Adina Williams, Samuel R. Bowman, Holger Schwenk, Veselin Stoyanov"
Using Domain Knowledge for Low Resource Named Entity Recognition,"  In recent years, named entity recognition has always been a popular research
in the field of natural language processing, while traditional deep learning
methods require a large amount of labeled data for model training, which makes
them not suitable for areas where labeling resources are scarce. In addition,
the existing cross-domain knowledge transfer methods need to adjust the entity
labels for different fields, so as to increase the training cost. To solve
these problems, enlightened by a processing method of Chinese named entity
recognition, we propose to use domain knowledge to improve the performance of
named entity recognition in areas with low resources. The domain knowledge
mainly applied by us is domain dictionary and domain labeled data. We use
dictionary information for each word to strengthen its word embedding and
domain labeled data to reinforce the recognition effect. The proposed model
avoids large-scale data adjustments in different domains while handling named
entities recognition with low resources. Experiments demonstrate the
effectiveness of our method, which has achieved impressive results on the data
set in the field of scientific and technological equipment, and the F1 score
has been significantly improved compared with many other baseline methods.
",2022-03-28T13:26:47Z,http://arxiv.org/abs/2203.14738v1,Yuan Shi
Sparsity-based Defense against Adversarial Attacks on Linear Classifiers,"  Deep neural networks represent the state of the art in machine learning in a
growing number of fields, including vision, speech and natural language
processing. However, recent work raises important questions about the
robustness of such architectures, by showing that it is possible to induce
classification errors through tiny, almost imperceptible, perturbations.
Vulnerability to such ""adversarial attacks"", or ""adversarial examples"", has
been conjectured to be due to the excessive linearity of deep networks. In this
paper, we study this phenomenon in the setting of a linear classifier, and show
that it is possible to exploit sparsity in natural data to combat
$\ell_{\infty}$-bounded adversarial perturbations. Specifically, we demonstrate
the efficacy of a sparsifying front end via an ensemble averaged analysis, and
experimental results for the MNIST handwritten digit database. To the best of
our knowledge, this is the first work to show that sparsity provides a
theoretically rigorous framework for defense against adversarial attacks.
",2018-01-15T08:18:33Z,http://arxiv.org/abs/1801.04695v3,"Zhinus Marzi, Soorya Gopalakrishnan, Upamanyu Madhow, Ramtin Pedarsani"
"Machine Learning in Python: Main developments and technology trends in
  data science, machine learning, and artificial intelligence","  Smarter applications are making better use of the insights gleaned from data,
having an impact on every industry and research discipline. At the core of this
revolution lies the tools and the methods that are driving it, from processing
the massive piles of data generated each day to learning from and taking useful
action. Deep neural networks, along with advancements in classical ML and
scalable general-purpose GPU computing, have become critical components of
artificial intelligence, enabling many of these astounding breakthroughs and
lowering the barrier to adoption. Python continues to be the most preferred
language for scientific computing, data science, and machine learning, boosting
both performance and productivity by enabling the use of low-level libraries
and clean high-level APIs. This survey offers insight into the field of machine
learning with Python, taking a tour through important topics to identify some
of the core hardware and software paradigms that have enabled it. We cover
widely-used libraries and concepts, collected together for holistic comparison,
with the goal of educating the reader and driving the field of Python machine
learning forward.
",2020-02-12T05:20:59Z,http://arxiv.org/abs/2002.04803v2,"Sebastian Raschka, Joshua Patterson, Corey Nolet"
FarsTail: A Persian Natural Language Inference Dataset,"  Natural language inference (NLI) is known as one of the central tasks in
natural language processing (NLP) which encapsulates many fundamental aspects
of language understanding. With the considerable achievements of data-hungry
deep learning methods in NLP tasks, a great amount of effort has been devoted
to develop more diverse datasets for different languages. In this paper, we
present a new dataset for the NLI task in the Persian language, also known as
Farsi, which is one of the dominant languages in the Middle East. This dataset,
named FarsTail, includes 10,367 samples which are provided in both the Persian
language as well as the indexed format to be useful for non-Persian
researchers. The samples are generated from 3,539 multiple-choice questions
with the least amount of annotator interventions in a way similar to the
SciTail dataset. A carefully designed multi-step process is adopted to ensure
the quality of the dataset. We also present the results of traditional and
state-of-the-art methods on FarsTail including different embedding methods such
as word2vec, fastText, ELMo, BERT, and LASER, as well as different modeling
approaches such as DecompAtt, ESIM, HBMP, and ULMFiT to provide a solid
baseline for the future research. The best obtained test accuracy is 83.38%
which shows that there is a big room for improving the current methods to be
useful for real-world NLP applications in different languages. We also
investigate the extent to which the models exploit superficial clues, also
known as dataset biases, in FarsTail, and partition the test set into easy and
hard subsets according to the success of biased models. The dataset is
available at https://github.com/dml-qom/FarsTail
",2020-09-18T13:04:04Z,http://arxiv.org/abs/2009.08820v2,"Hossein Amirkhani, Mohammad AzariJafari, Zohreh Pourjafari, Soroush Faridan-Jahromi, Zeinab Kouhkan, Azadeh Amirak"
"Transparent but Powerful: Explainability, Accuracy, and Generalizability
  in ADHD Detection from Social Media Data","  Attention-deficit/hyperactivity disorder (ADHD) is a prevalent mental health
condition affecting both children and adults, yet it remains severely
underdiagnosed. Recent advances in artificial intelligence, particularly in
Natural Language Processing (NLP) and Machine Learning (ML), offer promising
solutions for scalable and non-invasive ADHD screening methods using social
media data. This paper presents a comprehensive study on ADHD detection,
leveraging both shallow machine learning models and deep learning approaches,
including BiLSTM and transformer-based models, to analyze linguistic patterns
in ADHD-related social media text. Our results highlight the trade-offs between
interpretability and performance across different models, with BiLSTM offering
a balance of transparency and accuracy. Additionally, we assess the
generalizability of these models using cross-platform data from Reddit and
Twitter, uncovering key linguistic features associated with ADHD that could
contribute to more effective digital screening tools.
",2024-11-23T15:26:01Z,http://arxiv.org/abs/2411.15586v1,"D. Wiechmann, E. Kempa, E. Kerz, Y. Qiao"
The Transformer Network for the Traveling Salesman Problem,"  The Traveling Salesman Problem (TSP) is the most popular and most studied
combinatorial problem, starting with von Neumann in 1951. It has driven the
discovery of several optimization techniques such as cutting planes,
branch-and-bound, local search, Lagrangian relaxation, and simulated annealing.
The last five years have seen the emergence of promising techniques where
(graph) neural networks have been capable to learn new combinatorial
algorithms. The main question is whether deep learning can learn better
heuristics from data, i.e. replacing human-engineered heuristics? This is
appealing because developing algorithms to tackle efficiently NP-hard problems
may require years of research, and many industry problems are combinatorial by
nature. In this work, we propose to adapt the recent successful Transformer
architecture originally developed for natural language processing to the
combinatorial TSP. Training is done by reinforcement learning, hence without
TSP training solutions, and decoding uses beam search. We report improved
performances over recent learned heuristics with an optimal gap of 0.004% for
TSP50 and 0.39% for TSP100.
",2021-03-04T13:20:06Z,http://arxiv.org/abs/2103.03012v1,"Xavier Bresson, Thomas Laurent"
"Watch and learn -- a generalized approach for transferrable learning in
  deep neural networks via physical principles","  Transfer learning refers to the use of knowledge gained while solving a
machine learning task and applying it to the solution of a closely related
problem. Such an approach has enabled scientific breakthroughs in computer
vision and natural language processing where the weights learned in
state-of-the-art models can be used to initialize models for other tasks which
dramatically improve their performance and save computational time. Here we
demonstrate an unsupervised learning approach augmented with basic physical
principles that achieves fully transferrable learning for problems in
statistical physics across different physical regimes. By coupling a sequence
model based on a recurrent neural network to an extensive deep neural network,
we are able to learn the equilibrium probability distributions and
inter-particle interaction models of classical statistical mechanical systems.
Our approach, distribution-consistent learning, DCL, is a general strategy that
works for a variety of canonical statistical mechanical models (Ising and
Potts) as well as disordered (spin-glass) interaction potentials. Using data
collected from a single set of observation conditions, DCL successfully
extrapolates across all temperatures, thermodynamic phases, and can be applied
to different length-scales. This constitutes a fully transferrable
physics-based learning in a generalizable approach.
",2020-03-03T18:37:23Z,http://arxiv.org/abs/2003.02647v1,"Kyle Sprague, Juan Carrasquilla, Steve Whitelam, Isaac Tamblyn"
