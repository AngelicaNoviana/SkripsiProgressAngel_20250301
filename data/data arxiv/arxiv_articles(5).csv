Title,Summary,Published,Link,Authors
LASER: A new method for locally adaptive nonparametric regression,"In this article, we introduce \textsf{LASER} (Locally Adaptive Smoothing
Estimator for Regression), a computationally efficient locally adaptive
nonparametric regression method that performs variable bandwidth local
polynomial regression. We prove that it adapts (near-)optimally to the local
H\""{o}lder exponent of the underlying regression function
\texttt{simultaneously} at all points in its domain. Furthermore, we show that
there is a single ideal choice of a global tuning parameter under which the
above mentioned local adaptivity holds. Despite the vast literature on
nonparametric regression, instances of practicable methods with provable
guarantees of such a strong notion of local adaptivity are rare. The proposed
method achieves excellent performance across a broad range of numerical
experiments in comparison to popular alternative locally adaptive methods.",2024-12-27T18:59:03Z,http://arxiv.org/abs/2412.19802v1,"Sabyasachi Chatterjee, Subhajit Goswami, Soumendu Sundar Mukherjee"
"Streamlined Krylov construction and classification of ergodic Floquet
  systems","We generalize Krylov construction to periodically driven (Floquet) quantum
systems using the theory of orthogonal polynomials on the unit circle. Compared
to other approaches, our method works faster and maps any quantum dynamics to a
one-dimensional tight-binding Krylov chain. We also suggest a classification of
chaotic and integrable Floquet systems based on the asymptotic behavior of
Krylov chain hopping parameters (Verblunsky coefficients). We illustrate this
classification with random matrix ensembles, kicked top, and kicked Ising
chain.",2024-12-27T18:56:27Z,http://arxiv.org/abs/2412.19797v1,"Nikita Kolganov, Dmitrii A. Trunin"
"Data-driven analysis of anomalous transport and three-wave-coupling
  effects in E x B plasma discharges","Collisionless cross-field electron transport in an E x B configuration
relevant for electric propulsion is studied using data from a (z, {\theta})
full-PIC simulation. Higher-order spectral analysis shows that transport is
dominated by the in-phase interaction of the oscillations of the azimuthal
electric field and the electron density associated to the first electron
cyclotron drift instability (ECDI) mode. A secondary contribution emanates from
a lower-frequency mode, not predicted by linear ECDI theory, while higher modes
have a minor direct impact on transport. However, a bicoherence analysis
reveals that strong phase couplings exist among the ECDI modes, and a sparse
symbolic regression spectral model, based on the three-wave coupling equations,
suggests an inverse energy cascade as the most likely explanation, thus
suggesting that higher modes contribute indirectly to transport by quadratic
power transfer to the first mode. This work provides new insights into the
dynamics of anomalous plasma transport in E x B sources and the underlying
processes governing energy distribution across different scales, and supports
the validity of weak turbulence theory to examine their behavior.",2024-12-27T18:43:24Z,http://arxiv.org/abs/2412.19789v1,"Borja Bayón-Buján, Enrique Bello-Benítez, Jiewei Zhou, Mario Merino"
"Machine Learning for Sentiment Analysis of Imported Food in Trinidad and
  Tobago","This research investigates the performance of various machine learning
algorithms (CNN, LSTM, VADER, and RoBERTa) for sentiment analysis of Twitter
data related to imported food items in Trinidad and Tobago. The study addresses
three primary research questions: the comparative accuracy and efficiency of
the algorithms, the optimal configurations for each model, and the potential
applications of the optimized models in a live system for monitoring public
sentiment and its impact on the import bill. The dataset comprises tweets from
2018 to 2024, divided into imbalanced, balanced, and temporal subsets to assess
the impact of data balancing and the COVID-19 pandemic on sentiment trends. Ten
experiments were conducted to evaluate the models under various configurations.
Results indicated that VADER outperformed the other models in both multi-class
and binary sentiment classifications. The study highlights significant changes
in sentiment trends pre- and post-COVID-19, with implications for import
policies.",2024-12-27T18:25:08Z,http://arxiv.org/abs/2412.19781v1,"Cassandra Daniels, Koffka Khan"
Functionality of Random Graphs,"The functionality of a graph $G$ is the minimum number $k$ such that in every
induced subgraph of $G$ there exists a vertex whose neighbourhood is uniquely
determined by the neighborhoods of at most $k$ other vertices in the subgraph.
The functionality parameter was introduced in the context of adjacency labeling
schemes, and it generalises a number of classical and recent graph parameters
including degeneracy, twin-width, and symmetric difference. We establish the
functionality of a random graph $G(n,p)$ up to a constant factor for every
value of $p$.",2024-12-27T18:09:29Z,http://arxiv.org/abs/2412.19771v1,"John Sylvester, Viktor Zamaraev, Maksim Zhukovskii"
Classification of Minimal Abelian Coulomb Branches,"Obtaining the classification of 3d $\mathcal{N}=4$ quivers whose Coulomb
branches have an isolated singularity is an essential step in understanding
moduli spaces of vacua of supersymmetric field theories with 8 supercharges in
any dimension. In this work, we derive a full classification for such Abelian
quivers with arbitrary charges, and identify all possible Coulomb branch
geometries as quotients of $\mathbb{H}^n$ by $\mathrm{U}(1)$ or a finite cyclic
group. We give two proofs, one which uses the decay and fission algorithm, and
another one relying only on explicit computations involving 3d mirror symmetry.
In the process, we put forward a method for computing the 3d mirror of any
$\mathrm{U}(1)^r$ gauge theory, which is sensitive to discrete gauge factors in
the mirror theory. This constitutes a confirmation for the decay and fission
algorithm.",2024-12-27T17:54:59Z,http://arxiv.org/abs/2412.19766v1,"Antoine Bourget, Quentin Lamouret, Sinan Moura Soysüren, Marcus Sperling"
Can one hear the shape of a random walk?,"To what extent is the underlying distribution of a finitely supported
unbiased random walk on $\mathbb{Z}$ determined by the sequence of times at
which the walk returns to the origin? The main result of this paper is that, in
various senses, most unbiased random walks on $\mathbb{Z}$ are determined up to
equivalence by the sequence $I_1,I_2,I_3,\ldots$, where $I_n$ denotes the
probability of being at the origin after $n$ steps. The proof depends on the
classification of finite simple groups.",2024-12-27T17:42:34Z,http://arxiv.org/abs/2412.19762v1,Michael J. Larsen
Tree tilings in random regular graphs,"We show that for every $\epsilon&gt;0$ there exists a sufficiently large $d_0\in
\mathbb{N}$ such that for every $d\ge d_0$, \textbf{whp} the random $d$-regular
graph $G(n,d)$ contains a $T$-factor for every tree $T$ on at most
$(1-\epsilon)d/\log d$ vertices. This is best possible since, for large enough
integer $d$, \textbf{whp} $G(n,d)$ does not contain a
$\frac{(1+\epsilon)d}{\log d}$-star factor.",2024-12-27T17:35:47Z,http://arxiv.org/abs/2412.19756v1,"Sahar Diskin, Ilay Hoshen, Maksim Zhukovskii"
A random walk among random graphs,"Lecture notes of a master course given at Orsay between 2019-2024. Topics
covered include Part I: One-dimensional random walks, cycle lemma and
Bienaym\'e--Galton--Watson random trees. Part II: Erd\""os--R\'enyi random
graphs, three proofs of the emergence of the giant component. Part III: Random
recursive tree, random permutations and continuous time embedding techniques.
Intended for publication.",2024-12-27T17:21:41Z,http://arxiv.org/abs/2412.19752v1,Nicolas Curien
"Weak lumping of left-invariant random walks on left cosets of finite
  groups","Let $G$ be a finite group and let $H$ be a subgroup of $G$. The
left-invariant random walk driven by a probability measure $w$ on $G$ is the
Markov chain in which from any state $x \in G$, the probability of stepping to
$xg \in G$ is $w(g)$. The initial state is chosen randomly according to a given
distribution. The walk is said to lump weakly on left cosets if the induced
process on $G/H$ is a time-homogeneous Markov chain. We characterise all the
initial distributions and weights $w$ such that the walk is irreducible and
lumps weakly on left cosets, and determine all the possible transition matrices
of the induced Markov chain. In the case where $H$ is abelian we refine our
main results to give a necessary and sufficient condition for weak lumping by
an explicit system of linear equations on $w$, organized by the double cosets
$HxH$. As an application we consider shuffles of a deck of $n$ cards such that
repeated observations of the top card form a Markov chain. Such shuffles
include the random-to-top shuffle, and also, when the deck is started in a
uniform random order, the top-to-random shuffle. We give a further family of
examples in which our full theory of weak lumping is needed to verify that the
top card sequence is Markov.",2024-12-27T17:08:17Z,http://arxiv.org/abs/2412.19742v1,"Edward Crane, Álvaro Gutiérrez, Erin Russell, Mark Wildon"
"Periodically and aperiodically Thue-Morse driven long-range systems:
  from dynamical localization to slow dynamics","We investigate the electric-field driven power-law random banded
matrix(PLRBM) model where a variation in the power-law exponent $\alpha$ yields
a delocalization-to-localization phase transition. We examine the periodically
driven PLRBM model with the help of the Floquet operator. The level spacing
ratio and the generalized participation ratio of the Floquet Hamiltonian reveal
a drive-induced fractal phase accompanied by diffusive transport on the
delocalized side of the undriven PLRBM model. On the localized side, the
time-periodic model remains localized - the average spacing ratio corresponds
to Poisson statistics and logarithmic transport is observed in the dynamics.
Extending our analysis to the aperiodic Thue-Morse (TM) driven system, we find
that the aperiodically driven clean long-range hopping model (clean counterpart
of the PLRBM model) exhibits the phenomenon of \textit{exact dynamical
localization} (EDL) on tuning the drive-parameters at special points. The
disordered time-aperiodic system shows diffusive transport followed by
relaxation to the infinite-temperature state on the delocalized side, and a
prethermal plateau with subdiffusion on the localized side. Additionally, we
compare this with a quasi-periodically driven AAH model that also undergoes a
localization-delocalization transition. Unlike the disordered long-range model,
it features a prolonged prethermal plateau followed by subdiffusion to the
infinite temperature state, even on the delocalized side.",2024-12-27T16:55:47Z,http://arxiv.org/abs/2412.19736v1,"Vatsana Tiwari, Devendra Singh Bhakuni, Auditya Sharma"
"Generative Pretrained Embedding and Hierarchical Irregular Time Series
  Representation for Daily Living Activity Recognition","Within the evolving landscape of smart homes, the precise recognition of
daily living activities using ambient sensor data stands paramount. This paper
not only aims to bolster existing algorithms by evaluating two distinct
pretrained embeddings suited for ambient sensor activations but also introduces
a novel hierarchical architecture. We delve into an architecture anchored on
Transformer Decoder-based pre-trained embeddings, reminiscent of the GPT
design, and contrast it with the previously established state-of-the-art (SOTA)
ELMo embeddings for ambient sensors. Our proposed hierarchical structure
leverages the strengths of each pre-trained embedding, enabling the discernment
of activity dependencies and sequence order, thereby enhancing classification
precision. To further refine recognition, we incorporate into our proposed
architecture an hour-of-the-day embedding. Empirical evaluations underscore the
preeminence of the Transformer Decoder embedding in classification endeavors.
Additionally, our innovative hierarchical design significantly bolsters the
efficacy of both pre-trained embeddings, notably in capturing inter-activity
nuances. The integration of temporal aspects subtly but distinctively augments
classification, especially for time-sensitive activities. In conclusion, our
GPT-inspired hierarchical approach, infused with temporal insights, outshines
the SOTA ELMo benchmark.",2024-12-27T16:43:52Z,http://arxiv.org/abs/2412.19732v1,"Damien Bouchabou, Sao Mai Nguyen"
High-dimensional permutons: theory and applications,"Permutons, which are probability measures on the unit square $[0, 1]^2$ with
uniform marginals, are the natural scaling limits for sequences of (random)
permutations.
  We introduce a $d$-dimensional generalization of these measures for all $d
\ge 2$, which we call $d$-dimensional permutons, and extend -- from the
two-dimensional setting -- the theory to prove convergence of sequences of
(random) $d$-dimensional permutations to (random) $d$-dimensional permutons.
  Building on this new theory, we determine the random high-dimensional
permuton limits for two natural families of high-dimensional permutations.
First, we determine the $3$-dimensional permuton limit for Schnyder wood
permutations, which bijectively encode planar triangulations decorated by
triples of spanning trees known as Schnyder woods. Second, we identify the
$d$-dimensional permuton limit for $d$-separable permutations, a
pattern-avoiding class of $d$-dimensional permutations generalizing ordinary
separable permutations.
  Both high-dimensional permuton limits are random and connected to previously
studied universal 2-dimensional permutons, such as the Brownian separable
permutons and the skew Brownian permutons, and share interesting connections
with objects arising from random geometry, including the continuum random tree,
Schramm--Loewner evolutions, and Liouville quantum gravity surfaces.",2024-12-27T16:40:41Z,http://arxiv.org/abs/2412.19730v1,"Jacopo Borga, Andrew Lin"
"Learning to Forget: Bayesian Time Series Forecasting using Recurrent
  Sparse Spectrum Signature Gaussian Processes","The signature kernel is a kernel between time series of arbitrary length and
comes with strong theoretical guarantees from stochastic analysis. It has found
applications in machine learning such as covariance functions for Gaussian
processes. A strength of the underlying signature features is that they provide
a structured global description of a time series. However, this property can
quickly become a curse when local information is essential and forgetting is
required; so far this has only been addressed with ad-hoc methods such as
slicing the time series into subsegments. To overcome this, we propose a
principled, data-driven approach by introducing a novel forgetting mechanism
for signatures. This allows the model to dynamically adapt its context length
to focus on more recent information. To achieve this, we revisit the recently
introduced Random Fourier Signature Features, and develop Random Fourier
Decayed Signature Features (RFDSF) with Gaussian processes (GPs). This results
in a Bayesian time series forecasting algorithm with variational inference,
that offers a scalable probabilistic algorithm that processes and transforms a
time series into a joint predictive distribution over time steps in one pass
using recurrence. For example, processing a sequence of length $10^4$ steps in
$\approx 10^{-2}$ seconds and in $&lt; 1\text{GB}$ of GPU memory. We demonstrate
that it outperforms other GP-based alternatives and competes with
state-of-the-art probabilistic time series forecasting algorithms.",2024-12-27T16:31:09Z,http://arxiv.org/abs/2412.19727v1,"Csaba Tóth, Masaki Adachi, Michael A. Osborne, Harald Oberhauser"
EEG-Reptile: An Automatized Reptile-Based Meta-Learning Library for BCIs,"Meta-learning, i.e., ""learning to learn"", is a promising approach to enable
efficient BCI classifier training with limited amounts of data. It can
effectively use collections of in some way similar classification tasks, with
rapid adaptation to new tasks where only minimal data are available. However,
applying meta-learning to existing classifiers and BCI tasks requires
significant effort. To address this issue, we propose EEG-Reptile, an automated
library that leverages meta-learning to improve classification accuracy of
neural networks in BCIs and other EEG-based applications. It utilizes the
Reptile meta-learning algorithm to adapt neural network classifiers of EEG data
to the inter-subject domain, allowing for more efficient fine-tuning for a new
subject on a small amount of data. The proposed library incorporates an
automated hyperparameter tuning module, a data management pipeline, and an
implementation of the Reptile meta-learning algorithm. EEG-Reptile automation
level allows using it without deep understanding of meta-learning. We
demonstrate the effectiveness of EEG-Reptile on two benchmark datasets (BCI IV
2a, Lee2019 MI) and three neural network architectures (EEGNet, FBCNet,
EEG-Inception). Our library achieved improvement in both zero-shot and few-shot
learning scenarios compared to traditional transfer learning approaches.",2024-12-27T16:24:31Z,http://arxiv.org/abs/2412.19725v1,"Daniil A. Berdyshev, Artem M. Grachev, Sergei L. Shishkin, Bogdan L. Kozyrskiy"
"Trading Off Energy Storage and Payload -- An Analytical Model for
  Freight Train Configuration","To support planning of alternative fuel technology (e.g., battery-electric
locomotives) deployment for decarbonizing non-electrified freight rail, we
develop a convex optimization formulation with a closed-form solution to
determine the optimal number of energy storage tender cars in a train. The
formulation shares a similar structure to an Economic Order Quantity (EOQ)
model. For given market characteristics, cost forecasts, and technology
parameters, our model captures the trade-offs between inventory carrying costs
associated with trip times (including delays due to charging/refueling) and
ordering costs associated with train dispatch and operation (energy, amortized
equipment, and labor costs). To illustrate the framework, we find the optimal
number of battery-electric energy tender cars in 22,501 freight markets
(origin-destination pairs and commodities) for U.S. Class I railroads. The
results display heterogeneity in optimal configurations with lighter, yet more
time-sensitive shipments (e.g., intermodal) utilizing more battery tender cars.
For heavier commodities (e.g., coal) with lower holding costs, single battery
tender car configurations are generally optimal. The results also show that the
optimal train configurations are sensitive to delays associated with recharging
or swapping tender cars.",2024-12-27T16:18:35Z,http://arxiv.org/abs/2412.19719v1,"Max T. M. Ng, Adrian Hernandez, Pablo L. Durango-Cohen, Hani S. Mahmassani"
"Causal machine learning for heterogeneous treatment effects in the
  presence of missing outcome data","When estimating heterogeneous treatment effects, missing outcome data can
complicate treatment effect estimation, causing certain subgroups of the
population to be poorly represented. In this work, we discuss this commonly
overlooked problem and consider the impact that missing at random (MAR) outcome
data has on causal machine learning estimators for the conditional average
treatment effect (CATE). We then propose two de-biased machine learning
estimators for the CATE, the mDR-learner and mEP-learner, which address the
issue of under-representation by integrating inverse probability of censoring
weights into the DR-learner and EP-learner respectively. We show that under
reasonable conditions, these estimators are oracle efficient, and illustrate
their favorable performance through simulated data settings, comparing them to
existing CATE estimators, including comparison to estimators which use common
missing data techniques. Guidance on the implementation of these estimators is
provided and we present an example of their application using the ACTG175
trial, exploring treatment effect heterogeneity when comparing Zidovudine
mono-therapy against alternative antiretroviral therapies among HIV-1-infected
individuals.",2024-12-27T16:10:03Z,http://arxiv.org/abs/2412.19711v1,"Matthew Pryce, Karla Diaz-Ordaz, Ruth H. Keogh, Stijn Vansteelandt"
"All Finite (Anti)Hermitian Irreducible Representations of the de Sitter
  and Anti-de Sitter Lie Algebras and Their Lorentz Structure","Because of the importance of unitarity in quantum physics, work on the
representations of the de Sitter group has focussed on the unitary case, which
necessarily means infinite dimensional matrices for this non-compact group.
Here we address the finite dimensional representations resulting from the
requirement that the Lie algebra generators are either Hermitian or
anti-Hermitian. The complete classification of all such irreducible
representations is found and their matrix elements specified. These irreducible
representations (irreps) are based on backbones defined as the homogeneous
Lorentz sub-algebra and consisting of direct sums of the finite irreps of the
homogeneous Lorentz algebra (HLA). Only two types of such backbones arise (see
5.1a,b herein). Consequently, only certain dimensions of representation are
possible, namely 4, 5, 10, 14, 20, 30, 35, 55, 56, 91, etc or generally either
1/6 N(N+1)(N+2) or 1/6 N(N+1)(2N+1) where N=2,3,4,etc is the number of HLA
irreps in the backbone (minimum 2). The two Casimir invariants can be specified
in terms of a single integral or half-integral parameter, p. For irreps based
on (5.1a), -C1=p(p+1)-2 and C2=0 with p taking values 2,3,4,etc. For irreps
based on (5.1b), -C1=2(p^2-1) and -C2= p^2 (p^2-1) with p taking values
3/2,2,5/2,3,etc. These correspond to the same expressions found for the unitary
representations, -C1=p(p+1)+(q+1)(q-2) and -C2=p(p+1)q(q-1) with q=0 and q=p
respectively for the two types of irrep. There is thus a far more restricted
set of finite irreps with Hermitian or anti-Hermitian generators than for the
discrete infinite dimensional unitary irreps. The corresponding irreps of the
anti-de Sitter group follow immediately from the replacement of the 4-momentum
operators from V to iV.",2024-12-27T16:02:41Z,http://arxiv.org/abs/2412.19708v1,Richard A. W. Bradford
"An Integrated Optimization and Deep Learning Pipeline for Predicting
  Live Birth Success in IVF Using Feature Optimization and Transformer-Based
  Models","In vitro fertilization (IVF) is a widely utilized assisted reproductive
technology, yet predicting its success remains challenging due to the
multifaceted interplay of clinical, demographic, and procedural factors. This
study develops a robust artificial intelligence (AI) pipeline aimed at
predicting live birth outcomes in IVF treatments. The pipeline uses anonymized
data from 2010 to 2018, obtained from the Human Fertilization and Embryology
Authority (HFEA). We evaluated the prediction performance of live birth success
as a binary outcome (success/failure) by integrating different feature
selection methods, such as principal component analysis (PCA) and particle
swarm optimization (PSO), with different traditional machine learning-based
classifiers including random forest (RF) and decision tree, as well as deep
learning-based classifiers including custom transformer-based model and a tab
transformer model with an attention mechanism. Our research demonstrated that
the best performance was achieved by combining PSO for feature selection with
the TabTransformer-based deep learning model, yielding an accuracy of 99.50%
and an AUC of 99.96%, highlighting its significant performance to predict live
births. This study establishes a highly accurate AI pipeline for predicting
live birth outcomes in IVF, demonstrating its potential to enhance personalized
fertility treatments.",2024-12-27T15:46:59Z,http://arxiv.org/abs/2412.19696v1,"Arezoo Borji, Hossam Haick, Birgit Pohn, Antonia Graf, Jana Zakall, S M Ragib Shahriar Islam, Gernot Kronreif, Daniel Kovatchki, Heinz Strohmer, Sepideh Hatamikia"
"Quantum Many-Body Lattice C-R-T Symmetry: Fractionalization, Anomaly,
  and Symmetric Mass Generation","Charge conjugation (C), mirror reflection (R), and time reversal (T)
symmetries, along with internal symmetries, are essential for massless Majorana
and Dirac fermions. These symmetries are sufficient to rule out potential
fermion bilinear mass terms, thereby establishing a gapless free fermion fixed
point phase, pivotal for symmetric mass generation (SMG) transition. In this
work, we systematically study the anomaly of C-R-T-internal symmetry in all
spacetime dimensions by analyzing the projective representation (i.e. the
fractionalization) of the C-R-T-internal symmetry group in the quantum
many-body Hilbert space on the lattice. By discovering the
fermion-flavor-number-dependent C-R-T-internal symmetry's anomaly structure, we
demonstrate an alternative way to derive the minimal flavor number for SMG,
which shows consistency with known results from K\""ahler-Dirac fermion or
cobordism classification. Our findings reveal that, in general spatial
dimensions, either 8 copies of staggered Majorana fermions or 4 copies of
staggered Dirac fermions admit SMG. By directly searching for 4-fermion
interactions that form commuting stabilizers respecting all symmetry
constraints, we can prove the explicit SMG gapping retained a unique ground
state in the codespace. Furthermore, we establish the correspondence between
the symmetry operators of staggered fermions and free fermions, which is
instrumental in facilitating the analysis of symmetry fractionalization at the
field theory level.",2024-12-27T15:36:31Z,http://arxiv.org/abs/2412.19691v1,"Yang-Yang Li, Juven Wang, Yi-Zhuang You"
Emergent cell migration from cell shape deformations and T1 transitions,"T1 transitions, which are localised cell rearrangements, play an important
role in the fluidization of epithelial monolayers. Using a multi-phase field
model and an active elastic solid model, we show that although each cell
undergoes T1 transitions in time as uncorrelated, random events, the spatial
distribution of these events is highly correlated and is dependent on cell
shape. T1 transitions have a dual effect: cells losing neighbours tend to relax
their shape, while those gaining neighbours tend to elongate. By analysing the
statistics of successive T1 transitions undergone by a deformable cell, we find
asymmetric spatial distributions related to how cells lose or gain neighbours.
These asymmetric spatial patterns of T1 transitions promote directed cell
migration, and form the backbone for coherent flow patterns at tissue scales.",2024-12-27T15:26:35Z,http://arxiv.org/abs/2412.19686v1,"Harish P. Jain, Richard D. J. G. Ho, Luiza Angheluta"
"DLScanner: A parameter space scanner package assisted by deep learning
  methods","In this paper, we introduce a scanner package enhanced by deep learning (DL)
techniques. The proposed package addresses two significant challenges
associated with previously developed DL-based methods: slow convergence in
high-dimensional scans and the limited generalization of the DL network when
mapping random points to the target space. To tackle the first issue, we
utilize a similarity learning network that maps sampled points into a
representation space. In this space, in-target points are grouped together
while out-target points are effectively pushed apart. This approach enhances
the scan convergence by refining the representation of sampled points. The
second challenge is mitigated by integrating a dynamic sampling strategy.
Specifically, we employ a VEGAS mapping to adaptively suggest new points for
the DL network while also improving the mapping when more points are collected.
Our proposed framework demonstrates substantial gains in both performance and
efficiency compared to other scanning methods.",2024-12-27T14:52:42Z,http://arxiv.org/abs/2412.19675v1,"A. Hammad, Raymundo Ramos"
Spectral form factors for curved spacetimes with horizon,"The spectral form factor is believed to provide a special type of behavior
called ""dip-ramp-plateau"" in chaotic quantum systems which originates from the
random matrix theory. A similar behavior could be observed for deterministic
systems, ranging from the Riemann zeta function to the scattering amplitudes of
different types. It has been shown recently, the same behavior is observed for
the spectral form factor when the normal modes of a scalar massless field
theory in the brickwall model of the BTZ black hole are substituted as
eigenvalues of some quantum Hamiltonian. At the same time, the level spacing
distribution of these eigenvalues differs from that associated with the random
matrix theory ensembles. In this paper, we generalize these results considering
the recently proposed generalized spectral form factor for the de Sitter and
BTZ spacetimes. We study the details of this complex-valued form factor for
integrable quantum systems and for backgrounds with a horizon comparing it with
the random matrix theory behavior. As a result, we confirm that the scalar
field normal modes once again exhibit features of chaos.",2024-12-27T14:43:35Z,http://arxiv.org/abs/2412.19672v1,"Dmitry S. Ageev, Vasilii V. Pushkarev, Anastasia N. Zueva"
"Asymmetrical Reciprocity-based Federated Learning for Resolving
  Disparities in Medical Diagnosis","Geographic health disparities pose a pressing global challenge, particularly
in underserved regions of low- and middle-income nations. Addressing this issue
requires a collaborative approach to enhance healthcare quality, leveraging
support from medically more developed areas. Federated learning emerges as a
promising tool for this purpose. However, the scarcity of medical data and
limited computation resources in underserved regions make collaborative
training of powerful machine learning models challenging. Furthermore, there
exists an asymmetrical reciprocity between underserved and developed regions.
To overcome these challenges, we propose a novel cross-silo federated learning
framework, named FedHelp, aimed at alleviating geographic health disparities
and fortifying the diagnostic capabilities of underserved regions.
Specifically, FedHelp leverages foundational model knowledge via one-time API
access to guide the learning process of underserved small clients, addressing
the challenge of insufficient data. Additionally, we introduce a novel
asymmetric dual knowledge distillation module to manage the issue of asymmetric
reciprocity, facilitating the exchange of necessary knowledge between developed
large clients and underserved small clients. We validate the effectiveness and
utility of FedHelp through extensive experiments on both medical image
classification and segmentation tasks. The experimental results demonstrate
significant performance improvement compared to state-of-the-art baselines,
particularly benefiting clients in underserved regions.",2024-12-27T13:59:58Z,http://arxiv.org/abs/2412.19654v1,"Jiaqi Wang, Ziyi Yin, Quanzeng You, Lingjuan Lyu, Fenglong Ma"
"FreStega: A Plug-and-Play Method for Boosting Imperceptibility and
  Capacity in Generative Linguistic Steganography for Real-World Scenarios","Linguistic steganography embeds secret information in seemingly innocent
texts, safeguarding privacy in surveillance environments. Generative linguistic
steganography leverages the probability distribution of language models (LMs)
and applies steganographic algorithms to generate stego tokens, gaining
attention with recent Large Language Model (LLM) advancements. To enhance
security, researchers develop distribution-preserving stego algorithms to
minimize the gap between stego sampling and LM sampling. However, the reliance
on language model distributions, coupled with deviations from real-world cover
texts, results in insufficient imperceptibility when facing steganalysis
detectors in real-world scenarios. Moreover, LLM distributions tend to be more
deterministic, resulting in reduced entropy and, consequently, lower embedding
capacity. In this paper, we propose FreStega, a plug-and-play method to
reconstruct the distribution of language models used for generative linguistic
steganography. FreStega dynamically adjusts token probabilities from the
language model at each step of stegotext auto-regressive generation, leveraging
both sequential and spatial dimensions. In sequential adjustment, the
temperature is dynamically adjusted based on instantaneous entropy, enhancing
the diversity of stego texts and boosting embedding capacity. In the spatial
dimension, the distribution is aligned with guidance from the target domain
corpus, closely mimicking real cover text in the target domain. By reforming
the distribution, FreStega enhances the imperceptibility of stego text in
practical scenarios and improves steganographic capacity by 15.41\%, all
without compromising the quality of the generated text. FreStega serves as a
plug-and-play remedy to enhance the imperceptibility and embedding capacity of
existing distribution-preserving steganography methods in real-world scenarios.",2024-12-27T13:56:51Z,http://arxiv.org/abs/2412.19652v1,Kaiyi Pang
"Distributed Download from an External Data Source in Faulty Majority
  Settings","We extend the study of retrieval problems in distributed networks, focusing
on improving the efficiency and resilience of protocols in the \emph{Data
Retrieval (DR) Model}. The DR Model consists of a complete network (i.e., a
clique) with $k$ peers, up to $\beta k$ of which may be Byzantine (for $\beta
\in [0, 1)$), and a trusted \emph{External Data Source} comprising an array $X$
of $n$ bits ($n \gg k$) that the peers can query. Additionally, the peers can
also send messages to each other. In this work, we focus on the Download
problem that requires all peers to learn $X$. Our primary goal is to minimize
the maximum number of queries made by any honest peer and additionally optimize
time.
  We begin with a randomized algorithm for the Download problem that achieves
optimal query complexity up to a logarithmic factor. For the stronger dynamic
adversary that can change the set of Byzantine peers from one round to the
next, we achieve the optimal time complexity in peer-to-peer communication but
with larger messages. In broadcast communication where all peers (including
Byzantine peers) are required to send the same message to all peers, with
larger messages, we achieve almost optimal time and query complexities for a
dynamic adversary. Finally, in a more relaxed crash fault model, where peers
stop responding after crashing, we address the Download problem in both
synchronous and asynchronous settings. Using a deterministic protocol, we
obtain nearly optimal results for both query complexity and message sizes in
these scenarios.",2024-12-27T13:55:00Z,http://arxiv.org/abs/2412.19649v1,"John Augustine, Soumyottam Chatterjee, Valerie King, Manish Kumar, Shachar Meir, David Peleg"
Photonic classification on a single diffractive layer,"Photonic computation started to shape the future of fast, efficient and
accessible computation. The advantages brought by light based Diffractive Deep
Neural Networks (D2NN), are shown to be overwhelmingly advantageous especially
in targeting classification problems. However, cost and complexity of
multi-layer systems are the main challenges that reduce the deployment of this
technology. In this study, we develop a simple yet extremely efficient way to
achieve optical classification using a single diffractive optical layer. A
spatial light modulator is used not only to emulate the classifying system but
also the input medium for the objects to be classified by the system. Using our
approach, we classify road traffic signs which has a direct application on
daily life and safety. We perform classification of road signs under the effect
of noise and show that we can successfully classify road signs with more than
75% accuracy under 20% noise/imperfection.",2024-12-27T12:09:28Z,http://arxiv.org/abs/2412.19607v1,"Anil J. Pekgöz, Emre Yüce"
"Enhancing Fine-grained Image Classification through Attentive Batch
  Training","Fine-grained image classification, which is a challenging task in computer
vision, requires precise differentiation among visually similar object
categories. In this paper, we propose 1) a novel module called Residual
Relationship Attention (RRA) that leverages the relationships between images
within each training batch to effectively integrate visual feature vectors of
batch images and 2) a novel technique called Relationship Position Encoding
(RPE), which encodes the positions of relationships between original images in
a batch and effectively preserves the relationship information between images
within the batch. Additionally, we design a novel framework, namely
Relationship Batch Integration (RBI), which utilizes RRA in conjunction with
RPE, allowing the discernment of vital visual features that may remain elusive
when examining a singular image representative of a particular class. Through
extensive experiments, our proposed method demonstrates significant
improvements in the accuracy of different fine-grained classifiers, with an
average increase of $(+2.78\%)$ and $(+3.83\%)$ on the CUB200-2011 and Stanford
Dog datasets, respectively, while achieving a state-of-the-art results
$(95.79\%)$ on the Stanford Dog dataset. Despite not achieving the same level
of improvement as in fine-grained image classification, our method still
demonstrates its prowess in leveraging general image classification by
attaining a state-of-the-art result of $(93.71\%)$ on the Tiny-Imagenet
dataset. Furthermore, our method serves as a plug-in refinement module and can
be easily integrated into different networks.",2024-12-27T12:07:58Z,http://arxiv.org/abs/2412.19606v1,"Duy M. Le, Bao Q. Bui, Anh Tran, Cong Tran, Cuong Pham"
Multiple objective linear programming over the probability simplex,"This paper considers the problem of maximizing multiple linear functions over
the probability simplex. A classification of feasible points is indicated. A
necessary and sufficient condition for a member of each class to be an
efficient solution is stated. This characterization yields a computational
procedure for ascertaining whether a feasible point is efficient. The procedure
does not require that candidates for efficiency be extreme points. An
illustration of the procedure is offered.",2024-12-27T11:44:49Z,http://arxiv.org/abs/2412.19598v1,Anas Mifrani
"Ultralight Signal Classification Model for Automatic Modulation
  Recognition","The growing complexity of radar signals demands responsive and accurate
detection systems that can operate efficiently on resource-constrained edge
devices. Existing models, while effective, often rely on substantial
computational resources and large datasets, making them impractical for edge
deployment. In this work, we propose an ultralight hybrid neural network
optimized for edge applications, delivering robust performance across
unfavorable signal-to-noise ratios (mean accuracy of 96.3% at 0 dB) using less
than 100 samples per class, and significantly reducing computational overhead.",2024-12-27T11:03:26Z,http://arxiv.org/abs/2412.19585v1,"Alessandro Daniele Genuardi Oquendo, Agustín Matías Galante Cerviño, Nilotpal Sinha, Luc Andrea, Sam Mugel, Román Orús"
"A Comparative Study of Machine Unlearning Techniques for Image and Text
  Classification Models","Machine Unlearning has emerged as a critical area in artificial intelligence,
addressing the need to selectively remove learned data from machine learning
models in response to data privacy regulations. This paper provides a
comprehensive comparative analysis of six state-of-theart unlearning techniques
applied to image and text classification tasks. We evaluate their performance,
efficiency, and compliance with regulatory requirements, highlighting their
strengths and limitations in practical scenarios. By systematically analyzing
these methods, we aim to provide insights into their applicability,
challenges,and tradeoffs, fostering advancements in the field of ethical and
adaptable machine learning.",2024-12-27T10:58:55Z,http://arxiv.org/abs/2412.19583v1,"Omar M. Safa, Mahmoud M. Abdelaziz, Mustafa Eltawy, Mohamed Mamdouh, Moamen Gharib, Salaheldin Eltenihy, Nagia M. Ghanem, Mohamed M. Ismail"
"Gauging or extending bulk and boundary conformal field theories:
  Application to bulk and domain wall problem in topological matter and their
  descriptions by (mock) modular covariant","We study gauging operations (or group extensions) in (smeared) boundary
conformal field theories (BCFTs) and bulk conformal field theories and their
applications to various phenomena in topologically ordered systems. We apply
the resultant theories to the correspondence between the renormalization group
(RG) flow of CFTs and the classification of topological quantum field theories
in the testable information of general classes of partition functions. One can
obtain the bulk topological properties of $2+1$ dimensional topological ordered
phase corresponding to the massive RG flow of $1+1$ dimensional systems, or
smeared BCFT. We present an obstruction of mass condensation for smeared BCFT
analogous to the Lieb-Shultz-Mattis theorem for noninvertible symmetry. Related
to the bulk topological degeneracies in $2+1$ dimensions and quantum phases in
$1+1$ dimensions we construct a new series of BCFT. We also investigate the
implications of the massless RG flow of $1+1$ dimensional CFT to $2+1$
dimensional topological order which corresponds to the earlier proposal by L.
Kong and H. Zheng in [Nucl. Phys. B 966 (2021), 115384], arXiv:1912.01760
closely related to the integer-spin simple current by Schellekens and
Gato-Rivera. We study the properties of the product of two CFTs connected by
the two kinds of massless flows. The (mock) modular covariants appearing in the
analysis seem to contain new ones. By applying the folding trick to the coupled
model, we provide a general method to solve the gapped and charged domain wall.
One can obtain the general phenomenology of the transportation of anyons
through the domain wall. Our work gives a unified direction for the future
theoretical and numerical studies of the topological phase based on the
established data of classifications of conformal field theories or modular
invariants.",2024-12-27T10:46:30Z,http://arxiv.org/abs/2412.19577v1,Yoshiki Fukusumi
"The possible long-term periodic variability of the extremely luminous
  quasar WISE J090924.01+000211.1","The extremely luminous infrared galaxy (ELIRG), WISE J090924.01+000211.1
(hereafter; WISE J0909+0002, $z=1.87$) is an extraordinary object with a quasar
aspect. This study performs monitoring observations of WISE J0909+0002 with the
105 cm Murikabushi telescope, Okayama and Akeno 50 cm telescopes/MITSuME ($g'$,
$R_{\rm c}$, and $I_{\rm c}$ bands), and the SaCRA 55 cm telescope/MuSaSHI
($r$, $i$, and $z$ bands). We obtain the following results by combining the
UV/optical light curves of the CRTS, Pan-STARRS, and ZTF archive data, and our
observational data: (1) the light curves of WISE J0909+0002 present
quasi-periodic (sinusoidal) oscillations with the rest-frame period of $\sim$
660$-$689 day; (2) the structure functions of WISE J0909+0002 do not show a
damped random walk (DRW) trend; (3) the mock DRW light curves present
periodic-like trend on rare occasions in 10000 simulations; (4) the
relativistic boost scenario is favored, since the relation between variability
amplitude and power-law slope ratio is consistent with the theoretical
prediction of this scenario, and a substantial parameter space exists between
the inclination angles and the black hole mass; (5) the circumbinary disk model
is difficult to explain the spectral energy distribution of our target; (6) the
significant radio flux density of WISE J0909+0002 is not detected from the VLA
FIRST Survey, thus the radio jet precession scenario is ruled out. From our
results, the Doppler boost scenario is likely as a cause of the periodic
variability, consequently the quasi-periodic oscillations in WISE J0909+0002 is
possibly interpreted by a supermassive blackhole binary. Additional
observations to investigate the continuity of the periodic trend would bring
new insights into mechanisms of the quasi-periodic oscillations and/or ELIRGs.",2024-12-27T10:33:11Z,http://arxiv.org/abs/2412.19573v1,"Takashi Horiuchi, Yoshiki Toba, Toru Misawa, Katsuhiro L. Murata, Keisuke Isogai, Yoichi Yatsu, Ichiro Takahashi, Mahito Sasada, Masafumi Niwano, Narikazu Higuchi, Shunsuke Hayatsu, Hibiki Seki, Yumiko Oasa, Rikuto Sato"
Safe Interval Randomized Path Planing For Manipulators,"Planning safe paths in 3D workspace for high DoF robotic systems, such as
manipulators, is a challenging problem, especially when the environment is
populated with the dynamic obstacles that need to be avoided. In this case the
time dimension should be taken into account that further increases the
complexity of planning. To mitigate this issue we suggest to combine
safe-interval path planning (a prominent technique in heuristic search) with
the randomized planning, specifically, with the bidirectional rapidly-exploring
random trees (RRT-Connect) - a fast and efficient algorithm for
high-dimensional planning. Leveraging a dedicated technique of fast computation
of the safe intervals we end up with an efficient planner dubbed SI-RRT. We
compare it with the state of the art and show that SI-RRT consistently
outperforms the competitors both in runtime and solution cost.
  Our implementation of SI-RRT is publicly available at
https://github.com/PathPlanning/ManipulationPlanning-SI-RRT",2024-12-27T10:10:52Z,http://arxiv.org/abs/2412.19567v1,"Nuraddin Kerimov, Aleksandr Onegin, Konstantin Yakovlev"
"Real-time Reflectance Generation for UAV Multispectral Imagery using an
  Onboard Downwelling Spectrometer in Varied Weather Conditions","Advancements in unmanned aerial vehicle (UAV) remote sensing with spectral
imaging enable efficient assessment of critical agronomic traits. However,
existing reflectance calibration or generation methods suffer from limited
prediction accuracy and practical flexibility. This study explores reliable and
cost-efficient methods for the accurate conversion of digital number values
acquired from a multispectral imager into reflectance, leveraging real-time
solar spectra as references. To ensure consistent measurements of incident
light, an upward gimbal-mounted downwelling spectrometer was attached to the
UAV, and a sinusoidal model was developed to correct for solar position
variability. Using principal component analysis on the reference solar spectrum
for band selection, a multiple linear regression model with four sensitive
bands (4-Band MLR) and a 30 nm bandwidth achieved performance comparable to the
direct correction method. The root mean square error (RMSE) for reflectance
prediction improved by 86.1% compared to the empirical line method under
fluctuating cloudy conditions and by 59.6% compared to the downwelling light
sensor method averaged across different weather conditions. The RMSE was
calculated as 2.24% in a ground-based diurnal validation, and 2.03% in a UAV
campaign conducted at various times throughout a sunny day. Implementing the
4-Band MLR model enhanced the consistency of canopy reflectance within a
homogeneous vegetation area by 95.0% during spectral imaging in a large rice
field under significant cloud fluctuations. Additionally, improvements of 86.0%
and 90.3% were noted for two vegetation indices: the normalized difference
vegetation index (NDVI; a ratio index) and the difference vegetation index
(DVI; a non-ratio index), respectively.",2024-12-27T08:41:46Z,http://arxiv.org/abs/2412.19527v1,"Jiayang Xie, Yutao Shen, Haiyan Cen"
"Attribution for Enhanced Explanation with Transferable Adversarial
  eXploration","The interpretability of deep neural networks is crucial for understanding
model decisions in various applications, including computer vision.
AttEXplore++, an advanced framework built upon AttEXplore, enhances attribution
by incorporating transferable adversarial attack methods such as MIG and GRA,
significantly improving the accuracy and robustness of model explanations. We
conduct extensive experiments on five models, including CNNs (Inception-v3,
ResNet-50, VGG16) and vision transformers (MaxViT-T, ViT-B/16), using the
ImageNet dataset. Our method achieves an average performance improvement of
7.57\% over AttEXplore and 32.62\% compared to other state-of-the-art
interpretability algorithms. Using insertion and deletion scores as evaluation
metrics, we show that adversarial transferability plays a vital role in
enhancing attribution results. Furthermore, we explore the impact of
randomness, perturbation rate, noise amplitude, and diversity probability on
attribution performance, demonstrating that AttEXplore++ provides more stable
and reliable explanations across various models. We release our code at:
https://anonymous.4open.science/r/ATTEXPLOREP-8435/",2024-12-27T08:27:53Z,http://arxiv.org/abs/2412.19523v1,"Zhiyu Zhu, Jiayu Zhang, Zhibo Jin, Huaming Chen, Jianlong Zhou, Fang Chen"
"Real-time classification of EEG signals using Machine Learning
  deployment","The prevailing educational methods predominantly rely on traditional
classroom instruction or online delivery, often limiting the teachers' ability
to engage effectively with all the students simultaneously. A more intrinsic
method of evaluating student attentiveness during lectures can enable the
educators to tailor the course materials and their teaching styles in order to
better meet the students' needs. The aim of this paper is to enhance teaching
quality in real time, thereby fostering a higher student engagement in the
classroom activities. By monitoring the students' electroencephalography (EEG)
signals and employing machine learning algorithms, this study proposes a
comprehensive solution for addressing this challenge. Machine learning has
emerged as a powerful tool for simplifying the analysis of complex variables,
enabling the effective assessment of the students' concentration levels based
on specific parameters. However, the real-time impact of machine learning
models necessitates a careful consideration as their deployment is concerned.
This study proposes a machine learning-based approach for predicting the level
of students' comprehension with regard to a certain topic. A browser interface
was introduced that accesses the values of the system's parameters to determine
a student's level of concentration on a chosen topic. The deployment of the
proposed system made it necessary to address the real-time challenges faced by
the students, consider the system's cost, and establish trust in its efficacy.
This paper presents the efforts made for approaching this pertinent issue
through the implementation of innovative technologies and provides a framework
for addressing key considerations for future research directions.",2024-12-27T08:14:28Z,http://arxiv.org/abs/2412.19515v1,"Swati Chowdhuri, Satadip Saha, Samadrita Karmakar, Ankur Chanda"
"Uncertainty quantification for improving radiomic-based models in
  radiation pneumonitis prediction","Background and Objective: Radiation pneumonitis (RP) is a side effect of
thoracic radiation therapy. Recently, Machine learning (ML) models enhanced
with radiomic and dosiomic features provide better predictions by incorporating
spatial information beyond DVHs. However, to improve the clinical decision
process, we propose to use uncertainty quantification (UQ) to improve the
confidence in model prediction. This study evaluates the impact of post hoc UQ
methods on the discriminative performance and calibration of ML models for RP
prediction. Methods: This study evaluated four ML models: logistic regression
(LR), support vector machines (SVM), extreme gradient boosting (XGB), and
random forest (RF), using radiomic, dosiomic, and dosimetric features to
predict RP. We applied UQ methods, including Patt scaling, isotonic regression,
Venn-ABERS predictor, and Conformal Prediction, to quantify uncertainty. Model
performance was assessed through Area Under the Receiver Operating
Characteristic curve (AUROC), Area Under the Precision-Recall Curve (AUPRC),
and Adaptive Calibration Error (ACE) using Leave-One-Out Cross-Validation
(LOO-CV). Results: UQ methods enhanced predictive performance, particularly for
high-certainty predictions, while also improving calibration. Radiomic and
dosiomic features increased model accuracy but introduced calibration
challenges, especially for non-linear models like XGB and RF. Performance gains
from UQ methods were most noticeable at higher certainty thresholds.
Conclusion: Integrating UQ into ML models with radiomic and dosiomic features
improves both predictive accuracy and calibration, supporting more reliable
clinical decision-making. The findings emphasize the value of UQ methods in
enhancing applicability of predictive models for RP in healthcare settings.",2024-12-27T08:01:42Z,http://arxiv.org/abs/2412.19511v1,"Chanon Puttanawarut, Romen Samuel Wabina, Nat Sirirutbunkajorn"
"Multi-label Classification using Deep Multi-order Context-aware Kernel
  Networks","Multi-label classification is a challenging task in pattern recognition. Many
deep learning methods have been proposed and largely enhanced classification
performance. However, most of the existing sophisticated methods ignore context
in the models' learning process. Since context may provide additional cues to
the learned models, it may significantly boost classification performances. In
this work, we make full use of context information (namely geometrical
structure of images) in order to learn better context-aware similarities
(a.k.a. kernels) between images. We reformulate context-aware kernel design as
a feed-forward network that outputs explicit kernel mapping features. Our
obtained context-aware kernel network further leverages multiple orders of
patch neighbors within different distances, resulting into a more
discriminating Deep Multi-order Context-aware Kernel Network (DMCKN) for
multi-label classification. We evaluate the proposed method on the challenging
Corel5K and NUS-WIDE benchmarks, and empirical results show that our method
obtains competitive performances against the related state-of-the-art, and both
quantitative and qualitative performances corroborate its effectiveness and
superiority for multi-label image classification.",2024-12-27T07:16:11Z,http://arxiv.org/abs/2412.19491v1,"Mingyuan Jiu, Hailong Zhu, Hichem Sahbi"
Movable Antenna-Aided Near-Field Integrated Sensing and Communication,"Integrated sensing and communication (ISAC) is emerging as a pivotal
technology for next-generation wireless networks. However, existing ISAC
systems are based on fixed-position antennas (FPAs), which inevitably incur a
loss in performance when balancing the trade-off between sensing and
communication. Movable antenna (MA) technology offers promising potential to
enhance ISAC performance by enabling flexible antenna movement. Nevertheless,
exploiting more spatial channel variations requires larger antenna moving
regions, which may invalidate the conventional far-field assumption for
channels between transceivers. Therefore, this paper utilizes the MA to enhance
sensing and communication capabilities in near-field ISAC systems, where a
full-duplex base station (BS) is equipped with multiple transmit and receive
MAs movable in large-size regions to simultaneously sense multiple targets and
serve multiple uplink (UL) and downlink (DL) users for communication. We aim to
maximize the weighted sum of sensing and communication rates (WSR) by jointly
designing the transmit beamformers, sensing signal covariance matrices, receive
beamformers, and MA positions at the BS, as well as the UL power allocation.
The resulting optimization problem is challenging to solve, while we propose an
efficient two-layer random position (RP) algorithm to tackle it. In addition,
to reduce movement delay and cost, we design an antenna position matching (APM)
algorithm based on the greedy strategy to minimize the total MA movement
distance. Extensive simulation results demonstrate the substantial performance
improvement achieved by deploying MAs in near-field ISAC systems. Moreover, the
results show the effectiveness of the proposed APM algorithm in reducing the
antenna movement distance, which is helpful for energy saving and time overhead
reduction for MA-aided near-field ISAC systems with large moving regions.",2024-12-27T05:45:35Z,http://arxiv.org/abs/2412.19470v1,"Jingze Ding, Zijian Zhou, Xiaodan Shao, Bingli Jiao, Rui Zhang"
Focusing Image Generation to Mitigate Spurious Correlations,"Instance features in images exhibit spurious correlations with background
features, affecting the training process of deep neural classifiers. This leads
to insufficient attention to instance features by the classifier, resulting in
erroneous classification outcomes. In this paper, we propose a data
augmentation method called Spurious Correlations Guided Synthesis (SCGS) that
mitigates spurious correlations through image generation model. This approach
does not require expensive spurious attribute (group) labels for the training
data and can be widely applied to other debiasing methods. Specifically, SCGS
first identifies the incorrect attention regions of a pre-trained classifier on
the training images, and then uses an image generation model to generate new
training data based on these incorrect attended regions. SCGS increases the
diversity and scale of the dataset to reduce the impact of spurious
correlations on classifiers. Changes in the classifier's attention regions and
experimental results on three different domain datasets demonstrate that this
method is effective in reducing the classifier's reliance on spurious
correlations.",2024-12-27T04:48:56Z,http://arxiv.org/abs/2412.19457v1,"Xuewei Li, Zhenzhen Nie, Mei Yu, Zijian Zhang, Jie Gao, Tianyi Xu, Zhiqiang Liu"
"Exponentially accurate open quantum simulation via randomized
  dissipation with minimal ancilla","Simulating open quantum systems is an essential technique for understanding
complex physical phenomena and advancing quantum technologies. Some quantum
algorithms for simulating Lindblad dynamics achieve logarithmically short
circuit depth in terms of accuracy $\varepsilon$ by coherently encoding all
possible jump processes with a large ancilla consumption. Minimizing the space
complexity while achieving such a logarithmic depth remains an important
challenge. In this work, we present a quantum algorithm for simulating general
Lindblad dynamics with multiple jump operators aimed at an observable
estimation, that achieves both a logarithmically short circuit depth and a
minimum ancilla size. Toward simulating an exponentially accurate Taylor
expansion of the Lindblad propagator to ensure the circuit depth of
$\mathcal{O} (\log(1/\varepsilon))$, we develop a novel random circuit
compilation method that leverages dissipative processes with only a single jump
operator; importantly, the proposed method requires the minimal-size, $4 +
\lceil \log M \rceil$, ancilla qubits where each single jump operator has at
most $M$ Pauli strings. This work represents a significant step towards making
open quantum system simulations more feasible on early fault-tolerant quantum
computing devices.",2024-12-27T04:43:19Z,http://arxiv.org/abs/2412.19453v1,"Jumpei Kato, Kaito Wada, Kosuke Ito, Naoki Yamamoto"
"Comparative Performance Analysis of Quantum Machine Learning
  Architectures for Credit Card Fraud Detection","As financial fraud becomes increasingly complex, effective detection methods
are essential. Quantum Machine Learning (QML) introduces certain capabilities
that may enhance both accuracy and efficiency in this area. This study examines
how different quantum feature map and ansatz configurations affect the
performance of three QML-based classifiers-the Variational Quantum Classifier
(VQC), the Sampler Quantum Neural Network (SQNN), and the Estimator Quantum
Neural Network (EQNN)-when applied to two non-standardized financial fraud
datasets. Different quantum feature map and ansatz configurations are
evaluated, revealing distinct performance patterns. The VQC consistently
demonstrates strong classification results, achieving an F1 score of 0.88,
while the SQNN also delivers promising outcomes. In contrast, the EQNN
struggles to produce robust results, emphasizing the challenges presented by
non-standardized data. These findings highlight the importance of careful model
configuration in QML-based financial fraud detection. By showing how specific
feature maps and ansatz choices influence predictive success, this work guides
researchers and practitioners in refining QML approaches for complex financial
applications.",2024-12-27T04:17:34Z,http://arxiv.org/abs/2412.19441v1,"Mansour El Alami, Nouhaila Innan, Muhammad Shafique, Mohamed Bennai"
"Residual Feature-Reutilization Inception Network for Image
  Classification","Capturing feature information effectively is of great importance in the field
of computer vision. With the development of convolutional neural networks
(CNNs), concepts like residual connection and multiple scales promote continual
performance gains in diverse deep learning vision tasks. In this paper, we
propose a novel CNN architecture that it consists of residual
feature-reutilization inceptions (ResFRI) or split-residual
feature-reutilization inceptions (Split-ResFRI). And it is composed of four
convolutional combinations of different structures connected by specially
designed information interaction passages, which are utilized to extract
multi-scale feature information and effectively increase the receptive field of
the model. Moreover, according to the network structure designed above,
Split-ResFRI can adjust the segmentation ratio of the input information,
thereby reducing the number of parameters and guaranteeing the model
performance. Specifically, in experiments based on popular vision datasets,
such as CIFAR10 ($97.94$\%), CIFAR100 ($85.91$\%) and Tiny Imagenet
($70.54$\%), we obtain state-of-the-art results compared with other modern
models under the premise that the model size is approximate and no additional
data is used.",2024-12-27T03:55:25Z,http://arxiv.org/abs/2412.19433v1,"Yuanpeng He, Wenjie Song, Lijian Li, Tianxiang Zhan, Wenpin Jiao"
Revisiting PCA for time series reduction in temporal dimension,"Revisiting PCA for Time Series Reduction in Temporal Dimension; Jiaxin Gao,
Wenbo Hu, Yuntian Chen; Deep learning has significantly advanced time series
analysis (TSA), enabling the extraction of complex patterns for tasks like
classification, forecasting, and regression. Although dimensionality reduction
has traditionally focused on the variable space-achieving notable success in
minimizing data redundancy and computational complexity-less attention has been
paid to reducing the temporal dimension. In this study, we revisit Principal
Component Analysis (PCA), a classical dimensionality reduction technique, to
explore its utility in temporal dimension reduction for time series data. It is
generally thought that applying PCA to the temporal dimension would disrupt
temporal dependencies, leading to limited exploration in this area. However,
our theoretical analysis and extensive experiments demonstrate that applying
PCA to sliding series windows not only maintains model performance, but also
enhances computational efficiency. In auto-regressive forecasting, the temporal
structure is partially preserved through windowing, and PCA is applied within
these windows to denoise the time series while retaining their statistical
information. By preprocessing time-series data with PCA, we reduce the temporal
dimensionality before feeding it into TSA models such as Linear, Transformer,
CNN, and RNN architectures. This approach accelerates training and inference
and reduces resource consumption. Notably, PCA improves Informer training and
inference speed by up to 40% and decreases GPU memory usage of TimesNet by 30%,
without sacrificing model accuracy. Comparative analysis against other
reduction methods further highlights the effectiveness of PCA in improving the
efficiency of TSA models.",2024-12-27T03:17:26Z,http://arxiv.org/abs/2412.19423v1,"Jiaxin Gao, Wenbo Hu, Yuntian Chen"
"Generalized Uncertainty-Based Evidential Fusion with Hybrid Multi-Head
  Attention for Weak-Supervised Temporal Action Localization","Weakly supervised temporal action localization (WS-TAL) is a task of
targeting at localizing complete action instances and categorizing them with
video-level labels. Action-background ambiguity, primarily caused by background
noise resulting from aggregation and intra-action variation, is a significant
challenge for existing WS-TAL methods. In this paper, we introduce a hybrid
multi-head attention (HMHA) module and generalized uncertainty-based evidential
fusion (GUEF) module to address the problem. The proposed HMHA effectively
enhances RGB and optical flow features by filtering redundant information and
adjusting their feature distribution to better align with the WS-TAL task.
Additionally, the proposed GUEF adaptively eliminates the interference of
background noise by fusing snippet-level evidences to refine uncertainty
measurement and select superior foreground feature information, which enables
the model to concentrate on integral action instances to achieve better action
localization and classification performance. Experimental results conducted on
the THUMOS14 dataset demonstrate that our method outperforms state-of-the-art
methods. Our code is available in
\url{https://github.com/heyuanpengpku/GUEF/tree/main}.",2024-12-27T03:04:57Z,http://arxiv.org/abs/2412.19418v1,"Yuanpeng He, Lijian Li, Tianxiang Zhan, Wenpin Jiao, Chi-Man Pun"
DIPS: Optimal Dynamic Index for Poisson $\boldsymbolπ$ps Sampling,"This paper addresses the Poisson $\pi$ps sampling problem, a topic of
significant academic interest in various domains and with practical data mining
applications, such as influence maximization. The problem includes a set
$\mathcal{S}$ of $n$ elements, where each element $v$ is assigned a weight
$w(v)$ reflecting its importance. The goal is to generate a random subset $X$
of $\mathcal{S}$, where each element $v \in \mathcal{S}$ is included in $X$
independently with probability $\frac{c\cdot w(v)}{\sum_{v \in \mathcal{S}}
w(v)}$, where $0&lt;c\leq 1$ is a constant. The subsets must be independent across
different queries. While the Poisson $\pi$ps sampling problem can be reduced to
the well-studied subset sampling problem, updates in Poisson $\pi$ps sampling,
such as adding a new element or removing an element, would cause the
probabilities of all $n$ elements to change in the corresponding subset
sampling problem, making this approach impractical for dynamic scenarios. To
address this, we propose a dynamic index specifically tailored for the Poisson
$\pi$ps sampling problem, supporting optimal expected $\mathcal{O}(1)$ query
time and $\mathcal{O}(1)$ index update time, with an optimal $\mathcal{O}(n)$
space cost. Our solution involves recursively partitioning the set by weights
and ultimately using table lookup. The core of our solution lies in addressing
the challenges posed by weight explosion and correlations between elements.
Empirical evaluations demonstrate that our approach achieves significant
speedups in update time while maintaining consistently competitive query time
compared to the subset-sampling-based methods.",2024-12-27T02:47:44Z,http://arxiv.org/abs/2412.19415v1,"Jinchao Huang, Sibo Wang"
"MLLM-SUL: Multimodal Large Language Model for Semantic Scene
  Understanding and Localization in Traffic Scenarios","Multimodal large language models (MLLMs) have shown satisfactory effects in
many autonomous driving tasks. In this paper, MLLMs are utilized to solve joint
semantic scene understanding and risk localization tasks, while only relying on
front-view images. In the proposed MLLM-SUL framework, a dual-branch visual
encoder is first designed to extract features from two resolutions, and rich
visual information is conducive to the language model describing risk objects
of different sizes accurately. Then for the language generation, LLaMA model is
fine-tuned to predict scene descriptions, containing the type of driving
scenario, actions of risk objects, and driving intentions and suggestions of
ego-vehicle. Ultimately, a transformer-based network incorporating a regression
token is trained to locate the risk objects. Extensive experiments on the
existing DRAMA-ROLISP dataset and the extended DRAMA-SRIS dataset demonstrate
that our method is efficient, surpassing many state-of-the-art image-based and
video-based methods. Specifically, our method achieves 80.1% BLEU-1 score and
298.5% CIDEr score in the scene understanding task, and 59.6% accuracy in the
localization task. Codes and datasets are available at
https://github.com/fjq-tongji/MLLM-SUL.",2024-12-27T02:05:38Z,http://arxiv.org/abs/2412.19406v1,"Jiaqi Fan, Jianhua Wu, Jincheng Gao, Jianhao Yu, Yafei Wang, Hongqing Chu, Bingzhao Gao"
"Comparing Few to Rank Many: Active Human Preference Learning using
  Randomized Frank-Wolfe","We study learning of human preferences from a limited comparison feedback.
This task is ubiquitous in machine learning. Its applications such as
reinforcement learning from human feedback, have been transformational. We
formulate this problem as learning a Plackett-Luce model over a universe of $N$
choices from $K$-way comparison feedback, where typically $K \ll N$. Our
solution is the D-optimal design for the Plackett-Luce objective. The design
defines a data logging policy that elicits comparison feedback for a small
collection of optimally chosen points from all ${N \choose K}$ feasible
subsets. The main algorithmic challenge in this work is that even fast methods
for solving D-optimal designs would have $O({N \choose K})$ time complexity. To
address this issue, we propose a randomized Frank-Wolfe (FW) algorithm that
solves the linear maximization sub-problems in the FW method on randomly chosen
variables. We analyze the algorithm, and evaluate it empirically on synthetic
and open-source NLP datasets.",2024-12-27T01:10:17Z,http://arxiv.org/abs/2412.19396v1,"Kiran Koshy Thekumparampil, Gaurush Hiranandani, Kousha Kalantari, Shoham Sabach, Branislav Kveton"
"Two-echelon Electric Vehicle Routing Problem in Parcel Delivery: A
  Literature Review","Multi-echelon parcel delivery systems using electric vehicles (EVs) are
crucial for managing urban logistics complexity and promoting sustainability.
In multi-echelon systems, particularly within two-stage systems, larger
vehicles transport parcels from a central depot to satellite hubs, where
smaller EVs pick up the parcels and carry out last-mile deliveries. This system
could increase efficiency, reduce emissions, and improve service reliability.
The two-echelon electric vehicle routing problem (2E-EVRP), an extension of the
traditional two-echelon vehicle routing problem (2E-VRP), addresses EV-specific
challenges such as battery constraints and recharging stations to tackle
environmental impacts, urban congestion, and e-commerce demands. While
effectively reducing costs, energy use, and emissions, the 2E-EVRP faces
modeling challenges due to multi-echelon structures, EV limitations, and
recharging station selection. This paper systematically reviews 2E-EVRP
literature, analyzing key studies. It proposes a classification scheme to
categorize the papers based on the problem variants, objectives, constraints,
and solution methods. It identifies gaps such as delivery tardiness,
environmental trade-offs, multi-objective optimization, multiple depots, split
deliveries, and time-dependent travel conditions. Future research directions
include aligning models with urban policies, integrating parcel lockers,
enabling same-day delivery, and incorporating advanced technologies like
autonomous vehicles. Methodological advancements suggest using machine
learning, reinforcement learning, and simulation-based approaches to enhance
dynamic routing and real-time decision-making. These directions aim to expand
the 2E-EVRP applicability, addressing theoretical and practical challenges in
sustainable urban logistics for future works.",2024-12-27T01:05:59Z,http://arxiv.org/abs/2412.19395v1,"Nima Moradi, Niloufar Mirzavand Boroujeni, Navid Aftabi, Amin Aslani"
An Engorgio Prompt Makes Large Language Model Babble on,"Auto-regressive large language models (LLMs) have yielded impressive
performance in many real-world tasks. However, the new paradigm of these LLMs
also exposes novel threats. In this paper, we explore their vulnerability to
inference cost attacks, where a malicious user crafts Engorgio prompts to
intentionally increase the computation cost and latency of the inference
process. We design Engorgio, a novel methodology, to efficiently generate
adversarial Engorgio prompts to affect the target LLM's service availability.
Engorgio has the following two technical contributions. (1) We employ a
parameterized distribution to track LLMs' prediction trajectory. (2) Targeting
the auto-regressive nature of LLMs' inference process, we propose novel loss
functions to stably suppress the appearance of the &lt;EOS&gt; token, whose
occurrence will interrupt the LLM's generation process. We conduct extensive
experiments on 13 open-sourced LLMs with parameters ranging from 125M to 30B.
The results show that Engorgio prompts can successfully induce LLMs to generate
abnormally long outputs (i.e., roughly 2-13$\times$ longer to reach 90%+ of the
output length limit) in a white-box scenario and our real-world experiment
demonstrates Engergio's threat to LLM service with limited computing resources.
The code is accessible at https://github.com/jianshuod/Engorgio-prompt.",2024-12-27T01:00:23Z,http://arxiv.org/abs/2412.19394v1,"Jianshuo Dong, Ziyuan Zhang, Qingjie Zhang, Han Qiu, Tianwei Zhang, Hao Wang, Hewu Li, Qi Li, Chao Zhang, Ke Xu"
"An In-Depth Analysis of Adversarial Discriminative Domain Adaptation for
  Digit Classification","Domain adaptation is an active area of research driven by the growing demand
for robust machine learning models that perform well on real-world data.
Adversarial learning for deep neural networks (DNNs) has emerged as a promising
approach to improving generalization ability, particularly for image
classification. In this paper, we implement a specific adversarial learning
technique known as Adversarial Discriminative Domain Adaptation (ADDA) and
replicate digit classification experiments from the original ADDA paper. We
extend their findings by examining a broader range of domain shifts and provide
a detailed analysis of in-domain classification accuracy post-ADDA. Our results
demonstrate that ADDA significantly improves accuracy across certain domain
shifts with minimal impact on in-domain performance. Furthermore, we provide
qualitative analysis and propose potential explanations for ADDA's limitations
in less successful domain shifts. Code is at
https://github.com/eugenechoi2004/COS429_FINAL .",2024-12-27T00:36:40Z,http://arxiv.org/abs/2412.19391v1,"Eugene Choi, Julian Rodriguez, Edmund Young"
Truncated multirange percolation of words on the square lattice,"We study mixed long-range percolation on the square lattice. Each vertical
edge of unit length is independently open with probability $\varepsilon$, and
each horizontal edge of length $i$ is independently open with probability
$p_i$. Also, each vertex is assigned independently a random variable taking
values 1 and 0 with probability $p$ and $1-p$, respectively. We prove that for
a broad class of anisotropic long-range percolation models for which connection
probabilities $p_i$ satisfy some regularity conditions, all words
(semi-infinite binary sequences) are seen simultaneously from the origin with
positive probability, even if all edges with length larger than some constant
(depending on $\varepsilon$, $p$, and on the sequence $(p_i)$) are suppressed.",2024-12-26T23:27:13Z,http://arxiv.org/abs/2412.19379v1,"Pablo A. Gomes, Otávio Lima, Roger W. C. Silva"
"Minimal Batch Adaptive Learning Policy Engine for Real-Time Mid-Price
  Forecasting in High-Frequency Trading","High-frequency trading (HFT) has transformed modern financial markets, making
reliable short-term price forecasting models essential. In this study, we
present a novel approach to mid-price forecasting using Level 1 limit order
book (LOB) data from NASDAQ, focusing on 100 U.S. stocks from the S&amp;P 500 index
during the period from September to November 2022. Expanding on our previous
work with Radial Basis Function Neural Networks (RBFNN), which leveraged
automated feature importance techniques based on mean decrease impurity (MDI)
and gradient descent (GD), we introduce the Adaptive Learning Policy Engine
(ALPE) - a reinforcement learning (RL)-based agent designed for batch-free,
immediate mid-price forecasting. ALPE incorporates adaptive epsilon decay to
dynamically balance exploration and exploitation, outperforming a diverse range
of highly effective machine learning (ML) and deep learning (DL) models in
forecasting performance.",2024-12-26T22:49:53Z,http://arxiv.org/abs/2412.19372v1,"Adamantios Ntakaris, Gbenga Ibikunle"
"Evaluating Convolutional Neural Networks for COVID-19 classification in
  chest X-ray images","Coronavirus Disease 2019 (COVID-19) pandemic rapidly spread globally,
impacting the lives of billions of people. The effective screening of infected
patients is a critical step to struggle with COVID-19, and treating the
patients avoiding this quickly disease spread. The need for automated and
scalable methods has increased due to the unavailability of accurate automated
toolkits. Recent researches using chest X-ray images suggest they include
relevant information about the COVID-19 virus. Hence, applying machine learning
techniques combined with radiological imaging promises to identify this disease
accurately. It is straightforward to collect these images once it is spreadly
shared and analyzed in the world. This paper presents a method for automatic
COVID-19 detection using chest Xray images through four convolutional neural
networks, namely: AlexNet, VGG-11, SqueezeNet, and DenseNet-121. This method
had been providing accurate diagnostics for positive or negative COVID-19
classification. We validate our experiments using a ten-fold cross-validation
procedure over the training and test sets. Our findings include the shallow
fine-tuning and data augmentation strategies that can assist in dealing with
the low number of positive COVID-19 images publicly available. The accuracy for
all CNNs is higher than 97.00%, and the SqueezeNet model achieved the best
result with 99.20%.",2024-12-26T22:05:30Z,http://arxiv.org/abs/2412.19362v1,"Leonardo Gabriel Ferreira Rodrigues, Danilo Ferreira da Silva, Larissa Ferreira Rodrigues, João Fernando Mari"
Dynamic Skill Adaptation for Large Language Models,"We present Dynamic Skill Adaptation (DSA), an adaptive and dynamic framework
to adapt novel and complex skills to Large Language Models (LLMs). Compared
with previous work which learns from human-curated and static data in random
orders, we propose to first automatically generate and organize the training
data by mimicking the learning pathways of human and then dynamically tailor
the training data based on the training dynamics. Specifically, inspired by the
learning structures and teaching strategies in the human education system, we
first construct a skill graph by decomposing complex skills into sub-skills and
arranging them based on their dependencies in human syllables. For every skill,
we utilize LLMs to generate both textbook-like data which contains detailed
descriptions of skills for pre-training and exercise-like data which targets at
explicitly utilizing the skills to solve problems for instruction-tuning.
Furthermore, during the instruction-tuning, we dynamically update the training
data which down-weight easy-to-learn examples, generate more complex examples,
and filter out data with errors. Experiments on large language models such as
LLAMA and Mistral demonstrate the effectiveness of our proposed methods in
adapting math reasoning skills and social study skills.",2024-12-26T22:04:23Z,http://arxiv.org/abs/2412.19361v1,"Jiaao Chen, Diyi Yang"
"Improving the network traffic classification using the Packet Vision
  approach","The network traffic classification allows improving the management, and the
network services offer taking into account the kind of application. The future
network architectures, mainly mobile networks, foresee intelligent mechanisms
in their architectural frameworks to deliver application-aware network
requirements. The potential of convolutional neural networks capabilities,
widely exploited in several contexts, can be used in network traffic
classification. Thus, it is necessary to develop methods based on the content
of packets transforming it into a suitable input for CNN technologies. Hence,
we implemented and evaluated the Packet Vision, a method capable of building
images from packets raw-data, considering both header and payload. Our approach
excels those found in state-of-the-art by delivering security and privacy by
transforming the raw-data packet into images. Therefore, we built a dataset
with four traffic classes evaluating the performance of three CNNs
architectures: AlexNet, ResNet-18, and SqueezeNet. Experiments showcase the
Packet Vision combined with CNNs applicability and suitability as a promising
approach to deliver outstanding performance in classifying network traffic.",2024-12-26T21:56:03Z,http://arxiv.org/abs/2412.19360v1,"Rodrigo Moreira, Larissa Ferreira Rodrigues, Pedro Frosi Rosa, Flávio de Oliveira Silva"
"Transit-Length Distribution for Particle Transport in Binary Markovian
  Mixed Media","The correspondence between the telegraph random process and transport within
a binary stochastic Markovian mixture is established. This equivalence is used
to derive the distribution function for the transit length, defined as the
distance a particle moving along a straight-line trajectory travels through a
specific material zone within the random mixture. A numerically robust
asymptotic form of this distribution is obtained for highly mixed materials and
the convergence to the atomic-mix limit is shown. The validity of the
distribution is verified using a Monte Carlo simulation of the transport
process. The distribution is applied to particle transport in slab geometry
containing porous media for two cases: the transmission of light and the
stopping of charged particles. For both of these applications, analytical forms
using the approximate asymptotic model for the transmission probability of beam
sources are obtained and illustrative numerical results are provided. These
results show that in cases of highly mixed materials, the asymptotic forms are
more accurate than the atomic-mix limit.",2024-12-26T21:46:14Z,http://arxiv.org/abs/2412.19359v1,"Brian C. Kiedrowski, Emily H. Vu"
"Central limit theorems for linear spectral statistics of inhomogeneous
  random graphs with graphon limits","We establish central limit theorems (CLTs) for the linear spectral statistics
of the adjacency matrix of inhomogeneous random graphs across all sparsity
regimes, providing explicit covariance formulas under the assumption that the
variance profile of the random graphs converges to a graphon limit. Two types
of CLTs are derived for the (non-centered) adjacency matrix and the centered
adjacency matrix, with different scaling factors when the sparsity parameter
$p$ satisfies $np = n^{\Omega(1)}$, and with the same scaling factor when $np =
n^{o(1)}$. In both cases, the limiting covariance is expressed in terms of
homomorphism densities from certain types of finite graphs to a graphon. These
results highlight a phase transition in the centering effect for global
eigenvalue fluctuations. For the non-centered adjacency matrix, we also
identify new phase transitions for the CLTs in the sparse regime when $n^{1/m}
\ll np \ll n^{1/(m-1)}$ for $m \geq 2$. Furthermore, weaker conditions for the
graphon convergence of the variance profile are sufficient as $p$ decreases
from being constant to $np \to c\in (0,\infty)$. These findings reveal a novel
connection between graphon limits and linear spectral statistics in random
matrix theory.",2024-12-26T21:15:49Z,http://arxiv.org/abs/2412.19352v1,"Xiangyi Zhu, Yizhe Zhu"
"Sparse recovery from quadratic equations, part II: hardness and
  incoherence","We study the square root bottleneck in the recovery of sparse vectors from
quadratic equations. It is acknowledged that a sparse vector $ \mathbf x_0\in
\mathbb{R}^n$, $\| \mathbf x_0\|_0 = k$ can in theory be recovered from as few
as $O(k)$ generic quadratic equations but no polynomial time algorithm is known
for this task unless $m = \Omega(k^2)$. This bottleneck was in fact shown in
previous work to be essentially related to the initialization of descent
algorithms. Starting such algorithms sufficiently close to the planted signal
is known to imply convergence to this signal. In this paper, we show that as
soon as $m\gtrsim \mu_0^{-2}k \vee \mu_0^{-4}$ (up to log factors) where $\mu_0
= \| \mathbf x_0\|_\infty/\| \mathbf x_0\|_2$, it is possible to recover a
$k$-sparse vector $ \mathbf x_0\in \mathbb{R}^n$ from $m$ quadratic equations
of the form $\langle \mathbf A_i, \mathbf x \mathbf x^\intercal\rangle =
\langle \mathbf A_i, \mathbf x_0 \mathbf x_0^\intercal\rangle + \varepsilon_i $
by minimizing the classical empirical loss. The proof idea carries over to the
phase retrieval setting for which it provides an original initialization that
matches the current optimal sample complexity (see e.g. [Cai 2023]). In the
maximally incoherent regime $\mu_0^{-2}=k$, and for $m=o(k^2)$ we provide
evidence for topological hardness by showing that a property known as the
Overlap Gap Property (OGP), which originated in spin glass theory and is
conjectured to be indicative of algorithmic intractability when optimizing over
random structures, holds for a particular level of overparametrization. The key
ingredient of the proof is a lower bound on the tail of chi-squared random
variables which follows from the theory of moderate deviations.",2024-12-26T20:11:44Z,http://arxiv.org/abs/2412.19341v1,Augustin Cosse
"Random matrix statistics and zeroes of $L$-functions via probability in
  $λ$-rings","We introduce a theory of probability in $\lambda$-rings designed to
efficiently describe random variables valued in multisets of complex numbers,
varieties over a field, or other similar enriched settings. A key role is
played by the $\sigma$-moment generating function based on the plethystic
exponential, which allows us to describe distributions and argue with
independence in a way that is as simple as classical probability theory. As a
first application, we use this theory to obtain a concise description of the
asymptotic $\sigma$-moment generating functions describing distributions of
eigenvalues of Haar random matrices in compact classical groups. Beyond the
theory of probability in $\lambda$-rings, the proof uses only classical
invariant theory. Using our description we reprove the results of Diaconis and
Shahshahani on the joint distributions of traces of powers of matrices, and we
also treat symmetric groups. Next, we use Poonen's sieve to establish
equidistribution results for the zeroes of $L$-functions in some natural
families: simple Dirichlet characters for $\mathbb{F}_q(x)$ and the vanishing
cohomology of smooth hypersurface sections. We give concise descriptions of the
asymptotic $\sigma$-moment generating functions in these families, then compare
them to the associated random matrix distributions. These equidistribution
results are sideways in that we fix $q$ and take the degree $d$ to infinity, as
opposed to Deligne equidistribution for fixed $d$ as $q \rightarrow \infty$,
and the large $d$-limits are related to explicit descriptions of stable
homology with twisted coefficients.",2024-12-26T17:36:12Z,http://arxiv.org/abs/2412.19295v1,Sean Howe
"ViPCap: Retrieval Text-Based Visual Prompts for Lightweight Image
  Captioning","Recent lightweight image captioning models using retrieved data mainly focus
on text prompts. However, previous works only utilize the retrieved text as
text prompts, and the visual information relies only on the CLIP visual
embedding. Because of this issue, there is a limitation that the image
descriptions inherent in the prompt are not sufficiently reflected in the
visual embedding space. To tackle this issue, we propose ViPCap, a novel
retrieval text-based visual prompt for lightweight image captioning. ViPCap
leverages the retrieved text with image information as visual prompts to
enhance the ability of the model to capture relevant visual information. By
mapping text prompts into the CLIP space and generating multiple randomized
Gaussian distributions, our method leverages sampling to explore randomly
augmented distributions and effectively retrieves the semantic features that
contain image information. These retrieved features are integrated into the
image and designated as the visual prompt, leading to performance improvements
on the datasets such as COCO, Flickr30k, and NoCaps. Experimental results
demonstrate that ViPCap significantly outperforms prior lightweight captioning
models in efficiency and effectiveness, demonstrating the potential for a
plug-and-play solution.",2024-12-26T17:29:38Z,http://arxiv.org/abs/2412.19289v1,"Taewhan Kim, Soeun Lee, Si-Woo Kim, Dong-Jin Kim"
"Time Series Foundational Models: Their Role in Anomaly Detection and
  Prediction","Time series foundational models (TSFM) have gained prominence in time series
forecasting, promising state-of-the-art performance across various
applications. However, their application in anomaly detection and prediction
remains underexplored, with growing concerns regarding their black-box nature,
lack of interpretability and applicability. This paper critically evaluates the
efficacy of TSFM in anomaly detection and prediction tasks. We systematically
analyze TSFM across multiple datasets, including those characterized by the
absence of discernible patterns, trends and seasonality. Our analysis shows
that while TSFMs can be extended for anomaly detection and prediction,
traditional statistical and deep learning models often match or outperform TSFM
in these tasks. Additionally, TSFMs require high computational resources but
fail to capture sequential dependencies effectively or improve performance in
few-shot or zero-shot scenarios. \noindent The preprocessed datasets, codes to
reproduce the results and supplementary materials are available at
https://github.com/smtmnfg/TSFM.",2024-12-26T17:15:30Z,http://arxiv.org/abs/2412.19286v1,"Chathurangi Shyalika, Harleen Kaur Bagga, Ahan Bhatt, Renjith Prasad, Alaa Al Ghazo, Amit Sheth"
"Phase transitions in low-dimensional long-range random field Ising
  models","We consider the long-range random field Ising model in dimension $d = 1, 2$,
whereas the long-range interaction is of the form $J_{xy} = |x-y|^{-\alpha}$
with $1&lt; \alpha &lt; 3/2$ for $d=1$ and with $2 &lt; \alpha \leq 3$ for $d = 2$. Our
main results establish phase transitions in these regimes. In one dimension, we
employ a Peierls argument with some novel modification, suitable for dealing
with the randomness coming from the external field; in two dimensions, our
proof follows that of Affonso, Bissacot, and Maia (2023) with some adaptations,
but new ideas are required in the critical case of $\alpha=3$.",2024-12-26T16:56:04Z,http://arxiv.org/abs/2412.19281v1,"Jian Ding, Fenglin Huang, João Maia"
"Leveraging Self-Training and Variational Autoencoder for Agitation
  Detection in People with Dementia Using Wearable Sensors","Dementia is a neurodegenerative disorder that has been growing among elder
people over the past decades. This growth profoundly impacts the quality of
life for patients and caregivers due to the symptoms arising from it. Agitation
and aggression (AA) are some of the symptoms of people with severe dementia
(PwD) in long-term care or hospitals. AA not only causes discomfort but also
puts the patients or others at potential risk. Existing monitoring solutions
utilizing different wearable sensors integrated with Artificial Intelligence
(AI) offer a way to detect AA early enough for timely and adequate medical
intervention. However, most studies are limited by the availability of
accurately labeled datasets, which significantly affects the efficacy of such
solutions in real-world scenarios. This study presents a novel comprehensive
approach to detect AA in PwD using physiological data from the Empatica E4
wristbands. The research creates a diverse dataset, consisting of three
distinct datasets gathered from 14 participants across multiple hospitals in
Canada. These datasets have not been extensively explored due to their limited
labeling. We propose a novel approach employing self-training and a variational
autoencoder (VAE) to detect AA in PwD effectively. The proposed approach aims
to learn the representation of the features extracted using the VAE and then
uses a semi-supervised block to generate labels, classify events, and detect
AA. We demonstrate that combining Self-Training and Variational Autoencoder
mechanism significantly improves model performance in classifying AA in PwD.
Among the tested techniques, the XGBoost classifier achieved the highest
accuracy of 90.16\%. By effectively addressing the challenge of limited labeled
data, the proposed system not only learns new labels but also proves its
superiority in detecting AA.",2024-12-26T15:34:25Z,http://arxiv.org/abs/2412.19254v1,"Abeer Badawi, Somayya Elmoghazy, Samira Choudhury, Khalid Elgazzar, Amer Burhan"
"Localized exploration in contextual dynamic pricing achieves
  dimension-free regret","We study the problem of contextual dynamic pricing with a linear demand
model. We propose a novel localized exploration-then-commit (LetC) algorithm
which starts with a pure exploration stage, followed by a refinement stage that
explores near the learned optimal pricing policy, and finally enters a pure
exploitation stage. The algorithm is shown to achieve a minimax optimal,
dimension-free regret bound when the time horizon exceeds a polynomial of the
covariate dimension. Furthermore, we provide a general theoretical framework
that encompasses the entire time spectrum, demonstrating how to balance
exploration and exploitation when the horizon is limited. The analysis is
powered by a novel critical inequality that depicts the
exploration-exploitation trade-off in dynamic pricing, mirroring its existing
counterpart for the bias-variance trade-off in regularized regression. Our
theoretical results are validated by extensive experiments on synthetic and
real-world data.",2024-12-26T15:29:58Z,http://arxiv.org/abs/2412.19252v1,"Jinhang Chai, Yaqi Duan, Jianqing Fan, Kaizheng Wang"
Sentiment trading with large language models,"We investigate the efficacy of large language models (LLMs) in sentiment
analysis of U.S. financial news and their potential in predicting stock market
returns. We analyze a dataset comprising 965,375 news articles that span from
January 1, 2010, to June 30, 2023; we focus on the performance of various LLMs,
including BERT, OPT, FINBERT, and the traditional Loughran-McDonald dictionary
model, which has been a dominant methodology in the finance literature. The
study documents a significant association between LLM scores and subsequent
daily stock returns. Specifically, OPT, which is a GPT-3 based LLM, shows the
highest accuracy in sentiment prediction with an accuracy of 74.4%, slightly
ahead of BERT (72.5%) and FINBERT (72.2%). In contrast, the Loughran-McDonald
dictionary model demonstrates considerably lower effectiveness with only 50.1%
accuracy. Regression analyses highlight a robust positive impact of OPT model
scores on next-day stock returns, with coefficients of 0.274 and 0.254 in
different model specifications. BERT and FINBERT also exhibit predictive
relevance, though to a lesser extent. Notably, we do not observe a significant
relationship between the Loughran-McDonald dictionary model scores and stock
returns, challenging the efficacy of this traditional method in the current
financial context. In portfolio performance, the long-short OPT strategy excels
with a Sharpe ratio of 3.05, compared to 2.11 for BERT and 2.07 for FINBERT
long-short strategies. Strategies based on the Loughran-McDonald dictionary
yield the lowest Sharpe ratio of 1.23. Our findings emphasize the superior
performance of advanced LLMs, especially OPT, in financial market prediction
and portfolio management, marking a significant shift in the landscape of
financial analysis tools with implications to financial regulation and policy
analysis.",2024-12-26T15:01:24Z,http://arxiv.org/abs/2412.19245v1,"Kemal Kirtac, Guido Germano"
Functional structural equation modeling with latent variables,"Handling latent variables in Structural Equation Models (SEMs) in a case
where both the latent variables and their corresponding indicators in the
measurement error part of the model are random curves presents significant
challenges, especially with sparse data. In this paper, we develop a novel
family of Functional Structural Equation Models (FSEMs) that incorporate latent
variables modeled as Gaussian Processes (GPs). The introduced FSEMs are built
upon functional regression models having response variables modeled as
underlying GPs. The model flexibly adapts to cases when the random curves'
realizations are observed only over a sparse subset of the domain, and the
inferential framework is based on a restricted maximum likelihood approach. The
advantage of this framework lies in its ability and flexibility in handling
various data scenarios, including regularly and irregularly spaced points and
thus missing data. To extract smooth estimates for the functional parameters,
we employ a penalized likelihood approach that selects the smoothing parameters
using a cross-validation method. We evaluate the performance of the proposed
model using simulation studies and a real data example, which suggests that our
model performs well in practice. The uncertainty associated with the estimates
of the functional coefficients is also assessed by constructing confidence
regions for each estimate. The goodness of fit indices that are commonly used
to evaluate the fit of SEMs are developed for the FSEMs introduced in this
paper. Overall, the proposed method is a promising approach for modeling
functional data in SEMs with functional latent variables.",2024-12-26T14:57:14Z,http://arxiv.org/abs/2412.19242v1,"Fatemeh Asgari, Valeria Vitelli, Uta Sailer"
"Latenrgy: Model Agnostic Latency and Energy Consumption Prediction for
  Binary Classifiers","Machine learning systems increasingly drive innovation across scientific
fields and industry, yet challenges in compute overhead, specifically during
inference, limit their scalability and sustainability. Responsible AI
guardrails, essential for ensuring fairness, transparency, and privacy, further
exacerbate these computational demands. This study addresses critical gaps in
the literature, chiefly the lack of generalized predictive techniques for
latency and energy consumption, limited cross-comparisons of classifiers, and
unquantified impacts of RAI guardrails on inference performance. Using Theory
Construction Methodology, this work constructed a model-agnostic theoretical
framework for predicting latency and energy consumption in binary
classification models during inference. The framework synthesizes classifier
characteristics, dataset properties, and RAI guardrails into a unified
analytical instrument. Two predictive equations are derived that capture the
interplay between these factors while offering generalizability across diverse
classifiers. The proposed framework provides foundational insights for
designing efficient, responsible ML systems. It enables researchers to
benchmark and optimize inference performance and assists practitioners in
deploying scalable solutions. Finally, this work establishes a theoretical
foundation for balancing computational efficiency with ethical AI principles,
paving the way for future empirical validation and broader applications.",2024-12-26T14:51:24Z,http://arxiv.org/abs/2412.19241v1,Jason M. Pittman
"A Malliavin Calculus Approach to Backward Stochastic Volterra Integral
  Equations","In this paper, we establish existence, uniqueness, and regularity properties
of the solutions to multi-dimensional backward stochastic Volterra integral
equations (BSVIEs), whose (possibly random) generator reflects nonlinear
dependence on both the solution process and the martingale integrand component
of the adapted solutions, as well as their diagonal processes. The
well-posedness results are developed with the use of Malliavin calculus, which
renders a novel perspective in tackling with the challenging diagonal processes
while contrasts with the existing methods. We also provide a probabilistic
interpretation of the classical solutions to the counterpart semilinear partial
differential equations through the explicit adapted solutions of BSVIEs.
Moreover, we formulate with BSVIEs to explicitly characterize dynamically
optimal mean-variance portfolios for various stochastic investment
opportunities, with the myopic investment and intertemporal hedging demands
being identified as two diagonal processes of BSVIE solutions.",2024-12-26T14:34:26Z,http://arxiv.org/abs/2412.19236v1,"Qian Lei, Chi Seng Pun"
"VINEVI: A Virtualized Network Vision Architecture for Smart Monitoring
  of Heterogeneous Applications and Infrastructures","Monitoring heterogeneous infrastructures and applications is essential to
cope with user requirements properly, but it still lacks enhancements. The
well-known state-of-the-art methods and tools do not support seamless
monitoring of bare-metal, low-cost infrastructures, neither hosted nor
virtualized services with fine-grained details. This work proposes VIrtualized
NEtwork VIsion architecture (VINEVI), an intelligent method for seamless
monitoring heterogeneous infrastructures and applications. The VINEVI
architecture advances state of the art with a node-embedded traffic
classification agent placing physical and virtualized infrastructures enabling
real-time traffic classification. VINEVI combines this real-time traffic
classification with well-known tools such as Prometheus and Victoria Metrics to
monitor the entire stack from the hardware to the virtualized applications.
Experimental results showcased that VINEVI architecture allowed seamless
heterogeneous infrastructure monitoring with a higher level of detail beyond
literature. Also, our node-embedded real-time Internet traffic classifier
evolved with flexibility the methods with monitoring heterogeneous
infrastructures seamlessly.",2024-12-26T14:05:14Z,http://arxiv.org/abs/2412.19226v1,"Rodrigo Moreira, Hugo G. V. O. da Cunha, Larissa F. Rodrigues Moreira, Flávio de Oliveira Silva"
"Transformer-Based Wireless Capsule Endoscopy Bleeding Tissue Detection
  and Classification","Informed by the success of the transformer model in various computer vision
tasks, we design an end-to-end trainable model for the automatic detection and
classification of bleeding and non-bleeding frames extracted from Wireless
Capsule Endoscopy (WCE) videos. Based on the DETR model, our model uses the
Resnet50 for feature extraction, the transformer encoder-decoder for bleeding
and non-bleeding region detection, and a feedforward neural network for
classification. Trained in an end-to-end approach on the Auto-WCEBleedGen
Version 1 challenge training set, our model performs both detection and
classification tasks as a single unit. Our model achieves an accuracy, recall,
and F1-score classification percentage score of 98.28, 96.79, and 98.37
respectively, on the Auto-WCEBleedGen version 1 validation set. Further, we
record an average precision (AP @ 0.5), mean-average precision (mAP) of 0.7447
and 0.7328 detection results. This earned us a 3rd place position in the
challenge. Our code is publicly available via
https://github.com/BasitAlawode/WCEBleedGen.",2024-12-26T13:49:39Z,http://arxiv.org/abs/2412.19218v1,"Basit Alawode, Shibani Hamza, Adarsh Ghimire, Divya Velayudhan"
"Large Language Models Meet Graph Neural Networks: A Perspective of Graph
  Mining","Graph mining is an important area in data mining and machine learning that
involves extracting valuable information from graph-structured data. In recent
years, significant progress has been made in this field through the development
of graph neural networks (GNNs). However, GNNs are still deficient in
generalizing to diverse graph data. Aiming to this issue, Large Language Models
(LLMs) could provide new solutions for graph mining tasks with their superior
semantic understanding. In this review, we systematically review the
combination and application techniques of LLMs and GNNs and present a novel
taxonomy for research in this interdisciplinary field, which involves three
main categories: GNN-driving-LLM, LLM-driving-GNN, and GNN-LLM-co-driving.
Within this framework, we reveal the capabilities of LLMs in enhancing graph
feature extraction as well as improving the effectiveness of downstream tasks
such as node classification, link prediction, and community detection. Although
LLMs have demonstrated their great potential in handling graph-structured data,
their high computational requirements and complexity remain challenges. Future
research needs to continue to explore how to efficiently fuse LLMs and GNNs to
achieve more powerful graph learning and reasoning capabilities and provide new
impetus for the development of graph mining techniques.",2024-12-26T13:21:09Z,http://arxiv.org/abs/2412.19211v1,"Yuxin You, Zhen Liu, Xiangchao Wen, Yongtao Zhang, Wei Ai"
"Overlapping Schwarz Preconditioners for Randomized Neural Networks with
  Domain Decomposition","Randomized neural networks (RaNNs), in which hidden layers remain fixed after
random initialization, provide an efficient alternative for parameter
optimization compared to fully parameterized networks. In this paper, RaNNs are
integrated with overlapping Schwarz domain decomposition in two (main) ways:
first, to formulate the least-squares problem with localized basis functions,
and second, to construct overlapping preconditioners for the resulting linear
systems. In particular, neural networks are initialized randomly in each
subdomain based on a uniform distribution and linked through a partition of
unity, forming a global solution that approximates the solution of the partial
differential equation. Boundary conditions are enforced through a constraining
operator, eliminating the need for a penalty term to handle them. Principal
component analysis (PCA) is employed to reduce the number of basis functions in
each subdomain, yielding a linear system with a lower condition number. By
constructing additive and restricted additive Schwarz preconditioners, the
least-squares problem is solved efficiently using the Conjugate Gradient (CG)
and Generalized Minimal Residual (GMRES) methods, respectively. Our numerical
results demonstrate that the proposed approach significantly reduces
computational time for multi-scale and time-dependent problems. Additionally, a
three-dimensional problem is presented to demonstrate the efficiency of using
the CG method with an AS preconditioner, compared to an QR decomposition, in
solving the least-squares problem.",2024-12-26T13:08:58Z,http://arxiv.org/abs/2412.19207v1,"Yong Shang, Alexander Heinlein, Siddhartha Mishra, Fei Wang"
"GAIS: A Novel Approach to Instance Selection with Graph Attention
  Networks","Instance selection (IS) is a crucial technique in machine learning that aims
to reduce dataset size while maintaining model performance. This paper
introduces a novel method called Graph Attention-based Instance Selection
(GAIS), which leverages Graph Attention Networks (GATs) to identify the most
informative instances in a dataset. GAIS represents the data as a graph and
uses GATs to learn node representations, enabling it to capture complex
relationships between instances. The method processes data in chunks, applies
random masking and similarity thresholding during graph construction, and
selects instances based on confidence scores from the trained GAT model.
Experiments on 13 diverse datasets demonstrate that GAIS consistently
outperforms traditional IS methods in terms of effectiveness, achieving high
reduction rates (average 96\%) while maintaining or improving model
performance. Although GAIS exhibits slightly higher computational costs, its
superior performance in maintaining accuracy with significantly reduced
training data makes it a promising approach for graph-based data selection.",2024-12-26T12:51:14Z,http://arxiv.org/abs/2412.19201v1,"Zahiriddin Rustamov, Ayham Zaitouny, Rafat Damseh, Nazar Zaki"
New-type geometric gates in atomic arrays without Rydberg blockade,"The Rydberg blockade effect plays an important role in realizing two-qubit
gates in atomic arrays. Meanwhile, such mechanics will increase the crosstalk
between atoms and enhance the decoherence. In this paper, we propose a new
scheme to realize the controlled-phase gate without Rydberg blockade. The
scheme works effectively with large atomic spacings and is insensitive to the
thermal motions of atoms. The proposal is robust against random noises due to
the geometric characteristic and operates fast based on the non-adiabatic
evolution. The proposed gate is actually a new-type geometric gate that
consolidates the non-adiabatic holonomic control and the unconventional
geometric control simultaneously. The interference between two different types
of geometric phases can be investigated. Furthermore, we show that the scheme
with weak Rydberg interaction requires much less physical resources than the
present Rydberg blockade scheme. Therefore, our proposal provides a fast and
robust way to realize geometric quantum control, and it may trigger the
discoveries of new geometric gates in high-dimensional Hilbert space.",2024-12-26T12:24:36Z,http://arxiv.org/abs/2412.19193v1,"Yue Ming, Zhao-Xin Fu, Yan-Xiong Du"
"Game-Theoretically Secure Distributed Protocols for Fair Allocation in
  Coalitional Games","We consider game-theoretically secure distributed protocols for coalition
games that approximate the Shapley value with small multiplicative error. Since
all known existing approximation algorithms for the Shapley value are
randomized, it is a challenge to design efficient distributed protocols among
mutually distrusted players when there is no central authority to generate
unbiased randomness. The game-theoretic notion of maximin security has been
proposed to offer guarantees to an honest player's reward even if all other
players are susceptible to an adversary.
  Permutation sampling is often used in approximation algorithms for the
Shapley value. A previous work in 1994 by Zlotkin et al. proposed a simple
constant-round distributed permutation generation protocol based on commitment
scheme, but it is vulnerable to rushing attacks. The protocol, however, can
detect such attacks.
  In this work, we model the limited resources of an adversary by a violation
budget that determines how many times it can perform such detectable attacks.
Therefore, by repeating the number of permutation samples, an honest player's
reward can be guaranteed to be close to its Shapley value. We explore both high
probability and expected maximin security. We obtain an upper bound on the
number of permutation samples for high probability maximin security, even with
an unknown violation budget. Furthermore, we establish a matching lower bound
for the weaker notion of expected maximin security in specific permutation
generation protocols. We have also performed experiments on both synthetic and
real data to empirically verify our results.",2024-12-26T12:13:21Z,http://arxiv.org/abs/2412.19192v1,"T-H. Hubert Chan, Qipeng Kuang, Quan Xue"
Priors for second-order unbiased Bayes estimators,"Asymptotically unbiased priors, introduced by Hartigan (1965), are designed
to achieve second-order unbiasedness of Bayes estimators. This paper extends
Hartigan's framework to non-i.i.d. models by deriving a system of partial
differential equations that characterizes asymptotically unbiased priors.
Furthermore, we establish a necessary and sufficient condition for the
existence of such priors and propose a simple procedure for constructing them.
  The proposed method is applied to several examples, including the linear
regression model and the nested error regression (NER) model (also known as the
random effects model). Simulation studies evaluate the frequentist properties
of the Bayes estimator under the asymptotically unbiased prior for the NER
model, highlighting its effectiveness in small-sample settings.",2024-12-26T11:51:07Z,http://arxiv.org/abs/2412.19187v1,"Mana Sakai, Takeru Matsuda, Tatsuya Kubokawa"
"Outlier-Bias Removal with Alpha Divergence: A Robust Non-Convex
  Estimator for Linear Regression","Convex and penalized robust methods often suffer from bias induced by large
outliers, limiting their effectiveness in adversarial or heavy-tailed settings.
In this study, we propose a novel approach that eliminates this bias (when
possible) by leveraging a non-convex $M$-estimator based on the alpha
divergence. We address the problem of estimating the parameters vector in high
dimensional linear regression, even when a subset of the data has been
deliberately corrupted by an adversary with full knowledge of the dataset and
its underlying distribution.
  Our primary contribution is to demonstrate that the objective function,
although non-convex, exhibits convexity within a carefully chosen basin of
attraction, enabling robust and unbiased estimation. Additionally, we establish
three key theoretical guarantees for the estimator: (a) a deviation bound that
is minimax optimal up to a logarithmic factor, (b) an improved unbiased bound
when the outliers are large and (c) asymptotic normality as the sample size
increases. Finally, we validate the theoretical findings through empirical
comparisons with state-of-the-art estimators on both synthetic and real-world
datasets, highlighting the proposed method's superior robustness, efficiency,
and ability to mitigate outlier-induced bias.",2024-12-26T11:42:46Z,http://arxiv.org/abs/2412.19183v1,"Ilyes Hammouda, Mohamed Ndaoud, and Abd-Krim Seghouane"
"Dual Channel Multi-Attention in ViT for Biometric Authentication using
  Forehead Subcutaneous Vein Pattern and Periocular Pattern","Traditional biometric systems, like face and fingerprint recognition, have
encountered significant setbacks due to wearing face masks and hygiene
concerns. To meet the challenges of the partially covered face due to face
masks and hygiene concerns of fingerprint recognition, this paper proposes a
novel dual-channel multi-attention Vision Transformer (ViT) framework for
biometric authentication using forehead subcutaneous vein patterns and
periocular patterns, offering a promising alternative to traditional methods,
capable of performing well even with face masks and without any physical touch.
The proposed framework leverages a dual-channel ViT architecture, designed to
handle two distinct biometric traits. It can capture long-range dependencies of
independent features from the vein and periocular patterns. A custom classifier
is then designed to integrate the independently extracted features, producing a
final class prediction. The performance of the proposed algorithm was
rigorously evaluated using the Forehead Subcutaneous Vein Pattern and
Periocular Biometric Pattern (FSVP-PBP) database. The results demonstrated the
superiority of the algorithm over state-of-the-art methods, achieving
remarkable classification accuracy of $99.3 \pm 0.02\%$ with the combined vein
and periocular patterns.",2024-12-26T10:40:15Z,http://arxiv.org/abs/2412.19160v1,"Arun K. Sharma, Shubhobrata Bhattacharya, Motahar Reza"
"Referencing Where to Focus: Improving VisualGrounding with Referential
  Query","Visual Grounding aims to localize the referring object in an image given a
natural language expression. Recent advancements in DETR-based visual grounding
methods have attracted considerable attention, as they directly predict the
coordinates of the target object without relying on additional efforts, such as
pre-generated proposal candidates or pre-defined anchor boxes. However,
existing research primarily focuses on designing stronger multi-modal decoder,
which typically generates learnable queries by random initialization or by
using linguistic embeddings. This vanilla query generation approach inevitably
increases the learning difficulty for the model, as it does not involve any
target-related information at the beginning of decoding. Furthermore, they only
use the deepest image feature during the query learning process, overlooking
the importance of features from other levels. To address these issues, we
propose a novel approach, called RefFormer. It consists of the query adaption
module that can be seamlessly integrated into CLIP and generate the referential
query to provide the prior context for decoder, along with a task-specific
decoder. By incorporating the referential query into the decoder, we can
effectively mitigate the learning difficulty of the decoder, and accurately
concentrate on the target object. Additionally, our proposed query adaption
module can also act as an adapter, preserving the rich knowledge within CLIP
without the need to tune the parameters of the backbone network. Extensive
experiments demonstrate the effectiveness and efficiency of our proposed
method, outperforming state-of-the-art approaches on five visual grounding
benchmarks.",2024-12-26T10:19:20Z,http://arxiv.org/abs/2412.19155v1,"Yabing Wang, Zhuotao Tian, Qingpei Guo, Zheng Qin, Sanping Zhou, Ming Yang, Le Wang"
"To Predict or Not To Predict? Proportionally Masked Autoencoders for
  Tabular Data Imputation","Masked autoencoders (MAEs) have recently demonstrated effectiveness in
tabular data imputation. However, due to the inherent heterogeneity of tabular
data, the uniform random masking strategy commonly used in MAEs can disrupt the
distribution of missingness, leading to suboptimal performance. To address
this, we propose a proportional masking strategy for MAEs. Specifically, we
first compute the statistics of missingness based on the observed proportions
in the dataset, and then generate masks that align with these statistics,
ensuring that the distribution of missingness is preserved after masking.
Furthermore, we argue that simple MLP-based token mixing offers competitive or
often superior performance compared to attention mechanisms while being more
computationally efficient, especially in the tabular domain with the inherent
heterogeneity. Experimental results validate the effectiveness of the proposed
proportional masking strategy across various missing data patterns in tabular
datasets. Code is available at: \url{https://github.com/normal-kim/PMAE}.",2024-12-26T10:12:08Z,http://arxiv.org/abs/2412.19152v1,"Jungkyu Kim, Kibok Lee, Taeyoung Park"
"CLIP-GS: Unifying Vision-Language Representation with 3D Gaussian
  Splatting","Recent works in 3D multimodal learning have made remarkable progress.
However, typically 3D multimodal models are only capable of handling point
clouds. Compared to the emerging 3D representation technique, 3D Gaussian
Splatting (3DGS), the spatially sparse point cloud cannot depict the texture
information of 3D objects, resulting in inferior reconstruction capabilities.
This limitation constrains the potential of point cloud-based 3D multimodal
representation learning. In this paper, we present CLIP-GS, a novel multimodal
representation learning framework grounded in 3DGS. We introduce the GS
Tokenizer to generate serialized gaussian tokens, which are then processed
through transformer layers pre-initialized with weights from point cloud
models, resulting in the 3DGS embeddings. CLIP-GS leverages contrastive loss
between 3DGS and the visual-text embeddings of CLIP, and we introduce an image
voting loss to guide the directionality and convergence of gradient
optimization. Furthermore, we develop an efficient way to generate triplets of
3DGS, images, and text, facilitating CLIP-GS in learning unified multimodal
representations. Leveraging the well-aligned multimodal representations,
CLIP-GS demonstrates versatility and outperforms point cloud-based models on
various 3D tasks, including multimodal retrieval, zero-shot, and few-shot
classification.",2024-12-26T09:54:25Z,http://arxiv.org/abs/2412.19142v1,"Siyu Jiao, Haoye Dong, Yuyang Yin, Zequn Jie, Yinlong Qian, Yao Zhao, Humphrey Shi, Yunchao Wei"
"How Panel Layouts Define Manga: Insights from Visual Ablation
  Experiments","Today, manga has gained worldwide popularity. However, the question of how
various elements of manga, such as characters, text, and panel layouts, reflect
the uniqueness of a particular work, or even define it, remains an unexplored
area. In this paper, we aim to quantitatively and qualitatively analyze the
visual characteristics of manga works, with a particular focus on panel layout
features. As a research method, we used facing page images of manga as input to
train a deep learning model for predicting manga titles, examining
classification accuracy to quantitatively analyze these features. Specifically,
we conducted ablation studies by limiting page image information to panel
frames to analyze the characteristics of panel layouts. Through a series of
quantitative experiments using all 104 works, 12 genres, and 10,122 facing page
images from the Manga109 dataset, as well as qualitative analysis using
Grad-CAM, our study demonstrates that the uniqueness of manga works is strongly
reflected in their panel layouts.",2024-12-26T09:53:37Z,http://arxiv.org/abs/2412.19141v1,"Siyuan Feng, Teruya Yoshinaga, Katsuhiko Hayashi, Koki Washio, Hidetaka Kamigaito"
"CoheDancers: Enhancing Interactive Group Dance Generation through
  Music-Driven Coherence Decomposition","Dance generation is crucial and challenging, particularly in domains like
dance performance and virtual gaming. In the current body of literature, most
methodologies focus on Solo Music2Dance. While there are efforts directed
towards Group Music2Dance, these often suffer from a lack of coherence,
resulting in aesthetically poor dance performances. Thus, we introduce
CoheDancers, a novel framework for Music-Driven Interactive Group Dance
Generation. CoheDancers aims to enhance group dance generation coherence by
decomposing it into three key aspects: synchronization, naturalness, and
fluidity. Correspondingly, we develop a Cycle Consistency based Dance
Synchronization strategy to foster music-dance correspondences, an
Auto-Regressive-based Exposure Bias Correction strategy to enhance the fluidity
of the generated dances, and an Adversarial Training Strategy to augment the
naturalness of the group dance output. Collectively, these strategies enable
CohdeDancers to produce highly coherent group dances with superior quality.
Furthermore, to establish better benchmarks for Group Music2Dance, we construct
the most diverse and comprehensive open-source dataset to date, I-Dancers,
featuring rich dancer interactions, and create comprehensive evaluation
metrics. Experimental evaluations on I-Dancers and other extant datasets
substantiate that CoheDancers achieves unprecedented state-of-the-art
performance. Code will be released.",2024-12-26T08:47:13Z,http://arxiv.org/abs/2412.19123v1,"Kaixing Yang, Xulong Tang, Haoyu Wu, Qinliang Xue, Biao Qin, Hongyan Liu, Zhaoxin Fan"
"Constrained stochastic linear quadratic control under regime switching
  with controlled jump size","In this paper, we examine a stochastic linear-quadratic control problem
characterized by regime switching and Poisson jumps. All the coefficients in
the problem are random processes adapted to the filtration generated by
Brownian motion and the Poisson random measure for each given regime. The model
incorporates two distinct types of controls: the first is a conventional
control that appears in the continuous diffusion component, while the second is
an unconventional control, dependent on the variable $z$, which influences the
jump size in the jump diffusion component. Both controls are constrained within
general closed cones. By employing the Meyer-It\^o formula in conjunction with
a generalized squares completion technique, we rigorously and explicitly derive
the optimal value and optimal feedback control. These depend on solutions to
certain multi-dimensional fully coupled stochastic Riccati equations, which are
essentially backward stochastic differential equations with jumps (BSDEJs). We
establish the existence of a unique nonnegative solution to the BSDEJs. One of
the major tools used in the proof is the newly established comparison theorems
for multidimensional BSDEJs.",2024-12-26T07:42:23Z,http://arxiv.org/abs/2412.19100v1,"Xiaomin Shi, Zuo Quan Xu"
From Coin to Data: The Impact of Object Detection on Digital Numismatics,"In this work we investigate the application of advanced object detection
techniques to digital numismatics, focussing on the analysis of historical
coins. Leveraging models such as Contrastive Language-Image Pre-training
(CLIP), we develop a flexible framework for identifying and classifying
specific coin features using both image and textual descriptions. By examining
two distinct datasets, modern Russian coins featuring intricate ""Saint George
and the Dragon"" designs and degraded 1st millennium AD Southeast Asian coins
bearing Hindu-Buddhist symbols, we evaluate the efficacy of different detection
algorithms in search and classification tasks. Our results demonstrate the
superior performance of larger CLIP models in detecting complex imagery, while
traditional methods excel in identifying simple geometric patterns.
Additionally, we propose a statistical calibration mechanism to enhance the
reliability of similarity scores in low-quality datasets. This work highlights
the transformative potential of integrating state-of-the-art object detection
into digital numismatics, enabling more scalable, precise, and efficient
analysis of historical artifacts. These advancements pave the way for new
methodologies in cultural heritage research, artefact provenance studies, and
the detection of forgeries.",2024-12-26T07:05:53Z,http://arxiv.org/abs/2412.19091v1,"Rafael Cabral, Maria De Iorio, Andrew Harris"
"Assessing Pre-trained Models for Transfer Learning through Distribution
  of Spectral Components","Pre-trained model assessment for transfer learning aims to identify the
optimal candidate for the downstream tasks from a model hub, without the need
of time-consuming fine-tuning. Existing advanced works mainly focus on
analyzing the intrinsic characteristics of the entire features extracted by
each pre-trained model or how well such features fit the target labels. This
paper proposes a novel perspective for pre-trained model assessment through the
Distribution of Spectral Components (DISCO). Through singular value
decomposition of features extracted from pre-trained models, we investigate
different spectral components and observe that they possess distinct
transferability, contributing diversely to the fine-tuning performance.
Inspired by this, we propose an assessment method based on the distribution of
spectral components which measures the proportions of their corresponding
singular values. Pre-trained models with features concentrating on more
transferable components are regarded as better choices for transfer learning.
We further leverage the labels of downstream data to better estimate the
transferability of each spectral component and derive the final assessment
criterion. Our proposed method is flexible and can be applied to both
classification and regression tasks. We conducted comprehensive experiments
across three benchmarks and two tasks including image classification and object
detection, demonstrating that our method achieves state-of-the-art performance
in choosing proper pre-trained models from the model hub for transfer learning.",2024-12-26T06:54:22Z,http://arxiv.org/abs/2412.19085v1,"Tengxue Zhang, Yang Shu, Xinyang Chen, Yifei Long, Chenjuan Guo, Bin Yang"
A Microservice Graph Generator with Production Characteristics,"A production microservice application may provide multiple services, queries
of a service may have different call graphs, and a microservice may be shared
across call graphs. It is challenging to improve the resource efficiency of
such complex applications without proper benchmarks, while production traces
are too large to be used in experiments. To this end, we propose a Service
Dependency Graph Generator (DGG) that comprises a Data Handler and a Graph
Generator, for generating the service dependency graphs of benchmarks that
incorporate production-level characteristics from traces. The data handler
first constructs fine-grained call graphs with dynamic interface and repeated
calling features from the trace and merges them into dependency graphs, and
then clusters them into different categories based on the topological and
invocation types. Taking the organized data and the selected category, the
graph generator simulates the process of real microservices invoking downstream
microservices using a random graph model, generates multiple call graphs, and
merges the call graphs to form the small-scale service dependency graph with
production-level characteristics. Case studies show that DGG's generated graphs
are similar to real traces in terms of topologies. Moreover, the resource
scaling based on DGG's fine-grained call graph constructing increases the
resource efficiency by up to 44.8% while ensuring the required QoS.",2024-12-26T06:51:35Z,http://arxiv.org/abs/2412.19083v1,"Fanrong Du, Jiuchen Shi, Quan Chen, Li Li, Minyi Guo"
"Robust Speech and Natural Language Processing Models for Depression
  Screening","Depression is a global health concern with a critical need for increased
patient screening. Speech technology offers advantages for remote screening but
must perform robustly across patients. We have described two deep learning
models developed for this purpose. One model is based on acoustics; the other
is based on natural language processing. Both models employ transfer learning.
Data from a depression-labeled corpus in which 11,000 unique users interacted
with a human-machine application using conversational speech is used. Results
on binary depression classification have shown that both models perform at or
above AUC=0.80 on unseen data with no speaker overlap. Performance is further
analyzed as a function of test subset characteristics, finding that the models
are generally robust over speaker and session variables. We conclude that
models based on these approaches offer promise for generalized automated
depression screening.",2024-12-26T06:05:52Z,http://arxiv.org/abs/2412.19072v1,"Y. Lu, A. Harati, T. Rutowski, R. Oliveira, P. Chlebek, E. Shriberg"
"Equilibrium reinsurance and investment strategies for insurers with
  random risk aversion under Heston's SV model","This paper adopts expected certainty equivalents to consider the reinsurance
and investment problem for an insurer who maximizes the expected utility but
faces the random risk aversion. The insurer's surplus process is approximated
by a Brownian motion with drift, and the financial market is comprised of a
risk-free asset and a risky asset whose price is described by Heston's
stochastic volatility (SV) model. Under a game theoretic framework, a rigorous
verification theorem is provided for characterizing the equilibrium reinsurance
and investment strategies and the corresponding value function. Moreover, by
solving the pseudo Hamilton-Jacobi-Bellman (HJB) system, semi-analytic
expressions for the equilibrium reinsurance and investment strategies and the
corresponding value function are derived under the exponential utility. In
addition, some numerical experiments are given to illustrate the behavior of
the equilibrium reinsurance and investment strategies.",2024-12-26T04:10:05Z,http://arxiv.org/abs/2412.19050v1,"Jian-hao Kang, Zhun Gou, Nan-jing Huang"
CL-attack: Textual Backdoor Attacks via Cross-Lingual Triggers,"Backdoor attacks significantly compromise the security of large language
models by triggering them to output specific and controlled content. Currently,
triggers for textual backdoor attacks fall into two categories: fixed-token
triggers and sentence-pattern triggers. However, the former are typically easy
to identify and filter, while the latter, such as syntax and style, do not
apply to all original samples and may lead to semantic shifts. In this paper,
inspired by cross-lingual (CL) prompts of LLMs in real-world scenarios, we
propose a higher-dimensional trigger method at the paragraph level, namely
CL-attack. CL-attack injects the backdoor by using texts with specific
structures that incorporate multiple languages, thereby offering greater
stealthiness and universality compared to existing backdoor attack techniques.
Extensive experiments on different tasks and model architectures demonstrate
that CL-attack can achieve nearly 100% attack success rate with a low poisoning
rate in both classification and generation tasks. We also empirically show that
the CL-attack is more robust against current major defense methods compared to
baseline backdoor attacks. Additionally, to mitigate CL-attack, we further
develop a new defense called TranslateDefense, which can partially mitigate the
impact of CL-attack.",2024-12-26T03:13:03Z,http://arxiv.org/abs/2412.19037v1,"Jingyi Zheng, Tianyi Hu, Tianshuo Cong, Xinlei He"
"Reflection on Purpose Changes Students' Academic Interests: A Scalable
  Intervention in an Online Course Catalog","College students routinely use online course catalogs to explore a variety of
academic offerings. Course catalogs may therefore be an effective place to
encourage reflection on academic choices and interests. To test this, we
embedded a psychological intervention in an online course catalog to encourage
students to reflect on their purpose during course exploration. Results of a
randomized field experiment with over 4,000 students at a large U.S. university
show that a purpose intervention increased students' cognitive engagement in
describing their interests, but reduced search activities. Students became more
interested in courses related to creative arts and social change, but less in
computer and data science. The findings demonstrate the malleability of
students' interests during course exploration and suggest practical strategies
to support purpose reflection and guide students toward deliberate exploration
of their interests in higher education.",2024-12-26T03:12:50Z,http://arxiv.org/abs/2412.19035v1,"Youjie Chen, Pranathi Iyer, Rene F. Kizilcec"
Neural Networks Perform Sufficient Dimension Reduction,"This paper investigates the connection between neural networks and sufficient
dimension reduction (SDR), demonstrating that neural networks inherently
perform SDR in regression tasks under appropriate rank regularizations.
Specifically, the weights in the first layer span the central mean subspace. We
establish the statistical consistency of the neural network-based estimator for
the central mean subspace, underscoring the suitability of neural networks in
addressing SDR-related challenges. Numerical experiments further validate our
theoretical findings, and highlight the underlying capability of neural
networks to facilitate SDR compared to the existing methods. Additionally, we
discuss an extension to unravel the central subspace, broadening the scope of
our investigation.",2024-12-26T03:05:43Z,http://arxiv.org/abs/2412.19033v1,"Shuntuo Xu, Zhou Yu"
"Ergodicity for eventually continuous Markov--Feller semigroups on Polish
  spaces","This paper investigates the ergodicity of Markov--Feller semigroups on Polish
spaces, focusing on very weak regularity conditions, particularly the Ces\`aro
eventual continuity. First, it is showed that the Ces\`aro average of such
semigroups weakly converges to an ergodic measure when starting from its
support. This leads to a characterization of the relationship between Ces\`aro
eventual continuity, Ces\`aro e-property, and weak-* mean ergodicity. Next,
serval criteria are provided for the existence and uniqueness of invariant
measures via Ces\`aro eventual continuity and lower bound conditions,
establishing an equivalence relation between weak-* mean ergodicity and a lower
bound condition. Additionally, some refined properties of ergodic decomposition
are derived. Finally, the results are applied to several non-trivial examples,
including iterated function systems, Hopf's turbulence model with random
forces, and Lorenz system with noisy perturbations, either with or without
Ces\`aro eventual continuity.",2024-12-26T02:43:50Z,http://arxiv.org/abs/2412.19029v1,"Fuzhou Gong, Yong Liu, Yuan Liu, Ziyu Liu"
"Channel-Aware Optimal Transport: A Theoretical Framework for Generative
  Communication","Optimal transport has numerous applications, particularly in machine learning
tasks involving generative models. In practice, the transportation process
often encounters an information bottleneck, typically arising from the
conversion of a communication channel into a rate-limited bit pipeline using
error correction codes. While this conversion enables a channel-oblivious
approach to optimal transport, it fails to fully exploit the available degrees
of freedom. Motivated by the emerging paradigm of generative communication,
this paper examines the problem of channel-aware optimal transport, where a
block of i.i.d. random variables is transmitted through a memoryless channel to
generate another block of i.i.d. random variables with a prescribed marginal
distribution such that the end-to-end distortion is minimized. With unlimited
common randomness available to the encoder and decoder, the source-channel
separation architecture is shown to be asymptotically optimal as the
blocklength approaches infinity. On the other hand, in the absence of common
randomness, the source-channel separation architecture is generally suboptimal.
For this scenario, a hybrid coding scheme is proposed, which partially retains
the generative capabilities of the given channel while enabling reliable
transmission of digital information. It is demonstrated that the proposed
hybrid coding scheme can outperform both separation-based and uncoded schemes.",2024-12-26T02:23:08Z,http://arxiv.org/abs/2412.19025v1,"Xiqiang Qu, Ruibin Li, Jun Chen, Lei Yu, Xinbing Wang"
"Let the Rule Speak: Enhancing In-context Learning Debiasing with
  Interpretability","In-context learning, which allows large language models to perform diverse
tasks with a few demonstrations, is found to have imbalanced per-class
prediction accuracy on multi-class text classification. Although notable output
correction methods have been developed to tackle the issue and simultaneously
improve downstream prediction accuracy, they may fail to answer the core
interpretability challenges: why and which certain classes need corrections,
and more importantly, a tailored correction for per-sample, per-class's
probability. To address such interpretability gaps, we first find that the
imbalance arises from certain classes consistently receiving high ICL output
probabilities, whereas others receiving lower or mixed ranges, so the former is
more frequently chosen, resulting in higher accuracy; more crucially, we find
that these ranges have significantly varying degrees of influence on the
accuracy bias, highlighting the need for precise, interpretable probability
corrections by range. Motivated by this, we propose FuRud, a Fuzzy Rule
Optimization based Debiasing method, that (1) detects which classes need
corrections, and (2) for each correction-needed class, detects its probability
ranges and applies asymmetric amplifications or reductions to correct them
interpretably. Notably, across seven benchmark datasets, FuRud reduces the
pairwise class accuracy bias (COBias) by more than half (56%), while achieving
a relative increase of 21% in accuracy, outperforming state-of-the-art
debiasing methods. Moreover, FuRud can optimize downstream tasks with as few as
10 optimization examples. Furthermore, FuRud can work for prompt formats that
lead to highly skewed predictions. For example, FuRud greatly improves ICL
outputs which use letter options, with 44% relative accuracy increase and 54%
relative COBias reduction.",2024-12-26T01:56:42Z,http://arxiv.org/abs/2412.19018v1,"Ruixi Lin, Yang You"
"Brain Ageing Prediction using Isolation Forest Technique and Residual
  Neural Network (ResNet)","Brain aging is a complex and dynamic process, leading to functional and
structural changes in the brain. These changes could lead to the increased risk
of neurodegenerative diseases and cognitive decline. Accurate brain-age
estimation utilizing neuroimaging data has become necessary for detecting
initial signs of neurodegeneration. Here, we propose a novel deep learning
approach using the Residual Neural Network 101 Version 2 (ResNet101V2) model to
predict brain age from MRI scans. To train, validate and test our proposed
model, we used a large dataset of 2102 images which were selected randomly from
the International Consortium for Brain Mapping (ICBM). Next, we applied data
preprocessing techniques, including normalizing the images and using outlier
detection via Isolation Forest method. Then, we evaluated various pre-trained
approaches (namely: MobileNetV2, ResNet50V2, ResNet101V2, Xception). The
results demonstrated that the ResNet101V2 model has higher performance compared
with the other models, attaining MAEs of 0.9136 and 0.8242 years for before and
after using Isolation Forest process. Our method achieved a high accuracy in
brain age estimation in ICBM dataset and it provides a reliable brain age
prediction.",2024-12-26T01:49:21Z,http://arxiv.org/abs/2412.19017v1,"Saadat Behzadi, Danial Sharifrazi, Roohallah Alizadehsani, Mojtaba Lotfaliany, Mohammadreza Mohebbi"
Dynamic networks clustering via mirror distance,"The classification of different patterns of network evolution, for example in
brain connectomes or social networks, is a key problem in network inference and
modern data science. Building on the notion of a network's Euclidean mirror,
which captures its evolution as a curve in Euclidean space, we develop the
Dynamic Network Clustering through Mirror Distance (DNCMD), an algorithm for
clustering dynamic networks based on a distance measure between their
associated mirrors. We provide theoretical guarantees for DNCMD to achieve
exact recovery of distinct evolutionary patterns for latent position random
networks both when underlying vertex features change deterministically and when
they follow a stochastic process. We validate our theoretical results through
numerical simulations and demonstrate the application of DNCMD to understand
edge functions in Drosophila larval connectome data, as well as to analyze
temporal patterns in dynamic trade networks.",2024-12-26T01:14:21Z,http://arxiv.org/abs/2412.19012v1,"Runbing Zheng, Avanti Athreya, Marta Zlatic, Michael Clayton, Carey E. Priebe"
"Geospatial Data Fusion: Combining Lidar, SAR, and Optical Imagery with
  AI for Enhanced Urban Mapping","This study explores the integration of Lidar, Synthetic Aperture Radar (SAR),
and optical imagery through advanced artificial intelligence techniques for
enhanced urban mapping. By fusing these diverse geospatial datasets, we aim to
overcome the limitations associated with single-sensor data, achieving a more
comprehensive representation of urban environments. The research employs Fully
Convolutional Networks (FCNs) as the primary deep learning model for urban
feature extraction, enabling precise pixel-wise classification of essential
urban elements, including buildings, roads, and vegetation. To optimize the
performance of the FCN model, we utilize Particle Swarm Optimization (PSO) for
hyperparameter tuning, significantly enhancing model accuracy. Key findings
indicate that the FCN-PSO model achieved a pixel accuracy of 92.3% and a mean
Intersection over Union (IoU) of 87.6%, surpassing traditional single-sensor
approaches. These results underscore the potential of fused geospatial data and
AI-driven methodologies in urban mapping, providing valuable insights for urban
planning and management. The implications of this research pave the way for
future developments in real-time mapping and adaptive urban infrastructure
planning.",2024-12-25T22:17:31Z,http://arxiv.org/abs/2412.18994v1,"Sajjad Afroosheh, Mohammadreza Askari"
"Optimal Federated Learning for Functional Mean Estimation under
  Heterogeneous Privacy Constraints","Federated learning (FL) is a distributed machine learning technique designed
to preserve data privacy and security, and it has gained significant importance
due to its broad range of applications. This paper addresses the problem of
optimal functional mean estimation from discretely sampled data in a federated
setting.
  We consider a heterogeneous framework where the number of individuals,
measurements per individual, and privacy parameters vary across one or more
servers, under both common and independent design settings. In the common
design setting, the same design points are measured for each individual,
whereas in the independent design, each individual has their own random
collection of design points. Within this framework, we establish minimax upper
and lower bounds for the estimation error of the underlying mean function,
highlighting the nuanced differences between common and independent designs
under distributed privacy constraints.
  We propose algorithms that achieve the optimal trade-off between privacy and
accuracy and provide optimality results that quantify the fundamental limits of
private functional mean estimation across diverse distributed settings. These
results characterize the cost of privacy and offer practical insights into the
potential for privacy-preserving statistical analysis in federated
environments.",2024-12-25T22:06:12Z,http://arxiv.org/abs/2412.18992v1,"Tony Cai, Abhinav Chakraborty, Lasse Vuursteen"
"Detection and classification of DDoS flooding attacks by machine
  learning method","This study focuses on a method for detecting and classifying distributed
denial of service (DDoS) attacks, such as SYN Flooding, ACK Flooding, HTTP
Flooding, and UDP Flooding, using neural networks. Machine learning,
particularly neural networks, is highly effective in detecting malicious
traffic. A dataset containing normal traffic and various DDoS attacks was used
to train a neural network model with a 24-106-5 architecture. The model
achieved high Accuracy (99.35%), Precision (99.32%), Recall (99.54%), and
F-score (0.99) in the classification task. All major attack types were
correctly identified. The model was also further tested in the lab using
virtual infrastructures to generate normal and DDoS traffic. The results showed
that the model can accurately classify attacks under near-real-world
conditions, demonstrating 95.05% accuracy and balanced F-score scores for all
attack types. This confirms that neural networks are an effective tool for
detecting DDoS attacks in modern information security systems.",2024-12-25T21:58:52Z,http://arxiv.org/abs/2412.18990v1,"Dmytro Tymoshchuk, Oleh Yasniy, Mykola Mytnyk, Nataliya Zagorodna, Vitaliy Tymoshchuk"
Injecting Bias into Text Classification Models using Backdoor Attacks,"The rapid growth of natural language processing (NLP) and pre-trained
language models have enabled accurate text classification in a variety of
settings. However, text classification models are susceptible to backdoor
attacks, where an attacker embeds a trigger into the victim model to make the
model predict attacker-desired labels in targeted scenarios. In this paper, we
propose to utilize backdoor attacks for a new purpose: bias injection. We
develop a backdoor attack in which a subset of the training dataset is poisoned
to associate strong male actors with negative sentiment. We execute our attack
on two popular text classification datasets (IMDb and SST) and seven different
models ranging from traditional Doc2Vec-based models to LSTM networks and
modern transformer-based BERT and RoBERTa models. Our results show that the
reduction in backdoored models' benign classification accuracy is limited,
implying that our attacks remain stealthy, whereas the models successfully
learn to associate strong male actors with negative sentiment (100% attack
success rate with &gt;= 3% poison rate). Attacks on BERT and RoBERTa are
particularly more stealthy and effective, demonstrating an increased risk of
using modern and larger models. We also measure the generalizability of our
bias injection by proposing two metrics: (i) U-BBSR which uses previously
unseen words when measuring attack success, and (ii) P-BBSR which measures
attack success using paraphrased test samples. U-BBSR and P-BBSR results show
that the bias injected by our attack can go beyond memorizing a trigger phrase.",2024-12-25T19:32:02Z,http://arxiv.org/abs/2412.18975v1,"A. Dilara Yavuz, M. Emre Gursoy"
TINQ: Temporal Inconsistency Guided Blind Video Quality Assessment,"Blind video quality assessment (BVQA) has been actively researched for
user-generated content (UGC) videos. Recently, super-resolution (SR) techniques
have been widely applied in UGC. Therefore, an effective BVQA method for both
UGC and SR scenarios is essential. Temporal inconsistency, referring to
irregularities between consecutive frames, is relevant to video quality.
Current BVQA approaches typically model temporal relationships in UGC videos
using statistics of motion information, but inconsistencies remain unexplored.
Additionally, different from temporal inconsistency in UGC videos, such
inconsistency in SR videos is amplified due to upscaling algorithms. In this
paper, we introduce the Temporal Inconsistency Guided Blind Video Quality
Assessment (TINQ) metric, demonstrating that exploring temporal inconsistency
is crucial for effective BVQA. Since temporal inconsistencies vary between UGC
and SR videos, they are calculated in different ways. Based on this, a spatial
module highlights inconsistent areas across consecutive frames at coarse and
fine granularities. In addition, a temporal module aggregates features over
time in two stages. The first stage employs a visual memory capacity block to
adaptively segment the time dimension based on estimated complexity, while the
second stage focuses on selecting key features. The stages work together
through Consistency-aware Fusion Units to regress cross-time-scale video
quality. Extensive experiments on UGC and SR video quality datasets show that
our method outperforms existing state-of-the-art BVQA methods. Code is
available at https://github.com/Lighting-YXLI/TINQ.",2024-12-25T15:43:41Z,http://arxiv.org/abs/2412.18933v1,"Yixiao Li, Xiaoyuan Yang, Weide Liu, Xin Jin, Xu Jia, Yukun Lai, Haotao Liu, Paul L Rosin, Wei Zhou"
"Malware Classification using a Hybrid Hidden Markov Model-Convolutional
  Neural Network","The proliferation of malware variants poses a significant challenges to
traditional malware detection approaches, such as signature-based methods,
necessitating the development of advanced machine learning techniques. In this
research, we present a novel approach based on a hybrid architecture combining
features extracted using a Hidden Markov Model (HMM), with a Convolutional
Neural Network (CNN) then used for malware classification. Inspired by the
strong results in previous work using an HMM-Random Forest model, we propose
integrating HMMs, which serve to capture sequential patterns in opcode
sequences, with CNNs, which are adept at extracting hierarchical features. We
demonstrate the effectiveness of our approach on the popular Malicia dataset,
and we obtain superior performance, as compared to other machine learning
methods -- our results surpass the aforementioned HMM-Random Forest model. Our
findings underscore the potential of hybrid HMM-CNN architectures in bolstering
malware classification capabilities, offering several promising avenues for
further research in the field of cybersecurity.",2024-12-25T15:34:57Z,http://arxiv.org/abs/2412.18932v1,"Ritik Mehta, Olha Jureckova, Mark Stamp"
"Alternating Gradient-Type Algorithm for Bilevel Optimization with
  Inexact Lower-Level Solutions via Moreau Envelope-based Reformulation","In this paper, we study a class of bilevel optimization problems where the
lower-level problem is a convex composite optimization model, which arises in
various applications, including bilevel hyperparameter selection for
regularized regression models. To solve these problems, we propose an
Alternating Gradient-type algorithm with Inexact Lower-level Solutions (AGILS)
based on a Moreau envelope-based reformulation of the bilevel optimization
problem. The proposed algorithm does not require exact solutions of the
lower-level problem at each iteration, improving computational efficiency. We
prove the convergence of AGILS to stationary points and, under the
Kurdyka-{\L}ojasiewicz (KL) property, establish its sequential convergence.
Numerical experiments, including a toy example and a bilevel hyperparameter
selection problem for the sparse group Lasso model, demonstrate the
effectiveness of the proposed AGILS.",2024-12-25T15:19:36Z,http://arxiv.org/abs/2412.18929v1,"Xiaoning Bai, Shangzhi Zeng, and Jin Zhang, Lezhi Zhang"
"An Attentive Dual-Encoder Framework Leveraging Multimodal Visual and
  Semantic Information for Automatic OSAHS Diagnosis","Obstructive sleep apnea-hypopnea syndrome (OSAHS) is a common sleep disorder
caused by upper airway blockage, leading to oxygen deprivation and disrupted
sleep. Traditional diagnosis using polysomnography (PSG) is expensive,
time-consuming, and uncomfortable. Existing deep learning methods using facial
image analysis lack accuracy due to poor facial feature capture and limited
sample sizes. To address this, we propose a multimodal dual encoder model that
integrates visual and language inputs for automated OSAHS diagnosis. The model
balances data using randomOverSampler, extracts key facial features with
attention grids, and converts physiological data into meaningful text.
Cross-attention combines image and text data for better feature extraction, and
ordered regression loss ensures stable learning. Our approach improves
diagnostic efficiency and accuracy, achieving 91.3% top-1 accuracy in a
four-class severity classification task, demonstrating state-of-the-art
performance. Code will be released upon acceptance.",2024-12-25T14:42:17Z,http://arxiv.org/abs/2412.18919v1,"Yingchen Wei, Xihe Qiu, Xiaoyu Tan, Jingjing Huang, Wei Chu, Yinghui Xu, Yuan Qi"
"BCR-Net: Boundary-Category Refinement Network for Weakly Semi-Supervised
  X-Ray Prohibited Item Detection with Points","Automatic prohibited item detection in X-ray images is crucial for public
safety. However, most existing detection methods either rely on expensive box
annotations to achieve high performance or use weak annotations but suffer from
limited accuracy. To balance annotation cost and detection performance, we
study Weakly Semi-Supervised X-ray Prohibited Item Detection with Points
(WSSPID-P) and propose a novel \textbf{B}oundary-\textbf{C}ategory
\textbf{R}efinement \textbf{Net}work (\textbf{BCR-Net}) that requires only a
few box annotations and a large number of point annotations. BCR-Net is built
based on Group R-CNN and introduces a new Boundary Refinement (BR) module and a
new Category Refinement (CR) module. The BR module develops a dual attention
mechanism to focus on both the boundaries and salient features of prohibited
items. Meanwhile, the CR module incorporates contrastive branches into the
heads of RPN and ROI by introducing a scale- and rotation-aware contrastive
loss, enhancing intra-class consistency and inter-class separability in the
feature space. Based on the above designs, BCR-Net effectively addresses the
closely related problems of imprecise localization and inaccurate
classification. Experimental results on public X-ray datasets show the
effectiveness of BCR-Net, achieving significant performance improvements to
state-of-the-art methods under limited annotations.",2024-12-25T14:37:05Z,http://arxiv.org/abs/2412.18918v1,Sanjoeng Wong
Quantitative estimates of the singular values of random i.i.d. matrices,"Let $M$ be an $n\times n$ random i.i.d. matrix. This paper studies the
deviation inequality of $s_{n-k+1}(M)$, the $k$-th smallest singular value of
$M$. In particular, when the entries of $M$ are subgaussian, we show that for
any $\gamma\in (0, 1/2), \varepsilon&gt;0$ and $\log n\le k\le c\sqrt{n}$
  \begin{align}
  \textsf{P}\{s_{n-k+1}(M)\le \frac{\varepsilon}{\sqrt{n}} \}\le \Big(
\frac{C\varepsilon}{k}\Big)^{\gamma k^{2}}+e^{-c_{1}kn}.\nonumber
  \end{align}
  This result improves an existing result of Nguyen, which obtained a deviation
inequality of $s_{n-k+1}(M)$ with $(C\varepsilon/k)^{\gamma k^{2}}+e^{-cn}$
decay.",2024-12-25T14:01:39Z,http://arxiv.org/abs/2412.18912v1,"Guozheng Dai, Zhonggen Su, Hanchao Wang"
Relaxation behavior near the first-order phase transition line,"Using the Metropolis algorithm, we simulate the relaxation process of the
three-dimensional kinetic Ising model. Starting from a random initial
configuration, we first present the average equilibration time across the
entire phase boundary. It is observed that the average equilibration time
increases significantly as the temperature decreases from the critical
temperature ($T_{\rm c}$). The average equilibration time along the first-order
phase transition (1st-PT) line exhibits an ultra-slow relaxation. We also
investigate the dynamic scaling behavior with system sizes, and find that
dynamic scaling holds not only at $T_{\rm c}$, but also below $T_{\rm c}$. The
dynamic exponent below $T_{\rm c}$ is larger than that at $T_{\rm c}$.
Additionally, we analyze the dynamic scaling of the average autocorrelation
time and find that it depends on system size only near $T_{\rm c}$, while it
becomes size-independent both above and below $T_{\rm c}$. The extremely slow
relaxation dynamics observed near the 1st-PT is attributed to the complex
structure of the free energy.",2024-12-25T13:56:18Z,http://arxiv.org/abs/2412.18909v1,"Xiaobing Li, Ranran Guo, Mingmei Xu, Yu Zhou, Jinghua Fu, Yuanfang Wu"
"Research Experiment on Multi-Model Comparison for Chinese Text
  Classification Tasks","With the explosive growth of Chinese text data and advancements in natural
language processing technologies, Chinese text classification has become one of
the key techniques in fields such as information retrieval and sentiment
analysis, attracting increasing attention. This paper conducts a comparative
study on three deep learning models:TextCNN, TextRNN, and FastText.specifically
for Chinese text classification tasks. By conducting experiments on the
THUCNews dataset, the performance of these models is evaluated, and their
applicability in different scenarios is discussed.",2024-12-25T13:54:40Z,http://arxiv.org/abs/2412.18908v1,JiaCheng Li
"The Rank and Singular Values of the Inhomogeneous Subgaussian Random
  Matrices","Let A be an n*n random matrix with mean zero and independent inhomogeneous
non-constant subgaussian entries. We get that for some k, the probability of
the matrix has a lower rank than $n-k$ that is sub-exponential.Furthermore, we
get a deviation inequality for the singular values of A in this paper.
  This extends earlier results of Rudelson's paper in 2024 by removing the
assumption of the identical distribution of the entries across the matrix. Our
model covers inhomogeneous matrices, allowing different subgaussian moments for
the entries as long as their subgaussian moments have a standard upper bound
  In the past advance, the assumption of i.i.d entries was required due to the
lack of least common denominators of the non-i.i.d random matrix. We can
overcome this problem using a Randomized least common denominator (RLCD) from
Livshyts in 2021.",2024-12-25T13:37:23Z,http://arxiv.org/abs/2412.18906v1,"Guozheng Dai, Zeyan Song, Hanchao Wang"
"Adversarial Training for Graph Neural Networks via Graph Subspace Energy
  Optimization","Despite impressive capability in learning over graph-structured data, graph
neural networks (GNN) suffer from adversarial topology perturbation in both
training and inference phases. While adversarial training has demonstrated
remarkable effectiveness in image classification tasks, its suitability for GNN
models has been doubted until a recent advance that shifts the focus from
transductive to inductive learning. Still, GNN robustness in the inductive
setting is under-explored, and it calls for deeper understanding of GNN
adversarial training. To this end, we propose a new concept of graph subspace
energy (GSE) -- a generalization of graph energy that measures graph stability
-- of the adjacency matrix, as an indicator of GNN robustness against topology
perturbations. To further demonstrate the effectiveness of such concept, we
propose an adversarial training method with the perturbed graphs generated by
maximizing the GSE regularization term, referred to as AT-GSE. To deal with the
local and global topology perturbations raised respectively by LRBCD and PRBCD,
we employ randomized SVD (RndSVD) and Nystrom low-rank approximation to favor
the different aspects of the GSE terms. An extensive set of experiments shows
that AT-GSE outperforms consistently the state-of-the-art GNN adversarial
training methods over different homophily and heterophily datasets in terms of
adversarial accuracy, whilst more surprisingly achieving a superior clean
accuracy on non-perturbed graphs.",2024-12-25T12:04:18Z,http://arxiv.org/abs/2412.18886v1,"Ganlin Liu, Ziling Liang, Xiaowei Huang, Xinping Yi, Shi Jin"
MotionMap: Representing Multimodality in Human Pose Forecasting,"Human pose forecasting is inherently multimodal since multiple futures exist
for an observed pose sequence. However, evaluating multimodality is challenging
since the task is ill-posed. Therefore, we first propose an alternative
paradigm to make the task well-posed. Next, while state-of-the-art methods
predict multimodality, this requires oversampling a large volume of
predictions. This raises key questions: (1) Can we capture multimodality by
efficiently sampling a smaller number of predictions? (2) Subsequently, which
of the predicted futures is more likely for an observed pose sequence? We
address these questions with MotionMap, a simple yet effective heatmap based
representation for multimodality. We extend heatmaps to represent a spatial
distribution over the space of all possible motions, where different local
maxima correspond to different forecasts for a given observation. MotionMap can
capture a variable number of modes per observation and provide confidence
measures for different modes. Further, MotionMap allows us to introduce the
notion of uncertainty and controllability over the forecasted pose sequence.
Finally, MotionMap captures rare modes that are non-trivial to evaluate yet
critical for safety. We support our claims through multiple qualitative and
quantitative experiments using popular 3D human pose datasets: Human3.6M and
AMASS, highlighting the strengths and limitations of our proposed method.
Project Page: https://www.epfl.ch/labs/vita/research/prediction/motionmap/",2024-12-25T11:47:26Z,http://arxiv.org/abs/2412.18883v1,"Reyhaneh Hosseininejad, Megh Shukla, Saeed Saadatnejad, Mathieu Salzmann, Alexandre Alahi"
"TSceneJAL: Joint Active Learning of Traffic Scenes for 3D Object
  Detection","Most autonomous driving (AD) datasets incur substantial costs for collection
and labeling, inevitably yielding a plethora of low-quality and redundant data
instances, thereby compromising performance and efficiency. Many applications
in AD systems necessitate high-quality training datasets using both existing
datasets and newly collected data. In this paper, we propose a traffic scene
joint active learning (TSceneJAL) framework that can efficiently sample the
balanced, diverse, and complex traffic scenes from both labeled and unlabeled
data. The novelty of this framework is threefold: 1) a scene sampling scheme
based on a category entropy, to identify scenes containing multiple object
classes, thus mitigating class imbalance for the active learner; 2) a
similarity sampling scheme, estimated through the directed graph representation
and a marginalize kernel algorithm, to pick sparse and diverse scenes; 3) an
uncertainty sampling scheme, predicted by a mixture density network, to select
instances with the most unclear or complex regression outcomes for the learner.
Finally, the integration of these three schemes in a joint selection strategy
yields an optimal and valuable subdataset. Experiments on the KITTI, Lyft,
nuScenes and SUScape datasets demonstrate that our approach outperforms
existing state-of-the-art methods on 3D object detection tasks with up to 12%
improvements.",2024-12-25T11:07:04Z,http://arxiv.org/abs/2412.18870v1,"Chenyang Lei, Meiying Zhang, Weiyuan Peng, Qi Hao, Chengzhong Xu, Chunlin Ji, Guang Zhou"
"Digital Twin Enhanced Deep Reinforcement Learning for Intelligent
  Omni-Surface Configurations in MU-MIMO Systems","Intelligent omni-surface (IOS) is a promising technique to enhance the
capacity of wireless networks, by reflecting and refracting the incident signal
simultaneously. Traditional IOS configuration schemes, relying on all
sub-channels' channel state information and user equipments' mobility, are
difficult to implement in complex realistic systems. Existing works attempt to
address this issue employing deep reinforcement learning (DRL), but this method
requires a lot of trial-and-error interactions with the external environment
for efficient results and thus cannot satisfy the real-time decision-making. To
enable model-free and real-time IOS control, this paper puts forth a new
framework that integrates DRL and digital twins. DeepIOS, a DRL based IOS
configuration scheme with the goal of maximizing the sum data rate, is first
developed to jointly optimize the phase-shift and amplitude of IOS in
multi-user multiple-input-multiple-output systems. Thereafter, to further
reduce the computational complexity, DeepIOS introduces an action branch
architecture, which separately decides two optimization variables in parallel.
Finally, a digital twin module is constructed through supervised learning as a
pre-verification platform for DeepIOS, such that the decision-making's
real-time can be guaranteed. The formulated framework is a closed-loop system,
in which the physical space provides data to establish and calibrate the
digital space, while the digital space generates experience samples for DeepIOS
training and sends the trained parameters to the IOS controller for
configurations. Numerical results show that compared with random and MAB
schemes, the proposed framework attains a higher data rate and is more robust
to different settings. Furthermore, the action branch architecture reduces
DeepIOS's computational complexity, and the digital twin module improves the
convergence speed and run-time.",2024-12-25T09:53:07Z,http://arxiv.org/abs/2412.18856v1,"Xiaowen Ye, Xianghao Yu, Liqun Fu"
"Dynamics of Topological Defects in a Rashba Spin-Orbit Coupled
  Bose-Einstein Condensate","We investigate the quench dynamics of a two-dimensional Rashba spin-orbit
coupled Bose-Einstein condensate. Our study focuses on quenching the system
from a zero-momentum phase to a plane-wave phase. During this quench,
topological defects emerge in the form of vortices. These vortices and
anti-vortices exhibit a random spatial distribution with equal numbers,
mirroring the core principles of Kosterlitz-Thouless physics. In a uniform
system, we observe an exponential scaling of both the vortex production time
and the vortex number with the quench rate, consistent with the conventional
Kibble-Zurek mechanism. The decay of which adheres to a logarithmic law,
aligning with experimental observations.",2024-12-25T09:31:42Z,http://arxiv.org/abs/2412.18850v1,"Sheng Liu, Yong-Sheng Zhang"
"SWAG: Long-term Surgical Workflow Prediction with Generative-based
  Anticipation","While existing recognition approaches excel at identifying current surgical
phases, they provide limited foresight into future procedural steps,
restricting their intraoperative utility. Similarly, current anticipation
methods are constrained to predicting short-term events or singular future
occurrences, neglecting the dynamic and sequential nature of surgical
workflows. To address these limitations, we propose SWAG (Surgical Workflow
Anticipative Generation), a unified framework for phase recognition and
long-term anticipation of surgical workflows. SWAG employs two generative
decoding methods -- single-pass (SP) and auto-regressive (AR) -- to predict
sequences of future surgical phases. A novel prior knowledge embedding
mechanism enhances the accuracy of anticipatory predictions. The framework
addresses future phase classification and remaining time regression tasks.
Additionally, a regression-to-classification (R2C) method is introduced to map
continuous predictions to discrete temporal segments. SWAG's performance was
evaluated on the Cholec80 and AutoLaparo21 datasets. The single-pass
classification model with prior knowledge embeddings (SWAG-SP\*) achieved
53.5\% accuracy in 15-minute anticipation on AutoLaparo21, while the R2C model
reached 60.8\% accuracy on Cholec80. SWAG's single-pass regression approach
outperformed existing methods for remaining time prediction, achieving weighted
mean absolute errors of 0.32 and 0.48 minutes for 2- and 3-minute horizons,
respectively. SWAG demonstrates versatility across classification and
regression tasks, offering robust tools for real-time surgical workflow
anticipation. By unifying recognition and anticipatory capabilities, SWAG
provides actionable predictions to enhance intraoperative decision-making.",2024-12-25T09:29:57Z,http://arxiv.org/abs/2412.18849v1,"Maxence Boels, Yang Liu, Prokar Dasgupta, Alejandro Granados, Sebastien Ourselin"
Machine Learning-Based Detection of Pump-and-Dump Schemes in Real-Time,"Cryptocurrency markets often face manipulation through prevalent
pump-and-dump (P&amp;D) schemes, where self-organized Telegram groups, some
exceeding two million members, artificially inflate target cryptocurrency
prices. These groups sell premium access to inside information, worsening
information asymmetry and financial risks for subscribers and all investors.
This paper presents a real-time prediction pipeline to forecast target coins
and alert investors to possible P&amp;D schemes. In a Poloniex case study, the
model accurately identified the target coin among the top five from 50 random
coins in 24 out of 43 (55.81%) P&amp;D events. The pipeline uses advanced natural
language processing (NLP) to classify Telegram messages, identifying 2,079 past
pump events and detecting new ones in real-time. Our analysis also evaluates
the susceptibility of token standards - ERC-20, ERC-721, BRC-20, Inscriptions,
and Runes - to manipulation and identifies exchanges commonly involved in P&amp;D
schemes.",2024-12-25T09:23:36Z,http://arxiv.org/abs/2412.18848v1,"Manuel Bolz, Kevin Bründler, Liam Kane, Panagiotis Patsias, Liam Tessendorf, Krzysztof Gogol, Taehoon Kim, Claudio Tessone"
Quantifying the memory and dynamical stability of magnetar bursts,"The time series of energy and waiting time of magnetar bursts carry important
information about the source activity. In this paper, we investigate the memory
and dynamical stability of magnetar bursts from four soft gamma repeater (SGR)
sources: SGR 1806$-$20, SGR 1900+14, SGR J1935+2154 and SGR J1550$-$5418. Based
on the rescaled range analysis, we quantify the memory in magnetar bursts for
the first time and find that there exists long-term memory in the time series
of both waiting time and energy. We investigate the dynamical stability in the
context of randomness and chaos. For all the four SGR samples, we find that the
waiting time is not completely random, but the energy of two SGRs is consistent
with a total random organization. Furthermore, both waiting time and energy
exhibits weak chaos. We also find no significant difference between SGRs and
repeating fast radio bursts (FRBs) in the randomness-chaos phase space. The
statistical similarity between SGRs and repeating FRBs hints that there may be
potential physical connection between these two phenomena.",2024-12-25T08:22:36Z,http://arxiv.org/abs/2412.18821v1,"Yu Sang, Hai-Nan Lin"
A Tractable Approach for Queueing Analysis on Buffer-Aware Scheduling,"Low-latency communication has recently attracted considerable attention owing
to its potential of enabling delay-sensitive services in next-generation
industrial cyber-physical systems. To achieve target average or maximum delay
given random arrivals and time-varying channels, buffer-aware scheduling is
expected to play a vital role. Evaluating and optimizing buffer-aware
scheduling relies on its queueing analysis, while existing tools are not
sufficiently tractable. Particularly, Markov chain and Monte-Carlo based
approaches are computationally intensive, while large deviation theory (LDT)
and extreme value theory (EVT) fail in providing satisfactory accuracy in the
small-queue-length (SQL) regime. To tackle these challenges, a tractable yet
accurate queueing analysis is presented by judiciously bridging Markovian
analysis for the computationally manageable SQL regime and LDT/EVT for
large-queue-length (LQL) regime where approximation error diminishes
asymptotically. Specifically, we leverage censored Markov chain augmentation to
approximate the original one in the SQL regime, while a piecewise approach is
conceived to apply LDT/EVT across various queue-length intervals with different
scheduling parameters. Furthermore, we derive closed-form bounds on
approximation errors, validating the rigor and accuracy of our approach. As a
case study, the approach is applied to analytically analyze a
Lyapunov-drift-based cross-layer scheduling for wireless transmissions.
Numerical results demonstrate its potential in balancing accuracy and
complexity.",2024-12-25T07:46:27Z,http://arxiv.org/abs/2412.18812v1,"Lintao Li, Wei Chen"
Provable Uncertainty Decomposition via Higher-Order Calibration,"We give a principled method for decomposing the predictive uncertainty of a
model into aleatoric and epistemic components with explicit semantics relating
them to the real-world data distribution. While many works in the literature
have proposed such decompositions, they lack the type of formal guarantees we
provide. Our method is based on the new notion of higher-order calibration,
which generalizes ordinary calibration to the setting of higher-order
predictors that predict mixtures over label distributions at every point. We
show how to measure as well as achieve higher-order calibration using access to
$k$-snapshots, namely examples where each point has $k$ independent conditional
labels. Under higher-order calibration, the estimated aleatoric uncertainty at
a point is guaranteed to match the real-world aleatoric uncertainty averaged
over all points where the prediction is made. To our knowledge, this is the
first formal guarantee of this type that places no assumptions whatsoever on
the real-world data distribution. Importantly, higher-order calibration is also
applicable to existing higher-order predictors such as Bayesian and ensemble
models and provides a natural evaluation metric for such models. We demonstrate
through experiments that our method produces meaningful uncertainty
decompositions for image classification.",2024-12-25T07:26:36Z,http://arxiv.org/abs/2412.18808v1,"Gustaf Ahdritz, Aravind Gollakota, Parikshit Gopalan, Charlotte Peale, Udi Wieder"
"Ister: Inverted Seasonal-Trend Decomposition Transformer for Explainable
  Multivariate Time Series Forecasting","In long-term time series forecasting, Transformer-based models have achieved
great success, due to its ability to capture long-range dependencies. However,
existing transformer-based methods face challenges in accurately identifying
which variables play a pivotal role in the prediction process and tend to
overemphasize noisy channels, thereby limiting the interpretability and
practical effectiveness of the models. Besides, it faces scalability issues due
to quadratic computational complexity of self-attention. In this paper, we
propose a new model named Inverted Seasonal-Trend Decomposition Transformer
(Ister), which addresses these challenges in long-term multivariate time series
forecasting by designing an improved Transformer-based structure. Ister firstly
decomposes original time series into seasonal and trend components. Then we
propose a new Dot-attention mechanism to process the seasonal component, which
improves both accuracy, computation complexity and interpretability. Upon
completion of the training phase, it allows users to intuitively visualize the
significance of each feature in the overall prediction. We conduct
comprehensive experiments, and the results show that Ister achieves
state-of-the-art (SOTA) performance on multiple datasets, surpassing existing
models in long-term prediction tasks.",2024-12-25T06:37:19Z,http://arxiv.org/abs/2412.18798v1,"Fanpu Cao, Shu Yang, Zhengjian Chen, Ye Liu, Laizhong Cui"
Torque-Aware Momentum,"Efficiently exploring complex loss landscapes is key to the performance of
deep neural networks. While momentum-based optimizers are widely used in
state-of-the-art setups, classical momentum can still struggle with large,
misaligned gradients, leading to oscillations. To address this, we propose
Torque-Aware Momentum (TAM), which introduces a damping factor based on the
angle between the new gradients and previous momentum, stabilizing the update
direction during training. Empirical results show that TAM, which can be
combined with both SGD and Adam, enhances exploration, handles distribution
shifts more effectively, and improves generalization performance across various
tasks, including image classification and large language model fine-tuning,
when compared to classical momentum-based optimizers.",2024-12-25T05:58:07Z,http://arxiv.org/abs/2412.18790v1,"Pranshu Malviya, Goncalo Mordido, Aristide Baratin, Reza Babanezhad Harikandeh, Gintare Karolina Dziugaite, Razvan Pascanu, Sarath Chandar"
"Computational Analysis of Yaredawi YeZema Silt in Ethiopian Orthodox
  Tewahedo Church Chants","Despite its musicological, cultural, and religious significance, the
Ethiopian Orthodox Tewahedo Church (EOTC) chant is relatively underrepresented
in music research. Historical records, including manuscripts, research papers,
and oral traditions, confirm Saint Yared's establishment of three canonical
EOTC chanting modes during the 6th century. This paper attempts to investigate
the EOTC chants using music information retrieval (MIR) techniques. Among the
research questions regarding the analysis and understanding of EOTC chants,
Yaredawi YeZema Silt, namely the mode of chanting adhering to Saint Yared's
standards, is of primary importance. Therefore, we consider the task of
Yaredawi YeZema Silt classification in EOTC chants by introducing a new dataset
and showcasing a series of classification experiments for this task. Results
show that using the distribution of stabilized pitch contours as the feature
representation on a simple neural network-based classifier becomes an effective
solution. The musicological implications and insights of such results are
further discussed through a comparative study with the previous ethnomusicology
literature on EOTC chants. By making this dataset publicly accessible, we aim
to promote future exploration and analysis of EOTC chants and highlight
potential directions for further research, thereby fostering a deeper
understanding and preservation of this unique spiritual and cultural heritage.",2024-12-25T05:42:56Z,http://arxiv.org/abs/2412.18788v1,"Mequanent Argaw Muluneh, Yan-Tsung Peng, Li Su"
"Robustness Evaluation of Offline Reinforcement Learning for Robot
  Control Against Action Perturbations","Offline reinforcement learning, which learns solely from datasets without
environmental interaction, has gained attention. This approach, similar to
traditional online deep reinforcement learning, is particularly promising for
robot control applications. Nevertheless, its robustness against real-world
challenges, such as joint actuator faults in robots, remains a critical
concern. This study evaluates the robustness of existing offline reinforcement
learning methods using legged robots from OpenAI Gym based on average episodic
rewards. For robustness evaluation, we simulate failures by incorporating both
random and adversarial perturbations, representing worst-case scenarios, into
the joint torque signals. Our experiments show that existing offline
reinforcement learning methods exhibit significant vulnerabilities to these
action perturbations and are more vulnerable than online reinforcement learning
methods, highlighting the need for more robust approaches in this field.",2024-12-25T05:02:22Z,http://arxiv.org/abs/2412.18781v1,"Shingo Ayabe, Takuto Otomo, Hiroshi Kera, Kazuhiko Kawamoto"
"Integrating Zero-Shot Classification to Advance Long COVID Literature: A
  Systematic Social Media-Centered Review","Long COVID continues to challenge public health by affecting a significant
segment of individuals who have recovered from acute SARS-CoV-2 infection yet
endure prolonged and often debilitating symptoms. Social media has emerged as a
vital resource for those seeking real-time information, peer support, and
validating their health concerns related to Long COVID. This paper examines
recent works focusing on mining, analyzing, and interpreting user-generated
content on social media platforms such as Twitter, Reddit, Facebook, and
YouTube to capture the broader discourse on persistent post-COVID conditions. A
novel transformer-based zero-shot learning approach serves as the foundation
for classifying research papers in this area into four primary categories:
Clinical or Symptom Characterization, Advanced NLP or Computational Methods,
Policy, Advocacy, or Public Health Communication, and Online Communities and
Social Support. This methodology showcases the adaptability of advanced
language models in categorizing research papers without predefined training
labels, thus enabling a more rapid and scalable assessment of existing
literature. This review highlights the multifaceted nature of Long COVID
research, where computational techniques applied to social media data reveal
insights into narratives of individuals suffering from Long COVID. This review
also demonstrates the capacity of social media analytics to inform clinical
practice and contribute to policy-making related to Long COVID.",2024-12-25T05:01:17Z,http://arxiv.org/abs/2412.18779v1,Nirmalya Thakur
"Unified Local and Global Attention Interaction Modeling for Vision
  Transformers","We present a novel method that extends the self-attention mechanism of a
vision transformer (ViT) for more accurate object detection across diverse
datasets. ViTs show strong capability for image understanding tasks such as
object detection, segmentation, and classification. This is due in part to
their ability to leverage global information from interactions among visual
tokens. However, the self-attention mechanism in ViTs are limited because they
do not allow visual tokens to exchange local or global information with
neighboring features before computing global attention. This is problematic
because tokens are treated in isolation when attending (matching) to other
tokens, and valuable spatial relationships are overlooked. This isolation is
further compounded by dot-product similarity operations that make tokens from
different semantic classes appear visually similar. To address these
limitations, we introduce two modifications to the traditional self-attention
framework; a novel aggressive convolution pooling strategy for local feature
mixing, and a new conceptual attention transformation to facilitate interaction
and feature exchange between semantic concepts. Experimental results
demonstrate that local and global information exchange among visual features
before self-attention significantly improves performance on challenging object
detection tasks and generalizes across multiple benchmark datasets and
challenging medical datasets. We publish source code and a novel dataset of
cancerous tumors (chimeric cell clusters).",2024-12-25T04:53:19Z,http://arxiv.org/abs/2412.18778v1,"Tan Nguyen, Coy D. Heldermon, Corey Toler-Franklin"
"Arc-transitive maps with edge number coprime to the Euler characteristic
  -- I","This is one of a series of papers which aim towards a classification of
edge-transitive maps of which the Euler characteristic and the edge number are
coprime. This one establishes a framework and carries out the classification
work for arc-transitive maps with solvable automorphism groups, which
illustrates how the edge number impacts on the Euler characteristic for maps.
The classification is involved with the constructions of various new and
interesting arc-regular maps.",2024-12-25T03:07:33Z,http://arxiv.org/abs/2412.18758v1,"Caiheng Li, Luyi Liu"
"Towards a Statistical Understanding of Neural Networks: Beyond the
  Neural Tangent Kernel Theories","A primary advantage of neural networks lies in their feature learning
characteristics, which is challenging to theoretically analyze due to the
complexity of their training dynamics. We propose a new paradigm for studying
feature learning and the resulting benefits in generalizability. After
reviewing the neural tangent kernel (NTK) theory and recent results in kernel
regression, which address the generalization issue of sufficiently wide neural
networks, we examine limitations and implications of the fixed kernel theory
(as the NTK theory) and review recent theoretical advancements in feature
learning. Moving beyond the fixed kernel/feature theory, we consider neural
networks as adaptive feature models. Finally, we propose an over-parameterized
Gaussian sequence model as a prototype model to study the feature learning
characteristics of neural networks.",2024-12-25T03:03:58Z,http://arxiv.org/abs/2412.18756v1,"Haobo Zhang, Jianfa Lai, Yicheng Li, Qian Lin, Jun S. Liu"
The moments of the spectral form factor in SYK,"In chaotic quantum systems the spectral form factor exhibits a universal
linear ramp and plateau structure with superimposed erratic oscillations. The
mean signal and the statistics of the noise can be probed by the moments of the
spectral form factor, also known as higher-point spectral form factors. We
identify saddle points in the SYK model that describe the moments during the
ramp region. Perturbative corrections around the saddle point indicate that SYK
mimics random matrix statistics for the low order moments, while large
deviations for the high order moments arise from fluctuations near the edge of
the spectrum. The leading correction scales inversely with the number of random
parameters in the SYK Hamiltonian and is amplified in a sparsified version of
the SYK model, which we study numerically, even in regimes where a linear ramp
persists. Finally, we study the $q=2$ SYK model, whose spectral form factor
exhibits an exponential ramp with increased noise. These findings reveal how
deviations from random matrix universality arise in disordered systems and
motivate their interpretation from a bulk gravitational perspective.",2024-12-25T01:50:28Z,http://arxiv.org/abs/2412.18737v1,"Andrea Legramandi, Neil Talwar"
"Predicting Time Series of Networked Dynamical Systems without Knowing
  Topology","Many real-world complex systems, such as epidemic spreading networks and
ecosystems, can be modeled as networked dynamical systems that produce
multivariate time series. Learning the intrinsic dynamics from observational
data is pivotal for forecasting system behaviors and making informed decisions.
However, existing methods for modeling networked time series often assume known
topologies, whereas real-world networks are typically incomplete or inaccurate,
with missing or spurious links that hinder precise predictions. Moreover, while
networked time series often originate from diverse topologies, the ability of
models to generalize across topologies has not been systematically evaluated.
To address these gaps, we propose a novel framework for learning network
dynamics directly from observed time-series data, when prior knowledge of graph
topology or governing dynamical equations is absent. Our approach leverages
continuous graph neural networks with an attention mechanism to construct a
latent topology, enabling accurate reconstruction of future trajectories for
network states. Extensive experiments on real and synthetic networks
demonstrate that our model not only captures dynamics effectively without
topology knowledge but also generalizes to unseen time series originating from
diverse topologies.",2024-12-25T01:39:04Z,http://arxiv.org/abs/2412.18734v1,"Yanna Ding, Zijie Huang, Malik Magdon-Ismail, Jianxi Gao"
"Simi-SFX: A similarity-based conditioning method for controllable sound
  effect synthesis","Generating sound effects with controllable variations is a challenging task,
traditionally addressed using sophisticated physical models that require
in-depth knowledge of signal processing parameters and algorithms. In the era
of generative and large language models, text has emerged as a common,
human-interpretable interface for controlling sound synthesis. However, the
discrete and qualitative nature of language tokens makes it difficult to
capture subtle timbral variations across different sounds. In this research, we
propose a novel similarity-based conditioning method for sound synthesis,
leveraging differentiable digital signal processing (DDSP). This approach
combines the use of latent space for learning and controlling audio timbre with
an intuitive guiding vector, normalized within the range [0,1], to encode
categorical acoustic information. By utilizing pre-trained audio representation
models, our method achieves expressive and fine-grained timbre control. To
benchmark our approach, we introduce two sound effect datasets--Footstep-set
and Impact-set--designed to evaluate both controllability and sound quality.
Regression analysis demonstrates that the proposed similarity score effectively
controls timbre variations and enables creative applications such as timbre
interpolation between discrete classes. Our work provides a robust and
versatile framework for sound effect synthesis, bridging the gap between
traditional signal processing and modern machine learning techniques.",2024-12-25T00:14:50Z,http://arxiv.org/abs/2412.18710v1,"Yunyi Liu, Craig Jin"
"SurvAttack: Black-Box Attack On Survival Models through
  Ontology-Informed EHR Perturbation","Survival analysis (SA) models have been widely studied in mining electronic
health records (EHRs), particularly in forecasting the risk of critical
conditions for prioritizing high-risk patients. However, their vulnerability to
adversarial attacks is much less explored in the literature. Developing
black-box perturbation algorithms and evaluating their impact on
state-of-the-art survival models brings two benefits to medical applications.
First, it can effectively evaluate the robustness of models in pre-deployment
testing. Also, exploring how subtle perturbations would result in significantly
different outcomes can provide counterfactual insights into the clinical
interpretation of model prediction. In this work, we introduce SurvAttack, a
novel black-box adversarial attack framework leveraging subtle clinically
compatible, and semantically consistent perturbations on longitudinal EHRs to
degrade survival models' predictive performance. We specifically develop a
greedy algorithm to manipulate medical codes with various adversarial actions
throughout a patient's medical history. Then, these adversarial actions are
prioritized using a composite scoring strategy based on multi-aspect
perturbation quality, including saliency, perturbation stealthiness, and
clinical meaningfulness. The proposed adversarial EHR perturbation algorithm is
then used in an efficient SA-specific strategy to attack a survival model when
estimating the temporal ranking of survival urgency for patients. To
demonstrate the significance of our work, we conduct extensive experiments,
including baseline comparisons, explainability analysis, and case studies. The
experimental results affirm our research's effectiveness in illustrating the
vulnerabilities of patient survival models, model interpretation, and
ultimately contributing to healthcare quality.",2024-12-24T23:35:42Z,http://arxiv.org/abs/2412.18706v1,"Mohsen Nayebi Kerdabadi, Arya Hadizadeh Moghaddam, Bin Liu, Mei Liu, Zijun Yao"
Exceptional X-ray activity in BL Lacertae,"BL Lacertae is a unique blazar for which the X-ray band can cover either the
synchrotron or the inverse Compton, or both parts of the broadband spectral
energy distribution. In the latter case, when the spectral upturn is located in
the X-ray range, it allows contemporaneous study of the low- and high-energy
ends of the electron distribution function. In this work, we study spectral and
temporal variability using X-ray and optical observations of the blazar
performed with the Neil Gehrels Swift Observatory from 2020 to 2023. The large
set of observational data reveals intensive flaring activity, accompanied by
spectral changes in both spectral branches.
  We conclude that the low-energy and high-energy ends of the particle
distribution function are characterised by similar variability scales.
Additionally, the hard X-ray observations of BL Lacertae performed with the
Nuclear Spectroscopic Telescope Array (NuSTAR) confirm a concave spectral
curvature for some epochs of the blazar activity and reveal that it can be
shifted up to energies of as high as 8 keV. The time-resolved spectral analysis
allows us to disentangle X-ray spectral variability features of the synchrotron
from inverse Compton components.
  Despite significant variability of both spectral components, we find only
small changes in the position of the spectral upturn. The different slopes and
shapes of the X-ray spectrum of BL Lacertae demonstrate that the classification
of this source is not constant, and BL Lacertae can exhibit features of either
high-, intermediate-, or low-energy peaked blazar in different epochs of
observation. This also indicates that the spectral upturn for this blazar can
be located not only in the X-ray range of 0.3-10 keV, but also at lower or
higher energies.",2024-12-24T21:05:33Z,http://arxiv.org/abs/2412.18680v1,"Alicja Wierzcholska, Stefan Wagner"
"State-of-the-Art Underwater Vehicles and Technologies Enabling Smart
  Ocean: Survey and Classifications","The exploration and sustainable use of marine environments have become
increasingly critical as oceans cover over 70% of surface of Earth. This paper
provides a comprehensive survey and classification of state-of-the-art
underwater vehicles (UVs) and supporting technologies essential for enabling a
smart ocean. We categorize UVs into several types, including remotely operated
vehicles (ROVs), autonomous underwater vehicles (AUVs), hybrid underwater
vehicles (HUVs), unmanned surface vehicles (USVs), and underwater bionic
vehicles (UBVs). These technologies are fundamental in a wide range of
applications, such as environmental monitoring, deep-sea exploration, defense,
and underwater infrastructure inspection. Additionally, the paper explores
advancements in underwater communication technologies, namely acoustic,
optical, and hybrid systems, as well as key support facilities, including
submerged buoys, underwater docking stations, and wearable underwater
localization systems. By classifying the vehicles and analyzing their
technological capabilities and limitations, this work aims to guide future
developments in underwater exploration and monitoring, addressing challenges
such as energy efficiency, communication limitations, and environmental
adaptability. The paper concludes by discussing the integration of artificial
intelligence and machine learning in enhancing the autonomy and operational
efficiency of these systems, paving the way for the realization of a fully
interconnected and sustainable Smart Ocean.",2024-12-24T20:00:15Z,http://arxiv.org/abs/2412.18667v1,"Jiajie Xu, Xabier Irigoien, Mohamed-Slim Alouini"
"Orient Anything: Learning Robust Object Orientation Estimation from
  Rendering 3D Models","Orientation is a key attribute of objects, crucial for understanding their
spatial pose and arrangement in images. However, practical solutions for
accurate orientation estimation from a single image remain underexplored. In
this work, we introduce Orient Anything, the first expert and foundational
model designed to estimate object orientation in a single- and free-view image.
Due to the scarcity of labeled data, we propose extracting knowledge from the
3D world. By developing a pipeline to annotate the front face of 3D objects and
render images from random views, we collect 2M images with precise orientation
annotations. To fully leverage the dataset, we design a robust training
objective that models the 3D orientation as probability distributions of three
angles and predicts the object orientation by fitting these distributions.
Besides, we employ several strategies to improve synthetic-to-real transfer.
Our model achieves state-of-the-art orientation estimation accuracy in both
rendered and real images and exhibits impressive zero-shot ability in various
scenarios. More importantly, our model enhances many applications, such as
comprehension and generation of complex spatial concepts and 3D object pose
adjustment.",2024-12-24T18:58:43Z,http://arxiv.org/abs/2412.18605v1,"Zehan Wang, Ziang Zhang, Tianyu Pang, Chao Du, Hengshuang Zhao, Zhou Zhao"
LatentCRF: Continuous CRF for Efficient Latent Diffusion,"Latent Diffusion Models (LDMs) produce high-quality, photo-realistic images,
however, the latency incurred by multiple costly inference iterations can
restrict their applicability. We introduce LatentCRF, a continuous Conditional
Random Field (CRF) model, implemented as a neural network layer, that models
the spatial and semantic relationships among the latent vectors in the LDM. By
replacing some of the computationally-intensive LDM inference iterations with
our lightweight LatentCRF, we achieve a superior balance between quality, speed
and diversity. We increase inference efficiency by 33% with no loss in image
quality or diversity compared to the full LDM. LatentCRF is an easy add-on,
which does not require modifying the LDM.",2024-12-24T18:51:11Z,http://arxiv.org/abs/2412.18596v1,"Kanchana Ranasinghe, Sadeep Jayasumana, Andreas Veit, Ayan Chakrabarti, Daniel Glasner, Michael S Ryoo, Srikumar Ramalingam, Sanjiv Kumar"
"ClassifyViStA:WCE Classification with Visual understanding through
  Segmentation and Attention","Gastrointestinal (GI) bleeding is a serious medical condition that presents
significant diagnostic challenges, particularly in settings with limited access
to healthcare resources. Wireless Capsule Endoscopy (WCE) has emerged as a
powerful diagnostic tool for visualizing the GI tract, but it requires
time-consuming manual analysis by experienced gastroenterologists, which is
prone to human error and inefficient given the increasing number of patients.To
address this challenge, we propose ClassifyViStA, an AI-based framework
designed for the automated detection and classification of bleeding and
non-bleeding frames from WCE videos. The model consists of a standard
classification path, augmented by two specialized branches: an implicit
attention branch and a segmentation branch.The attention branch focuses on the
bleeding regions, while the segmentation branch generates accurate segmentation
masks, which are used for classification and interpretability. The model is
built upon an ensemble of ResNet18 and VGG16 architectures to enhance
classification performance. For the bleeding region detection, we implement a
Soft Non-Maximum Suppression (Soft NMS) approach with YOLOv8, which improves
the handling of overlapping bounding boxes, resulting in more accurate and
nuanced detections.The system's interpretability is enhanced by using the
segmentation masks to explain the classification results, offering insights
into the decision-making process similar to the way a gastroenterologist
identifies bleeding regions. Our approach not only automates the detection of
GI bleeding but also provides an interpretable solution that can ease the
burden on healthcare professionals and improve diagnostic efficiency. Our code
is available at ClassifyViStA.",2024-12-24T18:45:14Z,http://arxiv.org/abs/2412.18591v1,"S. Balasubramanian, Ammu Abhishek, Yedu Krishna, Darshan Gera"
Text-Driven Tumor Synthesis,"Tumor synthesis can generate examples that AI often misses or over-detects,
improving AI performance by training on these challenging cases. However,
existing synthesis methods, which are typically unconditional -- generating
images from random variables -- or conditioned only by tumor shapes, lack
controllability over specific tumor characteristics such as texture,
heterogeneity, boundaries, and pathology type. As a result, the generated
tumors may be overly similar or duplicates of existing training data, failing
to effectively address AI's weaknesses. We propose a new text-driven tumor
synthesis approach, termed TextoMorph, that provides textual control over tumor
characteristics. This is particularly beneficial for examples that confuse the
AI the most, such as early tumor detection (increasing Sensitivity by +8.5%),
tumor segmentation for precise radiotherapy (increasing DSC by +6.3%), and
classification between benign and malignant tumors (improving Sensitivity by
+8.2%). By incorporating text mined from radiology reports into the synthesis
process, we increase the variability and controllability of the synthetic
tumors to target AI's failure cases more precisely. Moreover, TextoMorph uses
contrastive learning across different texts and CT scans, significantly
reducing dependence on scarce image-report pairs (only 141 pairs used in this
study) by leveraging a large corpus of 34,035 radiology reports. Finally, we
have developed rigorous tests to evaluate synthetic tumors, including
Text-Driven Visual Turing Test and Radiomics Pattern Analysis, showing that our
synthetic tumors is realistic and diverse in texture, heterogeneity,
boundaries, and pathology.",2024-12-24T18:43:09Z,http://arxiv.org/abs/2412.18589v1,"Xinran Li, Yi Shuai, Chen Liu, Qi Chen, Qilong Wu, Pengfei Guo, Dong Yang, Can Zhao, Pedro R. A. S. Bassi, Daguang Xu, Kang Wang, Yang Yang, Alan Yuille, Zongwei Zhou"
Relativistic Lévy processes,"In this contribution, we investigate how to correctly describe sums of
independent and identically distributed random velocities in the theory of
special relativity. We derive a one-dimensional probability distribution of
velocities stable under relativistic velocity addition. In a given system, this
allows identifying distinct physical regimes in terms of the distribution's
concavity at the origin and the probability of measuring relativistic
velocities. These features provide a protocol to assess the relevance of
stochastic relativistic effects in actual experiments. As examples, we find
agreement with previous results about heavy-ion diffusion and show that our
findings are consistent with the distribution of momentum deviations observed
in measurements of antiproton cooling.",2024-12-24T18:17:27Z,http://arxiv.org/abs/2412.18581v1,"Lucas G. B. de Souza, M. G. E. da Luz, E. P. Raposo, Evaldo M. F. Curado, G. M. Viswanathan"
Randomized Benchmarking with Synthetic Quantum Circuits,"Randomized benchmarking (RB) comprises a set of mature and widely used
techniques for assessing the quality of operations on a quantum
information-processing system. Modern RB protocols for multiqubit systems
extract physically relevant error rates by exploiting the structure of the
group representation generated by the set of benchmarked operations. However,
existing techniques become prohibitively inefficient for representations that
are highly reducible yet decompose into irreducible subspaces of high
dimension. These situations prevail when benchmarking high-dimensional systems
such as qudits or bosonic modes, where experimental control is limited to
implementing a small subset of all possible unitary operations. In this work,
we introduce a broad framework for enhancing the sample efficiency of RB that
is sufficiently powerful to extend the practical reach of RB beyond the
multiqubit setting. Our strategy, which applies to any benchmarking group, uses
""synthetic"" quantum circuits with classical post-processing of both input and
output data to leverage the full structure of reducible superoperator
representations. To demonstrate the efficacy of our approach, we develop a
detailed theory of RB for systems with rotational symmetry. Such systems carry
a natural action of the group $\text{SU}(2)$, and they form the basis for
several novel quantum error-correcting codes. We show that, for experimentally
accessible high-spin systems, synthetic RB protocols can reduce the complexity
of measuring rotationally invariant error rates by more than two orders of
magnitude relative to standard approaches such as character RB.",2024-12-24T18:10:00Z,http://arxiv.org/abs/2412.18578v1,"Yale Fan, Riley Murray, Thaddeus D. Ladd, Kevin Young, Robin Blume-Kohout"
Von Neumann Entropy and Quantum Algorithmic Randomness,"A state $\rho=(\rho_n)_{n=1}^{\infty}$ is a sequence such that $\rho_n$ is a
density matrix on $n$ qubits. It formalizes the notion of an infinite sequence
of qubits. The von Neumann entropy $H(d)$ of a density matrix $d$ is the
Shannon entropy of its eigenvalue distribution. We show: (1) If $\rho$ is a
computable quantum Schnorr random state then $\lim_n [H(\rho_n )/n] = 1$. (2)
We define quantum s-tests for $s\in [0,1]$, show that $\liminf_n
[H(\rho_n)/n]\geq \{ s: \rho$ is covered by a quantum s-test $\}$ for
computable $\rho$ and construct states where this inequality is an equality.
(3) If $\exists c \exists^\infty n H(\rho_n)&gt; n-c$ then $\rho$ is strong
quantum random. Strong quantum randomness is a randomness notion which implies
quantum Schnorr randomness relativized to any oracle. (4) A computable state
$(\rho_n)_{n=1}^{\infty}$ is quantum Schnorr random iff the family of
distributions of the $\rho_n$'s is uniformly integrable. We show that the
implications in (1) and (3) are strict.",2024-12-24T18:09:45Z,http://arxiv.org/abs/2412.18646v1,Tejas Bhojraj
"Machine Learning Approaches to the Shafarevich-Tate Group of Elliptic
  Curves","We train machine learning models to predict the order of the Shafarevich-Tate
group of an elliptic curve over $\mathbb{Q}$. Building on earlier work of He,
Lee, and Oliver, we show that a feed-forward neural network classifier trained
on subsets of the invariants arising in the Birch--Swinnerton-Dyer conjectural
formula yields higher accuracies ($&gt; 0.9$) than any model previously studied.
In addition, we develop a regression model that may be used to predict orders
of this group not seen during training and apply this to the elliptic curve of
rank 29 recently discovered by Elkies and Klagsbrun. Finally we conduct some
exploratory data analyses and visualizations on our dataset. We use the
elliptic curve dataset from the L-functions and modular forms database (LMFDB).",2024-12-24T18:01:19Z,http://arxiv.org/abs/2412.18576v1,"Angelica Babei, Barinder S. Banwait, AJ Fong, Xiaoyu Huang, Deependra Singh"
HNCI: High-Dimensional Network Causal Inference,"The problem of evaluating the effectiveness of a treatment or policy commonly
appears in causal inference applications under network interference. In this
paper, we suggest the new method of high-dimensional network causal inference
(HNCI) that provides both valid confidence interval on the average direct
treatment effect on the treated (ADET) and valid confidence set for the
neighborhood size for interference effect. We exploit the model setting in
Belloni et al. (2022) and allow certain type of heterogeneity in node
interference neighborhood sizes. We propose a linear regression formulation of
potential outcomes, where the regression coefficients correspond to the
underlying true interference function values of nodes and exhibit a latent
homogeneous structure. Such a formulation allows us to leverage existing
literature from linear regression and homogeneity pursuit to conduct valid
statistical inferences with theoretical guarantees. The resulting confidence
intervals for the ADET are formally justified through asymptotic normalities
with estimable variances. We further provide the confidence set for the
neighborhood size with theoretical guarantees exploiting the repro samples
approach. The practical utilities of the newly suggested methods are
demonstrated through simulation and real data examples.",2024-12-24T17:41:41Z,http://arxiv.org/abs/2412.18568v1,"Wenqin Du, Rundong Ding, Yingying Fan, Jinchi Lv"
"Dynamic Optimization of Portfolio Allocation Using Deep Reinforcement
  Learning","Artificial intelligence is fundamentally transforming financial investment
decision-making paradigms, with deep reinforcement learning (DRL) demonstrating
significant application potential in domains such as robo-advisory services.
Given that traditional portfolio optimization methods face significant
challenges in effectively managing dynamic asset weight adjustments, this paper
approaches the problem from the perspective of practical trading processes and
develops a dynamic optimization model using deep reinforcement learning to
achieve more effective asset allocation. The study's innovations are twofold:
First, we propose a Sharpe ratio reward function specifically designed for
Actor-Critic deep reinforcement learning algorithms, which optimizes portfolio
performance by maximizing the average Sharpe ratio through random sampling and
reinforcement learning algorithms during the training process; Second, we
design deep neural networks that are specifically structured to meet asset
optimization objectives. The study empirically evaluates the model using
randomly selected constituent stocks from the CSI300 index and conducts
comparative analyses against traditional approaches, including mean-variance
optimization and risk parity strategies. Backtesting results demonstrate the
dynamic optimization model's effectiveness in portfolio asset allocation,
yielding enhanced risk reduction, superior risk-return metrics, and optimal
performance across comprehensive evaluation criteria.",2024-12-24T17:33:20Z,http://arxiv.org/abs/2412.18563v1,"Gang Huang, Xiaohua Zhou, Qingyang Song"
"Distilling Fine-grained Sentiment Understanding from Large Language
  Models","Fine-grained sentiment analysis (FSA) aims to extract and summarize user
opinions from vast opinionated text. Recent studies demonstrate that large
language models (LLMs) possess exceptional sentiment understanding
capabilities. However, directly deploying LLMs for FSA applications incurs high
inference costs. Therefore, this paper investigates the distillation of
fine-grained sentiment understanding from LLMs into small language models
(SLMs). We prompt LLMs to examine and interpret the sentiments of given reviews
and then utilize the generated content to pretrain SLMs. Additionally, we
develop a comprehensive FSA benchmark to evaluate both SLMs and LLMs. Extensive
experiments on this benchmark reveal that: (1) distillation significantly
enhances the performance of SLMs in FSA tasks, achieving a 6.00\% improvement
in $F_1$-score, and the distilled model can outperform Llama-2-7b with only
220M parameters; (2) distillation equips SLMs with excellent zero-shot
sentiment classification capabilities, enabling them to match or even exceed
their teacher models. These results suggest that distillation from LLMs is a
highly promising direction for FSA. We will release our code, data, and
pretrained model weights at
\url{https://github.com/HITSZ-HLT/FSA-Distillation}.",2024-12-24T17:05:26Z,http://arxiv.org/abs/2412.18552v1,"Yice Zhang, Guangyu Xie, Hongling Xu, Kaiheng Hou, Jianzhu Bao, Qianlong Wang, Shiwei Chen, Ruifeng Xu"
Consistency Checks for Language Model Forecasters,"Forecasting is a task that is difficult to evaluate: the ground truth can
only be known in the future. Recent work showing LLM forecasters rapidly
approaching human-level performance begs the question: how can we benchmark and
evaluate these forecasters instantaneously? Following the consistency check
framework, we measure the performance of forecasters in terms of the
consistency of their predictions on different logically-related questions. We
propose a new, general consistency metric based on arbitrage: for example, if a
forecasting AI illogically predicts that both the Democratic and Republican
parties have 60% probability of winning the 2024 US presidential election, an
arbitrageur can trade against the forecaster's predictions and make a profit.
We build an automated evaluation system that generates a set of base questions,
instantiates consistency checks from these questions, elicits the predictions
of the forecaster, and measures the consistency of the predictions. We then
build a standard, proper-scoring-rule forecasting benchmark, and show that our
(instantaneous) consistency metrics correlate with LLM forecasters' ground
truth Brier scores (which are only known in the future). We also release a
consistency benchmark that resolves in 2028, providing a long-term evaluation
tool for forecasting.",2024-12-24T16:51:35Z,http://arxiv.org/abs/2412.18544v1,"Daniel Paleka, Abhimanyu Pallavi Sudhir, Alejandro Alvarez, Vineeth Bhat, Adam Shen, Evan Wang, Florian Tramèr"
"GCN-ABFT: Low-Cost Online Error Checking for Graph Convolutional
  Networks","Graph convolutional networks (GCNs) are popular for building machine-learning
application for graph-structured data. This widespread adoption led to the
development of specialized GCN hardware accelerators. In this work, we address
a key architectural challenge for GCN accelerators: how to detect errors in GCN
computations arising from random hardware faults with the least computation
cost. Each GCN layer performs a graph convolution, mathematically equivalent to
multiplying three matrices, computed through two separate matrix
multiplications. Existing Algorithm-based Fault Tolerance(ABFT) techniques can
check the results of individual matrix multiplications. However, for a GCN
layer, this check should be performed twice. To avoid this overhead, this work
introduces GCN-ABFT that directly calculates a checksum for the entire
three-matrix product within a single GCN layer, providing a cost-effective
approach for error detection in GCN accelerators. Experimental results
demonstrate that GCN-ABFT reduces the number of operations needed for checksum
computation by over 21% on average for representative GCN applications. These
savings are achieved without sacrificing fault-detection accuracy, as evidenced
by the presented fault-injection analysis.",2024-12-24T16:27:19Z,http://arxiv.org/abs/2412.18534v1,"Christodoulos Peltekis, Giorgos Dimitrakopoulos"
"Explanatory Instructions: Towards Unified Vision Tasks Understanding and
  Zero-shot Generalization","Computer Vision (CV) has yet to fully achieve the zero-shot task
generalization observed in Natural Language Processing (NLP), despite following
many of the milestones established in NLP, such as large transformer models,
extensive pre-training, and the auto-regression paradigm, among others. In this
paper, we explore the idea that CV adopts discrete and terminological task
definitions (\eg, ``image segmentation''), which may be a key barrier to
zero-shot task generalization. Our hypothesis is that without truly
understanding previously-seen tasks--due to these terminological
definitions--deep models struggle to generalize to novel tasks. To verify this,
we introduce Explanatory Instructions, which provide an intuitive way to define
CV task objectives through detailed linguistic transformations from input
images to outputs. We create a large-scale dataset comprising 12 million
``image input $\to$ explanatory instruction $\to$ output'' triplets, and train
an auto-regressive-based vision-language model (AR-based VLM) that takes both
images and explanatory instructions as input. By learning to follow these
instructions, the AR-based VLM achieves instruction-level zero-shot
capabilities for previously-seen tasks and demonstrates strong zero-shot
generalization for unseen CV tasks. Code and dataset will be openly available
on our GitHub repository.",2024-12-24T16:08:25Z,http://arxiv.org/abs/2412.18525v2,"Yang Shen, Xiu-Shen Wei, Yifan Sun, Yuxin Song, Tao Yuan, Jian Jin, Heyang Xu, Yazhou Yao, Errui Ding"
"An Empirical Analysis of Federated Learning Models Subject to
  Label-Flipping Adversarial Attack","In this paper, we empirically analyze adversarial attacks on selected
federated learning models. The specific learning models considered are
Multinominal Logistic Regression (MLR), Support Vector Classifier (SVC),
Multilayer Perceptron (MLP), Convolution Neural Network (CNN), %Recurrent
Neural Network (RNN), Random Forest, XGBoost, and Long Short-Term Memory
(LSTM). For each model, we simulate label-flipping attacks, experimenting
extensively with 10 federated clients and 100 federated clients. We vary the
percentage of adversarial clients from 10% to 100% and, simultaneously, the
percentage of labels flipped by each adversarial client is also varied from 10%
to 100%. Among other results, we find that models differ in their inherent
robustness to the two vectors in our label-flipping attack, i.e., the
percentage of adversarial clients, and the percentage of labels flipped by each
adversarial client. We discuss the potential practical implications of our
results.",2024-12-24T15:47:25Z,http://arxiv.org/abs/2412.18507v1,"Kunal Bhatnagar, Sagana Chattanathan, Angela Dang, Bhargav Eranki, Ronnit Rana, Charan Sridhar, Siddharth Vedam, Angie Yao, Mark Stamp"
"Topological phases protected by projective PT symmetry in
  alkaline-earth-like atoms","An important aspect in categorizing topological phases is whether the system
is spinless or spinful, given that these classes exhibit distinct symmetry
algebras, leading to disparate topological classifications. By utilizing the
projective presentation strategy, the topological phases of spinless (or
spinful) systems can be emulated using spinful (or spinless) systems augmented
with gauge fields. In this study, we propose to implement the topological
phases safeguarded by the unique projective space-time (PT) symmetry inherent
to spinful models, using synthetic spinless alkaline-earth-like atoms.
Employing the separation of orbital and nuclear-spin degrees of freedom, the
model is configured as a rectangular tube penetrated by a uniform magnetic flux
through each plaquette, which simulates a spinless ladder endowed with
projective PT symmetry satisfying the algebraic properties of a spinful model.
For interacting topological phases with inter-orbital spin-exchange
interactions, which also adhere to PT symmetry, the four-fold degeneracy of
edge modes is split into two pairs of edge modes with two-fold degeneracy. We
map the complete phase diagram in the end and discover that these interacting
topological phases ultimately evolve into distinct charge-density-wave phases
via spontaneous symmetry breaking.",2024-12-24T15:25:04Z,http://arxiv.org/abs/2412.18494v1,"Xiaofan Zhou, Suotang Jia, Jian-Song Pan"
Matrix Chaos Inequalities and Chaos of Combinatorial Type,"Matrix concentration inequalities and their recently discovered sharp
counterparts provide powerful tools to bound the spectrum of random matrices
whose entries are linear functions of independent random variables. However, in
many applications in theoretical computer science and in other areas one
encounters more general random matrix models, called matrix chaoses, whose
entries are polynomials of independent random variables. Such models have often
been studied on a case-by-case basis using ad-hoc methods that can yield
suboptimal dimensional factors.
  In this paper we provide general matrix concentration inequalities for matrix
chaoses, which enable the treatment of such models in a systematic manner.
These inequalities are expressed in terms of flattenings of the coefficients of
the matrix chaos. We further identify a special family of matrix chaoses of
combinatorial type for which the flattening parameters can be computed
mechanically by a simple rule. This allows us to provide a unified treatment of
and improved bounds for matrix chaoses that arise in a variety of applications,
including graph matrices, Khatri-Rao matrices, and matrices that arise in
average case analysis of the sum-of-squares hierarchy.",2024-12-24T14:54:23Z,http://arxiv.org/abs/2412.18468v1,"Afonso S. Bandeira, Kevin Lucca, Petar Nizić-Nikolac, Ramon van Handel"
GeFL: Model-Agnostic Federated Learning with Generative Models,"Federated learning (FL) is a promising paradigm in distributed learning while
preserving the privacy of users. However, the increasing size of recent models
makes it unaffordable for a few users to encompass the model. It leads the
users to adopt heterogeneous models based on their diverse computing
capabilities and network bandwidth. Correspondingly, FL with heterogeneous
models should be addressed, given that FL typically involves training a single
global model. In this paper, we propose Generative Model-Aided Federated
Learning (GeFL), incorporating a generative model that aggregates global
knowledge across users of heterogeneous models. Our experiments on various
classification tasks demonstrate notable performance improvements of GeFL
compared to baselines, as well as limitations in terms of privacy and
scalability. To tackle these concerns, we introduce a novel framework, GeFL-F.
It trains target networks aided by feature-generative models. We empirically
demonstrate the consistent performance gains of GeFL-F, while demonstrating
better privacy preservation and robustness to a large number of clients. Codes
are available at [1].",2024-12-24T14:39:47Z,http://arxiv.org/abs/2412.18460v1,"Honggu Kang, Seohyeon Cha, Joonhyuk Kang"
"Shoving tubes through shapes gives a sufficient and efficient shape
  statistic","The Persistent Homology Transform (PHT) was introduced in the field of
Topological Data Analysis about 10 years ago, and has since been proven to be a
very powerful descriptor of Euclidean shapes. The PHT consists of scanning a
shape from all possible directions $v\in S^{n-1}$ and then computing the
persistent homology of sublevel set filtrations of the respective height
functions $h_v$; this results in a sufficient and continuous descriptor of
Euclidean shapes. We introduce a generalisation of the PHT in which we consider
arbitrary parameter spaces and sublevel sets with respect to any function. In
particular, we study transforms, defined on the Grassmannian
$\mathbb{A}\mathbb{G}(m,n)$ of affine subspaces of $\mathbb{R}^n$, that allow
to scan a shape by probing it with all possible affine $m$-dimensional
subspaces $P\subset \mathbb{R}^n$, for fixed dimension $m$, and by computing
persistent homology of sublevel set filtrations of the function
$\mathrm{dist}(\cdot, P)$ encoding the distance from the flat $P$. We call such
transforms ""distance-from-flat"" PHTs. We show that these transforms are
injective and continuous and that they provide computational advantages over
the classical PHT. In particular, we show that it is enough to compute homology
only in degrees up to $m-1$ to obtain injectivity; for $m=1$ this provides a
very powerful and computationally advantageous tool for examining shapes, which
in a previous work by a subset of the authors has proven to significantly
outperform state-of-the-art neural networks for shape classification tasks.",2024-12-24T14:22:43Z,http://arxiv.org/abs/2412.18452v1,"Adam Onus, Nina Otter, Renata Turkes"
"Re-assessing ImageNet: How aligned is its single-label assumption with
  its multi-label nature?","ImageNet, an influential dataset in computer vision, is traditionally
evaluated using single-label classification, which assumes that an image can be
adequately described by a single concept or label. However, this approach may
not fully capture the complex semantics within the images available in
ImageNet, potentially hindering the development of models that effectively
learn these intricacies. This study critically examines the prevalent
single-label benchmarking approach and advocates for a shift to multi-label
benchmarking for ImageNet. This shift would enable a more comprehensive
assessment of the capabilities of deep neural network (DNN) models. We analyze
the effectiveness of pre-trained state-of-the-art DNNs on ImageNet and one of
its variants, ImageNetV2. Studies in the literature have reported unexpected
accuracy drops of 11% to 14% on ImageNetV2. Our findings show that these
reported declines are largely attributable to a characteristic of the dataset
that has not received sufficient attention -- the proportion of images with
multiple labels. Taking this characteristic into account, the results of our
experiments provide evidence that there is no substantial degradation in
effectiveness on ImageNetV2. Furthermore, we acknowledge that ImageNet
pre-trained models exhibit some capability at capturing the multi-label nature
of the dataset even though they were trained under the single-label assumption.
Consequently, we propose a new evaluation approach to augment existing
approaches that assess this capability. Our findings highlight the importance
of considering the multi-label nature of the ImageNet dataset during
benchmarking. Failing to do so could lead to incorrect conclusions regarding
the effectiveness of DNNs and divert research efforts from addressing other
substantial challenges related to the reliability and robustness of these
models.",2024-12-24T12:55:31Z,http://arxiv.org/abs/2412.18409v1,"Esla Timothy Anzaku, Seyed Amir Mousavi, Arnout Van Messem, Wesley De Neve"
"Generalized Mean Absolute Directional Loss as a Solution to Overfitting
  and High Transaction Costs in Machine Learning Models Used in High-Frequency
  Algorithmic Investment Strategies","Regardless of the selected asset class and the level of model complexity
(Transformer versus LSTM versus Perceptron/RNN), the GMADL loss function
produces superior results than standard MSE-type loss functions and has better
numerical properties in the context of optimization than MADL. Better results
mean the possibility of achieving a higher risk-weighted return based on buy
and sell signals built on forecasts generated by a given theoretical model
estimated using the GMADL versus MSE or MADL function. In practice, GMADL
solves the problem of selecting the most preferable feature in both
classification and regression problems, improving the performance of each
estimation. What is important is that, through additional parameterization,
GMADL also solves the problem of optimizing investment systems on
high-frequency data in such a way that they focus on strategy variants that
contain fewer transactions so that transaction costs do not reduce the
effectiveness of a given strategy to zero. Moreover, the implementation
leverages state-of-the-art machine learning tools, including frameworks for
hyperparameter tuning, architecture testing, and walk-forward optimization,
ensuring robust and scalable solutions for real-world algorithmic trading.",2024-12-24T12:51:40Z,http://arxiv.org/abs/2412.18405v1,"Jakub Michańków, Paweł Sakowski, Robert Ślepaczuk"
"Scheme to Detect the Strong-to-weak Symmetry Breaking via Randomized
  Measurements","Symmetry breaking plays a central role in classifying the phases of quantum
many-body systems. Recent developments have highlighted a novel
symmetry-breaking pattern, in which the strong symmetry of a density matrix
spontaneously breaks to the week symmetry. This strong-to-weak symmetry
breaking is typically detected using multi-replica correlation functions, such
as the R\'enyi-2 correlator. In this letter, we propose a practical protocol
for detecting strong-to-weak symmetry breaking in experiments using the
randomized measurement toolbox. Our scheme involves collecting the results of
random Pauli measurements for (i) the original quantum state and (ii) the
quantum state after evolution with the charged operators. Based on the
measurement results, with a large number of samples, we can obtain the exact
solution to the R\'enyi-2 correlator. With a small sample size, we can still
provide an alternative approach to estimate the phase boundary to a decent
accuracy. We perform numerical simulations of Ising chains with all-to-all
decoherence as an exemplary demonstration. Our result opens the opportunity for
the experimental studies of the novel quantum phases in mixed quantum states.",2024-12-24T12:41:38Z,http://arxiv.org/abs/2412.18397v1,"Ning Sun, Pengfei Zhang, Lei Feng"
"Local smoothing estimates for Schrödinger equations in modulation
  spaces","Motivated by a recent work of Schippa (2022), we consider local smoothing
estimates for Schr\""{o}dinger equations in modulation spaces. By using the
C\'{o}rdoba-Fefferman type reverse square function inequality and the bilinear
Strichartz estimate, we can refine the summability exponent of modulation
spaces. Next, we will also discuss a new type of randomized Strichartz estimate
in modulation spaces. Finally, we will show that the reverse function estimate
implies the Strichartz estimates in modulation spaces. From this implication,
we obtain the reverse square function estimate of critical order.",2024-12-24T11:45:00Z,http://arxiv.org/abs/2412.18363v1,Kotaro Inami
ORAN Drives Higher Returns on Investments in Urban and Suburban Regions,"This paper provides the first incentive analysis of open radio access
networks (ORAN) using game theory. We assess strategic interactions between
telecom supply chain stakeholders: mobile network operators (MNOs), network
infrastructure suppliers (NIS), and original equipment manufacturers (OEMs)
across three procurement scenarios: (i) Traditional, (ii) Predatory as
monolithic radio access networks (MRAN), and (iii) DirectOEM as ORAN. We use
random forest and gradient boosting models to evaluate the optimal margins
across urban, suburban, and rural U.S. regions. Results suggest that ORAN
deployment consistently demonstrates higher net present value (NPV) of profits
in urban and suburban regions, outperforming the traditional procurement
strategy by 11% to 31%. However, rural areas present lower NPVs across all
scenarios, with significant variability at the county level. This analysis
offers actionable insights for telecom investment strategies, bridging
technical innovation with economic outcomes and addressing strategic supply
chain dynamics through a game-theoretic lens.",2024-12-24T11:08:15Z,http://arxiv.org/abs/2412.18346v1,"Priyanka Sharma, Edward J. Oughton, Aleksan Shanoyan"
"Predator Prey Scavenger Model using Holling's Functional Response of
  Type III and Physics-Informed Deep Neural Networks","Nonlinear mathematical models introduce the relation between various physical
and biological interactions present in nature. One of the most famous models is
the Lotka-Volterra model which defined the interaction between predator and
prey species present in nature. However, predators, scavengers, and prey
populations coexist in a natural system where scavengers can additionally rely
on the dead bodies of predators present in the system. Keeping this in mind,
the formulation and simulation of the predator prey scavenger model is
introduced in this paper. For the predation response, respective prey species
are assumed to have Holling's functional response of type III. The proposed
model is tested for various simulations and is found to be showing satisfactory
results in different scenarios. After simulations, the American forest dataset
is taken for parameter estimation which imitates the real-world case. For
parameter estimation, a physics-informed deep neural network is used with the
Adam backpropagation method which prevents the avalanche effect in trainable
parameters updation. For neural networks, mean square error and
physics-informed informed error are considered. After the neural network, the
hence-found parameters are fine-tuned using the
Broyden-Fletcher-Goldfarb-Shanno algorithm. Finally, the hence-found parameters
using a natural dataset are tested for stability using Jacobian stability
analysis. Future research work includes minimization of error induced by
parameters, bifurcation analysis, and sensitivity analysis of the parameters.",2024-12-24T11:02:38Z,http://arxiv.org/abs/2412.18344v1,"Aneesh Panchal, Kirti Beniwal, Vivek Kumar"
"Extremum Encoding for Joint Baseband Signal Compression and Time-Delay
  Estimation for Distributed Systems","The ubiquitous time-delay estimation (TDE) problem becomes nontrivial when
sensors are non-co-located and communication between them is limited. Building
on the recently proposed ""extremum encoding"" compression-estimation scheme, we
address the critical extension to complex-valued signals, suitable for
radio-frequency (RF) baseband processing. This extension introduces new
challenges, e.g., due to unknown phase of the signal of interest and random
phase of the noise, rendering a na\""ive application of the original scheme
inapplicable and irrelevant. In the face of these challenges, we propose a
judiciously adapted, though natural, extension of the scheme, paving its way to
RF applications. While our extension leads to a different statistical analysis,
including extremes of non-Gaussian distributions, we show that, ultimately, its
asymptotic behavior is akin to the original scheme. We derive an exponentially
tight upper bound on its error probability, corroborate our results via
simulation experiments, and demonstrate the superior performance compared to
two benchmark approaches.",2024-12-24T10:42:01Z,http://arxiv.org/abs/2412.18334v1,"Amir Weiss, Yuval Kochman, Gregory W. Wornell"
"On K-stability of $\mathbb P^3$ blown up along a smooth genus $2$ curve
  of degree $5$","We prove K-stability for infinitely many smooth members of the family 2.19 of
the Mukai-Mori classification.",2024-12-24T10:06:10Z,http://arxiv.org/abs/2412.18317v1,"Tiago Duarte Guerreiro, Luca Giovenzana, Nivedita Viswanathan"
Data-Driven Self-Supervised Graph Representation Learning,"Self-supervised graph representation learning (SSGRL) is a representation
learning paradigm used to reduce or avoid manual labeling. An essential part of
SSGRL is graph data augmentation. Existing methods usually rely on heuristics
commonly identified through trial and error and are effective only within some
application domains. Also, it is not clear why one heuristic is better than
another. Moreover, recent studies have argued against some techniques (e.g.,
dropout: that can change the properties of molecular graphs or destroy relevant
signals for graph-based document classification tasks).
  In this study, we propose a novel data-driven SSGRL approach that
automatically learns a suitable graph augmentation from the signal encoded in
the graph (i.e., the nodes' predictive feature and topological information). We
propose two complementary approaches that produce learnable feature and
topological augmentations. The former learns multi-view augmentation of node
features, and the latter learns a high-order view of the topology. Moreover,
the augmentations are jointly learned with the representation. Our approach is
general that it can be applied to homogeneous and heterogeneous graphs. We
perform extensive experiments on node classification (using nine homogeneous
and heterogeneous datasets) and graph property prediction (using another eight
datasets). The results show that the proposed method matches or outperforms the
SOTA SSGRL baselines and performs similarly to semi-supervised methods. The
anonymised source code is available at https://github.com/AhmedESamy/dsgrl/",2024-12-24T10:04:19Z,http://arxiv.org/abs/2412.18316v1,"Ahmed E. Samy, Zekarias T. Kefatoa, Sarunas Girdzijauskasa"
Noether Symmetry Analysis for Generalized Brans-Dicke Cosmology,"We present the complete solution to the classification problem regarding the
variational symmetries of the generalized Brans-Dicke cosmological model in the
presence of a second scalar field minimally coupled to gravity and the
generalized Brans-Dicke scalar field theory. Through the symmetry analysis, we
were able to specify the functional form of the field equations such that they
become integrable. Additionally, new families of integrable cosmological models
are presented.",2024-12-24T09:54:13Z,http://arxiv.org/abs/2412.18311v1,Andronikos Paliathanasis
Modern Approach to 2D Conformal Field Theory,"The primary aim of these lecture notes is to introduce the modern approach to
two-dimensional conformal field theory (2D CFT). The study of analytical
methods in two-dimensional conformal field theory has developed over several
decades, starting with BPZ. The development of analytical methods, particularly
in rational conformal field theory (RCFT), has been remarkable, with complete
classifications achieved for certain model groups. One motivation for studying
CFT comes from its ability to describe quantum critical systems. Given that
realistic quantum critical systems are fundamentally RCFTs, it is somewhat
natural that the analytical methods of RCFT have evolved significantly.
  CFTs other than RCFTs are called irrational conformal field theories (ICFTs).
Compared to RCFTs, the study of ICFTs has not progressed as much. Putting aside
whether there is a physical motivation or not, ICFTs inherently possess a
difficulty that makes them challenging to approach. However, with the
development of quantum gravity, the advancement of analytical methods for ICFTs
has become essential. The reason lies in the AdS/CFT correspondence. AdS/CFT
refers to the relationship between $d+1$ dimensional quantum gravity and $d$
dimensional CFT. Within this correspondence, the CFT appears as a
non-perturbative formulation of quantum gravity. Except in special cases, this
CFT belongs to ICFT. Against this backdrop, the methods for ICFTs have rapidly
developed in recent years. Many of these ICFT methods are indispensable for
modern quantum gravity research. Unfortunately, they cannot be learned from
textbooks on 2D CFTs. These lecture notes aim to fill this gap. Specifically,
we will cover techniques that have already been applied in many studies, such
as {\it HHLL block} and {\it monodromy method}, and important results that have
become proper nouns, such as {\it Hellerman bound} and {\it HKS bound}.",2024-12-24T09:45:00Z,http://arxiv.org/abs/2412.18307v1,Yuya Kusuki
"Device-independent, high bit-rate quantum random number generator with
  beam-splitter-free architecture and live Bell test certification","We present a beam-splitter-free, high-bit rate, device-independent quantum
random number generator (DI-QRNG) with real-time quantumness certification via
live Bell test data. Using a 20-mm-long, type-0 phase-matched PPKTP crystal in
a polarization Sagnac interferometer, we generated degenerate, non-collinear
parametric down-converted entangled photons at 810 nm in an annular ring
distribution with pair photons appearing at diametrically opposite points on
the ring randomly. Dividing the ring into six sections and collecting photons
from opposite sections, we developed three entangled photon sources from a
single resource (optics, laser, and nonlinear crystal). Using a pump power of
12.4 mW at 405 nm, we recorded coincidence (1 ns window) timestamps of any two
sources without projection to assign random bits (0 and 1) while measuring the
Bell parameter (S $&gt;$ 2) with the third source for live quantumness
certification. We have generated 90 million raw bits in 46.4 seconds, with a
minimum entropy extraction ratio exceeding 97$\%$. Post-processed using a
Toeplitz matrix, the QRNG achieved a 1.8 Mbps bit rate, passing all NIST 800-22
and TestU01 tests. Increasing the coincidence window to 2 ns boosts the bit
rate to over 2 Mbps, maintaining minimum entropy above 95$\%$ but reducing the
Bell parameter to S = 1.73. This novel scalable scheme eliminates beam
splitters, enabling robust, multi-bit DI-QRNG with enhanced ring sectioning and
trustworthy certification for practical high-rate applications.",2024-12-24T08:43:54Z,http://arxiv.org/abs/2412.18285v1,"Ayan Kumar Nai, Vimlesh Kumar, G. K. Samanta"
"Improved Feature Generating Framework for Transductive Zero-shot
  Learning","Feature Generative Adversarial Networks have emerged as powerful generative
models in producing high-quality representations of unseen classes within the
scope of Zero-shot Learning (ZSL). This paper delves into the pivotal influence
of unseen class priors within the framework of transductive ZSL (TZSL) and
illuminates the finding that even a marginal prior bias can result in
substantial accuracy declines. Our extensive analysis uncovers that this
inefficacy fundamentally stems from the utilization of an unconditional unseen
discriminator - a core component in existing TZSL. We further establish that
the detrimental effects of this component are inevitable unless the generator
perfectly fits class-specific distributions. Building on these insights, we
introduce our Improved Feature Generation Framework, termed I-VAEGAN, which
incorporates two novel components: Pseudo-conditional Feature Adversarial (PFA)
learning and Variational Embedding Regression (VER). PFA circumvents the need
for prior estimation by explicitly injecting the predicted semantics as pseudo
conditions for unseen classes premised by precise semantic regression.
Meanwhile, VER utilizes reconstructive pre-training to learn class statistics,
obtaining better semantic regression. Our I-VAEGAN achieves state-of-the-art
TZSL accuracy across various benchmarks and priors. Our code would be released
upon acceptance.",2024-12-24T08:42:16Z,http://arxiv.org/abs/2412.18282v1,"Zihan Ye, Xinyuan Ru, Shiming Chen, Yaochu Jin, Kaizhu Huang, Xiaobo Jin"
"RaCMC: Residual-Aware Compensation Network with Multi-Granularity
  Constraints for Fake News Detection","Multimodal fake news detection aims to automatically identify real or fake
news, thereby mitigating the adverse effects caused by such misinformation.
Although prevailing approaches have demonstrated their effectiveness,
challenges persist in cross-modal feature fusion and refinement for
classification. To address this, we present a residual-aware compensation
network with multi-granularity constraints (RaCMC) for fake news detection,
that aims to sufficiently interact and fuse cross-modal features while
amplifying the differences between real and fake news. First, a multiscale
residual-aware compensation module is designed to interact and fuse features at
different scales, and ensure both the consistency and exclusivity of feature
interaction, thus acquiring high-quality features. Second, a multi-granularity
constraints module is implemented to limit the distribution of both the news
overall and the image-text pairs within the news, thus amplifying the
differences between real and fake news at the news and feature levels. Finally,
a dominant feature fusion reasoning module is developed to comprehensively
evaluate news authenticity from the perspectives of both consistency and
inconsistency. Experiments on three public datasets, including Weibo17,
Politifact and GossipCop, reveal the superiority of the proposed method.",2024-12-24T08:08:29Z,http://arxiv.org/abs/2412.18254v1,"Xinquan Yu, Ziqi Sheng, Wei Lu, Xiangyang Luo, Jiantao Zhou"
"An Improved Fault Diagnosis Strategy for Induction Motors Using Weighted
  Probability Ensemble Deep Learning","Early detection of faults in induction motors is crucial for ensuring
uninterrupted operations in industrial settings. Among the various fault types
encountered in induction motors, bearing, rotor, and stator faults are the most
prevalent. This paper introduces a Weighted Probability Ensemble Deep Learning
(WPEDL) methodology, tailored for effectively diagnosing induction motor faults
using high-dimensional data extracted from vibration and current features. The
Short-Time Fourier Transform (STFT) is employed to extract features from both
vibration and current signals. The performance of the WPEDL fault diagnosis
method is compared against conventional deep learning models, demonstrating the
superior efficacy of the proposed system. The multi-class fault diagnosis
system based on WPEDL achieves high accuracies across different fault types:
99.05% for bearing (vibrational signal), 99.10%, and 99.50% for rotor (current
and vibration signal), and 99.60%, and 99.52% for stator faults (current and
vibration signal) respectively. To evaluate the robustness of our multi-class
classification decisions, tests have been conducted on a combined dataset of
52,000 STFT images encompassing all three faults. Our proposed model
outperforms other models, achieving an accuracy of 98.89%. The findings
underscore the effectiveness and reliability of the WPEDL approach for
early-stage fault diagnosis in IMs, offering promising insights for enhancing
industrial operational efficiency and reliability.",2024-12-24T08:02:44Z,http://arxiv.org/abs/2412.18249v1,"Usman Ali, Waqas Ali, Umer Ramzan"
"Detection and Forecasting of Parkinson Disease Progression from Speech
  Signal Features Using MultiLayer Perceptron and LSTM","Accurate diagnosis of Parkinson disease, especially in its early stages, can
be a challenging task. The application of machine learning techniques helps
improve the diagnostic accuracy of Parkinson disease detection but only few
studies have presented work towards the prediction of disease progression. In
this research work, Long Short Term Memory LSTM was trained using the
diagnostic features on Parkinson patients speech signals, to predict the
disease progression while a Multilayer Perceptron MLP was trained on the same
diagnostic features to detect the disease. Diagnostic features selected using
two well-known feature selection methods named Relief-F and Sequential Forward
Selection and applied on LSTM and MLP have shown to accurately predict the
disease progression as stage 2 and 3 and its existence respectively.",2024-12-24T08:02:43Z,http://arxiv.org/abs/2412.18248v1,"Majid Ali, Hina Shakir, Asia Samreen, Sohaib Ahmed"
"Fréchet regression for multi-label feature selection with implicit
  regularization","Fr\'echet regression extends linear regression to model complex responses
  in metric spaces, making it particularly relevant for multi-label regression,
  where each instance can have multiple associated labels. However, variable
  selection within this framework remains underexplored. In this paper, we pro
pose a novel variable selection method that employs implicit regularization
  instead of traditional explicit regularization approaches, which can
introduce
  bias. Our method effectively captures nonlinear interactions between predic
tors and responses while promoting model sparsity. We provide theoretical
  results demonstrating selection consistency and illustrate the performance of
  our approach through numerical examples",2024-12-24T08:02:28Z,http://arxiv.org/abs/2412.18247v1,"Dou El Kefel Mansouri, Seif-Eddine Benkabou, Khalid Benabdeslem"
"Calculations of some doping nanostructurations and patterns improving
  the functionality of high-temperature superconductors for bolometer device
  applications","We calculate the effects of doping nanostructuration and the patterning of
thin films of high-temperature superconductors (HTS) with the aim of optimizing
their functionality as sensing materials for resistive transition-edge
bolometer devices (TES). We focus, in particular, on spatial variations of the
carrier doping into the CuO$_2$ layers due to oxygen off-stoichiometry, (that
induce, in turn, critical temperature variations) and explore following two
major cases of such structurations: First, the random nanoscale disorder
intrinsically associated to doping levels that do not maximize the
superconducting critical temperature; our studies suggest that this first
simple structuration already improves some of the bolometric operational
parameters with respect to the conventional, nonstructured HTS materials used
until now. Secondly, we consider the imposition of regular arrangements of
zones with different nominal doping levels (patterning); we find that such
regular patterns may improve the bolometer performance even further. We find
one design that improves, with respect to nonstructured HTS materials, both the
saturation power and the operating temperature width by more than one order of
magnitude. It also almost doubles the response of the sensor to radiation.",2024-12-24T07:51:28Z,http://arxiv.org/abs/2412.18240v1,"J. C. Verde, A. S. Viz, M. M. Botana, C. Montero-Orille, M. V. Ramallo"
"OMG-HD: A High-Resolution AI Weather Model for End-to-End Forecasts from
  Observations","In recent years, Artificial Intelligence Weather Prediction (AIWP) models
have achieved performance comparable to, or even surpassing, traditional
Numerical Weather Prediction (NWP) models by leveraging reanalysis data.
However, a less-explored approach involves training AIWP models directly on
observational data, enhancing computational efficiency and improving forecast
accuracy by reducing the uncertainties introduced through data assimilation
processes. In this study, we propose OMG-HD, a novel AI-based regional
high-resolution weather forecasting model designed to make predictions directly
from observational data sources, including surface stations, radar, and
satellite, thereby removing the need for operational data assimilation. Our
evaluation shows that OMG-HD outperforms both the European Centre for
Medium-Range Weather Forecasts (ECMWF)'s high-resolution operational
forecasting system, IFS-HRES, and the High-Resolution Rapid Refresh (HRRR)
model at lead times of up to 12 hours across the contiguous United States
(CONUS) region. We achieve up to a 13% improvement on RMSE for 2-meter
temperature, 17% on 10-meter wind speed, 48% on 2-meter specific humidity, and
32% on surface pressure compared to HRRR. Our method shows that it is possible
to use AI-driven approaches for rapid weather predictions without relying on
NWP-derived weather fields as model input. This is a promising step towards
using observational data directly to make operational forecasts with AIWP
models.",2024-12-24T07:46:50Z,http://arxiv.org/abs/2412.18239v1,"Pengcheng Zhao, Jiang Bian, Zekun Ni, Weixin Jin, Jonathan Weyn, Zuliang Fang, Siqi Xiang, Haiyu Dong, Bin Zhang, Hongyu Sun, Kit Thambiratnam, Qi Zhang"
"Lensless speckle reconstructive spectrometer via physics-aware neural
  network","The speckle field yielded by disordered media is extensively employed for
spectral measurements. Existing speckle reconstructive spectrometers (RSs)
implemented by neural networks primarily rely on supervised learning, which
necessitates large-scale spectra-speckle pairs. However, beyond system
stability requirements for prolonged data collection, generating diverse
spectra with high resolution and finely labeling them is particularly
difficult. A lack of variety in datasets hinders the generalization of neural
networks to new spectrum types. Here we avoid this limitation by introducing
PhyspeNet, an untrained spectrum reconstruction framework combining a
convolutional neural network (CNN) with a physical model of a chaotic optical
cavity. Without pre-training and prior knowledge about the spectrum under test,
PhyspeNet requires only a single captured speckle for various multi-wavelength
reconstruction tasks. Experimentally, we demonstrate a lens-free, snapshot RS
system by leveraging the one-to-many mapping between spatial and spectrum
domains in a random medium. Dual-wavelength peaks separated by 2 pm can be
distinguished, and a maximum working bandwidth of 40 nm is achieved with high
measurement accuracy. This approach establishes a new paradigm for neural
network-based RS systems, entirely eliminating reliance on datasets while
ensuring that computational results exhibit a high degree of generalizability
and physical explainability.",2024-12-24T07:45:43Z,http://arxiv.org/abs/2412.18238v1,"Junrui Liang, Min Jiang, Zhongming Huang, Junhong He, Yanting Guo, Yanzhao Ke, Jun Ye, Jiangming Xu, Jun Li, Jinyong Leng, Pu Zhou"
"Band Prompting Aided SAR and Multi-Spectral Data Fusion Framework for
  Local Climate Zone Classification","Local climate zone (LCZ) classification is of great value for understanding
the complex interactions between urban development and local climate. Recent
studies have increasingly focused on the fusion of synthetic aperture radar
(SAR) and multi-spectral data to improve LCZ classification performance.
However, it remains challenging due to the distinct physical properties of
these two types of data and the absence of effective fusion guidance. In this
paper, a novel band prompting aided data fusion framework is proposed for LCZ
classification, namely BP-LCZ, which utilizes textual prompts associated with
band groups to guide the model in learning the physical attributes of different
bands and semantics of various categories inherent in SAR and multi-spectral
data to augment the fused feature, thus enhancing LCZ classification
performance. Specifically, a band group prompting (BGP) strategy is introduced
to align the visual representation effectively at the level of band groups,
which also facilitates a more adequate extraction of semantic information of
different bands with textual information. In addition, a multivariate
supervised matrix (MSM) based training strategy is proposed to alleviate the
problem of positive and negative sample confusion by completing the supervised
information. The experimental results demonstrate the effectiveness and
superiority of the proposed data fusion framework.",2024-12-24T07:40:07Z,http://arxiv.org/abs/2412.18235v1,"Haiyan Lan, Shujun Li, Mingjie Xie, Xuanjia Zhao, Hongning Liu, Pengming Feng, Dongli Xu, Guangjun He, Jian Guan"
Towards Macro-AUC oriented Imbalanced Multi-Label Continual Learning,"In Continual Learning (CL), while existing work primarily focuses on the
multi-class classification task, there has been limited research on Multi-Label
Learning (MLL). In practice, MLL datasets are often class-imbalanced, making it
inherently challenging, a problem that is even more acute in CL. Due to its
sensitivity to imbalance, Macro-AUC is an appropriate and widely used measure
in MLL. However, there is no research to optimize Macro-AUC in MLCL
specifically. To fill this gap, in this paper, we propose a new memory
replay-based method to tackle the imbalance issue for Macro-AUC-oriented MLCL.
Specifically, inspired by recent theory work, we propose a new Reweighted
Label-Distribution-Aware Margin (RLDAM) loss. Furthermore, to be compatible
with the RLDAM loss, a new memory-updating strategy named Weight Retain
Updating (WRU) is proposed to maintain the numbers of positive and negative
instances of the original dataset in memory. Theoretically, we provide superior
generalization analyses of the RLDAM-based algorithm in terms of Macro-AUC,
separately in batch MLL and MLCL settings. This is the first work to offer
theoretical generalization analyses in MLCL to our knowledge. Finally, a series
of experimental results illustrate the effectiveness of our method over several
baselines. Our codes are available at
https://github.com/ML-Group-SDU/Macro-AUC-CL.",2024-12-24T07:30:20Z,http://arxiv.org/abs/2412.18231v1,"Yan Zhang, Guoqiang Wu, Bingzheng Wang, Teng Pang, Haoliang Sun, Yilong Yin"
"Leveraging Convolutional Neural Network-Transformer Synergy for
  Predictive Modeling in Risk-Based Applications","With the development of the financial industry, credit default prediction, as
an important task in financial risk management, has received increasing
attention. Traditional credit default prediction methods mostly rely on machine
learning models, such as decision trees and random forests, but these methods
have certain limitations in processing complex data and capturing potential
risk patterns. To this end, this paper proposes a deep learning model based on
the combination of convolutional neural networks (CNN) and Transformer for
credit user default prediction. The model combines the advantages of CNN in
local feature extraction with the ability of Transformer in global dependency
modeling, effectively improving the accuracy and robustness of credit default
prediction. Through experiments on public credit default datasets, the results
show that the CNN+Transformer model outperforms traditional machine learning
models, such as random forests and XGBoost, in multiple evaluation indicators
such as accuracy, AUC, and KS value, demonstrating its powerful ability in
complex financial data modeling. Further experimental analysis shows that
appropriate optimizer selection and learning rate adjustment play a vital role
in improving model performance. In addition, the ablation experiment of the
model verifies the advantages of the combination of CNN and Transformer and
proves the complementarity of the two in credit default prediction. This study
provides a new idea for credit default prediction and provides strong support
for risk assessment and intelligent decision-making in the financial field.
Future research can further improve the prediction effect and generalization
ability by introducing more unstructured data and improving the model
architecture.",2024-12-24T07:07:14Z,http://arxiv.org/abs/2412.18222v1,"Yuhan Wang, Zhen Xu, Yue Yao, Jinsong Liu, Jiating Lin"
"ICM-Assistant: Instruction-tuning Multimodal Large Language Models for
  Rule-based Explainable Image Content Moderation","Controversial contents largely inundate the Internet, infringing various
cultural norms and child protection standards. Traditional Image Content
Moderation (ICM) models fall short in producing precise moderation decisions
for diverse standards, while recent multimodal large language models (MLLMs),
when adopted to general rule-based ICM, often produce classification and
explanation results that are inconsistent with human moderators. Aiming at
flexible, explainable, and accurate ICM, we design a novel rule-based dataset
generation pipeline, decomposing concise human-defined rules and leveraging
well-designed multi-stage prompts to enrich short explicit image annotations.
Our ICM-Instruct dataset includes detailed moderation explanation and
moderation Q-A pairs. Built upon it, we create our ICM-Assistant model in the
framework of rule-based ICM, making it readily applicable in real practice. Our
ICM-Assistant model demonstrates exceptional performance and flexibility.
Specifically, it significantly outperforms existing approaches on various
sources, improving both the moderation classification (36.8\% on average) and
moderation explanation quality (26.6\% on average) consistently over existing
MLLMs. Code/Data is available at https://github.com/zhaoyuzhi/ICM-Assistant.",2024-12-24T06:45:36Z,http://arxiv.org/abs/2412.18216v1,"Mengyang Wu, Yuzhi Zhao, Jialun Cao, Mingjie Xu, Zhongming Jiang, Xuehui Wang, Qinbin Li, Guangneng Hu, Shengchao Qin, Chi-Wing Fu"
"Relative Alpha in the Magneto-Hydro-Dynamics (MHD) with open magnetic
  field boundary and its application to the solar eruption","An instability criterion in the MHD with the open boundary of magnetic field
is proposed in this paper. We use a series of linear force-free extrapolation
field, in which the normal part of magnetic field is fixed, to obtain the
linear fitting coefficient called relative alpha by using the co-joined value
of magnetic free energy and magnetic flux at the open boundary ($E_f \Phi ^2$)
and the square of relative magnetic helicity ($H_R^2$). We calculate this
coefficient of the magnetic field above active regions NOAA~8210 and NOAA~11429
obtained by the photospheric-data-driven magnetohydrodynamics (MHD) model. It
is found that the fitting coefficient is a good proxy of the criterion to
indicate the occurrence of instability after which the magnetic reconnection
happens and caused the fast release of magnetic energy. We also applied this
method to the continuous evolution of three-dimension magnetic field of
NOAA~11158 based on the measurement of photospheric vector magnetic field of
SDO/HMI by the Non-linear Force-Free (NLFF) extrapolation method. The
calculated coefficient when the major flare happened based on the extrapolation
data is very close to the expected ones, which perfectly reflects the
occurrence of instability and the difference is even less than 7\%. This
relative alpha is very helpful to evaluate how far it is from the instability
in the MHD and quantitatively estimate the occurrence of solar eruption in the
space weather forecast.",2024-12-24T06:35:30Z,http://arxiv.org/abs/2412.18210v1,"Shangbin Yang, Joerg Buechner, Jean Carlo Santos, Jan Skala, Hongqi Zhang"
BoxMAC -- A Boxing Dataset for Multi-label Action Classification,"In competitive combat sports like boxing, analyzing a boxers's performance
statics is crucial for evaluating the quantity and variety of punches delivered
during bouts. These statistics provide valuable data and feedback, which are
routinely used for coaching and performance enhancement. We introduce BoxMAC, a
real-world boxing dataset featuring 15 professional boxers and encompassing 13
distinct action labels. Comprising over 60,000 frames, our dataset has been
meticulously annotated for multiple actions per frame with inputs from a boxing
coach. Since two boxers can execute different punches within a single
timestamp, this problem falls under the domain of multi-label action
classification. We propose a novel architecture for jointly recognizing
multiple actions in both individual images and videos. We investigate baselines
using deep neural network architectures to address both tasks. We believe that
BoxMAC will enable researchers and practitioners to develop and evaluate more
efficient models for performance analysis. With its realistic and diverse
nature, BoxMAC can serve as a valuable resource for the advancement of boxing
as a sport",2024-12-24T06:20:01Z,http://arxiv.org/abs/2412.18204v1,Shashikanta Sahoo
"Developing Cryptocurrency Trading Strategy Based on Autoencoder-CNN-GANs
  Algorithms","This paper leverages machine learning algorithms to forecast and analyze
financial time series. The process begins with a denoising autoencoder to
filter out random noise fluctuations from the main contract price data. Then,
one-dimensional convolution reduces the dimensionality of the filtered data and
extracts key information. The filtered and dimensionality-reduced price data is
fed into a GANs network, and its output serve as input of a fully connected
network. Through cross-validation, a model is trained to capture features that
precede large price fluctuations. The model predicts the likelihood and
direction of significant price changes in real-time price sequences, placing
trades at moments of high prediction accuracy. Empirical results demonstrate
that using autoencoders and convolution to filter and denoise financial data,
combined with GANs, achieves a certain level of predictive performance,
validating the capabilities of machine learning algorithms to discover
underlying patterns in financial sequences. Keywords - CNN;GANs;
Cryptocurrency; Prediction.",2024-12-24T06:14:34Z,http://arxiv.org/abs/2412.18202v2,"Zhuohuan Hu, Richard Yu, Zizhou Zhang, Haoran Zheng, Qianying Liu, Yining Zhou"
"VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics
  Manipulation with Long-Horizon Reasoning Tasks","General-purposed embodied agents are designed to understand the users'
natural instructions or intentions and act precisely to complete universal
tasks. Recently, methods based on foundation models especially
Vision-Language-Action models (VLAs) have shown a substantial potential to
solve language-conditioned manipulation (LCM) tasks well. However, existing
benchmarks do not adequately meet the needs of VLAs and relative algorithms. To
better define such general-purpose tasks in the context of LLMs and advance the
research in VLAs, we present VLABench, an open-source benchmark for evaluating
universal LCM task learning. VLABench provides 100 carefully designed
categories of tasks, with strong randomization in each category of task and a
total of 2000+ objects. VLABench stands out from previous benchmarks in four
key aspects: 1) tasks requiring world knowledge and common sense transfer, 2)
natural language instructions with implicit human intentions rather than
templates, 3) long-horizon tasks demanding multi-step reasoning, and 4)
evaluation of both action policies and language model capabilities. The
benchmark assesses multiple competencies including understanding of
mesh\&amp;texture, spatial relationship, semantic instruction, physical laws,
knowledge transfer and reasoning, etc. To support the downstream finetuning, we
provide high-quality training data collected via an automated framework
incorporating heuristic skills and prior information. The experimental results
indicate that both the current state-of-the-art pretrained VLAs and the
workflow based on VLMs face challenges in our tasks.",2024-12-24T06:03:42Z,http://arxiv.org/abs/2412.18194v1,"Shiduo Zhang, Zhe Xu, Peiju Liu, Xiaopeng Yu, Yuan Li, Qinghui Gao, Zhaoye Fei, Zhangyue Yin, Zuxuan Wu, Yu-Gang Jiang, Xipeng Qiu"
"On the Applicability of Zero-Shot Cross-Lingual Transfer Learning for
  Sentiment Classification in Distant Language Pairs","This research explores the applicability of cross-lingual transfer learning
from English to Japanese and Indonesian using the XLM-R pre-trained model. The
results are compared with several previous works, either by models using a
similar zero-shot approach or a fully-supervised approach, to provide an
overview of the zero-shot transfer learning approach's capability using XLM-R
in comparison with existing models. Our models achieve the best result in one
Japanese dataset and comparable results in other datasets in Japanese and
Indonesian languages without being trained using the target language.
Furthermore, the results suggest that it is possible to train a multi-lingual
model, instead of one model for each language, and achieve promising results.",2024-12-24T05:50:18Z,http://arxiv.org/abs/2412.18188v1,"Andre Rusli, Makoto Shishido"
"PCM Selector: Penalized Covariate-Mediator Selection Operator for
  Evaluating Linear Causal Effects","For a data-generating process for random variables that can be described with
a linear structural equation model, we consider a situation in which (i) a set
of covariates satisfying the back-door criterion cannot be observed or (ii)
such a set can be observed, but standard statistical estimation methods cannot
be applied to estimate causal effects because of
multicollinearity/high-dimensional data problems. We propose a novel two-stage
penalized regression approach, the penalized covariate-mediator selection
operator (PCM Selector), to estimate the causal effects in such scenarios.
Unlike existing penalized regression analyses, when a set of intermediate
variables is available, PCM Selector provides a consistent or less biased
estimator of the causal effect. In addition, PCM Selector provides a variable
selection procedure for intermediate variables to obtain better estimation
accuracy of the causal effects than does the back-door criterion.",2024-12-24T05:34:05Z,http://arxiv.org/abs/2412.18180v1,"Hisayoshi Nanmo, Manabu Kuroki"
VisionGRU: A Linear-Complexity RNN Model for Efficient Image Analysis,"Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) are two
dominant models for image analysis. While CNNs excel at extracting multi-scale
features and ViTs effectively capture global dependencies, both suffer from
high computational costs, particularly when processing high-resolution images.
Recently, state-space models (SSMs) and recurrent neural networks (RNNs) have
attracted attention due to their efficiency. However, their performance in
image classification tasks remains limited. To address these challenges, this
paper introduces VisionGRU, a novel RNN-based architecture designed for
efficient image classification. VisionGRU leverages a simplified Gated
Recurrent Unit (minGRU) to process large-scale image features with linear
complexity. It divides images into smaller patches and progressively reduces
the sequence length while increasing the channel depth, thus facilitating
multi-scale feature extraction. A hierarchical 2DGRU module with bidirectional
scanning captures both local and global contexts, improving long-range
dependency modeling, particularly for tasks like semantic segmentation.
Experimental results on the ImageNet and ADE20K datasets demonstrate that
VisionGRU outperforms ViTs, significantly reducing memory usage and
computational costs, especially for high-resolution images. These findings
underscore the potential of RNN-based approaches for developing efficient and
scalable computer vision solutions. Codes will be available at
https://github.com/YangLiu9208/VisionGRU.",2024-12-24T05:27:11Z,http://arxiv.org/abs/2412.18178v2,"Shicheng Yin, Kaixuan Yin, Weixing Chen, Enbo Huang, Yang Liu"
"Unlocking the Hidden Treasures: Enhancing Recommendations with Unlabeled
  Data","Collaborative filtering (CF) stands as a cornerstone in recommender systems,
yet effectively leveraging the massive unlabeled data presents a significant
challenge. Current research focuses on addressing the challenge of unlabeled
data by extracting a subset that closely approximates negative samples.
Regrettably, the remaining data are overlooked, failing to fully integrate this
valuable information into the construction of user preferences. To address this
gap, we introduce a novel positive-neutral-negative (PNN) learning paradigm.
PNN introduces a neutral class, encompassing intricate items that are
challenging to categorize directly as positive or negative samples. By training
a model based on this triple-wise partial ranking, PNN offers a promising
solution to learning complex user preferences. Through theoretical analysis, we
connect PNN to one-way partial AUC (OPAUC) to validate its efficacy.
Implementing the PNN paradigm is, however, technically challenging because: (1)
it is difficult to classify unlabeled data into neutral or negative in the
absence of supervised signals; (2) there does not exist any loss function that
can handle set-level triple-wise ranking relationships. To address these
challenges, we propose a semi-supervised learning method coupled with a
user-aware attention model for knowledge acquisition and classification
refinement. Additionally, a novel loss function with a two-step centroid
ranking approach enables handling set-level rankings. Extensive experiments on
four real-world datasets demonstrate that, when combined with PNN, a wide range
of representative CF models can consistently and significantly boost their
performance. Even with a simple matrix factorization, PNN can achieve
comparable performance to sophisticated graph neutral networks.",2024-12-24T05:07:55Z,http://arxiv.org/abs/2412.18170v1,"Yuhan Zhao, Rui Chen, Qilong Han, Hongtao Song, Li Chen"
"From Pairwise to Ranking: Climbing the Ladder to Ideal Collaborative
  Filtering with Pseudo-Ranking","Intuitively, an ideal collaborative filtering (CF) model should learn from
users' full rankings over all items to make optimal top-K recommendations. Due
to the absence of such full rankings in practice, most CF models rely on
pairwise loss functions to approximate full rankings, resulting in an immense
performance gap. In this paper, we provide a novel analysis using the multiple
ordinal classification concept to reveal the inevitable gap between a pairwise
approximation and the ideal case. However, bridging the gap in practice
encounters two formidable challenges: (1) none of the real-world datasets
contains full ranking information; (2) there does not exist a loss function
that is capable of consuming ranking information. To overcome these challenges,
we propose a pseudo-ranking paradigm (PRP) that addresses the lack of ranking
information by introducing pseudo-rankings supervised by an original noise
injection mechanism. Additionally, we put forward a new ranking loss function
designed to handle ranking information effectively. To ensure our method's
robustness against potential inaccuracies in pseudo-rankings, we equip the
ranking loss function with a gradient-based confidence mechanism to detect and
mitigate abnormal gradients. Extensive experiments on four real-world datasets
demonstrate that PRP significantly outperforms state-of-the-art methods.",2024-12-24T05:01:16Z,http://arxiv.org/abs/2412.18168v1,"Yuhan Zhao, Rui Chen, Li Chen, Shuang Zhang, Qilong Han, Hongtao Song"
"Accelerating Post-Tornado Disaster Assessment Using Advanced Deep
  Learning Models","Post-disaster assessments of buildings and infrastructure are crucial for
both immediate recovery efforts and long-term resilience planning. This
research introduces an innovative approach to automating post-disaster
assessments through advanced deep learning models. Our proposed system employs
state-of-the-art computer vision techniques (YOLOv11 and ResNet50) to rapidly
analyze images and videos from disaster sites, extracting critical information
about building characteristics, including damage level of structural components
and the extent of damage. Our experimental results show promising performance,
with ResNet50 achieving 90.28% accuracy and an inference time of 1529ms per
image on multiclass damage classification. This study contributes to the field
of disaster management by offering a scalable, efficient, and objective tool
for post-disaster analysis, potentially capable of transforming how communities
and authorities respond to and learn from catastrophic events.",2024-12-24T04:04:33Z,http://arxiv.org/abs/2412.18147v1,"Robinson Umeike, Thang Dao, Shane Crawford"
"Supervised centrality Cvia sparse network influence regression: an
  application to the 2021 henan floods' social network","The social characteristics of players in a social network are closely
associated with their network positions and relational importance. Identifying
those influential players in a network is of great importance as it helps to
understand how ties are formed, how information is propagated, and, in turn,
can guide the dissemination of new information. Motivated by a Sina Weibo
social network analysis of the 2021 Henan Floods, where response variables for
each Sina Weibo user are available, we propose a new notion of supervised
centrality that emphasizes the task-specific nature of a player's centrality.
To estimate the supervised centrality and identify important players, we
develop a novel sparse network influence regression by introducing individual
heterogeneity for each user. To overcome the computational difficulties in
fitting the model for large social networks, we further develop a
forward-addition algorithm and show that it can consistently identify a
superset of the influential Sina Weibo users. We apply our method to analyze
three responses in the Henan Floods data: the number of comments, reposts, and
likes, and obtain meaningful results. A further simulation study corroborates
the developed method.",2024-12-24T04:00:44Z,http://arxiv.org/abs/2412.18145v1,"Yingying Ma, Wei Lan, Chenlei Leng, Ting Li, Hansheng Wang"
Neural Conformal Control for Time Series Forecasting,"We introduce a neural network conformal prediction method for time series
that enhances adaptivity in non-stationary environments. Our approach acts as a
neural controller designed to achieve desired target coverage, leveraging
auxiliary multi-view data with neural network encoders in an end-to-end manner
to further enhance adaptivity. Additionally, our model is designed to enhance
the consistency of prediction intervals in different quantiles by integrating
monotonicity constraints and leverages data from related tasks to boost
few-shot learning performance. Using real-world datasets from epidemics,
electric demand, weather, and others, we empirically demonstrate significant
improvements in coverage and probabilistic accuracy, and find that our method
is the only one that combines good calibration with consistency in prediction
intervals.",2024-12-24T03:56:25Z,http://arxiv.org/abs/2412.18144v1,"Ruipu Li, Alexander Rodríguez"
"An Instrumental Value for Data Production and its Application to Data
  Pricing","How much value does a dataset or a data production process have to an agent
who wishes to use the data to assist decision-making? This is a fundamental
question towards understanding the value of data as well as further pricing of
data. This paper develops an approach for capturing the instrumental value of
data production processes, which takes two key factors into account: (a) the
context of the agent's decision-making problem; (b) prior data or information
the agent already possesses. We ''micro-found'' our valuation concepts by
showing how they connect to classic notions of information design and signals
in information economics. When instantiated in the domain of Bayesian linear
regression, our value naturally corresponds to information gain. Based on our
designed data value, we then study a basic monopoly pricing setting with a
buyer looking to purchase from a seller some labeled data of a certain feature
direction in order to improve a Bayesian regression model. We show that when
the seller has the ability to fully customize any data request, she can extract
the first-best revenue (i.e., full surplus) from any population of buyers,
i.e., achieving first-degree price discrimination. If the seller can only sell
data that are derived from an existing data pool, this limits her ability to
customize, and achieving first-best revenue becomes generally impossible.
However, we design a mechanism that achieves seller revenue at most $\log
(\kappa)$ less than the first-best revenue, where $\kappa$ is the condition
number associated with the data matrix. A corollary of this result is that the
seller can extract the first-best revenue in the multi-armed bandits special
case.",2024-12-24T03:53:57Z,http://arxiv.org/abs/2412.18140v1,"Rui Ai, Boxiang Lyu, Zhaoran Wang, Zhuoran Yang, Haifeng Xu"
Learning Randomized Reductions and Program Properties,"The correctness of computations remains a significant challenge in computer
science, with traditional approaches relying on automated testing or formal
verification. Self-testing/correcting programs introduce an alternative
paradigm, allowing a program to verify and correct its own outputs via
randomized reductions, a concept that previously required manual derivation. In
this paper, we present Bitween, a method and tool for automated learning of
randomized (self)-reductions and program properties in numerical programs.
Bitween combines symbolic analysis and machine learning, with a surprising
finding: polynomial-time linear regression, a basic optimization method, is not
only sufficient but also highly effective for deriving complex randomized
self-reductions and program invariants, often outperforming sophisticated
mixed-integer linear programming solvers. We establish a theoretical framework
for learning these reductions and introduce RSR-Bench, a benchmark suite for
evaluating Bitween's capabilities on scientific and machine learning functions.
Our empirical results show that Bitween surpasses state-of-the-art tools in
scalability, stability, and sample efficiency when evaluated on nonlinear
invariant benchmarks like NLA-DigBench. Bitween is open-source as a Python
package and accessible via a web interface that supports C language programs.",2024-12-24T03:42:53Z,http://arxiv.org/abs/2412.18134v1,"Ferhat Erata, Orr Paradise, Timos Antonopoulos, ThanhVu Nguyen, Shafi Goldwasser, Ruzica Piskac"
"Age Optimal Sampling for Unreliable Channels under Unknown Channel
  Statistics","In this paper, we study a system in which a sensor forwards status updates to
a receiver through an error-prone channel, while the receiver sends the
transmission results back to the sensor via a reliable channel. Both channels
are subject to random delays. To evaluate the timeliness of the status
information at the receiver, we use the Age of Information (AoI) metric. The
objective is to design a sampling policy that minimizes the expected
time-average AoI, even when the channel statistics (e.g., delay distributions)
are unknown. We first review the threshold structure of the optimal offline
policy under known channel statistics and then reformulate the design of the
online algorithm as a stochastic approximation problem. We propose a
Robbins-Monro algorithm to solve this problem and demonstrate that the optimal
threshold can be approximated almost surely. Moreover, we prove that the
cumulative AoI regret of the online algorithm increases with rate
$\mathcal{O}(\ln K)$, where $K$ is the number of successful transmissions. In
addition, our algorithm is shown to be minimax order optimal, in the sense that
for any online learning algorithm, the cumulative AoI regret up to the $K$-th
successful transmissions grows with the rate at least $\Omega(\ln K)$ in the
worst case delay distribution. Finally, we improve the stability of the
proposed online learning algorithm through a momentum-based stochastic gradient
descent algorithm. Simulation results validate the performance of our proposed
algorithm.",2024-12-24T03:06:22Z,http://arxiv.org/abs/2412.18119v1,"Hongyi He, Haoyue Tang, Jiayu Pan, Jintao Wang, Jian Song, Leandros Tassiulas"
The EnvDesign Model: A Method to Solve the Environment Design Problem,"Today, several people and organizations rely on cloud platforms. The
reliability of cloud platforms depends heavily on the performance of their
internal programs (agents). To better prevent regressions in cloud platforms,
the design of pre-production testing environments (that test new agents, new
hardwares, and other changes) must take into account the diversity of
server/node properties (hardware model, virtual machine type, etc.) across the
fleet and dynamically emphasize or de-emphasize the prevalence of certain node
properties based on current testing priorities. This paper formulates this task
as the ""environment design"" problem and presents the EnvDesign model, a method
that uses graph theory and optimization algorithms to solve the environment
design problem. The EnvDesign model was built on context and techniques that
apply to combinatorial testing in general, so it can support combinatorial
testing in other domains.",2024-12-24T02:45:12Z,http://arxiv.org/abs/2412.18109v1,"Akshay Sathiya, Rohit Pandey"
"Beyond the Known: Enhancing Open Set Domain Adaptation with Unknown
  Exploration","Convolutional neural networks (CNNs) can learn directly from raw data,
resulting in exceptional performance across various research areas. However,
factors present in non-controllable environments such as unlabeled datasets
with varying levels of domain and category shift can reduce model accuracy. The
Open Set Domain Adaptation (OSDA) is a challenging problem that arises when
both of these issues occur together. Existing OSDA approaches in literature
only align known classes or use supervised training to learn unknown classes as
a single new category. In this work, we introduce a new approach to improve
OSDA techniques by extracting a set of high-confidence unknown instances and
using it as a hard constraint to tighten the classification boundaries.
Specifically, we use a new loss constraint that is evaluated in three different
ways: (1) using pristine negative instances directly; (2) using data
augmentation techniques to create randomly transformed negatives; and (3) with
generated synthetic negatives containing adversarial features. We analyze
different strategies to improve the discriminator and the training of the
Generative Adversarial Network (GAN) used to generate synthetic negatives. We
conducted extensive experiments and analysis on OVANet using three widely-used
public benchmarks, the Office-31, Office-Home, and VisDA datasets. We were able
to achieve similar H-score to other state-of-the-art methods, while increasing
the accuracy on unknown categories.",2024-12-24T02:27:35Z,http://arxiv.org/abs/2412.18105v1,"Lucas Fernando Alvarenga e Silva, Samuel Felipe dos Santos, Nicu Sebe, Jurandy Almeida"
"An Attention-based Framework with Multistation Information for
  Earthquake Early Warnings","Earthquake early warning systems play crucial roles in reducing the risk of
seismic disasters. Previously, the dominant modeling system was the
single-station models. Such models digest signal data received at a given
station and predict earth-quake parameters, such as the p-phase arrival time,
intensity, and magnitude at that location. Various methods have demonstrated
adequate performance. However, most of these methods present the challenges of
the difficulty of speeding up the alarm time, providing early warning for
distant areas, and considering global information to enhance performance.
Recently, deep learning has significantly impacted many fields, including
seismology. Thus, this paper proposes a deep learning-based framework, called
SENSE, for the intensity prediction task of earthquake early warning systems.
To explicitly consider global information from a regional or national
perspective, the input to SENSE comprises statistics from a set of stations in
a given region or country. The SENSE model is designed to learn the
relationships among the set of input stations and the locality-specific
characteristics of each station. Thus, SENSE is not only expected to provide
more reliable forecasts by considering multistation data but also has the
ability to provide early warnings to distant areas that have not yet received
signals. This study conducted extensive experiments on datasets from Taiwan and
Japan. The results revealed that SENSE can deliver competitive or even better
performances compared with other state-of-the-art methods.",2024-12-24T02:18:17Z,http://arxiv.org/abs/2412.18099v1,"Yu-Ming Huang, Kuan-Yu Chen, Wen-Wei Lin, Da-Yi Chen"
LangYa: Revolutionizing Cross-Spatiotemporal Ocean Forecasting,"Ocean forecasting is crucial for both scientific research and societal
benefits. Currently, the most accurate forecasting systems are global ocean
forecasting systems (GOFSs), which represent the ocean state variables (OSVs)
as discrete grids and solve partial differential equations (PDEs) governing the
transitions of oceanic state variables using numerical methods. However, GOFSs
processes are computationally expensive and prone to cumulative errors.
Recently, large artificial intelligence (AI)-based models significantly boosted
forecasting speed and accuracy. Unfortunately, building a large AI ocean
forecasting system that can be considered cross-spatiotemporal and air-sea
coupled forecasts remains a significant challenge. Here, we introduce LangYa, a
cross-spatiotemporal and air-sea coupled ocean forecasting system. Results
demonstrate that the time embedding module in LangYa enables a single model to
make forecasts with lead times ranging from 1 to 7 days. The air-sea coupled
module effectively simulates air-sea interactions. The ocean self-attention
module improves network stability and accelerates convergence during training,
and the adaptive thermocline loss function improves the accuracy of thermocline
forecasting. Compared to existing numerical and AI-based ocean forecasting
systems, LangYa uses 27 years of global ocean data from the Global Ocean
Reanalysis and Simulation version 12 (GLORYS12) for training and achieves more
reliable deterministic forecasting results for OSVs. LangYa forecasting system
provides global ocean researchers with access to a powerful software tool for
accurate ocean forecasting and opens a new paradigm for ocean science.",2024-12-24T02:14:39Z,http://arxiv.org/abs/2412.18097v2,"Nan Yang, Chong Wang, Meihua Zhao, Zimeng Zhao, Huiling Zheng, Bin Zhang, Jianing Wang, Xiaofeng Li"
Finite groups whose subgroup graph contains a vertex of large degree,"T.C. Burness and S.D. Scott \cite{3} classified finite groups $G$ such that
the number of prime order subgroups of $G$ is greater than $|G|/2-1$. In this
note, we study finite groups $G$ whose subgroup graph contains a vertex of
degree greater than $|G|/2-1$. The classification given for finite solvable
groups extends the work of Burness and Scott.",2024-12-24T01:58:40Z,http://arxiv.org/abs/2412.18087v1,Marius Tărnăuceanu
"Light rings and shadows of static black holes in effective quantum
  gravity II: A new solution without Cauchy horizons","Among the three known types of static solutions proposed within the
Hamiltonian constraint approach to effective quantum gravity (EQG), the first
two have been extensively investigated, whereas the third type-which preserves
general covariance, is free of Cauchy horizons, and was only recently
obtained-remains relatively unexplored. This solution can describe a black hole
with an event horizon for certain parameter ranges, or a horizonless compact
object beyond those ranges. In this paper, we focus on the third type and show
that its light rings feature both stable and unstable branches, and that the
black hole shadow size grows with the quantum parameter-unlike in the first two
types. However, when we account for both the shadow and the lensing ring, the
overall behavior closely resembles that of the second type, in which an
increasing quantum parameter leads to a larger portion of the lensing ring
being occupied by the shadow. This feature can serve as a hallmark of black
holes in EQG, offering a potential way to distinguish them from their GR
counterparts. Remarkably, the parameter ranges under which the solution remains
a black hole are highly consistent with the current observational constraints
on black hole shadows, lending strong support to the classification of the
third type of compact object in EQG as a black hole endowed with an event
horizon.",2024-12-24T01:44:25Z,http://arxiv.org/abs/2412.18083v1,"Wentao Liu, Di Wu, Jieci Wang"
